<!DOCTYPE html><html xmlns:dc="http://purl.org/dc/terms/" itemscope itemtype="http://schema.org/Article"><head><meta http-equiv=Content-Type content="text/html; charset=utf-8"><title>A Note on Randomness Extraction</title><meta name="citation_title" content="A Note on Randomness Extraction"><meta name="og:title" content="A Note on Randomness Extraction"><meta name="og:type" content="article"><meta name="og:site_name" content="peteroupc.github.io"><meta name="twitter:title" content="A Note on Randomness Extraction"><meta name="author" content="Peter Occil"/><meta name="viewport" content="width=device-width"><link rel=stylesheet type="text/css" href="/style.css"></head><body>  <div class="header">
<nav><p><a href="#navigation">Menu</a> - <a href="#top">Top</a> - <a href="/">Home</a></nav></div>
<div class="mainarea" id="top">
<h1>A Note on Randomness Extraction</h1>

<p><a href="mailto:poccil14@gmail.com"><strong>Peter Occil</strong></a></p>

<p><em>Randomness extraction</em> (also known as <em>unbiasing</em>, <em>debiasing</em>, <em>deskewing</em>, <em>whitening</em>, or <em>entropy extraction</em>) is a set of techniques for generating unbiased random bits from biased sources.  This note covers some useful extraction techniques.</p>

<p><a id=In_Information_Security></a></p>

<h2>In Information Security</h2>

<p>In information security, randomness extraction serves to generate a seed, password, encryption key, or other secret value from hard-to-predict nondeterministic sources.</p>

<p>Randomness extraction for information security is discussed in NIST SP 800-90B sec. 3.1.5.1, and RFC 4086 sec. 4.2 and 5.2. Possible choices of such extractors include keyed cryptographic hash functions (see, e.g., (Cliff et al., 2009)<sup><a href="#Note1"><strong>(1)</strong></a></sup>; (Coretti et al., 2019)<sup><a href="#Note2"><strong>(2)</strong></a></sup>) and two-universal hash functions with a fixed but randomly chosen seed (Frauchiger et al., 2013)<sup><a href="#Note3"><strong>(3)</strong></a></sup>. In information security applications:</p>

<ul>
<li>Unkeyed hash functions and other unkeyed extraction functions should not be used by themselves in randomness extraction.</li>
<li>Lossless compression should not be used as a randomness extractor.</li>
<li>Where possible, there should be two or more independent nondeterministic sources from which to apply randomness extraction.</li>
</ul>

<p>Some papers also refer to two-source extractors and resilient functions (especially the works by E. Chattopadhyay and D. Zuckerman), but there are few if any real implementations of these extraction techniques.</p>

<blockquote>
<p><strong>Example:</strong> The Cliff reference reviewed the use of HMAC (hash-based message authentication code) algorithms, and implies that one way to generate a seed is as follows:</p>

<ol>
<li>Gather data with at least 512 bits of entropy.</li>
<li>Run HMAC-SHA-512 with that data to generate a 512-bit HMAC.</li>
<li>Take the first 170 (or fewer) bits as the seed (512 divided by 3, rounded down).</li>
</ol>
</blockquote>

<p><a id=Outside_of_Information_Security></a></p>

<h2>Outside of Information Security</h2>

<p>Outside of information security, randomness extraction serves the purpose of recycling randomly generated numbers or, more generally, to transform those numbers from one form to another while preserving their randomness.  This can be done, for example, to reduce calls to a pseudorandom number generator (PRNG) or to generate a new seed for such a PRNG.</p>

<p>Perhaps the most familiar example of randomness extraction is the one by von Neumann (1951)<sup><a href="#Note4"><strong>(4)</strong></a></sup>:</p>

<ol>
<li>Flip a coin twice (whose bias is unknown).</li>
<li>If the coin lands heads then tails, return heads.  If it lands tails then heads, return tails.  If neither is the case, go to step 1.</li>
</ol>

<p>An algorithm found in (Morina et al. 2019)<sup><a href="#Note5"><strong>(5)</strong></a></sup> (called <strong>Algorithm M</strong> in this note) extends this to loaded dice.  According to personal communication with K. Łatuszyński, the key &quot;is to find two non overlapping events of the same probability&quot; via &quot;symmetric events {X_1 &lt; X_2}  and  {X_2 &lt; X_1} that have the same probability&quot;.</p>

<ol>
<li>Throw a (loaded) die, call the result <em>X</em>.  Throw the die again, call the result <em>Y</em>.</li>
<li>If <em>X</em> is less than <em>Y</em>, return 0.  If <em>X</em> is greater than <em>Y</em>, return 1.  If neither is the case, go to step 1.</li>
</ol>

<p>Algorithm M in fact works in a surprisingly broad range of cases; for more, see the <a href="#Appendix"><strong>appendix</strong></a>.</p>

<p>Pae (2005)<sup><a href="#Note6"><strong>(6)</strong></a></sup> and (Pae and Loui 2006)<sup><a href="#Note7"><strong>(7)</strong></a></sup> characterize <em>extracting functions</em>.  Informally, an <em>extracting function</em> is a function that maps a fixed number of digits to a variable number of bits such that, whenever the input has a given number of ones, twos, etc., every output bit-string of a given length is as likely to occur as every other output bit-string of that length, regardless of the input&#39;s bias.<sup><a href="#Note8"><strong>(8)</strong></a></sup>  Among others, von Neumann&#39;s extractor and the one by Peres (1992)<sup><a href="#Note9"><strong>(9)</strong></a></sup> are extracting functions.  The Peres extractor takes a list of bits (zeros and ones with the same bias) as input and is described as follows:</p>

<ol>
<li>Create two empty lists named U and V. Then, while two or more bits remain in the input:

<ol>
<li>If the next two bits are 0/0, append 0 to U and 0 to V.</li>
<li>Otherwise, if those bits are 0/1, append 1 to U, then write a 0.</li>
<li>Otherwise, if those bits are 1/0, append 1 to U, then write a 1.</li>
<li>Otherwise, if those bits are 1/1, append 0 to U and 1 to V.</li>
</ol></li>
<li>Run this algorithm recursively, reading from the bits placed in U.</li>
<li>Run this algorithm recursively, reading from the bits placed in V.</li>
</ol>

<p>A streaming algorithm, which builds something like an &quot;extractor tree&quot;, is another example of a randomness extractor (Zhou and Bruck 2012)<sup><a href="#Note10"><strong>(10)</strong></a></sup>.</p>

<p>I maintain <a href="https://github.com/peteroupc/peteroupc.github.io/blob/master/rextract.rb"><strong>source code of this extractor and the Peres extractor</strong></a>, which also includes additional notes on randomness extraction.</p>

<p>Pae&#39;s &quot;entropy-preserving&quot; binarization (Pae 2020)<sup><a href="#Note11"><strong>(11)</strong></a></sup>, given below, is meant to be used in other extractor algorithms such as the ones mentioned above.  It assumes the number of possible values, <em>n</em>, is known. However, it is obviously not efficient if <em>n</em> is a large number.</p>

<ol>
<li>Let <em>f</em> be a number in the interval [0, <em>n</em>) that was previously randomly generated.  If <em>f</em> is greater than 0, output a 1 (and go to step 2).</li>
<li>If <em>f</em> is less than <em>n</em> &minus; 1, output a 0 <em>x</em> times, where <em>x</em> is (<em>n</em> &minus; 1) &minus; <em>f</em>.</li>
</ol>

<p>Some additional notes:</p>

<ul>
<li>Different kinds of random numbers should not be mixed in the same extractor stream.  For example, if one source outputs random 6-sided die results, another source outputs random sums of rolling 2 six-sided dice, and a third source outputs coin flips with a bias of 0.75, there should be three extractor streams (for instance, three extractor trees that implement the Zhou and Bruck algorithm).</li>
<li>Hash functions, such as those mentioned in my <a href="https://peteroupc.github.io/hqrand.html#Counter_Based_PRNGs"><strong>examples of high-quality PRNGs</strong></a>, also serve to produce random-behaving numbers from a variable number of bits.  In general, they can&#39;t be extracting functions; however, their output can serve as input to an extraction algorithm.</li>
<li>Peres (1992)<sup><a href="#Note9"><strong>(9)</strong></a></sup> warns that if a program takes enough biased bits so that the extracting function outputs <em>m</em> bits with them, those <em>m</em> bits will not be uniformly distributed.  Instead, the extracting function should be passed blocks of biased bits, one block at a time (where each block should have a fixed length of at least 2 bits), until <em>m</em> bits or more are generated by the extractor this way.</li>
<li>Extractors that maintain state, such as the Zhou and Bruck extractor tree, should be used only on sources whose bias does not change significantly over time.  Dividing the source into blocks, as in the previous note, and assigning one extractor instance to each block, can improve robustness for sources whose bias can change over time.</li>
<li>The lower bound on the average number of coin flips needed to turn a biased coin into an unbiased coin is as follows (and is a special case of the <em>entropy bound</em>; see, e.g., (Pae 2005)<sup><a href="#Note6"><strong>(6)</strong></a></sup>, (Peres 1992)<sup><a href="#Note9"><strong>(9)</strong></a></sup>): ln(2) / ((&lambda; &minus; 1) * ln(1 &minus; &lambda;) &minus; &lambda; * ln(&lambda;)), where &lambda; is the bias of the input coin and ranges from 0 for always tails to 1 for always heads.  According to this formula, a growing number of coin flips is needed if the input coin is strongly biased towards heads or tails.  (For certain values of &lambda;, Kozen (2014)<sup><a href="#Note12"><strong>(12)</strong></a></sup> showed a tighter lower bound of this kind, but this bound is non-trivial and assumes &lambda; is known.)</li>
</ul>

<p><a id=Notes></a></p>

<h2>Notes</h2>

<ul>
<li><small><sup id=Note1>(1)</sup> Cliff, Y., Boyd, C., Gonzalez Nieto, J. &quot;How to Extract and Expand Randomness: A Summary and Explanation of Existing Results&quot;, 2009.</small></li>
<li><small><sup id=Note2>(2)</sup> Coretti, S., Dodis, Y., et al., &quot;Seedless Fruit is the Sweetest: Random Number Generation, Revisited&quot;, 2019.</small></li>
<li><small><sup id=Note3>(3)</sup> Frauchiger, D., Renner, R., Troyer, M., &quot;True randomness from realistic quantum devices&quot;, 2013.</small></li>
<li><small><sup id=Note4>(4)</sup> von Neumann, J., &quot;Various techniques used in connection with random digits&quot;, 1951.</small></li>
<li><small><sup id=Note5>(5)</sup> Morina, G., Łatuszyński, K., et al., &quot;<a href="https://arxiv.org/abs/1912.09229"><strong>From the Bernoulli Factory to a Dice Enterprise via Perfect Sampling of Markov Chains</strong></a>&quot;, arXiv:1912.09229 [math.PR], 2019.</small></li>
<li><small><sup id=Note6>(6)</sup> Pae, S., &quot;Random number generation using a biased source&quot;, dissertation, University of Illinois at Urbana-Champaign, 2005.</small></li>
<li><small><sup id=Note7>(7)</sup> Pae, S., Loui, M.C., &quot;Randomizing functions: Simulation of discrete probability distribution using a source of unknown distribution&quot;, <em>IEEE Transactions on Information Theory</em> 52(11), November 2006.</small></li>
<li><small><sup id=Note8>(8)</sup> It follows from this definition that an extracting function must map an all-X string (such as an all-zeros string) to the empty string, since there is only one empty string but more than one string of any other length.  Thus, no reversible function can be extracting, and a function that never returns an empty string (including nearly all hash functions) can&#39;t be extracting, either.</small></li>
<li><small><sup id=Note9>(9)</sup> Peres, Y., &quot;Iterating von Neumann&#39;s procedure for extracting random bits&quot;, Annals of Statistics 1992,20,1, p. 590-597.</small></li>
<li><small><sup id=Note10>(10)</sup> Zhou, H. and Bruck, J., &quot;<a href="https://arxiv.org/abs/1209.0730"><strong>Streaming algorithms for optimal generation of random bits</strong></a>&quot;, arXiv:1209.0730 [cs.IT], 2012.</small></li>
<li><small><sup id=Note11>(11)</sup> S. Pae, &quot;<a href="https://arxiv.org/abs/1602.06058v2"><strong>Binarization Trees and Random Number Generation</strong></a>&quot;, arXiv:1602.06058v2 [cs.DS].</small></li>
<li><small><sup id=Note12>(12)</sup> Kozen, D., <a href="http://www.cs.cornell.edu/%7Ekozen/Papers/Coinflip.pdf"><strong>&quot;Optimal Coin Flipping&quot;</strong></a>, 2014.</small></li>
<li><small><sup id=Note13>(13)</sup> Montes Gutiérrez, I., &quot;Comparison of alternatives under uncertainty and imprecision&quot;, doctoral thesis, Universidad de Oviedo, 2014.</small></li>
<li><small><sup id=Note14>(14)</sup> De Schuymer, Bart, Hans De Meyer, and Bernard De Baets. &quot;A fuzzy approach to stochastic dominance of random variables&quot;, in <em>International Fuzzy Systems Association World Congress</em> 2003.</small></li>
<li><small><sup id=Note15>(15)</sup> Camion, Paul, &quot;Unbiased die rolling with a biased die&quot;, North Carolina State University. Dept. of Statistics, 1974.</small></li>
</ul>

<p><a id=Appendix></a></p>

<h2>Appendix</h2>

<p>&nbsp;</p>

<p><a id=On_Algorithm_M></a></p>

<h3>On Algorithm M</h3>

<p>Algorithm M works regardless of what numbers <em>X</em> and <em>Y</em> can take on and with what probability, and even if the &quot;dice&quot; for <em>X</em> and <em>Y</em> are loaded differently, as long as the chance that the first &quot;die&quot; shows a number less than the second &quot;die&quot; is the same as the chance that the first &quot;die&quot; shows a greater number, and as long as each <em>pair</em> of throws is independent of any other.</p>

<p>More formally, P(<em>X</em> &lt; <em>Y</em>) must be equal to P(<em>X</em> &gt; <em>Y</em>).  This relationship is equivalent to <em>statistical indifference</em> (Montes Gutiérrez 2014)<sup><a href="#Note13"><strong>(13)</strong></a></sup>, (De Schuymer et al. 2003)<sup><a href="#Note14"><strong>(14)</strong></a></sup>. This relationship works even if <em>X</em> and <em>Y</em> are dependent on each other but independent of everything else; this is easy to see if we treat <em>X</em> and <em>Y</em> as a single random &quot;vector&quot; [<em>X</em>, <em>Y</em>].  This is shown by the following two propositions:</p>

<p><strong>Proposition 1.</strong> <em>Let X and Y be real-valued random variables.  Then Algorithm M outputs 0 or 1 with equal probability if and only if X and Y are statistically indifferent.</em></p>

<p><em>Proof.</em> For any <em>X</em> and <em>Y</em> there are only three mutually exclusive possibilities, <em>X</em>&gt;<em>Y</em>, <em>Y</em>&gt;<em>X</em>, and <em>X</em>=<em>Y</em>.   For the algorithm to return 0, <em>X</em> must be less than <em>Y</em>, and for it to return 1, <em>X</em> must be greater than <em>Y</em>.</p>

<p>For the &quot;only if&quot; part: For the algorithm to return 0 or 1 with equal probability, it must be that P(<em>X</em>&gt;<em>Y</em>) = P(<em>Y</em>&gt;<em>X</em>).  But this necessarily means that P(<em>X</em>&gt;<em>Y</em>) and P(<em>X</em>&gt;<em>Y</em>) are both 1/2 or less.  And if we assign half of the remainder (the remainder being P(<em>X</em>=<em>Y</em>)) to each probability, we get&mdash;</p>

<ul>
<li>P(<em>X</em>&gt;<em>Y</em>) + P(<em>X</em>=<em>Y</em>)/2 = 1/2, and</li>
<li>P(<em>Y</em>&gt;<em>X</em>) + P(<em>X</em>=<em>Y</em>)/2 = 1/2,</li>
</ul>

<p>and thus, <em>X</em> and <em>Y</em> must be statistically indifferent by definition (see below).</p>

<p>For the &quot;if&quot; part:  If <em>X</em> and <em>Y</em> are statistically indifferent, this means that &alpha; = P(<em>X</em>&gt;<em>Y</em>) + P(<em>X</em>=<em>Y</em>)/2 and &beta; = P(<em>Y</em>&gt;<em>X</em>) + P(<em>X</em>=<em>Y</em>)/2 are equal and &alpha; = &beta; = 1/2.  Since both &alpha; and &beta; are equal and P(<em>X</em>=<em>Y</em>) in &alpha; and &beta; are also equal, this must mean that P(<em>X</em>&gt;<em>Y</em>) = P(<em>Y</em>&gt;<em>X</em>).  It thus follows that for <em>X</em> and <em>Y</em>, the algorithm will return 0 or 1 with equal probability.  ◻</p>

<p><strong>Proposition 2.</strong> <em>Let X and Y be real-valued random variables that are independent, identically distributed, and defined on the same probability space.  Then X and Y are statistically indifferent.</em></p>

<p><em>Proof.</em> By definition, <em>X</em> and <em>Y</em> are statistically indifferent if and only if <em>X</em> is statistically preferred to <em>Y</em> and vice versa (that is, P(<em>X</em>&gt;<em>Y</em>) + P(<em>X</em>=<em>Y</em>)/2 &gt;= P(<em>Y</em>&gt;<em>X</em>) + P(<em>Y</em>=<em>X</em>)/2) (De Schuymer et al. 2003)<sup><a href="#Note14"><strong>(14)</strong></a></sup>.  Moreover, because both random variables are identically distributed, their distribution functions <em>F</em><sub><em>X</em></sub> and  <em>F</em><sub><em>Y</em></sub> are the same, and therefore their values and expectations for any given <em>z</em> (e.g., <em>F</em><sub><em>X</em></sub>(<em>z</em>) and E[<em>F</em><sub><em>X</em></sub>(<em>z</em>)], respectively) are the same.</p>

<p>If we look at Theorem 3.12 in (Montes Gutiérrez 2014)<sup><a href="#Note13"><strong>(13)</strong></a></sup>, we see that we can replace&mdash;</p>

<ul>
<li>the left hand side of Equation 3.5 with 0 &minus; 0, since it&#39;s a difference of expectations of the same distribution function and random variable, and</li>
<li>the right hand side with (1/2) * 0, since the difference of  <em>P</em>(<em>X</em> =<em>Y</em>) and  <em>P</em>(<em>X</em> = <em>X&prime;</em>) is taken and <em>P</em>(<em>X</em> =<em>Y</em>) is equivalent to <em>P</em>(<em>X</em> = <em>X&prime;</em>), which is equivalent because <em>X</em>, <em>X&prime;</em> and <em>Y</em> are identically distributed by the hypotheses of this proposition and Theorem 3.12.</li>
</ul>

<p>As a result, Equation 3.5 becomes 0 &gt;= 0, which is true and thus establishes that <em>X</em> is statistically preferred to <em>Y</em> (by Theorem 3.12).  It thus trivially follows that <em>Y</em> is likewise statistically preferred to <em>X</em> once we replace the roles of both variables, since both variables are identically distributed.  As a result, <em>X</em> and <em>Y</em> are found to be statistically indifferent and the proposition is proved.  ◻</p>

<p>Here are some of the many examples where this algorithm works:</p>

<ul>
<li>Set <em>X</em> and <em>Y</em> to two independent Gaussian random numbers with a mean of 0 but a different standard deviation. Or...</li>
<li>Set <em>X</em> and <em>Y</em> to two independent uniform(0, 1) random numbers.  Or...</li>
<li>Set <em>X</em> and <em>Y</em> to two independent uniform(0, 1) random numbers, then set <em>Y</em> to (<em>X</em>+<em>Y</em>)/2.</li>
</ul>

<p>See also a procedure given as a remark near the end of a paper by Camion (1974)<sup><a href="#Note15"><strong>(15)</strong></a></sup>.</p>

<p><a id=License></a></p>

<h2>License</h2>

<p>Any copyright to this page is released to the Public Domain.  In case this is not possible, this page is also licensed under <a href="https://creativecommons.org/publicdomain/zero/1.0/"><strong>Creative Commons Zero</strong></a>.</p>
</div><nav id="navigation"><ul>
<li><a href="/">Back to start site.</a>
<li><a href="https://github.com/peteroupc/peteroupc.github.io">This site's repository (source code)</a>
<li><a href="https://github.com/peteroupc/peteroupc.github.io/issues">Post an issue or comment</a></ul>
<p>
If you like this software, you should consider donating to me, Peter O., at the link below:</p>
<p class="printonly"><b>peteroupc.github.io</b></p>
<div class="noprint">
<a href="https://www.paypal.com/cgi-bin/webscr?cmd=_s-xclick&hosted_button_id=56E5T4FH7KD2S">
<img src="https://www.paypalobjects.com/en_US/i/btn/btn_donateCC_LG.gif"
name="submit" border="2" alt="PayPal - The safer, easier way to pay online!"></a>
<p>
<a href="//twitter.com/share">Share via Twitter</a>, <a href="//www.facebook.com/sharer/sharer.php" id="sharer">Share via Facebook</a>
</p>
</div>
</nav><script>
if("share" in navigator){
 document.getElementById("sharer").href="javascript:void(null)";
 document.getElementById("sharer").innerHTML="Share This Page";
 navigator.share({title:document.title,url:document.location.href}).then(
   function(){});
} else {
 document.getElementById("sharer").href="//www.facebook.com/sharer/sharer.php?u="+
    encodeURIComponent(document.location.href)
}
</script>
</body></html>
