<!DOCTYPE html><html><head><meta http-equiv=Content-Type content="text/html; charset=utf-8"><title>An Exact Beta Generator</title><meta name="viewport" content="width=device-width"><link rel=stylesheet type="text/css" href="/style.css"></head><body>  <div class="header">
<p><a href="#navigation">Menu</a> - <a href="#top">Top</a> - <a href="/">Home</a> -
<a href="http://peteroupc.github.io/">Donate to Me</a></p></div>
<div class="mainarea" id="top">
<h1>An Exact Beta Generator</h1>

<p><a href="mailto:poccil14@gmail.com"><strong>Peter Occil</strong></a></p>

<p><a id=Introduction></a></p>

<h2>Introduction</h2>

<p>This page introduces a new sampler for beta-distributed random numbers.  Unlike any other specially-designed beta sampler I am aware of, this sampler&mdash;</p>

<ul>
<li>avoids floating-point arithmetic, and</li>
<li>samples from the beta distribution (with both parameters 1 or greater) to an arbitrary precision and with user-specified error bounds (and thus is &quot;exact&quot; in the sense defined in (Karney 2014)<sup><a href="#Note1"><strong>(1)</strong></a></sup>).</li>
</ul>

<p>It takes advantage of a construct called the <em>Bernoulli factory</em> (Keane and O&#39;Brien 1994)<sup><a href="#Note2"><strong>(2)</strong></a></sup> (Flajolet et al., 2010)<sup><a href="#Note3"><strong>(3)</strong></a></sup>, which can simulate an arbitrary probability by transforming biased coins to biased coins, as well as the &quot;geometric bag&quot; technique to be described later.  One important feature of Bernoulli factories is that they can simulate a given probability <em>exactly</em>, without having to calculate that probability manually, which is important if the probability can be an irrational number that no computer can compute exactly (such as <code>pow(p, 1/2)</code> or <code>exp(-2)</code>).</p>

<p>This page shows <a href="#Sampler_Code"><strong>Python code</strong></a> for my new sampler.</p>

<p><a id=About_the_Beta_Distribution></a></p>

<h2>About the Beta Distribution</h2>

<p>The <a href="https://en.wikipedia.org/wiki/Beta_distribution"><strong>beta distribution</strong></a> is a bounded-domain probability distribution; its two parameters, <code>alpha</code> and <code>beta</code>, are both greater than 0 and describe the distribution&#39;s shape.  Depending on <code>alpha</code> and <code>beta</code>, the shape can be a smooth peak or a smooth valley.  The beta distribution can take on values in the interval [0, 1].  Any value in this interval (<code>x</code>) can occur with a probability proportional to&mdash;</p>

<pre>pow(x, alpha - 1) * pow(1 - x, beta - 1).               (1)
</pre>

<p>Although <code>alpha</code> and <code>beta</code> can each be greater than 0, this sampler only works if both parameters are 1 or greater.</p>

<p><a id=Building_Blocks></a></p>

<h2>Building Blocks</h2>

<p>The beta sampler relies on several building blocks described in this section.</p>

<p>One of them is the &quot;geometric bag&quot; technique by Flajolet and others (2010)<sup><a href="#Note3"><strong>(3)</strong></a></sup>, which generates heads or tails with a probability that is built up digit by digit.   A <em>geometric bag</em> is a list of items, where each item is a digit, or a placeholder value (which represents an unsampled digit), and represents a list of the digits after the radix point, from left to right, of a real number in the interval [0, 1], that is, the number&#39;s <em>digit expansion</em> (or <em>binary expansion</em> for base 2). (Note that Flajolet et al. cover only the binary case of a geometric bag).</p>

<p>The algorithm <strong>SampleGeometricBag</strong> is a Bernoulli factory algorithm described as follows:</p>

<ol>
<li> Let N be a geometric(1/<em>b</em>) random number, where <em>b</em> is the radix (e.g., 2 for binary).  In this document, a geometric(<em>p</em>) random number is the number of failures before the first success, where a success occurs with probability <em>p</em>. For example, in the binary case, flip fair coins until tails is flipped, then let N be the number of heads flipped this way.</li>
<li> If the item at position N in the geometric bag is a digit (e.g., 0 or 1 for binary), return that item. (Positions start at 0.)  Otherwise, set the item at that position to a digit chosen uniformly at random (e.g., either 0 or 1 for binary), increasing the geometric bag&#39;s capacity as necessary, then return the newly set item.  (As a result, there may be &quot;gaps&quot; in the geometric bag where no digit was sampled yet.)</li>
</ol>

<p><strong>SampleGeometricBagComplement</strong> is the same as the <strong>SampleGeometricBag</strong> algorithm, except the return value is 1 minus the original return value.  The result is that if <strong>SampleGeometricBag</strong> outputs 1 with probability <em>U</em>, <strong>SampleGeometricBagComplement</strong> outputs 1 with probability 1 &minus; <em>U</em>.</p>

<p><strong>FillGeometricBag</strong> generates a <code>p</code>-digit-precision number (a number with <code>p</code> digits after the radix point) from a geometric bag as follows:</p>

<ol>
<li>For each position in [0, <code>p</code>), if the item at that position is not a digit, set the item there to to a digit chosen uniformly at random (e.g., either 0 or 1 for binary), increasing the geometric bag&#39;s capacity as necessary. (See also (Oberhoff 2018, sec. 8)<sup><a href="#Note4"><strong>(4)</strong></a></sup>.)</li>
<li>Take the first <code>p</code> digits of the geometric bag and return &Sigma;<sub><em>i</em>=0, <em>p</em>&minus;1</sub> bag[<em>i</em>] * <em>b</em><sup>&minus;<em>i</em>&minus;1</sup>, where <em>b</em> is the radix.  (If it somehow happens that digits beyond <code>p</code> are set to 0 or 1, then the implementation could choose instead to fill all unsampled digits between the first and the last set digit and return the full number, optionally rounding it to a <code>p</code>-digit-precision number with a rounding mode of choice.)</li>
</ol>

<p><strong>PowerBernoulliFactory</strong> is a Bernoulli factory algorithm that transforms a coin that produces heads with probability <code>p</code> into a coin that produces heads with probability <code>pow(p, y)</code>.  The case where <code>y</code> is in (0, 1) is due to recent work by Mendo (2019)<sup><a href="#Note5"><strong>(5)</strong></a></sup>.  The algorithm takes a Bernoulli factory sub-algorithm (the coin that produces heads with probability <code>p</code>) as well as the parameter <em>y</em>, and is described as follows:</p>

<ol>
<li>If <em>y</em> is equal to 1, call the sub-algorithm and return the result.</li>
<li>If <em>y</em> is greater than 1, call the sub-algorithm <code>floor(y)</code> times and call <strong>PowerBernoulliFactory</strong> (once) with <em>y</em> = <em>y</em> &minus; floor(<em>y</em>).  Return 1 if all these calls return 1; otherwise, return 0.</li>
<li><em>y</em> is less than 1, so set <em>i</em> to 1.</li>
<li>Call the sub-algorithm; if it returns 1, return 1.</li>
<li>Return 0 with probability <em>y</em>/<em>i</em>.</li>
<li>Add 1 to <em>i</em> and go to step 4.</li>
</ol>

<p>The <strong>kthsmallest</strong> method generates the &#39;k&#39;th smallest &#39;bitcount&#39;-digit uniform random number out of &#39;n&#39; of them, is also relied on by this beta sampler.  It is used when both <code>a</code> and <code>b</code> are integers, based on the known property that a beta random variable in this case is the <code>a</code>th smallest uniform (0, 1) random number out of <code>a + b - 1</code> of them (Devroye 1986, p. 431)<sup><a href="#Note6"><strong>(6)</strong></a></sup>.</p>

<p><strong>kthsmallest</strong>, however, doesn&#39;t simply generate &#39;n&#39; &#39;bitcount&#39;-digit numbers and then sort them.  Rather, it builds up their digit expansions digit by digit, via the concept of &quot;u-rands&quot; (Karney 2014)<sup><a href="#Note1"><strong>(1)</strong></a></sup>.    It uses the observation that (in the binary case) each uniform (0, 1) random number is equally likely to be less than half or greater than half; thus, the number of uniform numbers that are less than half vs. greater than half follows a binomial(n, 1/2) distribution (and of the numbers less than half, say, the less-than-one-quarter vs. greater-than-one-quarter numbers follows the same distribution, and so on).    Thanks to this observation, the algorithm can generate a sorted sample &quot;on the fly&quot;.  A similar observation applies to other bases than base 2 if we use the multinomial distribution instead of the binomial distribution.</p>

<p>The algorithm is as follows:</p>

<ol>
<li>Create <code>n</code> empty u-rands.</li>
<li>Set <code>index</code> to 1.</li>
<li>If <code>index &lt;= k</code> and <code>index + n &gt;= k</code>:

<ol>
<li>Generate <strong>v</strong>, a multinomial random vector with <em>b</em> probabilities equal to 1/<em>b</em>, where <em>b</em> is the radix (for the binary case, <em>b</em> = 2, so this is equivalent to generating <code>LC</code> = binomial(<code>n</code>, 0.5) and setting <strong>v</strong> to {<code>LC</code>, <code>n - LC</code>}).</li>
<li>Starting at <code>index</code>, append the digit 0 to the first <strong>v</strong>[0] u-rands, a 1 digit to the next <strong>v</strong>[1] u-rands, and so on to appending a <em>b</em> &minus; 1 digit to the last <strong>v</strong>[<em>b</em> &minus; 1] u-rands (for the binary case, this means appending a 0 bit to the first <code>LC</code> u-rands and a 1 bit to the next <code>n - LC</code> u-rands).</li>
<li>For each integer <em>i</em> in [0, <em>b</em>): If <strong>v</strong>[<em>i</em>] &gt; 1, repeat step 3 and these substeps with <code>index</code> = <code>index</code> + &Sigma;<sub><em>j</em>=0, <em>i</em>&minus;1</sub> <strong>v</strong>[<em>j</em>] and <code>n</code> = <strong>v</strong>[<em>i</em>]. (For the binary case, this means: If<code>LC &gt; 1</code>, repeat step 3 and these substeps with the same <code>index</code> and <code>n = LC</code>; then, if <code>n - LC &gt; 1</code>, repeat step 3 and these substeps with <code>index = index+LC</code>, and <code>n = n - LC</code>).</li>
</ol></li>
<li>Take the <code>k</code>th u-rand (starting at 1) and fill it with uniform random digits as necessary to make a <code>bitcount</code>-digits number (similarly to <strong>FillGeometricBag</strong> above). (See also (Oberhoff 2018, sec. 8)<sup><a href="#Note4"><strong>(4)</strong></a></sup>.)  Return that u-rand.</li>
</ol>

<p><a id=The_Algorithm></a></p>

<h2>The Algorithm</h2>

<p>The full algorithm of the beta generator is as follows.  It takes three parameters: <em>a</em> &gt;= 1 and <em>b</em> &gt;= 1 are the parameters to the beta distribution, and <em>p</em> &gt; 0 is a precision parameter.</p>

<ol>
<li>Special case: If <em>a</em> = 0 and <em>b</em> = 0, return a uniform <em>p</em>-digit-precision number (for example, in the binary case, RandomBits(<em>p</em>) / 2<sup><em>p</em></sup> where <code>RandomBits(x)</code> returns an x-bit block of unbiased random bits).</li>
<li>Special case: If <em>a</em> and <em>b</em> are both integers, return the result of <strong>kthsmallest</strong> with parameters (<em>a</em> &minus; <em>b</em> + 1) and <em>a</em> in that order, and fill it as necessary to make a <em>p</em>-digit-precision number (similarly to <strong>FillGeometricBag</strong> above).</li>
<li>Create an empty list to serve as a &quot;geometric bag&quot;.</li>
<li>While true:

<ol>
<li>Remove all digits from the geometric bag.  This will result in an empty uniform random number, <em>U</em>, for the following steps, which will accept <em>U</em> with probability <em>U</em><sup>a&minus;1</sup>*(1&minus;<em>U</em>)<sup>b&minus;1</sup>) (the proportional probability for the beta distribution), as <em>U</em> is built up.</li>
<li>Call the <strong>PowerBernoulliFactory</strong> using the <strong>SampleGeometricBag</strong> algorithm and parameter <em>a</em> &minus; 1 (which will return 1 with probability <em>U</em><sup>a&minus;1</sup>).  If the result is 0, go to substep 1.</li>
<li>Call the <strong>PowerBernoulliFactory</strong> using the <strong>SampleGeometricBagComplement</strong> algorithm and parameter <em>b</em> &minus; 1 (which will return 1 with probability (1&minus;<em>U</em>)<sup>b&minus;1</sup>).  If the result is 0, go to substep 1. (Note that substeps 2 and 3 don&#39;t depend on each other and can be done in either order without affecting correctness, and this is taken advantage of in the Python code below.)</li>
<li><em>U</em> was accepted, so return the result of <strong>FillGeometricBag</strong>.</li>
</ol></li>
</ol>

<p><a id=Sampler_Code></a></p>

<h2>Sampler Code</h2>

<p>The following Python code implements the algorithm just described.  It relies on a class I wrote called &quot;<a href="https://github.com/peteroupc/peteroupc.github.io/blob/master/bernoulli.py"><strong>bernoulli.py</strong></a>&quot;, which collects a number of Bernoulli factories, some of which are relied on by the code below.  This includes the building blocks mentioned earlier.  The Python code also relies on a method I wrote called <code>kthsmallest</code>, which generates the kth smallest number in an arbitrary precision.  This will be described later in this page.</p>

<p>This code is far from fast, though, at least in Python.</p>

<pre>import math
import random
import bernoulli
from randomgen import RandomGen
from fractions import Fraction

def _toreal(ret, precision):
        # NOTE: Although we convert to a floating-point
        # number here, this is not strictly necessary and
        # is merely for convenience.
        return ret*1.0/(1&lt;&lt;precision)

def betadist(b, ax, ay, bx, by, precision=53):
        # Beta distribution for alpha&gt;=1 and beta&gt;=1
        bag=[]
        bpower=Fraction(bx, by)-1
        apower=Fraction(ax, ay)-1
        # Special case for a=b=1
        if bpower==0 and apower==0:
           return random.randint(0, (1&lt;&lt;precision)-1)*1.0/(1&lt;&lt;precision)
        # Special case if a and b are integers
        if int(bpower) == bpower and int(apower) == apower:
           a=int(Fraction(ax, ay))
           b=int(Fraction(bx, by))
           return _toreal(RandomGen().kthsmallest(a+b-1,a, \
                  precision), precision)
        # Create a &quot;geometric bag&quot; to hold a uniform random
        # number (U), described by Flajolet et al. 2010
        gb=lambda: b.geometric_bag(bag)
        # Complement of &quot;geometric bag&quot;
        gbcomp=lambda: b.geometric_bag(bag)^1
        bPowerBigger=(bpower &gt; apower)
        while True:
           # Create a uniform random number (U) bit-by-bit, and
           # accept it with probability U^(a-1)*(1-U)^(b-1), which
           # is the unnormalized PDF of the beta distribution
           bag.clear()
           r=1
           if bPowerBigger:
             # Produce 1 with probability (1-U)^(b-1)
             r=b.power(gbcomp, bpower)
             # Produce 1 with probability U^(a-1)
             if r==1: r=b.power(gb, apower)
           else:
             # Produce 1 with probability U^(a-1)
             r=b.power(gb, apower)
             # Produce 1 with probability (1-U)^(b-1)
             if r==1: r=b.power(gbcomp, bpower)
           if r == 1:
                 # Accepted, so fill up the &quot;bag&quot; and return the
                 # uniform number
                 ret=_fill_geometric_bag(b, bag, precision)
                 return ret

def _fill_geometric_bag(b, bag, precision):
        ret=0
        lb=min(len(bag), precision)
        for i in range(lb):
           if i&gt;=len(bag) or bag[i]==None:
              ret=(ret&lt;&lt;1)|b.randbit()
           else:
              ret=(ret&lt;&lt;1)|bag[i]
        if len(bag) &lt; precision:
           diff=precision-len(bag)
           ret=(ret &lt;&lt; diff)|random.randint(0,(1 &lt;&lt; diff)-1)
        # Now we have a number that is a multiple of
        # 2^-precision.
        return _toreal(ret, precision)
</pre>

<p><a id=Known_Issues></a></p>

<h3>Known Issues</h3>

<p>The bigger <code>alpha</code> or <code>beta</code> is, the smaller the area of acceptance becomes (and the more likely random numbers get rejected by this method, raising its run-time).  This is because <code>max(u^(alpha-1)*(1-u)^(beta-1))</code>, the peak of the density, approaches 0 as the parameters get bigger.  One idea to solve this issue is to expand the density so that the acceptance rate increases.  The following was tried:</p>

<ul>
<li>Estimate an upper bound for the peak of the density <code>peak</code>, given <code>alpha</code> and <code>beta</code>.</li>
<li>Calculate a largest factor <code>c</code> such that <code>peak * c = m &lt; 0.5</code>.</li>
<li>Use Huber&#39;s <code>linear_lowprob</code> Bernoulli factory (implemented in <em>bernoulli.py</em>) (Huber 2016)<sup><a href="#Note7"><strong>(7)</strong></a></sup>, taking the values found for <code>c</code> and <code>m</code>.  Testing shows that the choice of <code>m</code> is crucial for performance.</li>
</ul>

<p>But doing so apparently worsened the performance (in terms of random bits used) compared to the simple rejection approach.</p>

<p><a id=Correctness_Testing></a></p>

<h2>Correctness Testing</h2>

<p>To test the correctness of this sampler, the Kolmogorov&ndash;Smirnov test was applied with various values of <code>alpha</code> and <code>beta</code> and the default precision of 53, using SciPy&#39;s <code>kstest</code> method.  The code for the test is very simple: <code>kst = scipy.stats.kstest(ksample, lambda x: scipy.stats.beta.cdf(x, alpha, beta))</code>, where <code>ksample</code> is a sample of random numbers generated using the sampler above.  Note that SciPy uses a two-sided Kolmogorov&ndash;Smirnov test by default.</p>

<p>See the results of the <a href="https://peteroupc.github.io/betadistresults.html"><strong>correctness testing</strong></a>.   For each pair of parameters, five samples with 50,000 numbers per sample were taken, and results show the lowest and highest Kolmogorov&ndash;Smirnov statistics and p-values achieved for the five samples.  Note that a p-value extremely close to 0 or 1 strongly indicates that the samples do not come from the corresponding beta distribution.</p>

<p><a id=Exact_Simulation_of_Continuous_Distributions_on_0_1></a></p>

<h2>Exact Simulation of Continuous Distributions on [0, 1]</h2>

<p>The beta distribution is one case of a general approach to simulating continuous distributions with support on the interval [0, 1], and this with arbitrary precision, thanks to Bernoulli factories.  This general approach can sample an <code>n</code>-digit expansion (of an arbitrary radix) of a number following that continuous distribution, and is described as follows:</p>

<ol>
<li>Create a &quot;geometric bag&quot;, that is, an &quot;empty&quot; uniform random number also known as a &quot;u-rand&quot;.</li>
<li><p>As the geometric bag builds up a uniform random number, accept the number with a probability that can be represented by Bernoulli factories, or reject it otherwise.  As shown by Keane and O&#39;Brien <sup><a href="#Note2"><strong>(2)</strong></a></sup>, this is possible if and only if the probability function, in the interval [0, 1]&mdash;</p>

<ul>
<li>is continuous everywhere, and</li>
<li>either returns a constant value in [0, 1] everywhere, or returns a value in [0, 1] at each of the points 0 and 1 and a value in (0, 1) at each other point,</li>
</ul>

<p>and they give the example of 2<em>p</em> as a probability function that cannot be represented by a Bernoulli factory.  In the case of constants, they can be represented by a geometric bag&mdash;</p>

<ul>
<li>that is prefilled with the digit expansion of the constant in question, or</li>
<li>that uses a modified <strong>SampleGeometricBag</strong> algorithm in which the constant&#39;s digit expansion&#39;s digits are not sampled at random, but rather calculated &quot;on the fly&quot; and as necessary.</li>
</ul></li>
<li><p>If the geometric bag is accepted, fill the unsampled digits of the bag with uniform random digits as necessary to make an <code>n</code>-digit-precision number (similarly to <strong>FillGeometricBag</strong> above).</p></li>
</ol>

<p>The beta distribution&#39;s probability function at (1) fits these requirements (for <code>alpha</code> and <code>beta</code> both greater than 1), since it&#39;s continuous and never returns 0 or 1 outside of the points 0 and 1, thus it can be simulated by Bernoulli factories and is covered by this general approach.</p>

<p><a id=An_Example_The_Continuous_Bernoulli_Distribution></a></p>

<h3>An Example: The Continuous Bernoulli Distribution</h3>

<p>The continuous Bernoulli distribution (Loaiza-Ganem and Cunningham 2019)<sup><a href="#Note8"><strong>(8)</strong></a></sup> was designed to considerably improve performance of variational autoencoders (a machine learning model) in modeling continuous data that takes values in the interval [0, 1], including &quot;almost-binary&quot; image data.</p>

<p>The continous Bernoulli distribution takes one parameter <code>lamda</code> (a number in [0, 1]), and takes on values in the interval [0, 1] with a probability proportional to&mdash;</p>

<pre>pow(lamda, x) * pow(1 - lamda, 1 - x).
</pre>

<p>Again, this function meets the requirements stated by Keane and O&#39;Brien, so it can be simulated via Bernoulli factories.  Thus, this distribution can be simulated in Python using a geometric bag (which represents <em>x</em> in the formula above) and a two-coin exponentiating Bernoulli factory.</p>

<p>The <strong>two-coin power factory</strong> has the following algorithm.  It is based on the <strong>PowerBernoulliFactory</strong> given earlier (including the algorithm from Mendo (2019)<sup><a href="#Note5"><strong>(5)</strong></a></sup>), but changed to accept a second Bernoulli factory sub-algorithm rather than a fixed value for the exponent. To the best of my knowledge, I am not aware of any other article or paper that presents this exact Bernoulli factory.</p>

<ol>
<li>Set <em>i</em> to 1.</li>
<li>Call the base sub-algorithm; if it returns 1, return 1.</li>
<li>Call the exponent sub-algorithm; if it returns 1, return 0 with probability 1/<em>i</em>.</li>
<li>Add 1 to <em>i</em> and go to step 1.</li>
</ol>

<p>The algorithm for sampling the continuous Bernoulli distribution follows.  It uses a <strong>lambda Bernoulli factory</strong> algorithm, which returns 1 with probability <code>lamda</code>.</p>

<ol>
<li>Create an empty list to serve as a &quot;geometric bag&quot;.</li>
<li>Create a <strong>complementary lambda Bernoulli factory</strong> that returns 1 minus the result of the <strong>lambda Bernoulli factory</strong>.</li>
<li>While true:

<ol>
<li>Remove all digits from the geometric bag.  This will result in an empty uniform random number, <em>U</em>, for the following steps, which will accept <em>U</em> with probability <code>lamda</code><sup><em>U</em></sup>*(1&minus;<code>lamda</code>)<sup>1&minus;<em>U</em></sup>) (the proportional probability for the beta distribution), as <em>U</em> is built up.</li>
<li>Call the <strong>two-coin power factory</strong> using the <strong>lambda Bernoulli factory</strong> as the base and <strong>SampleGeometricBag</strong> as the exponent (which will return 1 with probability <code>lamda</code><sup><em>U</em></sup>).  If the result is 0, go to substep 1.</li>
<li>Call the <strong>two-coin power factory</strong> using the <strong>complementary lambda Bernoulli factory</strong> as the base and <strong>SampleGeometricBagComplement</strong> algorithm and parameter <em>b</em> &minus; 1 (which will return 1 with probability (1-<code>lamda</code>)<sup>1&minus;<em>U</em></sup>).  If the result is 0, go to substep 1. (Note that substeps 2 and 3 don&#39;t depend on each other and can be done in either order without affecting correctness.)</li>
<li><em>U</em> was accepted, so return the result of <strong>FillGeometricBag</strong>.</li>
</ol></li>
</ol>

<p>The Python code that samples the continuous Bernoulli distribution follows.</p>

<pre>def _twofacpower(b, fbase, fexponent):
    &quot;&quot;&quot; Bernoulli factory B(p, q) =&gt; B(p^q).
           - fbase, fexponent: Functions that return 1 if heads and 0 if tails.
             The first is the base, the second is the exponent.
             &quot;&quot;&quot;
    i = 1
    while True:
        if fbase() == 1:
            return 1
        if fexponent() == 1 and \
            b.zero_or_one(1, i) == 1:
            return 0
        i = i + 1

def contbernoullidist(b, lamda, precision=53):
    # Continuous Bernoulli distribution
    bag=[]
    lamda=Fraction(lamda)
    gb=lambda: b.geometric_bag(bag)
    # Complement of &quot;geometric bag&quot;
    gbcomp=lambda: b.geometric_bag(bag)^1
    fcoin=b.coin(lamda)
    lamdab=lambda: fcoin()
    # Complement of &quot;lambda coin&quot;
    lamdabcomp=lambda: fcoin()^1
    acc=0
    while True:
       # Create a uniform random number (U) bit-by-bit, and
       # accept it with probability lamda^U*(1-lamda)^(1-U), which
       # is the unnormalized PDF of the beta distribution
       bag.clear()
       # Produce 1 with probability lamda^U
       r=_twofacpower(b, lamdab, gb)
       # Produce 1 with probability (1-lamda)^(1-U)
       if r==1: r=_twofacpower(b, lamdabcomp, gbcomp)
       if r == 1:
             # Accepted, so fill up the &quot;bag&quot; and return the
             # uniform number
             ret=_fill_geometric_bag(b, bag, precision)
             return ret
       acc+=1
</pre>

<p><a id=Acknowledgments></a></p>

<h2>Acknowledgments</h2>

<p>I acknowledge Claude Gravel who reviewed this article.</p>

<p><a id=Notes></a></p>

<h2>Notes</h2>

<p><small><sup id=Note1>(1)</sup> Karney, C.F.F., &quot;<a href="https://arxiv.org/abs/1303.6257v2"><strong>Sampling exactly from the normal distribution</strong></a>&quot;, arXiv:1303.6257v2  [physics.comp-ph], 2014.</small></p>

<p><small><sup id=Note2>(2)</sup> Keane,  M.  S.,  and  O&#39;Brien,  G.  L., &quot;A Bernoulli factory&quot;, <em>ACM Transactions on Modeling and Computer Simulation</em> 4(2), 1994.</small></p>

<p><small><sup id=Note3>(3)</sup> Flajolet, P., Pelletier, M., Soria, M., &quot;<a href="https://arxiv.org/abs/0906.5560v2"><strong>On Buffon machines and numbers</strong></a>&quot;, arXiv:0906.5560v2  [math.PR], 2010.</small></p>

<p><small><sup id=Note4>(4)</sup> Oberhoff, Sebastian, &quot;<a href="https://dc.uwm.edu/etd/1888"><strong>Exact Sampling and Prefix Distributions</strong></a>&quot;, <em>Theses and Dissertations</em>, University of Wisconsin Milwaukee, 2018.</small></p>

<p><small><sup id=Note5>(5)</sup> Mendo, Luis. &quot;An asymptotically optimal Bernoulli factory for certain functions that can be expressed as power series.&quot; Stochastic Processes and their Applications 129, no. 11 (2019): 4366-4384.</small></p>

<p><small><sup id=Note6>(6)</sup> Devroye, L., <a href="http://luc.devroye.org/rnbookindex.html"><strong><em>Non-Uniform Random Variate Generation</em></strong></a>, 1986.</small></p>

<p><small><sup id=Note7>(7)</sup> Huber, M., &quot;<a href="https://arxiv.org/abs/1507.00843v2"><strong>Optimal linear Bernoulli factories for small mean problems</strong></a>&quot;, arXiv:1507.00843v2 [math.PR], 2016</small></p>

<p><small><sup id=Note8>(8)</sup> Loaiza-Ganem, G., Cunningham, J.P., &quot;<a href="https://arxiv.org/abs/1907.06845v5"><strong>The continuous Bernoulli: fixing a pervasive error in variational autoencoders</strong></a>&quot;, arXiv:1907.06845v5  [stat.ML], 2019.</small></p>

<p><a id=License></a></p>

<h2>License</h2>

<p>Any copyright to this page is released to the Public Domain.  In case this is not possible, this page is also licensed under <a href="https://creativecommons.org/publicdomain/zero/1.0/"><strong>Creative Commons Zero</strong></a>.</p>
</div><nav id="navigation"><ul>
<li><a href="/">Back to start site.</a>
<li><a href="https://github.com/peteroupc/peteroupc.github.io">This site's repository (source code)</a>
<li><a href="https://github.com/peteroupc/peteroupc.github.io/issues">Post an issue or comment</a></ul>
<p>
If you like this software, you should consider donating to me, Peter O., at the link below:</p>
<p class="printonly"><b>peteroupc.github.io</b></p>
<div class="noprint">
<a href="https://www.paypal.com/cgi-bin/webscr?cmd=_s-xclick&hosted_button_id=56E5T4FH7KD2S">
<img src="https://www.paypalobjects.com/en_US/i/btn/btn_donateCC_LG.gif"
name="submit" border="2" alt="PayPal - The safer, easier way to pay online!"></a>
<p>
<a href="//twitter.com/share">Share via Twitter</a>, <a href="//www.facebook.com/sharer/sharer.php" id="sharer">Share via Facebook</a>
</p>
</div>
</nav><script>
if("share" in navigator){
 document.getElementById("sharer").href="javascript:void(null)";
 document.getElementById("sharer").innerHTML="Share This Page";
 navigator.share({title:document.title,url:document.location.href}).then(
   function(){});
} else {
 document.getElementById("sharer").href="//www.facebook.com/sharer/sharer.php?u="+
    encodeURIComponent(document.location.href)
}
</script>
</body></html>
