<!DOCTYPE html><html><head><meta http-equiv=Content-Type content="text/html; charset=utf-8"><title>Random Number Generation and Sampling Methods</title><meta name="viewport" content="width=device-width"><link rel=stylesheet type="text/css" href="/style.css"></head><body>  <div class="header">
<p><a href="#navigation">Menu</a> - <a href="#top">Top</a> - <a href="/">Home</a> -
<a href="http://peteroupc.github.io/">Donate to Me</a></p></div>
<div class="mainarea" id="top">
<h1>Random Number Generation and Sampling Methods</h1>

<p><a href="mailto:poccil14@gmail.com"><strong>Peter Occil</strong></a></p>

<p>Begun on June 4, 2017; last updated on Jun. 25, 2019.</p>

<p>Discusses many ways applications can do random number generation and sampling from an underlying RNG and includes pseudocode for many of them.</p>

<p><a id=Introduction></a></p>

<h2>Introduction</h2>

<p>This page discusses many ways applications can generate and sample random content using an underlying random number generator (RNG), often with pseudocode. Those methods include&mdash;</p>

<ul>
<li>ways to generate uniform random numbers from an underlying RNG (such as the <a href="#Core_Random_Generation_Method"><strong>core method, <code>RNDINT(N)</code></strong></a>),</li>
<li>ways to generate randomized content and conditions, such as <a href="#Boolean_True_False_Conditions"><strong>true/false conditions</strong></a>, <a href="#Shuffling"><strong>shuffling</strong></a>, and <a href="#Sampling_Without_Replacement_Choosing_Several_Unique_Items"><strong>sampling unique items from a list</strong></a>, and</li>
<li>generating non-uniform random numbers, including <a href="#Weighted_Choice"><strong>weighted choice</strong></a>, the <a href="#Normal_Gaussian_Distribution"><strong>normal distribution</strong></a>, and <a href="#Index_of_Non_Uniform_Distributions"><strong>other probability distributions</strong></a>.</li>
</ul>

<p><a href="https://peteroupc.github.io/randomgen.zip"><strong>Sample Python code</strong></a> that implements many of the methods in this document is available.</p>

<p>All the random number methods presented on this page are ultimately based on an underlying RNG; however, the methods make no assumptions on that RNG&#39;s implementation (e.g., whether that RNG uses only its input and its state to produce numbers) or on that RNG&#39;s statistical quality or predictability.</p>

<p><strong>In general, this document does not cover:</strong></p>

<ul>
<li>How to choose an underlying RNG for a particular application, including in terms of security, performance, and quality.  I have written more on RNG recommendations in <a href="https://peteroupc.github.io/random.html"><strong>another document</strong></a>.</li>
<li>Randomness extraction (also known as <em>unbiasing</em>, <em>deskewing</em>, or <em>whitening</em>), such as <a href="https://peteroupc.github.io/random.html#Hash_Functions"><strong>hash functions</strong></a> and von Neumann unbiasing.</li>
</ul>

<p><a id=About_This_Document></a></p>

<h3>About This Document</h3>

<p><strong>This is an open-source document; for an updated version, see the</strong> <a href="https://github.com/peteroupc/peteroupc.github.io/raw/master/randomfunc.md"><strong>source code</strong></a> <strong>or its</strong> <a href="https://github.com/peteroupc/peteroupc.github.io/blob/master/randomfunc.md"><strong>rendering on GitHub</strong></a><strong>.  You can send comments on this document either on</strong> <a href="https://www.codeproject.com/Articles/1190459/Random-Number-Generation-and-Sampling-Methods"><strong>CodeProject</strong></a> <strong>or on the</strong> <a href="https://github.com/peteroupc/peteroupc.github.io/issues"><strong>GitHub issues page</strong></a><strong>.</strong></p>

<p><strong>Comments on any aspect of this document are welcome, but especially comments on the following:</strong></p>

<ul>
<li><strong>Corrections to any method given on this page.</strong></li>
<li><strong>Requests to provide an implementation of any method given here in other programming languages, in addition to Python.</strong></li>
<li><strong>If there is enough interest by readers, I may discuss approaches to generate random graphs or matrices.</strong> &lt;!-- Generating a random maze is equivalent to generating a random spanning tree of a mesh graph.  Generating a random path is equivalent to a simple random walk of a (weighted or unweighted) graph. --&gt;</li>
<li><strong>Suggestions to add probability distributions to this document.</strong></li>
<li><strong>Ways to implement any of the randomization methods given in &quot;Randomization with Real Numbers&quot; using only random integers.</strong></li>
<li><strong>Suggestions to trim the size of this document, such as by limiting it to the most common and most useful methods for generating random numbers.</strong></li>
</ul>

<p><a id=Contents></a></p>

<h2>Contents</h2>

<ul>
<li><a href="#Introduction"><strong>Introduction</strong></a>

<ul>
<li><a href="#About_This_Document"><strong>About This Document</strong></a></li>
</ul></li>
<li><a href="#Contents"><strong>Contents</strong></a></li>
<li><a href="#Notation_and_Definitions"><strong>Notation and Definitions</strong></a></li>
<li><a href="#Uniform_Random_Numbers"><strong>Uniform Random Numbers</strong></a>

<ul>
<li><a href="#RNDINT_Random_Integers_in_0_N"><code>RNDINT</code>: Random Integers in [0, N]</a></li>
<li><a href="#RNDINTRANGE_Random_Integers_in_N_M"><code>RNDINTRANGE</code>: Random Integers in [N, M]</a></li>
<li><a href="#RNDINTEXC_Random_Integers_in_0_N"><strong><code>RNDINTEXC</code>: Random Integers in [0, N)</strong></a></li>
<li><a href="#RNDINTEXCRANGE_Random_Integers_in_N_M"><strong><code>RNDINTEXCRANGE</code>: Random Integers in [N, M)</strong></a></li>
<li><a href="#Uniform_Random_Bits"><strong>Uniform Random Bits</strong></a></li>
<li><a href="#Certain_Programming_Environments"><strong>Certain Programming Environments</strong></a></li>
</ul></li>
<li><a href="#Randomization_Techniques"><strong>Randomization Techniques</strong></a>

<ul>
<li><a href="#Boolean_True_False_Conditions"><strong>Boolean (True/False) Conditions</strong></a></li>
<li><a href="#Random_Sampling"><strong>Random Sampling</strong></a>

<ul>
<li><a href="#Sampling_With_Replacement_Choosing_a_Random_Item_from_a_List"><strong>Sampling With Replacement: Choosing a Random Item from a List</strong></a></li>
<li><a href="#Sampling_Without_Replacement_Choosing_Several_Unique_Items"><strong>Sampling Without Replacement: Choosing Several Unique Items</strong></a></li>
<li><a href="#Shuffling"><strong>Shuffling</strong></a></li>
<li><a href="#Random_Character_Strings"><strong>Random Character Strings</strong></a></li>
<li><a href="#Pseudocode_for_Random_Sampling"><strong>Pseudocode for Random Sampling</strong></a></li>
</ul></li>
<li><a href="#Rejection_Sampling"><strong>Rejection Sampling</strong></a></li>
<li><a href="#Random_Walks"><strong>Random Walks</strong></a></li>
<li><a href="#Randomization_in_Statistical_Testing"><strong>Randomization in Statistical Testing</strong></a></li>
<li><a href="#A_Note_on_Sorting_Random_Numbers"><strong>A Note on Sorting Random Numbers</strong></a></li>
</ul></li>
<li><a href="#General_Non_Uniform_Distributions"><strong>General Non-Uniform Distributions</strong></a>

<ul>
<li><a href="#Weighted_Choice"><strong>Weighted Choice</strong></a>

<ul>
<li><a href="#Weighted_Choice_With_Replacement"><strong>Weighted Choice With Replacement</strong></a></li>
<li><a href="#Weighted_Choice_Without_Replacement_Multiple_Copies"><strong>Weighted Choice Without Replacement (Multiple Copies)</strong></a></li>
<li><a href="#Weighted_Choice_Without_Replacement_Single_Copies"><strong>Weighted Choice Without Replacement (Single Copies)</strong></a></li>
</ul></li>
<li><a href="#Mixtures_of_Distributions"><strong>Mixtures of Distributions</strong></a></li>
<li><a href="#Transformations_of_Random_Numbers"><strong>Transformations of Random Numbers</strong></a>

<ul>
<li><a href="#Censored_and_Truncated_Random_Numbers"><strong>Censored and Truncated Random Numbers</strong></a></li>
</ul></li>
</ul></li>
<li><a href="#Specific_Non_Uniform_Distributions"><strong>Specific Non-Uniform Distributions</strong></a>

<ul>
<li><a href="#Dice"><strong>Dice</strong></a></li>
<li><a href="#Hypergeometric_Distribution"><strong>Hypergeometric Distribution</strong></a></li>
<li><a href="#Random_Integers_with_a_Given_Positive_Sum"><strong>Random Integers with a Given Positive Sum</strong></a></li>
<li><a href="#Multinomial_Distribution"><strong>Multinomial Distribution</strong></a></li>
</ul></li>
<li><a href="#Randomization_with_Real_Numbers"><strong>Randomization with Real Numbers</strong></a>

<ul>
<li><a href="#Uniform_Random_Real_Numbers"><strong>Uniform Random Real Numbers</strong></a>

<ul>
<li><a href="#RNDU01_Family_Random_Numbers_Bounded_by_0_and_1"><strong><code>RNDU01</code> Family: Random Numbers Bounded by 0 and 1</strong></a></li>
<li><a href="#Alternative_Implementation_for_RNDU01"><strong>Alternative Implementation for <code>RNDU01</code></strong></a></li>
<li><a href="#RNDRANGE_Family_Random_Numbers_in_an_Arbitrary_Interval"><strong><code>RNDRANGE</code> Family: Random Numbers in an Arbitrary Interval</strong></a></li>
</ul></li>
<li><a href="#Monte_Carlo_Sampling_Expected_Values_Integration_and_Optimization"><strong>Monte Carlo Sampling: Expected Values, Integration, and Optimization</strong></a></li>
<li><a href="#Random_Walks_Additional_Examples"><strong>Random Walks: Additional Examples</strong></a></li>
<li><a href="#Low_Discrepancy_Sequences"><strong>Low-Discrepancy Sequences</strong></a></li>
<li><a href="#Weighted_Choice_Involving_Real_Numbers"><strong>Weighted Choice Involving Real Numbers</strong></a>

<ul>
<li><a href="#Weighted_Choice_Without_Replacement_Indefinite_Size_List"><strong>Weighted Choice Without Replacement (Indefinite-Size List)</strong></a></li>
<li><a href="#Continuous_Weighted_Choice"><strong>Continuous Weighted Choice</strong></a></li>
</ul></li>
<li><a href="#Mixtures_Additional_Examples"><strong>Mixtures: Additional Examples</strong></a></li>
<li><a href="#Transformations_of_Random_Numbers_Additional_Examples"><strong>Transformations of Random Numbers: Additional Examples</strong></a></li>
<li><a href="#Random_Numbers_from_a_Distribution_of_Data_Points"><strong>Random Numbers from a Distribution of Data Points</strong></a></li>
<li><a href="#Random_Numbers_from_an_Arbitrary_Distribution"><strong>Random Numbers from an Arbitrary Distribution</strong></a></li>
<li><a href="#Gibbs_Sampling"><strong>Gibbs Sampling</strong></a></li>
<li><a href="#Dice_Optimization_for_Many_Dice"><strong>Dice: Optimization for Many Dice</strong></a></li>
<li><a href="#Normal_Gaussian_Distribution"><strong>Normal (Gaussian) Distribution</strong></a></li>
<li><a href="#Binomial_Distribution_Optimization_for_Many_Trials"><strong>Binomial Distribution: Optimization for Many Trials</strong></a></li>
<li><a href="#Poisson_Distribution"><strong>Poisson Distribution</strong></a></li>
<li><a href="#Gamma_Distribution"><strong>Gamma Distribution</strong></a></li>
<li><a href="#Beta_Distribution"><strong>Beta Distribution</strong></a></li>
<li><a href="#Negative_Binomial_Distribution"><strong>Negative Binomial Distribution</strong></a></li>
<li><a href="#von_Mises_Distribution"><strong>von Mises Distribution</strong></a></li>
<li><a href="#Stable_Distribution"><strong>Stable Distribution</strong></a></li>
<li><a href="#Multivariate_Normal_Multinormal_Distribution"><strong>Multivariate Normal (Multinormal) Distribution</strong></a></li>
<li><a href="#Random_Real_Numbers_with_a_Given_Positive_Sum"><strong>Random Real Numbers with a Given Positive Sum</strong></a></li>
<li><a href="#Gaussian_and_Other_Copulas"><strong>Gaussian and Other Copulas</strong></a></li>
<li><a href="#Index_of_Non_Uniform_Distributions"><strong>Index of Non-Uniform Distributions</strong></a></li>
<li><a href="#Geometric_Sampling"><strong>Geometric Sampling</strong></a>

<ul>
<li><a href="#Random_Points_Inside_a_Box"><strong>Random Points Inside a Box</strong></a></li>
<li><a href="#Random_Points_Inside_a_Simplex"><strong>Random Points Inside a Simplex</strong></a></li>
<li><a href="#Random_Points_on_the_Surface_of_a_Hypersphere"><strong>Random Points on the Surface of a Hypersphere</strong></a></li>
<li><a href="#Random_Points_Inside_a_Ball_or_Shell"><strong>Random Points Inside a Ball or Shell</strong></a></li>
<li><a href="#Random_Latitude_and_Longitude"><strong>Random Latitude and Longitude</strong></a></li>
</ul></li>
</ul></li>
<li><a href="#Acknowledgments"><strong>Acknowledgments</strong></a></li>
<li><a href="#Notes"><strong>Notes</strong></a></li>
<li><a href="#Appendix"><strong>Appendix</strong></a>

<ul>
<li><a href="#Implementation_of_erf"><strong>Implementation of <code>erf</code></strong></a></li>
<li><a href="#Mean_and_Variance_Calculation"><strong>Mean and Variance Calculation</strong></a></li>
<li><a href="#Norm_Calculation"><strong>Norm Calculation</strong></a></li>
</ul></li>
<li><a href="#License"><strong>License</strong></a></li>
</ul>

<p><a id=Notation_and_Definitions></a></p>

<h2>Notation and Definitions</h2>

<ul>
<li>The <a href="https://peteroupc.github.io/pseudocode.html"><strong>pseudocode conventions</strong></a> apply to this document.</li>
<li><strong>Intervals.</strong> The following notation is used for intervals:

<ul>
<li>[<code>a</code>, <code>b</code>) means &quot;<code>a</code> or greater, but less than <code>b</code>&quot;.</li>
<li>(<code>a</code>, <code>b</code>) means &quot;greater than <code>a</code>, but less than <code>b</code>&quot;.</li>
<li>(<code>a</code>, <code>b</code>] means &quot;greater than <code>a</code> and less than or equal to <code>b</code>&quot;.</li>
<li>[<code>a</code>, <code>b</code>] means &quot;<code>a</code> or greater and <code>b</code> or less&quot;.</li>
</ul></li>
<li><strong>Random number generator (RNG).</strong> Software and/or hardware that seeks to generate independent numbers that seem to occur by chance and that are approximately uniformly distributed<sup><a href="#Note1"><strong>(1)</strong></a></sup>.</li>
</ul>

<p><a id=Uniform_Random_Numbers></a></p>

<h2>Uniform Random Numbers</h2>

<p>This section describes how an underlying RNG can be used to generate independent uniformly-distributed random integers.  This section describes four methods: <code>RNDINT</code>, <code>RNDINTEXC</code>, <code>RNDINTRANGE</code>, <code>RNDINTEXCRANGE</code>.  Of these, <code>RNDINT</code>, described next, can serve as the basis for the remaining methods.</p>

<p><a id=RNDINT_Random_Integers_in_0_N></a></p>

<h3><code>RNDINT</code>: Random Integers in [0, N]</h3>

<p>In this document, <strong><code>RNDINT(maxInclusive)</code></strong> is the core method for using an underlying RNG to generate independent uniform random integers <strong>in the interval [0, <code>maxInclusive</code>]</strong>.<sup><a href="#Note2"><strong>(2)</strong></a></sup> For the pseudocode given below:</p>

<table><thead>
<tr>
<th>If the underlying RNG produces:</th>
<th>Then <code>RNG()</code> is:</th>
<th>And <code>MODULUS</code> is:</th>
</tr>
</thead><tbody>
<tr>
<td>Integers in the interval [0, <em>n</em>).</td>
<td>The underlying RNG.</td>
<td><em>n</em>.</td>
</tr>
<tr>
<td>Numbers in the interval [0, 1) known to be evenly spaced by a number <em>p</em> (e.g., dSFMT).</td>
<td>The underlying RNG, except with its outputs multiplied by <em>p</em>.</td>
<td>1/<em>p</em>.</td>
</tr>
<tr>
<td>Numbers not specified above.</td>
<td>A new RNG formed by writing the underlying RNG&#39;s outputs to a stream of memory units (such as 8-bit bytes) and using a <em>randomness extraction</em> technique to transform that stream to <em>n</em>-bit integers.</td>
<td>2<sup><em>n</em></sup>.</td>
</tr>
</tbody></table>

<pre>METHOD RndIntHelperNonPowerOfTwo(maxInclusive)
    cx = floor(maxInclusive / MODULUS) + 1
    while true
       ret = cx * RNG()
       // NOTE: If this method is implemented using a fixed-
       // precision type, the addition operation below should
       // check for overflow and should reject the number
       // if overflow would result.
       ret = ret + RNDINT(cx - 1)
       if ret &lt;= maxInclusive: return ret
    end
END METHOD

METHOD RndIntHelperPowerOfTwo(maxInclusive)
  // NOTE: Finds the number of bits minus 1 needed
  // to represent MODULUS (in other words, the number
  // of random bits returned by RNG() ). This will
  // be a constant here, though.
  modBits = ln(MODULUS)/ln(2)
  // Calculate the bit count of maxInclusive
  bitCount = 0
  tempnumber = maxInclusive
  while tempnumber &gt; 0
    // NOTE: If the programming language implements
    // division with two integers by truncating to an
    // integer, the division can be used as is without
    // using a &quot;floor&quot; function.
    tempnumber = floor(tempnumber / 2)
    bitCount = bitCount + 1
  end
  while true
    // Build a number with `bitCount` bits
    tempnumber = 0
    while bitCount &gt; 0
      wordBits = modBits
      rngNumber = RNG()
      if wordBits &gt; bitCount
        wordBits = bitCount
        // Truncate number to &#39;wordBits&#39; bits
        // NOTE: If the programming language supports a bitwise
        // AND operator, the mod operation can be implemented
        // as &quot;rndNumber AND ((1 &lt;&lt; wordBits) - 1)&quot;
        rngNumber = rem(rngNumber, (1 &lt;&lt; wordBits))
      end
      tempnumber = tempnumber &lt;&lt; wordBits
      // NOTE: In programming languages that
      // support the OR operator between two
      // integers, that operator can replace the
      // plus operator below.
      tempnumber = tempnumber + rngNumber
      bitCount = bitCount - wordBits
    end
    // Accept the number if allowed
    if tempnumber &lt;= maxInclusive: return tempnumber
  end
END METHOD

METHOD RNDINT(maxInclusive)
  // maxInclusive must be 0 or greater
  if maxInclusive &lt; 0: return error
  if maxInclusive == 0: return 0
  // N equals modulus
  if maxInclusive == MODULUS - 1: return RNG()
  // NOTE: Finds the number of bits minus 1 needed
  // to represent MODULUS (if it&#39;s a power of 2).
  // This will be a constant here, though.
  modBits=ln(MODULUS)/ln(2)
  // NOTE: The following condition checks if MODULUS
  // is a power of 2.  This will be a constant here, though.
  isPowerOfTwo=floor(modBits) == modBits
  // Special cases if MODULUS is a power of 2
  if isPowerOfTwo
       if maxInclusive == 1: return rem(RNG(), 2)
       if maxInclusive == 3 and modBits &gt;= 2: return rem(RNG(), 4)
       if maxInclusive == 255 and modBits &gt;= 8: return rem(RNG(), 256)
       if maxInclusive == 65535 and modBits &gt;=16: return rem(RNG(), 65535)
   end
  if maxInclusive &gt; MODULUS - 1:
     if isPowerOfTwo
       return RndIntHelperPowerOfTwo(maxInclusive)
     else
       return RndIntHelperNonPowerOfTwo(maxInclusive)
     end
  else
    // NOTE: If the programming language implements
    // division with two integers by truncating to an
    // integer, the division can be used as is without
    // using a &quot;floor&quot; function.
    nPlusOne = maxInclusive + 1
    maxexc = floor((MODULUS - 1) / nPlusOne) * nPlusOne
    while true
      ret = RNG()
      if ret &lt; nPlusOne: return ret
      if ret &lt; maxexc: return rem(ret, nPlusOne)
    end
  end
END METHOD
</pre>

<blockquote>
<p><strong>Notes:</strong></p>

<ol>
<li>The <code>RNDINT</code> implementation given here is not necessarily performant.  Performance optimizations include multithreading or vectorization (SIMD instructions) to help reduce the time to generate multiple random numbers at once, or saving unused bits generated by <code>RNDINT</code> if <code>MODULUS</code> is 2<sup>32</sup> or another power of 2 (indicating <code>RNG()</code> outputs <em>n</em>-bit integers).</li>
<li>In functional programming languages such as Haskell, <code>RNDINT()</code>, as well as <code>RNG()</code> itself and other random-number-generating methods in this document, can be implemented by taking a random generator state as an additional parameter, and returning a list of two items, namely, the random number and a new random generator state (as in the Haskell package <code>AC-Random</code>).  This works only if the <code>RNG()</code> implementation uses only its input and its state to produce random numbers.</li>
</ol>

<p><strong>Examples:</strong></p>

<ol>
<li>To generate a random number that&#39;s either -1 or 1, the following idiom can be used: <code>(RNDINT(1) * 2 - 1)</code>.</li>
<li>To generate a random integer that&#39;s divisible by a positive integer (<code>DIV</code>), generate the integer with any method (such as <code>RNDINT</code>), let <code>X</code> be that integer, then generate <code>X - rem(X, DIV)</code> if <code>X &gt;= 0</code>, or <code>X - (DIV - rem(abs(X), DIV))</code> otherwise. (Depending on the method, the resulting integer may be out of range, in which case this procedure is to be repeated.)</li>
<li>A random 2-dimensional point on an NxM grid can be expressed as a single integer as follows:

<ul>
<li>To generate a random NxM point <code>P</code>, generate <code>P = RNDINT(N * M - 1)</code> (<code>P</code> is thus in the interval [0, <code>N * M</code>)).</li>
<li>To convert a point <code>P</code> to its 2D coordinates, generate <code>[rem(P, N), floor(P / N)]</code>. (Each coordinate starts at 0.)</li>
<li>To convert 2D coordinates <code>coord</code> to an NxM point, generate <code>P = coord[1] * N + coord[0]</code>.</li>
</ul></li>
</ol>
</blockquote>

<p><a id=RNDINTRANGE_Random_Integers_in_N_M></a></p>

<h3><code>RNDINTRANGE</code>: Random Integers in [N, M]</h3>

<p>The na&iuml;ve way of generating a <strong>random integer in the interval [<code>minInclusive</code>, <code>maxInclusive</code>]</strong>, shown below, works well for nonnegative integers and arbitrary-precision integers.</p>

<pre> METHOD RNDINTRANGE(minInclusive, maxInclusive)
   // minInclusive must not be greater than maxInclusive
   if minInclusive &gt; maxInclusive: return error
   return minInclusive + RNDINT(maxInclusive - minInclusive)
 END METHOD
</pre>

<p>The na&iuml;ve approach won&#39;t work as well, though, if the integer format can express negative and nonnegative integers and the difference between <code>maxInclusive</code> and <code>minInclusive</code> exceeds the highest possible integer for the format.  For integer formats that can express&mdash;</p>

<ol>
<li>any integer in the interval [-1 - <code>MAXINT</code>, <code>MAXINT</code>] (e.g., Java <code>int</code>, <code>short</code>, or <code>long</code>), or</li>
<li>any integer in the interval [-<code>MAXINT</code>, <code>MAXINT</code>] (e.g., Java <code>float</code> and <code>double</code> and .NET&#39;s implementation of <code>System.Decimal</code>),</li>
</ol>

<p>where <code>MAXINT</code> is an integer greater than 0, the following pseudocode for <code>RNDINTRANGE</code> can be used.</p>

<pre>METHOD RNDINTRANGE(minInclusive, maxInclusive)
   // minInclusive must not be greater than maxInclusive
   if minInclusive &gt; maxInclusive: return error
   if minInclusive == maxInclusive: return minInclusive
   if minInclusive==0: return RNDINT(maxInclusive)
   // Difference does not exceed maxInclusive
   if minInclusive &gt; 0 or minInclusive + MAXINT &gt;= maxInclusive
       return minInclusive + RNDINT(maxInclusive - minInclusive)
   end
   while true
     ret = RNDINT(MAXINT)
     // NOTE: For case 1, use the following line:
     if RNDINT(1) == 0: ret = -1 - ret
     // NOTE: For case 2, use the following three lines
     // instead of the preceding line; these lines
     // avoid negative zero
     // negative = RNDINT(1) == 0
     // if negative: ret = 0 - ret
     // if negative and ret == 0: continue
     if ret &gt;= minInclusive and ret &lt;= maxInclusive: return ret
   end
END METHOD
</pre>

<blockquote>
<p><strong>Examples:</strong></p>

<ol>
<li>To simulate rolling an N-sided die (N greater than 1), generate a random number in the interval [1, N] by <code>RNDINTRANGE(1, N)</code>.</li>
<li>To generate a random integer with one base-10 digit, generate <code>RNDINTRANGE(0, 9)</code>.</li>
<li>To generate a random integer with N base-10 digits (where N is 2 or greater), where the first digit can&#39;t be 0, generate <code>RNDINTRANGE(pow(10, N-1), pow(10, N) - 1)</code>.</li>
<li><p>Pseudocode like the following can be used to choose a <strong>random date-and-time</strong> bounded by two dates-and-times (<code>date1</code>, <code>date2</code>).  In the following pseudocode, <code>DATETIME_TO_NUMBER</code> and <code>NUMBER_TO_DATETIME</code> convert a date-and-time to or from a number, respectively, at the required granularity, for instance, month, day, or hour granularity (the details of such conversion depend on the date-and-time format and are outside the scope of this document).</p>

<pre>dtnum1 = DATETIME_TO_NUMBER(date1)
dtnum2 = DATETIME_TO_NUMBER(date2)
// Choose a random date-and-time
// in [dtnum1, dtnum2].  Any other
// random selection strategy can be
// used here instead.
num = RNDINTRANGE(date1, date2)
result = NUMBER_TO_DATETIME(num)
</pre></li>
</ol>
</blockquote>

<p><a id=RNDINTEXC_Random_Integers_in_0_N></a></p>

<h3><code>RNDINTEXC</code>: Random Integers in [0, N)</h3>

<p><code>RNDINTEXC(maxExclusive)</code>, which generates a <strong>random integer in the interval</strong> <strong>[0, <code>maxExclusive</code>)</strong>, can be implemented as follows<sup><a href="#Note3"><strong>(3)</strong></a></sup>:</p>

<pre> METHOD RNDINTEXC(maxExclusive)
    if maxExclusive &lt;= 0: return error
    return RNDINT(maxExclusive - 1)
 END METHOD
</pre>

<blockquote>
<p><strong>Note:</strong> <code>RNDINTEXC</code> is not given as the core random generation method because it&#39;s harder to fill integers in popular integer formats with random bits with this method.</p>

<p><strong>Example:</strong> Generating a random number in the interval [<code>mn</code>, <code>mx</code>) in increments equal to <code>step</code> is equivalent to generating <code>mn+step*RNDINTEXC(ceil((mx-mn)/(1.0*step)))</code>.</p>
</blockquote>

<p><a id=RNDINTEXCRANGE_Random_Integers_in_N_M></a></p>

<h3><code>RNDINTEXCRANGE</code>: Random Integers in [N, M)</h3>

<p><strong><code>RNDINTEXCRANGE</code></strong> returns a <strong>random integer in the interval</strong> <strong>[<code>minInclusive</code>, <code>maxExclusive</code>)</strong>.  It can be implemented using <a href="#RNDINTRANGE_Random_Integers_in_N_M"><strong><code>RNDINTRANGE</code></strong></a>, as the following pseudocode demonstrates.</p>

<pre>METHOD RNDINTEXCRANGE(minInclusive, maxExclusive)
   if minInclusive &gt;= maxExclusive: return error
   if minInclusive &gt;=0
     return RNDINTRANGE(minInclusive, maxExclusive - 1)
   end
   while true
     ret = RNDINTRANGE(minInclusive, maxExclusive)
     if ret &lt; maxExclusive: return ret
   end
END METHOD
</pre>

<p><a id=Uniform_Random_Bits></a></p>

<h3>Uniform Random Bits</h3>

<p>The idiom <code>RNDINT((1 &lt;&lt; b) - 1)</code> is a na&iuml;ve way of generating a <strong>uniform random <code>b</code>-bit integer</strong> (with maximum 2<sup><code>b</code></sup> - 1).</p>

<p>In practice, memory is usually divided into <em>bytes</em>, or 8-bit nonnegative integers in the interval [0, 255].  In this case, a block of memory can be filled with random bits by setting each byte in the block to <code>RNDINT(255)</code>. (There may be faster, RNG-specific ways to fill memory with random bytes, such as with RNGs that generate random numbers in parallel.  These ways are not detailed in this document.)</p>

<p><a id=Certain_Programming_Environments></a></p>

<h3>Certain Programming Environments</h3>

<p>For certain programming environments, there are special considerations:</p>

<ul>
<li>Shell scripts and Microsoft Windows batch files are designed for running other programs, rather than general-purpose programming.  However, batch files and <code>bash</code> (a shell script interpreter) might support a variable which returns a random integer in the interval [0, 32767] (called <code>%RANDOM%</code> or <code>$RANDOM</code>, respectively); neither variable is designed for information security.</li>
<li>Query languages such as SQL have no procedural elements such as loops and branches.  Moreover, standard SQL does not include an RNG in its suite of functionality, but popular SQL dialects often do &mdash; with idiosyncratic behavior.<sup><a href="#Note4"><strong>(4)</strong></a></sup></li>
</ul>

<p>Whenever possible, the methods in this document should be implemented in a more general-purpose programming language than query languages, shell scripts, and batch files, especially if information security is a goal.</p>

<p><a id=Randomization_Techniques></a></p>

<h2>Randomization Techniques</h2>

<p>This section describes commonly used randomization techniques, such as shuffling, selection of several unique items, and creating random strings of text.</p>

<p><a id=Boolean_True_False_Conditions></a></p>

<h3>Boolean (True/False) Conditions</h3>

<p>To generate a condition that is true at the specified probabilities, use
the following idioms in an <code>if</code> condition:</p>

<ul>
<li>True or false with equal probability: <code>RNDINT(1) == 0</code>.</li>
<li>True with X percent probability: <code>RNDINTEXC(100) &lt; X</code>.</li>
<li>True with probability X/Y: <code>RNDINTEXC(Y) &lt; X</code>.</li>
<li>True with odds of X to Y: <code>RNDINTEXC(X + Y) &lt; X</code>.</li>
<li>True with probability P, where P is in the interval [0, 1] (a <em>Bernoulli trial</em>): Convert P to an acceptably close rational number X/Y, then do <code>RNDINTEXC(Y) &lt; X</code>.</li>
</ul>

<blockquote>
<p><strong>Examples:</strong></p>

<ul>
<li>True with probability 3/8: <code>RNDINTEXC(8) &lt; 3</code>.</li>
<li>True with odds of 100 to 1: <code>RNDINTEXC(101) &lt; 1</code>.</li>
<li>True with 20% probability: <code>RNDINTEXC(100) &lt; 20</code>.</li>
</ul>
</blockquote>

<p>The following helper method generates 1 with probability <code>x</code>/<code>y</code> and 0 otherwise:</p>

<pre>METHOD ZeroOrOne(x,y)
  if RNDINTEXC(y)&lt;x: return 1
  return 0
END METHOD
</pre>

<p><a id=Random_Sampling></a></p>

<h3>Random Sampling</h3>

<p>This section contains ways to choose one or more items from among a collection of them, where each item in the collection has the same chance to be chosen as any other.  This is called <em>random sampling</em> and can be done <em>with replacement</em> or <em>without replacement</em>.</p>

<p><a id=Sampling_With_Replacement_Choosing_a_Random_Item_from_a_List></a></p>

<h4>Sampling With Replacement: Choosing a Random Item from a List</h4>

<p><em>Sampling with replacement</em>  essentially means taking a random item and putting it back.  To choose a random item from a list&mdash;</p>

<ul>
<li>whose size is known in advance, use the idiom <code>list[RNDINTEXC(size(list))]</code>; or</li>
<li>whose size is not known in advance, generate <code>RandomKItemsFromFile(file, 1)</code>, in <a href="#Pseudocode_for_Random_Sampling"><strong>pseudocode given later</strong></a> (the result will be a 1-item list or be an empty list if there are no items).</li>
</ul>

<p><a id=Sampling_Without_Replacement_Choosing_Several_Unique_Items></a></p>

<h4>Sampling Without Replacement: Choosing Several Unique Items</h4>

<p><em>Sampling without replacement</em>  essentially means taking a random item <em>without</em> putting it back.   There are several approaches for doing a uniform random choice of <code>k</code> unique items or values from among <code>n</code> available items or values, depending on such things as whether <code>n</code> is known and how big <code>n</code> and <code>k</code> are.</p>

<ol>
<li><strong>If <code>n</code> is not known in advance:</strong> Use the <em>reservoir sampling</em> method; see the <code>RandomKItemsFromFile</code> method, in <a href="#Pseudocode_for_Random_Sampling"><strong>pseudocode given later</strong></a>.</li>
<li><strong>If <code>n</code> is relatively small (for example, if there are 200 available items, or there is a range of numbers from 0 through 200 to choose from):</strong>  If <strong>items are to be chosen from a list in relative order</strong>, then the <code>RandomKItemsInOrder</code> method, in <a href="#Pseudocode_for_Random_Sampling"><strong>pseudocode given later</strong></a>, demonstrates a solution.  Otherwise, one of the following will choose <code>k</code> items <strong>in random order</strong>:

<ul>
<li>Store all the items in a list, <a href="#Shuffling"><strong>shuffle</strong></a> that list, then choose the first <code>k</code> items from that list.</li>
<li>If the items are already stored in a list and the list&#39;s order can be changed, then shuffle that list and choose the first <code>k</code> items from the shuffled list.</li>
<li>If the items are already stored in a list and the list&#39;s order can&#39;t be changed, then store the indices to those items in another list, shuffle the latter list, then choose the first <code>k</code> indices (or the items corresponding to those indices) from the latter list.</li>
<li>If <code>k</code> is much smaller than <code>n</code>, proceed as in item 3 instead.</li>
</ul></li>
<li><strong>If <code>k</code> is much smaller than <code>n</code>:</strong>  The first three cases below will choose <code>k</code> items in random order:

<ul>
<li><strong>If the items are stored in a list whose order can be changed:</strong> Do a <em>partial shuffle</em> of that list, then choose the <em>last</em> <code>k</code> items from that list.  A <em>partial shuffle</em> proceeds as given in the section &quot;<a href="#Shuffling"><strong>Shuffling</strong></a>&quot;, except the partial shuffle stops after <code>k</code> swaps have been made (where swapping one item with itself counts as a swap).</li>
<li>Otherwise, <strong>if the items are stored in a list and <code>n</code> is not very large (for example, less than 5000):</strong> Store the indices to those items in another list, do a <em>partial shuffle</em> of the latter list, then choose the <em>last</em> <code>k</code> indices (or the items corresponding to those indices) from the latter list.</li>
<li>Otherwise, <strong>if <code>n</code> is not very large:</strong> Store all the items in a list, do a <em>partial shuffle</em> of that list, then choose the <em>last</em> <code>k</code> items from that list.</li>
<li>Otherwise, see item 5.</li>
</ul></li>
<li><strong>If <code>n - k</code> is much smaller than <code>n</code> and the sampled items need not be in random order:</strong>  Proceed as in step 3, except the partial shuffle involves <code>n - k</code> swaps and the <em>first</em> <code>k</code> items are chosen rather than the last <code>k</code>.</li>
<li><p><strong>Otherwise (for example, if 32-bit or larger integers will be chosen so that <code>n</code> is 2<sup>32</sup>, or if <code>n</code> is otherwise very large):</strong> Create a data structure to store the indices to items already chosen.  When a new index to an item is randomly chosen, add it to the data structure if it&#39;s not already there, or if it is, choose a new random index.  Repeat this process until <code>k</code> indices were added to the data structure this way.  Examples of suitable data structures are&mdash;</p>

<ul>
<li>a <a href="https://en.wikipedia.org/wiki/Hash_table"><strong>hash table</strong></a>,</li>
<li>a compressed bit set (e.g, &quot;roaring bitmap&quot;, EWAH), and</li>
<li>a self-sorting data structure such as a <a href="https://en.wikipedia.org/wiki/Red%E2%80%93black_tree"><strong>red&ndash;black tree</strong></a>, if the random items are to be retrieved in sorted order or in index order.</li>
</ul>

<p>Many applications require generating unique random numbers to identify database records or other shared resources.  In this case, the choice of underlying RNG is important; see my <a href="https://peteroupc.github.io/random.html#Unique_Random_Identifiers"><strong>RNG recommendation document</strong></a>.</p></li>
</ol>

<p><a id=Shuffling></a></p>

<h4>Shuffling</h4>

<p>The <a href="https://en.wikipedia.org/wiki/Fisher-Yates_shuffle"><strong>Fisher&ndash;Yates shuffle method</strong></a> shuffles a list (puts its items in a random order) such that all permutations (arrangements) of that list are equally likely to occur, assuming the RNG it uses can choose any one of those permutations.  However, that method is also easy to write incorrectly &mdash; see also (Atwood 2007)<sup><a href="#Note5"><strong>(5)</strong></a></sup>.  The following pseudocode is designed to shuffle a list&#39;s contents.</p>

<pre>METHOD Shuffle(list)
   // NOTE: Check size of the list early to prevent
   // `i` from being less than 0 if the list&#39;s size is 0 and
   // `i` is implemented using an nonnegative integer
   // type available in certain programming languages.
   if size(list) &gt;= 2
      // Set i to the last item&#39;s index
      i = size(list) - 1
      while i &gt; 0
         // Choose an item ranging from the first item
         // up to the item given in `i`. Note that the item
         // at i+1 is excluded.
         k = RNDINTEXC(i + 1)
         // The following is wrong since it introduces biases:
         // &quot;k = RNDINTEXC(size(list))&quot;
         // The following is wrong since the algorithm won&#39;t
         // choose from among all possible permutations:
         // &quot;k = RNDINTEXC(i)&quot;
         // Swap item at index i with item at index k;
         // in this case, i and k may be the same
         tmp = list[i]
         list[i] = list[k]
         list[k] = tmp
         // Move i so it points to the previous item
         i = i - 1
      end
   end
   // NOTE: An implementation can return the
   // shuffled list, as is done here, but this is not required.
   return list
END METHOD
</pre>

<p>The choice of underlying RNG is important when it comes to shuffling; see my <a href="https://peteroupc.github.io/random.html#Shuffling"><strong>RNG recommendation document on shuffling</strong></a>.</p>

<p><a id=Random_Character_Strings></a></p>

<h4>Random Character Strings</h4>

<p>To generate a random string of characters:</p>

<ol>
<li>Generate a list of the letters, digits, and/or other characters the string can have.  Examples are given later in this section.</li>
<li>Build a new string whose characters are chosen from that character list.  The pseudocode below demonstrates this by creating a list, rather than a string, where the random characters will be held.  It also takes the number of characters as a parameter named <code>stringSize</code>.  (How to convert this list to a text string depends on the programming language and is outside the scope of this page.)</li>
</ol>

<p>&nbsp;</p>

<pre>METHOD RandomString(characterList, stringSize)
  i = 0
  newString = NewList()
  while i &lt; stringSize
    // Choose a character from the list
    randomChar = characterList[RNDINTEXC(size(characterList))]
    // Add the character to the string
    AddItem(newString, randomChar)
    i = i + 1
  end
  return newString
END METHOD
</pre>

<p>The following are examples of character lists:</p>

<ol>
<li>For an <em>alphanumeric string</em>, or string of letters and digits, the characters can be the basic digits &quot;0&quot; to &quot;9&quot; (U+0030-U+0039, nos. 48-57), the basic upper case letters &quot;A&quot; to &quot;Z&quot; (U+0041-U+005A, nos. 65-90), and the basic lower case letters &quot;a&quot; to &quot;z&quot; (U+0061-U+007A, nos. 96-122), as given in the Unicode Standard.</li>
<li>For a base-10 digit string, the characters can be the basic digits only.</li>
<li>For a base-16 digit (hexadecimal) string, the characters can be the basic digits as well as the basic letters &quot;A&quot; to &quot;F&quot; or &quot;a&quot; to &quot;f&quot; (not both).</li>
</ol>

<blockquote>
<p><strong>Notes:</strong></p>

<ol>
<li>If the list of characters is fixed, the list can be created in advance at runtime or compile time, or (if every character takes up the same number of code units) a string type as provided in the programming language can be used to store the list as a string.</li>
<li><strong>Unique random strings:</strong> Often applications need to generate a string of characters that&#39;s not only random, but also unique.  This can be done by storing a list (such as a hash table) of strings already generated and checking newly generated strings against that list.<sup><a href="#Note6"><strong>(6)</strong></a></sup></li>
<li><strong>Word generation:</strong> This technique could also be used to generate &quot;pronounceable&quot; words, but this is less flexible than other approaches; see also &quot;<a href="#Weighted_Choice_With_Replacement"><strong>Weighted Choice With Replacement</strong></a>&quot;.</li>
</ol>
</blockquote>

<p><a id=Pseudocode_for_Random_Sampling></a></p>

<h4>Pseudocode for Random Sampling</h4>

<p>The following pseudocode implements two methods:</p>

<ol>
<li><code>RandomKItemsFromFile</code> implements <a href="https://en.wikipedia.org/wiki/Reservoir_sampling"><strong><em>reservoir sampling</em></strong></a>; it chooses up to <code>k</code> random items from a file of indefinite size (<code>file</code>). Although the pseudocode refers to files and lines, the technique applies to any situation when items are retrieved one at a time from a data set or list whose size is not known in advance.  See the comments to find out how <code>RandomKItemsFromFile</code> can be used to choose an item at random only if it meets certain criteria (see &quot;<a href="#Rejection_Sampling"><strong>Rejection Sampling</strong></a>&quot; for example criteria).</li>
<li><code>RandomKItemsInOrder</code> returns a list of up to <code>k</code> random items from the given list (<code>list</code>), in the order in which they appeared in the list.  It is based on a technique presented in Devroye 1986, p. 620.</li>
</ol>

<p>&nbsp;</p>

<pre>METHOD RandomKItemsFromFile(file, k)
  list = NewList()
  j = 0
  index = 0
  while true
    // Get the next line from the file
    item = GetNextLine(file)
    thisIndex = index
    index = index + 1
    // If the end of the file was reached, break
    if item == nothing: break
    // NOTE 1: The following line is OPTIONAL
    // and can be used to choose only random lines
    // in the file that meet certain criteria,
    // expressed as MEETS_CRITERIA below.
    // ------
    // if not MEETS_CRITERIA(item): continue
    // ------
    if j &lt; k // phase 1 (fewer than k items)
      AddItem(list, item)
      // NOTE 2: To add the line number (starting at
      // 0) rather than the item, use the following
      // line instead of the previous one:
      // AddItem(list, thisIndex)
      j = j + 1
    else // phase 2
      j = RNDINT(thisIndex)
      if j &lt; k: list[j] = item
      // NOTE 3: To add the line number (starting at
      // 0) rather than the item, use the following
      // line instead of the previous one:
      // if j &lt; k: list[j] = thisIndex
    end
  end
  // NOTE 4: We shuffle at the end in case k or
  // fewer lines were in the file, since in that
  // case the items would appear in the same
  // order as they appeared in the file
  // if the list weren&#39;t shuffled.  This line
  // can be removed, however, if the items
  // in the returned list need not appear
  // in random order.
  if size(list)&gt;=2: Shuffle(list)
  return list
end

METHOD RandomKItemsInOrder(list, k)
  i = 0
  kk = k
  ret = NewList()
  n = size(list)
  while i &lt; n and size(ret) &lt; k
    u = RNDINTEXC(n - i)
    if u &lt;= kk
      AddItem(ret, list[i])
      kk = kk - 1
    end
    i = i + 1
  end
  return ret
END METHOD
</pre>

<blockquote>
<p><strong>Examples:</strong></p>

<ol>
<li>Assume a file (<code>file</code>) has the lines <code>&quot;f&quot;</code>, <code>&quot;o&quot;</code>, <code>&quot;o&quot;</code>, <code>&quot;d&quot;</code>, in that order.  If we modify <code>RandomKItemsFromFile</code> as given in notes 2 and 3 there, and treat <code>MEETS_CRITERIA(item)</code> above as <code>item == &quot;o&quot;</code> (in note 1 of that method), then we can choose a random line number of an &quot;o&quot; line by <code>RandomKItemsFromFile(file, 1)</code>.</li>
<li>Removing <code>k</code> random items from a list of <code>n</code> items (<code>list</code>) is equivalent to generating a new
list by <code>RandomKItemsInOrder(list, n - k)</code>.</li>
<li><strong>Filtering:</strong> If an application needs to sample the same list (with or without replacement) repeatedly, but only from among a selection of that list&#39;s items, it can create a list of items it wants to sample from (or a list of indices to those items), and sample from the new list instead.<sup><a href="#Note7"><strong>(7)</strong></a></sup>  This won&#39;t work well, though, for lists of indefinite or very large size.</li>
</ol>
</blockquote>

<p><a id=Rejection_Sampling></a></p>

<h3>Rejection Sampling</h3>

<p><em>Rejection sampling</em> is a simple and flexible approach for generating random content that meets certain requirements.  To implement rejection sampling:</p>

<ol>
<li>Generate the random content (such as a random number) by any method and with any distribution and range.</li>
<li>If the content doesn&#39;t meet predetermined criteria, go to step 1.</li>
</ol>

<p>Example criteria include checking&mdash;</p>

<ul>
<li>whether a random number is prime,</li>
<li>whether a random number is divisible or not by certain numbers,</li>
<li>whether a random number is not among recently chosen random numbers,</li>
<li>whether a random number was not already chosen (with the aid of a hash table, red-black tree, or similar structure),</li>
<li>whether a random number was not chosen more often in a row than desired,</li>
<li>whether a random point is sufficiently distant from previous random points (with the aid of a KD-tree or similar structure),</li>
<li>whether a random string matches a regular expression,</li>
<li>whether a random number is not included in a &quot;blacklist&quot; of numbers, or</li>
<li>two or more of the foregoing criteria.</li>
</ul>

<p>(KD-trees, hash tables, red-black trees, prime-number testing algorithms, and regular expressions are outside the scope of this document.)</p>

<p><a id=Random_Walks></a></p>

<h3>Random Walks</h3>

<p>A <em>random walk</em> is a process with random behavior over time.  A simple form of random walk involves generating a random number that changes the state of the walk.  The pseudocode below generates a random walk of <em>n</em> random numbers, where <code>STATEJUMP()</code> is the next number to add to the current state (see examples later in this section).</p>

<pre>METHOD RandomWalk(n)
  // Create a new list with an initial state
  list=[0]
  // Add &#39;n&#39; new numbers to the list.
  for i in 0...n: AddItem(list, list[i] + STATEJUMP())
  return list
END METHOD
</pre>

<blockquote>
<p><strong>Note:</strong> A <strong>white noise process</strong> is simulated by creating a list of random numbers generated independently and in the same way.  Such a process generally models behavior over time that does not depend on the time or the current state.  One example is <code>ZeroOrOne(px,py)</code> (for modeling a <em>Bernoulli process</em>, where each number is 0 or 1 depending on the probability <code>px</code>/<code>py</code>).</p>

<p><strong>Examples:</strong></p>

<ol>
<li>If <code>STATEJUMP()</code> is <code>RNDINT(1) * 2 - 1</code>, the random walk generates numbers that each differ from the last by -1 or 1, chosen at random.</li>
<li>If <code>STATEJUMP()</code> is <code>ZeroOrOne(px,py) * 2 - 1</code>, the random walk generates numbers that each differ from the last by -1 or 1 depending on the probability <code>px</code>/<code>py</code>.</li>
<li><strong>Binomial process:</strong> If <code>STATEJUMP()</code> is <code>ZeroOrOne(px,py)</code>, the random walk advances the state with probability <code>px</code>/<code>py</code>.</li>
</ol>
</blockquote>

<p><a id=Randomization_in_Statistical_Testing></a></p>

<h3>Randomization in Statistical Testing</h3>

<p>Statistical testing uses shuffling and <em>bootstrapping</em> to help draw conclusions on data through randomization.</p>

<ul>
<li><a href="#Shuffling"><strong>Shuffling</strong></a> is used when each item in a data set belongs to one of several mutually exclusive groups.  Here, one or more <strong>simulated data sets</strong> are generated by shuffling the original data set and regrouping each item in the shuffled data set in order, such that the number of items in each group for the simulated data set is the same as for the original data set.</li>
<li><a href="https://en.wikipedia.org/wiki/Bootstrapping_%28statistics%29"><strong><em>Bootstrapping</em></strong></a> is a method of creating one or more random samples (simulated data sets) of an existing data set, where the items in each sample are chosen <a href="#Sampling_With_Replacement_Choosing_a_Random_Item_from_a_List"><strong>at random with replacement</strong></a>.  (Each random sample can contain duplicates this way.)  See also (Brownlee 2018)<sup><a href="#Note8"><strong>(8)</strong></a></sup>.</li>
</ul>

<p>After creating the simulated data sets, one or more statistics, such as the mean, are calculated for each simulated data set as well as the original data set, then the statistics for the simulated data sets are compared with those of the original (such comparisons are outside the scope of this document).</p>

<p><a id=A_Note_on_Sorting_Random_Numbers></a></p>

<h3>A Note on Sorting Random Numbers</h3>

<p>In general, sorting random numbers is no different from sorting any other data. (Sorting algorithms are outside this document&#39;s scope.) <sup><a href="#Note9"><strong>(9)</strong></a></sup></p>

<p><a id=General_Non_Uniform_Distributions></a></p>

<h2>General Non-Uniform Distributions</h2>

<p>Some applications need to choose random items or numbers such that some of them are more likely to be chosen than others (a <em>non-uniform</em> distribution). Most of the techniques in this section show how to use the <a href="#Uniform_Random_Numbers"><strong>uniform random number methods</strong></a> to generate such random items or numbers.</p>

<p><a id=Weighted_Choice></a></p>

<h3>Weighted Choice</h3>

<p>The weighted choice method generates a random item or number from among a collection of them with separate probabilities of each item or number being chosen.  There are several kinds of weighted choice.</p>

<p><a id=Weighted_Choice_With_Replacement></a></p>

<h4>Weighted Choice With Replacement</h4>

<p>The first kind is called weighted choice <em>with replacement</em> (which can be thought of as drawing a ball, then putting it back), where the probability of choosing each item doesn&#39;t change as items are chosen.</p>

<p>The following pseudocode implements a method <code>WeightedChoice</code> that takes a single list <code>weights</code> of weights (integers 0 or greater), and returns the index of a weight from that list.  The greater the weight, the more likely its index will be chosen.</p>

<pre>METHOD WeightedChoice(weights)
    if size(weights) == 0: return error
    msum = 0
    // Get the sum of all weights
    // NOTE: Kahan summation is more robust
    // than the naive summing given here
    i = 0
    while i &lt; size(weights)
        msum = msum + weights[i]
        i = i + 1
    end
    // Choose a random integer from 0 and less than
    // the sum of weights.
    value = RNDINTEXC(sum)
    // Choose the object according to the given value
    i = 0
    lastItem = size(weights) - 1
    runningValue = 0
    while i &lt; size(weights)
       if weights[i] &gt; 0
          newValue = runningValue + weights[i]
          lastItem = i
          // NOTE: Includes start, excludes end
          if value &lt; newValue: break
          runningValue = newValue
       end
       i = i + 1
    end
    // If we didn&#39;t break above, this is a last
    // resort (might happen because rounding
    // error happened somehow)
    return lastItem
END METHOD
</pre>

<blockquote>
<p><strong>Note:</strong> The Python sample code contains a variant of this
method for generating multiple random points in one call.</p>

<p><strong>Examples:</strong></p>

<ol>
<li>Assume we have the following list: <code>[&quot;apples&quot;, &quot;oranges&quot;, &quot;bananas&quot;, &quot;grapes&quot;]</code>, and <code>weights</code> is the following: <code>[3, 15, 1, 2]</code>.  The weight for &quot;apples&quot; is 3, and the weight for &quot;oranges&quot; is 15.  Since &quot;oranges&quot; has a higher weight than &quot;apples&quot;, the index for &quot;oranges&quot; (1) is more likely to be chosen than the index for &quot;apples&quot; (0) with the <code>WeightedChoice</code> method.  The following idiom implements how to get a randomly chosen item from the list with that method: <code>item = list[WeightedChoice(weights)]</code>.</li>
<li>Assume the weights from example 1 are used and the list contains ranges of numbers instead of strings: <code>[[0, 5], [5, 10], [10, 11], [11, 13]]</code>.  After a random range is chosen, an independent uniform number is chosen randomly within the chosen range (including the lower bound but not the upper bound).  For example, code like the following chooses a random integer this way: <code>number = RNDINTEXCRANGE(item[0], item[1])</code>. (See also &quot;<a href="#Mixtures_of_Distributions"><strong>Mixtures of Distributions</strong></a>&quot;.)</li>
<li><strong>Piecewise constant distribution.</strong> Assume the weights from example 1 are used and the list contains the following: <code>[0, 5, 10, 11, 13]</code> (one more item than the weights).  This expresses four ranges, the same as in example 2.  After a random index is chosen with <code>index = WeightedChoice(weights)</code>, an independent uniform number is chosen randomly within the corresponding range (including the lower bound but not the upper bound).  For example, code like the following chooses a random integer this way: <code>number = RNDINTEXCRANGE(list[index], list[index + 1])</code>.</li>
<li>A <a href="https://en.wikipedia.org/wiki/Markov_chain"><strong>Markov chain</strong></a> models one or more <em>states</em> (for example, individual letters or syllables), and stores the probabilities to transition from one state to another (e.g., &quot;b&quot; to &quot;e&quot; with a chance of 20 percent, or &quot;b&quot; to &quot;b&quot; with a chance of 1 percent).  Thus, each state can be seen as having its own list of <em>weights</em> for each relevant state transition.  For example, a Markov chain for generating <strong>&quot;pronounceable&quot; words</strong>, or words similar to natural-language words, can include &quot;start&quot; and &quot;stop&quot; states for the start and end of the word, respectively.</li>
</ol>
</blockquote>

<p><a id=Weighted_Choice_Without_Replacement_Multiple_Copies></a></p>

<h4>Weighted Choice Without Replacement (Multiple Copies)</h4>

<p>For positive integer weights, to implement weighted choice <em>without replacement</em> (which can be thought of as drawing a ball <em>without</em> putting it back), generate an index by <code>WeightedChoice</code>, and then decrease the weight for the chosen index by 1.  In this way, <strong>each weight behaves like the number of &quot;copies&quot; of each item</strong>. The pseudocode below is an example of this.</p>

<pre>// Get the sum of weights.
// NOTE: This code assumes--
// - that `weights` is a list that can be modified,
// - that all the weights are integers 0 or greater, and
// - that `list`, a list of items, was already
//   declared earlier and has at least as many
//   items as `weights`.
// If the original weights are needed for something
// else, a copy of that list should be made first,
// but the copying process is not shown here.
totalWeight = 0
i = 0
while i &lt; size(weights)
    totalWeight = totalWeight + weights[i]
    i = i + 1
end
// Choose as many items as the sum of weights
i = 0
items = NewList()
while i &lt; totalWeight
    index = WeightedChoice(weights)
    // Decrease weight by 1 to implement selection
    // without replacement.
    weights[index] = weights[index] - 1
    AddItem(items, list[index])
    i = i + 1
end
</pre>

<p>Alternatively, if all the weights are integers 0 or greater and their sum is relatively small, create a list with as many copies of each item as its weight, then <a href="#Shuffling"><strong>shuffle</strong></a> that list.  The resulting list will be ordered in a way that corresponds to a weighted random choice without replacement.</p>

<blockquote>
<p><strong>Note:</strong> The weighted sampling described in this section can be useful to some applications (particularly some games) that wish to control which random numbers appear, to make the random outcomes appear fairer to users (e.g., to avoid long streaks of good outcomes or of bad outcomes).  When used for this purpose, each item represents a different outcome (e.g., &quot;good&quot; or &quot;bad&quot;), and the lists are replenished once no further items can be chosen.  However, this kind of sampling should not be used for this purpose whenever information security (ISO/IEC 27000) is involved, including when predicting future random numbers would give a player or user a significant and unfair advantage.</p>
</blockquote>

<p><a id=Weighted_Choice_Without_Replacement_Single_Copies></a></p>

<h4>Weighted Choice Without Replacement (Single Copies)</h4>

<p>Weighted choice can also choose items from a list, where each item has a separate probability of being chosen and <strong>can be chosen no more than once</strong>.  In this case, after choosing a random index, set the weight for that index to 0 to keep it from being chosen again.  The pseudocode below is an example of this.</p>

<pre>// NOTE: This code assumes--
// - that `weights` is a list that can be modified, and
// - that `list`, a list of items, was already
//   declared earlier and has at least as many
//   items as `weights`.
// If the original weights are needed for something
// else, a copy of that list should be made first,
// but the copying process is not shown here.
chosenItems = NewList()
i = 0
// Choose k items from the list
while i &lt; k or i &lt; size(weights)
    index = WeightedChoice(weights)
    // Set the weight for the chosen index to 0
    // so it won&#39;t be chosen again
    weights[index] = 0
    // Add the item at the chosen index
    AddItem(chosenItems, list[index])
end
// `chosenItems` now contains the items chosen
</pre>

<p>The technique presented here can solve the problem of sorting a list of items such that higher-weighted items are more likely to appear first.</p>

<p><a id=Mixtures_of_Distributions></a></p>

<h3>Mixtures of Distributions</h3>

<p>A <em>mixture</em> consists of two or more probability distributions with separate probabilities of being sampled. To generate random content from a mixture&mdash;</p>

<ol>
<li>generate <code>index = WeightedChoice(weights)</code>, where <code>weights</code> is a list of relative probabilities that each distribution in the mixture will be sampled, then</li>
<li>based on the value of <code>index</code>, generate the random content from the corresponding distribution.</li>
</ol>

<blockquote>
<p><strong>Examples:</strong></p>

<ol>
<li><p>One mixture consists of the sum of three six-sided virtual die rolls and the result of one six-sided die roll, but there is an 80% chance to roll one six-sided virtual die rather than three.  The following pseudocode shows how this mixture can be sampled:</p>

<pre>index = WeightedChoice([80, 20])
number = 0
// If index 0 was chosen, roll one die
if index==0: number = RNDINTRANGE(1,6)
// Else index 1 was chosen, so roll three dice
else: number = RNDINTRANGE(1,6) +
   RNDINTRANGE(1,6) + RNDINTRANGE(1,6)
</pre></li>
<li><p>Choosing, independently and uniformly, a random point from a complex shape (in any number of dimensions) is equivalent to doing such sampling from a mixture of simpler shapes that make up the complex shape (here, the <code>weights</code> list holds the n-dimensional &quot;volume&quot; of each simpler shape).  For example, a simple closed 2D polygon can be <a href="https://en.wikipedia.org/wiki/Polygon_triangulation"><strong><em>triangulated</em></strong></a>, or decomposed into <a href="#Random_Points_Inside_a_Simplex"><strong>triangles</strong></a>, and a mixture of those triangles can be sampled.<sup><a href="#Note10"><strong>(10)</strong></a></sup></p></li>
<li>Take a set of nonoverlapping integer ranges.  To choose a random integer from those ranges independently and uniformly:

<ul>
<li>Create a list (<code>weights</code>) of weights for each range.  Each range is given a weight of <code>(mx - mn) + 1</code>, where <code>mn</code> is that range&#39;s minimum and <code>mx</code> is its maximum.</li>
<li>Choose an index using <code>WeightedChoice(weights)</code>, then generate <code>RNDINTRANGE(mn, mx)</code>, where <code>mn</code> is the corresponding range&#39;s minimum and <code>mx</code> is its maximum.</li>
</ul></li>
</ol>
</blockquote>

<p><a id=Transformations_of_Random_Numbers></a></p>

<h3>Transformations of Random Numbers</h3>

<p>Random numbers can be generated by combining and/or transforming one or more random numbers and/or discarding some of them.</p>

<p>As an example, <a href="http://www.redblobgames.com/articles/probability/damage-rolls.html"><strong>&quot;Probability and Games: Damage Rolls&quot;</strong></a> by Red Blob Games includes interactive graphics showing score distributions for lowest-of, highest-of, drop-the-lowest, and reroll game mechanics.<sup><a href="#Note11"><strong>(11)</strong></a></sup>  These and similar distributions can be generalized as follows.</p>

<p>Generate one or more random numbers, each with a separate probability distribution, then<sup><a href="#Note12"><strong>(12)</strong></a></sup>:</p>

<ol>
<li><strong>Highest-of:</strong>  Choose the highest generated number.</li>
<li><strong>Drop-the-lowest:</strong>  Add all generated numbers except the lowest.</li>
<li><strong>Reroll-the-lowest:</strong>  Add all generated numbers except the lowest, then add a number generated randomly by a separate probability distribution.</li>
<li><strong>Lowest-of:</strong>  Choose the lowest generated number.</li>
<li><strong>Drop-the-highest:</strong>  Add all generated numbers except the highest.</li>
<li><strong>Reroll-the-highest:</strong>  Add all generated numbers except the highest, then add a number generated randomly by a separate probability distribution.</li>
<li><strong>Sum:</strong> Add all generated numbers.</li>
<li><strong>Mean:</strong> Find the mean of all generated numbers.</li>
<li><strong>Geometric transformation:</strong> Treat the numbers as an <em>n</em>-dimensional point, then apply a geometric transformation, such as a rotation or other <em>affine transformation</em><sup><a href="#Note13"><strong>(13)</strong></a></sup>, to that point.</li>
</ol>

<p>If the probability distributions are the same, then strategies 1 to 3 make higher numbers more likely, and strategies 4 to 6, lower numbers.</p>

<blockquote>
<p><strong>Note:</strong> Variants of strategy 4 &mdash; e.g., choosing the second-, third-, or nth-lowest number &mdash; are formally called second-, third-, or nth-<strong>order statistics distributions</strong>, respectively.</p>

<p><strong>Examples:</strong></p>

<ol>
<li>The idiom <code>min(RNDINTRANGE(1, 6), RNDINTRANGE(1, 6))</code> takes the lowest of two six-sided die results (strategy 4).  Due to this approach, 1 is more likely to occur than 6.</li>
<li>The idiom <code>RNDINTRANGE(1, 6) + RNDINTRANGE(1, 6)</code> takes the result of two six-sided dice (see also &quot;<a href="#Dice"><strong>Dice</strong></a>&quot;) (strategy 7).</li>
<li>A <a href="#Binomial_Distribution_Optimization_for_Many_Trials"><strong>binomial distribution</strong></a> models the sum of <code>n</code> random numbers each generated by <code>ZeroOrOne(px,py)</code> (strategy 7), that is, the number of successes in <code>n</code> independent trials, each with a success probability of <code>px</code>/<code>py</code>.<sup><a href="#Note14"><strong>(14)</strong></a></sup></li>
</ol>
</blockquote>

<p><a id=Censored_and_Truncated_Random_Numbers></a></p>

<h4>Censored and Truncated Random Numbers</h4>

<p>To generate a <em>censored</em> random number, generate a random number as usual, then&mdash;</p>

<ul>
<li>if that number is less than a minimum threshold, use the minimum threshold instead, and/or</li>
<li>if that number is greater than a maximum threshold, use the maximum threshold instead.</li>
</ul>

<p>To generate a <em>truncated</em> random number, generate random numbers as usual until a number generated this way is not less than a minimum threshold, not greater than a maximum threshold, or both.</p>

<p><a id=Specific_Non_Uniform_Distributions></a></p>

<h2>Specific Non-Uniform Distributions</h2>

<p>This section contains information on some of the most common non-uniform probability distributions.</p>

<p><a id=Dice></a></p>

<h3>Dice</h3>

<p>The following method generates a random result of rolling virtual dice. It takes three parameters: the number of dice (<code>dice</code>), the number of sides in each die (<code>sides</code>), and a number to add to the result (<code>bonus</code>) (which can be negative, but the result of the subtraction is 0 if that result is greater).</p>

<pre>METHOD DiceRoll(dice, sides, bonus)
    if dice &lt; 0 or sides &lt; 1: return error
    ret = 0
    for i in 0...dice: ret=ret+RNDINTRANGE(1, sides)
    return max(0, ret + bonus)
END METHOD
</pre>

<blockquote>
<p><strong>Examples:</strong> The result of rolling&mdash;</p>

<ul>
<li>four six-sided virtual dice (&quot;4d6&quot;) is <code>DiceRoll(4,6,0)</code>,</li>
<li>three ten-sided virtual dice, with 4 added (&quot;3d10 + 4&quot;), is <code>DiceRoll(3,10,4)</code>, and</li>
<li>two six-sided virtual dice, with 2 subtracted (&quot;2d6 - 2&quot;), is <code>DiceRoll(2,6,-2)</code>.</li>
</ul>
</blockquote>

<p><a id=Hypergeometric_Distribution></a></p>

<h3>Hypergeometric Distribution</h3>

<p>The following method generates a random integer that follows a <em>hypergeometric distribution</em>.  When a given number of items are drawn at random without replacement from a collection of items each labeled either <code>1</code> or <code>0</code>,  the random integer expresses the number of items drawn this way that are labeled <code>1</code>.  In the method below, <code>trials</code> is the number of items drawn at random, <code>ones</code> is the number of items labeled <code>1</code> in the set, and <code>count</code> is the number of items labeled <code>1</code> or <code>0</code> in that set.</p>

<pre>METHOD Hypergeometric(trials, ones, count)
    if ones &lt; 0 or count &lt; 0 or trials &lt; 0 or
       ones &gt; count or trials &gt; count
      return error
    end
    if ones == 0: return 0
    successes = 0
    i = 0
    currentCount = count
    currentOnes = ones
    while i &lt; trials and currentOnes &gt; 0
      if RNDINTEXC(currentCount) &lt; currentOnes
        currentOnes = currentOnes - 1
        successes = successes + 1
      end
      currentCount = currentCount - 1
      i = i + 1
    end
    return successes
END METHOD
</pre>

<blockquote>
<p><strong>Example:</strong> In a 52-card deck of Anglo-American playing cards, 12 of the cards are face cards (jacks, queens, or kings).  After the deck is shuffled and seven cards are drawn, the number of face cards drawn this way follows a hypergeometric distribution where <code>trials</code> is 7, <code>ones</code> is
12, and <code>count</code> is 52.</p>
</blockquote>

<p><a id=Random_Integers_with_a_Given_Positive_Sum></a></p>

<h3>Random Integers with a Given Positive Sum</h3>

<p>The following pseudocode shows how to generate integers with a given positive sum, where the combination is chosen uniformly at random from among all possible combinations. (The algorithm for this was presented in (Smith and Tromble 2004)<sup><a href="#Note15"><strong>(15)</strong></a></sup>.)  In the pseudocode below&mdash;</p>

<ul>
<li>the method <code>PositiveIntegersWithSum</code> returns <code>n</code> integers greater than 0 that sum to <code>total</code>,</li>
<li>the method <code>IntegersWithSum</code> returns <code>n</code> integers 0 or greater that sum to <code>total</code>, and</li>
<li><code>Sort(list)</code> sorts the items in <code>list</code> in ascending order (note that sort algorithms are outside the scope of this document).</li>
</ul>

<p>&nbsp;</p>

<pre>METHOD PositiveIntegersWithSum(n, total)
    if n &lt;= 0 or total &lt;=0: return error
    ls = NewList()
    ret = NewList()
    AddItem(ls, 0)
    while size(ls) &lt; n
      c = RNDINTEXCRANGE(1, total)
      found = false
      for j in 1...size(ls)
        if ls[j] == c
          found = true
          break
        end
      end
      if found == false: AddItem(ls, c)
    end
    Sort(ls)
    AddItem(ls, total)
    for i in 1...size(ls): AddItem(ret,
        list[i] - list[i - 1])
    return ret
END METHOD

METHOD IntegersWithSum(n, total)
  if n &lt;= 0 or total &lt;=0: return error
  ret = PositiveIntegersWithSum(n, total + n)
  for i in 0...size(ret): ret[i] = ret[i] - 1
  return ret
END METHOD
</pre>

<blockquote>
<p><strong>Notes:</strong></p>

<ol>
<li>To generate a uniformly randomly chosen combination of <code>N</code> numbers with a given positive average <code>avg</code>, generate a uniformly randomly chosen combination of <code>N</code> numbers with the sum <code>N * avg</code>.</li>
<li>To generate a uniformly randomly chosen combination of <code>N</code> numbers <code>min</code> or greater and with a given positive sum <code>sum</code>, generate a uniformly randomly chosen combination of <code>N</code> numbers with the sum <code>sum - n * min</code>, then add <code>min</code> to each number generated this way.</li>
</ol>
</blockquote>

<p><a id=Multinomial_Distribution></a></p>

<h3>Multinomial Distribution</h3>

<p>The <em>multinomial distribution</em> models the number of times each of several mutually exclusive events happens among a given number of trials, where each event can have a separate probability of happening.  In the pseudocode below, <code>trials</code> is the number of trials, and <code>weights</code> is a list of the relative probabilities of each event.  The method tallies the events as they happen and returns a list (with the same size as <code>weights</code>) containing the number of successes for each event.</p>

<pre>METHOD Multinomial(trials, weights)
    if trials &lt; 0: return error
    // create a list of successes
    list = NewList()
    for i in 0...size(weights): AddItem(list, 0)
    for i in 0...trials
        // Choose an index
        index = WeightedChoice(weights)
        // Tally the event at the chosen index
        list[index] = list[index] + 1
    end
    return list
END METHOD
</pre>

<p><a id=Randomization_with_Real_Numbers></a></p>

<h2>Randomization with Real Numbers</h2>

<p>This section describes randomization methods that use random real numbers, not just random integers.</p>

<p>However, whenever possible, <strong>applications should work with random integers</strong>, rather than other random real numbers.  This is because:</p>

<ul>
<li>Computers can represent integers more naturally than other real numbers, making random integer generation algorithms more portable and more numerically stable than random real number generation algorithms.</li>
<li>No computer can choose from among all real numbers between two others, since there are infinitely many of them.</li>
</ul>

<p><a id=Uniform_Random_Real_Numbers></a></p>

<h3>Uniform Random Real Numbers</h3>

<p>This section defines the following methods that generate uniform random real numbers:</p>

<ul>
<li>Random Numbers in 0-1 Bounded Interval: <code>RNDU01</code>, <code>RNDU01ZeroExc</code>, <code>RNDU01OneExc</code>, <code>RNDU01ZeroOneExc</code>.</li>
<li>Random Numbers in Arbitrary Interval: <code>RNDRANGE</code>, <code>RNDRANGEMinExc</code>, <code>RNDRANGEMaxExc</code>, <code>RNDRANGEMinMaxExc</code>.</li>
</ul>

<p><a id=RNDU01_Family_Random_Numbers_Bounded_by_0_and_1></a></p>

<h4><code>RNDU01</code> Family: Random Numbers Bounded by 0 and 1</h4>

<p>This section defines four methods that generate a <strong>random number bounded by 0 and 1</strong>.  There are several ways to implement each of those four methods; for each method, the ways are ordered from most preferred to least preferred, and <code>X</code> and <code>INVX</code> are defined later.</p>

<ul>
<li><strong><code>RNDU01()</code>, interval [0, 1]</strong>:

<ul>
<li>For Java <code>float</code> or <code>double</code>, use the alternative implementation given later.</li>
<li><code>RNDINT(X) * INVX</code>.</li>
<li><code>RNDINT(X) / X</code>, if the number format can represent <code>X</code>.</li>
</ul></li>
<li><p><strong><code>RNDU01OneExc()</code>, interval [0, 1)</strong>:</p>

<ul>
<li>Generate <code>RNDU01()</code> in a loop until a number other than 1.0 is generated this way.</li>
<li><code>RNDINT(X - 1) * INVX</code>.</li>
<li><code>RNDINTEXC(X) * INVX</code>.</li>
<li><code>RNDINT(X - 1) / X</code>, if the number format can represent <code>X</code>.</li>
<li><code>RNDINTEXC(X) / X</code>, if the number format can represent <code>X</code>.</li>
</ul>

<p>Note that <code>RNDU01OneExc()</code> corresponds to <code>Math.random()</code> in Java and JavaScript.  See also &quot;Generating uniform doubles in the unit interval&quot; in the <a href="http://xoroshiro.di.unimi.it/#remarks"><strong><code>xoroshiro+</code> remarks page</strong></a>.</p></li>
<li><strong><code>RNDU01ZeroExc()</code>, interval (0, 1]</strong>:

<ul>
<li>Generate <code>RNDU01()</code> in a loop until a number other than 0.0 is generated this way.</li>
<li><code>(RNDINT(X - 1) + 1) * INVX</code>.</li>
<li><code>(RNDINTEXC(X) + 1) * INVX</code>.</li>
<li><code>(RNDINT(X - 1) + 1) / X</code>, if the number format can represent <code>X</code>.</li>
<li><code>(RNDINTEXC(X) + 1) / X</code>, if the number format can represent <code>X</code>.</li>
<li><code>1.0 - RNDU01OneExc()</code> (but this is recommended only if the set of numbers <code>RNDU01OneExc()</code> could return &mdash; as opposed to their probability &mdash; is evenly distributed).</li>
</ul></li>
<li><strong><code>RNDU01ZeroOneExc()</code>, interval (0, 1)</strong>:

<ul>
<li>Generate <code>RNDU01()</code> in a loop until a number other than 0.0 or 1.0 is generated this way.</li>
<li><code>(RNDINT(X - 2) + 1) * INVX</code>.</li>
<li><code>(RNDINTEXC(X - 1) + 1) * INVX</code>.</li>
<li><code>(RNDINT(X - 2) + 1) / X</code>, if the number format can represent <code>X</code>.</li>
<li><code>(RNDINTEXC(X - 1) + 1) / X</code>, if the number format can represent <code>X</code>.</li>
</ul></li>
</ul>

<p>In the idioms above:</p>

<ul>
<li><code>X</code> is the highest integer <code>p</code> such that all multiples of <code>1/p</code> in the interval [0, 1] are representable in the number format in question.  For example&mdash;

<ul>
<li>for the 64-bit IEEE 754 binary floating-point format (e.g., Java <code>double</code>), <code>X</code> is 2<sup>53</sup> (9007199254740992),</li>
<li>for the 32-bit IEEE 754 binary floating-point format (e.g., Java <code>float</code>), <code>X</code> is 2<sup>24</sup> (16777216),</li>
<li>for the 64-bit IEEE 754 decimal floating-point format, <code>X</code> is 10<sup>16</sup>, and</li>
<li>for the .NET Framework decimal format (<code>System.Decimal</code>), <code>X</code> is 10<sup>28</sup>.</li>
</ul></li>
<li><code>INVX</code> is the constant 1 divided by <code>X</code>.</li>
</ul>

<p><a id=Alternative_Implementation_for_RNDU01></a></p>

<h4>Alternative Implementation for <code>RNDU01</code></h4>

<p>For Java&#39;s <code>double</code> and <code>float</code> (or generally, any fixed-precision binary floating-point format with fixed exponent range), the following pseudocode for <code>RNDU01()</code> can be used instead. See also (Downey 2007)<sup><a href="#Note16"><strong>(16)</strong></a></sup>.  In the pseudocode below, <code>SIGBITS</code> is the binary floating-point format&#39;s precision (the number of binary digits the format can represent without loss; e.g., 53 for Java&#39;s <code>double</code>).</p>

<pre>METHOD RNDU01()
    e=-SIGBITS
    while true
        if RNDINT(1)==0: e = e - 1
      else: break
    end
    sig = RNDINT((1 &lt;&lt; (SIGBITS - 1)) - 1)
    if sig==0 and RNDINT(1)==0: e = e + 1
    sig = sig + (1 &lt;&lt; (SIGBITS - 1))
    // NOTE: This multiplication should result in
    // a real number, not necessarily an integer;
    // if `e` is sufficiently
    // small, the number might underflow to 0
    // depending on the number format
    return sig * pow(2, e)
END METHOD
</pre>

<p><a id=RNDRANGE_Family_Random_Numbers_in_an_Arbitrary_Interval></a></p>

<h4><code>RNDRANGE</code> Family: Random Numbers in an Arbitrary Interval</h4>

<p><strong><code>RNDRANGE</code></strong> generates a <strong>random number in the interval [<code>minInclusive</code>, <code>maxInclusive</code>]</strong>.</p>

<p>For arbitrary-precision or non-negative number formats, the following pseudocode implements <code>RNDRANGE()</code>.</p>

<pre>METHOD RNDRANGE(minInclusive, maxInclusive)
    if minInclusive &gt; maxInclusive: return error
    return minInclusive + (maxInclusive - minInclusive) * RNDU01()
END METHOD
</pre>

<p>For other number formats (including Java&#39;s <code>double</code> and <code>float</code>), the pseudocode above can overflow if the difference between <code>maxInclusive</code> and <code>minInclusive</code> exceeds the maximum possible value for the format.  For such formats, the following pseudocode for <code>RNDRANGE()</code> can be used instead.  In the pseudocode below, <code>NUM_MAX</code> is the highest possible finite number for the number format.  The pseudocode assumes that the highest possible value is positive and the lowest possible value is negative.</p>

<pre>METHOD RNDRANGE(minInclusive, maxInclusive)
   if minInclusive &gt; maxInclusive: return error
   if minInclusive == maxInclusive: return minInclusive
   // usual: Difference does not exceed maxInclusive
   usual=minInclusive &gt;= 0 or
       minInclusive + NUM_MAX &gt;= maxInclusive
   rng=NUM_MAX
   if usual: rng = (maxInclusive - minInclusive)
   while true
     ret = rng * RNDU01()
     if usual: return minInclusive + ret
     // NOTE: If the number format has positive and negative
     // zero, as is the case for Java `float` and
     // `double` and .NET&#39;s implementation of `System.Decimal`,
     // for example, use the following:
     negative = RNDINT(1) == 0
     if negative: ret = 0 - ret
     if negative and ret == 0: continue
     // NOTE: For fixed-precision fixed-point numbers implemented
     // using number formats that range from [-1-max, max] (such as Java&#39;s
     // `short`, `int`, and `long`), use the following line
     // instead of the preceding three lines, where `QUANTUM` is the
     // smallest representable number greater than 0
     // in the fixed-point format:
     // if RNDINT(1) == 0: ret = (0 - QUANTUM) - ret
     if ret &gt;= minInclusive and ret &lt;= maxInclusive: return ret
   end
END METHOD
</pre>

<p><strong>REMARK:</strong> Multiplying by <code>RNDU01()</code> in both cases above is not ideal, since doing so merely stretches that number to fit the range if the range is greater than 1.  There may be more sophisticated ways to fill the gaps that result this way in <code>RNDRANGE</code>.<sup><a href="#Note17"><strong>(17)</strong></a></sup></p>

<p>Three related methods can be derived from <code>RNDRANGE</code> as follows:</p>

<ul>
<li><strong><code>RNDRANGEMaxExc</code>, interval [<code>mn</code>, <code>mx</code>)</strong>:

<ul>
<li>Generate <code>RNDRANGE(mn, mx)</code> in a loop until a number other than <code>mx</code> is generated this way.  Return an error if <code>mn &gt;= mx</code>.</li>
</ul></li>
<li><strong><code>RNDRANGEMinExc</code>, interval [<code>mn</code>, <code>mx</code>)</strong>:

<ul>
<li>Generate <code>RNDRANGE(mn, mx)</code> in a loop until a number other than <code>mn</code> is generated this way.  Return an error if <code>mn &gt;= mx</code>.</li>
</ul></li>
<li><strong><code>RNDRANGEMinMaxExc</code>, interval (<code>mn</code>, <code>mx</code>)</strong>:

<ul>
<li>Generate <code>RNDRANGE(mn, mx)</code> in a loop until a number other than <code>mn</code> or <code>mx</code> is generated this way.  Return an error if <code>mn &gt;= mx</code>.</li>
</ul></li>
</ul>

<p><a id=Monte_Carlo_Sampling_Expected_Values_Integration_and_Optimization></a></p>

<h3>Monte Carlo Sampling: Expected Values, Integration, and Optimization</h3>

<p><strong>Requires random real numbers.</strong></p>

<p>Randomization is the core of <strong>Monte Carlo sampling</strong>; it can be used to estimate the <strong>expected value</strong> of a function given a random process or sampling distribution.  The following pseudocode estimates the expected value from a list of random numbers generated the same way.  Here, <code>EFUNC</code> is the function, and <code>MeanAndVariance</code> is given in the <a href="#Mean_and_Variance_Calculation"><strong>appendix</strong></a>.  <code>Expectation</code> returns a list of two numbers &mdash; the estimated expected value and its standard error.</p>

<pre>METHOD Expectation(numbers)
  ret=[]
  for i in 0...size(numbers)
     AddItem(ret,EFUNC(numbers[i]))
  end
  merr=MeanAndVariance(ret)
  merr[1]=merr[1]*(size(ret)-1.0)/size(ret)
  merr[1]=sqrt(merr[1]/size(ret))
  return merr
END METHOD
</pre>

<p>Examples of expected values include the following:</p>

<ul>
<li>The <strong><code>n</code>th raw moment</strong> (mean of <code>n</code>th powers) if <code>EFUNC(x)</code> is <code>pow(x, n)</code>.</li>
<li>The <strong>mean</strong>, if <code>EFUNC(x)</code> is <code>x</code>.</li>
<li>The <strong><code>n</code>th sample central moment</strong>, if <code>EFUNC(x)</code> is <code>pow(x-m, n)</code>, where <code>m</code> is the mean of the sampled numbers.</li>
<li>The (biased) <strong>sample variance</strong>, the second sample central moment.</li>
<li>The <strong>probability</strong>, if <code>EFUNC(x)</code> is <code>1</code> if some condition is met or <code>0</code> otherwise.</li>
</ul>

<p>If the sampling domain is also limited to random numbers meeting a given condition (such as <code>x &lt; 2</code> or <code>x != 10</code>), then the estimated expected value is also called the estimated <em>conditional expectation</em>.</p>

<p><a href="https://en.wikipedia.org/wiki/Monte_Carlo_integration"><strong>Monte Carlo integration</strong></a> is a way to estimate a multidimensional integral; randomly sampled numbers are put into a list (<code>nums</code>) and the estimated integral and its standard error are then calculated with <code>Expectation(nums)</code> with <code>EFUNC(x) = x</code>, and multiplied by the volume of the sampling domain.</p>

<p>A third application of Monte Carlo sampling is <a href="http://mathworld.wolfram.com/StochasticOptimization.html"><strong>stochastic optimization</strong></a> for finding the minimum or maximum value of a function with one or more variables; examples include <a href="https://en.wikipedia.org/wiki/Simulated_annealing"><strong><em>simulated annealing</em></strong></a> and <a href="https://en.wikipedia.org/wiki/Simultaneous_perturbation_stochastic_approximation"><strong><em>simultaneous perturbation stochastic approximation</em></strong></a> (see also (Spall 1998)<sup><a href="#Note18"><strong>(18)</strong></a></sup>).</p>

<p><a id=Random_Walks_Additional_Examples></a></p>

<h3>Random Walks: Additional Examples</h3>

<p><strong>Requires random real numbers.</strong></p>

<ul>
<li>One example of a white noise process is a list of <code>Normal(0, 1)</code> numbers (<em>Gaussian white noise</em>).</li>
<li>If <code>STATEJUMP()</code> is <code>RNDRANGE(-1, 1)</code>, the random state is advanced by a random real number in the interval [-1, 1].</li>
<li>A <strong>continuous-time process</strong> models random behavior at every moment, not just at discrete times.  There are two popular examples:

<ul>
<li>A <em>Wiener process</em> has random states and jumps that are normally distributed (a process of this kind is also known as <em>Brownian motion</em>). For a random walk that follows a Wiener process, <code>STATEJUMP()</code> is <code>Normal(mu * timediff, sigma * sqrt(timediff))</code>, where  <code>mu</code> is the average value per time unit, <code>sigma</code> is the volatility, and <code>timediff</code> is the time difference between samples.</li>
<li>In a <em>Poisson process</em>, the time between each event is a random exponential variable, namely, <code>-ln(RNDU01ZeroOneExc()) / rate</code>, where <code>rate</code> is the average number of events per time unit. An <em>inhomogeneous Poisson process</em> results if <code>rate</code> can vary with the &quot;timestamp&quot; before each event jump.</li>
</ul></li>
</ul>

<p><a id=Low_Discrepancy_Sequences></a></p>

<h3>Low-Discrepancy Sequences</h3>

<p><strong>Requires random real numbers.</strong></p>

<p>A <a href="https://en.wikipedia.org/wiki/Low-discrepancy_sequence"><strong><em>low-discrepancy sequence</em></strong></a> (or <em>quasirandom sequence</em>) is a sequence of numbers that follow a uniform distribution, but are less likely to form &quot;clumps&quot; than independent uniform random numbers are.  The following are examples:</p>

<ul>
<li>Sobol and Halton sequences are too complicated to show here.</li>
<li>Linear congruential generators with modulus <code>m</code>, a full period, and &quot;good lattice structure&quot;; a sequence of <code>n</code>-dimensional points is then <code>[MLCG(i), MLCG(i+1), ..., MLCG(i+n-1)]</code> for each integer <code>i</code> in the interval [1, <code>m</code>] (L&#39;Ecuyer 1999)<sup><a href="#Note19"><strong>(19)</strong></a></sup> (see example pseudocode below).</li>
</ul>

<p>&nbsp;</p>

<pre>METHOD MLCG(seed) // m = 262139
  if seed&lt;=0: return error
  return rem(92717*seed,262139)/262139.0
END METHOD
</pre>

<p>In most cases, RNGs can be used to generate a &quot;seed&quot; to start the low-discrepancy sequence at.</p>

<p>In Monte Carlo integration and other estimations (described earlier), low-discrepancy sequences are often used to achieve more efficient &quot;random&quot; sampling.</p>

<p><a id=Weighted_Choice_Involving_Real_Numbers></a></p>

<h3>Weighted Choice Involving Real Numbers</h3>

<p>The <code>WeightedChoice</code> method in &quot;<a href="#Weighted_Choice_With_Replacement"><strong>Weighted Choice With Replacement</strong></a>&quot; can be modified to accept real numbers other than integers as weights by changing <code>value = RNDINTEXC(sum)</code> to <code>value = RNDRANGEMaxExc(0, sum)</code>.</p>

<p><a id=Weighted_Choice_Without_Replacement_Indefinite_Size_List></a></p>

<h4>Weighted Choice Without Replacement (Indefinite-Size List)</h4>

<p><strong>Requires random real numbers.</strong></p>

<p>If the number of items in a list is not known in advance, then the following pseudocode implements a <code>RandomKItemsFromFileWeighted</code> that selects up to <code>k</code> random items from a file (<code>file</code>) of indefinite size (similarly to <a href="#Pseudocode_for_Random_Sampling"><strong><code>RandomKItemsFromFile</code></strong></a>).  See (Efraimidis and Spirakis 2005)<sup><a href="#Note20"><strong>(20)</strong></a></sup>, and see also (Efraimidis 2015)<sup><a href="#Note21"><strong>(21)</strong></a></sup>.  In the pseudocode below, <code>WEIGHT_OF_ITEM(item, thisIndex)</code> is a placeholder for arbitrary code that calculates the weight of an individual item based on its value and its index (starting at 0); the item is ignored if its weight is 0 or less.</p>

<pre>METHOD RandomKItemsFromFileWeighted(file, k)
  list = NewList()
  j = 0
  index = 0
  skIndex = 0
  smallestKey = 0
  t = 0
  while true
    // Get the next line from the file
    item = GetNextLine(file)
    thisIndex = index
    index = index + 1
    // If the end of the file was reached, break
    if item == nothing: break
    weight = WEIGHT_OF_ITEM(item, thisIndex)
    // Ignore if item&#39;s weight is 0 or less
    if weight &lt;= 0: continue
    key = pow(RNDU01(),1.0/weight)
    // NOTE: If all weights are integers, the following
    // two lines can be used instead of the previous line,
    // where nthroot(num, n) is the &#39;n&#39;th root, rounded
    // down, of &#39;num&#39;, and X is an arbitrary integer
    // greater than 0:
    // if weight == 1: key = RNDINTEXC(X)
    // else: key = nthroot(RNDINTEXC(X)*X,weight)
    t = smallestKey
    if index == 0 or key &lt; smallestKey
      skIndex = index
      smallestKey = key
    end
    if j &lt; k // phase 1 (fewer than k items)
      AddItem(list, item)
      // To add the line number (starting at
      // 0) rather than the item, use the following
      // line instead of the previous one:
      // AddItem(list, thisIndex)
      j = j + 1
    else // phase 2
      if t &lt; key: list[skIndex] = item
      // To add the line number (starting at
      // 0) rather than the item, use the following
      // line instead of the previous one:
      // if t &lt; key: list[skIndex] = thisIndex
    end
  end
  // Optional shuffling here.
  // See NOTE 4 in RandomKItemsFromFile code.
  if size(list)&gt;=2: Shuffle(list)
  return list
end
</pre>

<blockquote>
<p><strong>Note:</strong> Weighted choice <em>with replacement</em> can be implemented by doing one or more concurrent runs of <code>RandomKItemsFromFileWeighted(file, 1)</code> (making sure each run traverses <code>file</code> the same way for multiple runs as for a single run) (Efraimidis 2015)<sup><a href="#Note21"><strong>(21)</strong></a></sup>.</p>
</blockquote>

<p><a id=Continuous_Weighted_Choice></a></p>

<h4>Continuous Weighted Choice</h4>

<p><strong>Requires random real numbers.</strong></p>

<p>The continuous weighted choice method generates a random number that follows a continuous probability distribution (here, a <a href="http://en.cppreference.com/w/cpp/numeric/random/piecewise_linear_distribution"><strong><em>piecewise linear distribution</em></strong></a>).</p>

<p>The pseudocode below takes two lists as follows:</p>

<ul>
<li><code>values</code> is a list of numbers (which need not be integers). If the numbers are arranged in ascending order, which they should, the first number in this list can be returned exactly, but not the last number.</li>
<li><code>weights</code> is a list of weights for the given numbers (where each number and its weight have the same index in both lists).   The greater a number&#39;s weight, the more likely it is that a number close to that number will be chosen.  Each weight should be 0 or greater.</li>
</ul>

<p>&nbsp;</p>

<pre>METHOD ContinuousWeightedChoice(values, weights)
    if size(values) &lt;= 0 or size(weights) &lt; size(values): return error
    if size(values) == 1: return values[0]
    // Get the sum of all areas between weights
    // NOTE: Kahan summation is more robust
    // than the naive summing given here
    msum = 0
    areas = NewList()
    i = 0
    while i &lt; size(values) - 1
      weightArea = abs((weights[i] + weights[i + 1]) * 0.5 *
            (values[i + 1] - values[i]))
      AddItem(areas, weightArea)
      msum = msum + weightArea
       i = i + 1
    end
    // Generate random numbers
    value = RNDRANGEMaxExc(0, sum)
    wt=RNDU01OneExc()
    // Interpolate a number according to the given value
    i=0
    // Get the number corresponding to the random number
    runningValue = 0
    while i &lt; size(values) - 1
     area = areas[i]
     if area &gt; 0
      newValue = runningValue + area
      // NOTE: Includes start, excludes end
      if value &lt; newValue
       w1=weights[i]
       w2=weights[i+1]
       interp=wt
       if diff&gt;0
        s=sqrt(w2*w2*wt+w1*w1-w1*w1*wt)
        interp=(s-w1)/diff
        if interp&lt;0 or interp&gt;1: interp=-(s+w1)/diff
       end
       if diff&lt;0
        s=sqrt(w1*w1*wt+w2*w2-w2*w2*wt)
        interp=-(s-w2)/diff
        if interp&lt;0 or interp&gt;1: interp=(s+w2)/diff
        interp=1-interp
       end
       retValue = values[i] + (values[i + 1] - values[i]) *
         interp
       return retValue
      end
      runningValue = newValue
     end
     i = i + 1
    end
    // Last resort (might happen because rounding
    // error happened somehow)
    return values[size(values) - 1]
END METHOD
</pre>

<blockquote>
<p><strong>Note:</strong> The Python sample code contains a variant to the method
above for returning more than one random number in one call.</p>

<p><strong>Example</strong>: Assume <code>values</code> is the following: <code>[0, 1, 2, 2.5, 3]</code>, and <code>weights</code> is the following: <code>[0.2, 0.8, 0.5, 0.3, 0.1]</code>.  The weight for 2 is 0.5, and that for 2.5 is 0.3.  Since 2 has a higher weight than 2.5, numbers near 2 are more likely to be chosen than numbers near 2.5 with the <code>ContinuousWeightedChoice</code> method.</p>
</blockquote>

<p><a id=Mixtures_Additional_Examples></a></p>

<h3>Mixtures: Additional Examples</h3>

<p><strong>Requires random real numbers.</strong></p>

<ol>
<li>Example 3 in &quot;<a href="#Mixtures_of_Distributions"><strong>Mixtures of Distributions</strong></a>&quot; can be adapted to nonoverlapping real number ranges by assigning weights <code>mx - mn</code> instead of <code>(mx - mn) + 1</code> and using <code>RNDRANGEMaxExc</code> instead of <code>RNDINTRANGE</code>.</li>
<li><p>A <strong>hyperexponential distribution</strong> is a mixture of <a href="#Gamma_Distribution"><strong>exponential distributions</strong></a>, each one with a separate weight and separate rate.  An example is below.</p>

<pre> index = WeightedChoice([0.6, 0.3, 0.1])
 // Rates of the three exponential distributions
 rates = [0.3, 0.1, 0.05]
 // Generate an exponential random number with chosen rate
 number = -ln(RNDU01ZeroOneExc()) / rates[index]
</pre></li>
</ol>

<p>&nbsp;</p>

<p><a id=Transformations_of_Random_Numbers_Additional_Examples></a></p>

<h3>Transformations of Random Numbers: Additional Examples</h3>

<p><strong>Requires random real numbers.</strong></p>

<p>See the <a href="#Mean_and_Variance_Calculation"><strong>appendix</strong></a> for how calculating the mean of a list of numbers can be implemented.</p>

<ol>
<li>Sampling a <strong>Bates distribution</strong> involves sampling <em>n</em> random numbers by <code>RNDRANGE(minimum, maximum)</code>, then finding the mean of those numbers (strategy 8, mean).</li>
<li>A <strong>compound Poisson distribution</strong> models the sum<sup><a href="#Note12"><strong>(12)</strong></a></sup>
of <em>n</em> random numbers each generated the same way, where <em>n</em> follows a <a href="#Poisson_Distribution"><strong>Poisson distribution</strong></a> (e.g., <code>n = Poisson(10)</code> for an average of 10 numbers) (strategy 7, sum).</li>
<li>A <strong>P&oacute;lya&ndash;Aeppli distribution</strong> is a compound Poisson distribution in which the random numbers are generated by <code>NegativeBinomial(1, 1-p)+1</code> for a fixed <code>p</code>.</li>
<li>A <strong>hypoexponential distribution</strong> models the sum<sup><a href="#Note12"><strong>(12)</strong></a></sup>
of <em>n</em> random numbers that follow an exponential distribution and each have a separate <code>lamda</code> parameter (see &quot;<a href="#Gamma_Distribution"><strong>Gamma Distribution</strong></a>&quot;).</li>
<li>A random point (<code>x</code>, <code>y</code>) can be transformed (strategy 9, geometric transformation) to derive a point with <strong>correlated random</strong> coordinates (old <code>x</code>, new <code>x</code>) as follows (see (Saucier 2000)<sup><a href="#Note22"><strong>(22)</strong></a></sup>, sec. 3.8): <code>[x, y*sqrt(1 - rho * rho) + rho * x]</code>, where <code>x</code> and <code>y</code> are independent random numbers generated the same way, and <code>rho</code> is a <em>correlation coefficient</em> in the interval [-1, 1] (if <code>rho</code> is 0, the variables are uncorrelated).</li>
</ol>

<p><a id=Random_Numbers_from_a_Distribution_of_Data_Points></a></p>

<h3>Random Numbers from a Distribution of Data Points</h3>

<p><strong>Requires random real numbers.</strong></p>

<p><strong>Density estimation models.</strong> Generating random numbers (or data points) based on how a list of numbers (or data points) is distributed involves a family of data models called <a href="http://scikit-learn.org/stable/modules/density.html"><strong>density estimation</strong></a> models, including the ones given below.  These models seek to describe the distribution of data points in a given data set, where areas with more points are more likely to be sampled.</p>

<ol>
<li><strong>Histograms</strong> are sets of one or more non-overlapping <em>bins</em>, which are generally of equal size.  Histograms are <a href="#Mixtures_of_Distributions"><strong><em>mixtures</em></strong></a>, where each bin&#39;s weight is the number of data points in that bin.  After a bin is randomly chosen, a random data point that could fit in that bin is generated (that point need not be an existing data point).</li>
<li><strong>Gaussian</strong> <a href="https://en.wikipedia.org/wiki/Mixture_model"><strong>mixture models</strong></a> are also mixtures, in this case, mixtures of one or more <a href="#Normal_Gaussian_Distribution"><strong>Gaussian (normal) distributions</strong></a>.</li>
<li><strong>Kernel distributions</strong> are mixtures of sampling distributions, one for each data point. Estimating a kernel distribution is called <a href="https://en.wikipedia.org/wiki/Kernel_density_estimation"><strong><em>kernel density estimation</em></strong></a>.  To sample from a kernel distribution:

<ol>
<li>Choose one of the numbers or points in the list at random <a href="#Sampling_With_Replacement_Choosing_a_Random_Item_from_a_List"><strong>with replacement</strong></a>.</li>
<li>Add a randomized &quot;jitter&quot; to the chosen number or point; for example, add a separately generated <code>Normal(0, sigma)</code> to the chosen number or each component of the chosen point, where <code>sigma</code> is the <em>bandwidth</em><sup><a href="#Note23"><strong>(23)</strong></a></sup>.</li>
</ol></li>
<li><strong>Stochastic interpolation</strong> is described in (Saucier 2000)<sup><a href="#Note22"><strong>(22)</strong></a></sup>, sec. 5.3.4.  It involves choosing a data point at random, taking the mean of that point and its <em>k</em> nearest neighbors, and shifting that mean by a random weighted sum<sup><a href="#Note12"><strong>(12)</strong></a></sup>
of the differences between each of those points and that mean (here, the weight is <code>RNDRANGE((1-sqrt(k*3))/(k+1.0), (1+sqrt(k*3))/(k+1.0))</code> for each point). This approach assumes that the lowest and highest values of each dimension are 0 and 1, respectively, so that arbitrary data points have to be shifted and scaled accordingly.</li>
<li><strong>Fitting a known distribution</strong> (such as the normal distribution), with unknown parameters, to data can be done by <a href="https://en.wikipedia.org/wiki/Maximum_likelihood_estimation"><strong>maximum likelihood estimation</strong></a> or the <a href="https://en.wikipedia.org/wiki/Method_of_moments"><strong>method of moments</strong></a>, among other ways.  If several kinds of distributions are possible fitting choices, then the kind showing the best <em>goodness of fit</em> for the data (e.g., chi-squared goodness of fit) is chosen.</li>
</ol>

<p><strong>Regression models.</strong> A <em>regression model</em> is a model that summarizes data as a formula and an error term.  If an application has data in the form of inputs and outputs (e.g., monthly sales figures) and wants to sample a random but plausible output given a known input point (e.g., sales for a future month), then the application can fit and sample a regression model for that data.  For example, a <em>linear regression model</em>, which simulates the value of <code>y</code> given known inputs <code>a</code> and <code>b</code>, can be sampled as follows: <code>y = c1 * a + c2 * b + c3 + Normal(mse)</code>, where <code>mse</code> is the mean squared error and <code>c1</code>, <code>c2</code>, and <code>c3</code> are the coefficients of the model.  (Here, <code>Normal(mse)</code> is the error term.)</p>

<p><strong>Generative models.</strong> These are machine-learning models that take random numbers as input and generate outputs (such as images or sounds) that are similar to examples they have already seen.  <a href="https://en.wikipedia.org/wiki/Generative_adversarial_network"><strong><em>Generative adversarial networks</em></strong></a> are one kind of generative model.</p>

<blockquote>
<p><strong>Note:</strong> A comprehensive survey of density estimation, regression, or generative models, or how to fit such models to data, are outside the scope of this document.<sup><a href="#Note24"><strong>(24)</strong></a></sup></p>
</blockquote>

<p><a id=Random_Numbers_from_an_Arbitrary_Distribution></a></p>

<h3>Random Numbers from an Arbitrary Distribution</h3>

<p><strong>Requires random real numbers.</strong></p>

<p>Many probability distributions can be defined in terms of any of the following:</p>

<ul>
<li>The <a href="https://en.wikipedia.org/wiki/Cumulative_distribution_function"><strong><em>cumulative distribution function</em></strong></a>, or <em>CDF</em>, returns, for each number, the probability for a randomly generated variable to be equal to or less than that number; the probability is in the interval [0, 1].</li>
<li>The <a href="https://en.wikipedia.org/wiki/Probability_density_function"><strong><em>probability density function</em></strong></a>, or <em>PDF</em>, is, roughly and intuitively, a curve of weights 0 or greater, where for each number, the greater its weight, the more likely a number close to that number is randomly chosen.<sup><a href="#Note25"><strong>(25)</strong></a></sup></li>
<li>The <em>inverse cumulative distribution function</em> (<em>inverse CDF</em>) is the inverse of the CDF and maps numbers in the interval [0, 1) to numbers in the distribution, from low to high.</li>
</ul>

<p>Depending on what information is known about the distribution, random numbers that approximately follow that distribution can be generated as follows:</p>

<ul>
<li><p><strong>PDF is known</strong>, even if the area under the PDF isn&#39;t 1:</p>

<ul>
<li><strong>Piecewise interpolation.</strong> Use the PDF to calculate the weights for a number of sample points (usually regularly spaced). Create one list with the sampled points in ascending order (the <code>list</code>) and another list of the same size with the PDF&#39;s values at those points (the <code>weights</code>).  Finally, generate a random number bounded by the lowest and highest sampled point using a weighted choice method (e.g., <a href="#Continuous_Weighted_Choice"><strong><code>ContinuousWeightedChoice(list, weights)</code></strong></a>).  The <a href="https://peteroupc.github.io/randomgen.zip"><strong>Python sample code</strong></a> includes a <code>numbers_from_pdf</code> method (for continuous PDFs) and an <code>integers_from_pdf</code> method (for discrete PDFs) that implement this approach.</li>
<li><p><a href="#Rejection_Sampling"><strong>Rejection sampling.</strong></a>  If the PDF can be more easily sampled by another distribution with its own PDF (<code>PDF2</code>) that &quot;dominates&quot; <code>PDF</code> in the sense that <code>PDF2(x) &gt;= PDF(x)</code> at every valid <code>x</code>, then generate random numbers with that distribution until a number (<code>n</code>) that satisfies <code>PDF(n) &gt;= RNDRANGEMaxExc(0, PDF2(n))</code> is generated this way (that is, sample points in <code>PDF2</code> until a point falls within <code>PDF</code>). (See also Saucier 2000, pp. 6-7, 39; Devroye 1986, pp. 41-43; and &quot;<a href="https://mathworks.com/help/stats/generating-random-data.html"><strong>Generating Pseudorandom Numbers</strong></a>&quot;.)</p>

<p>To sample a random number in the interval [<code>low</code>, <code>high</code>) from a PDF with a positive maximum value no greater than <code>peak</code> at that interval, generate <code>x = RNDRANGEMaxExc(low, high)</code> and <code>y = RNDRANGEMaxExc(0, peak)</code> until <code>y &lt; PDF(x)</code>, then take the last <code>x</code> generated this way. (See also Saucier 2000, pp. 6-7.)</p>

<p>For example, a custom distribution&#39;s PDF, <code>PDF</code>, is <code>exp(-abs(x*x*x))</code>, and the exponential distribution&#39;s PDF, <code>PDF2</code>, is <code>exp(-x)</code>.  The exponential PDF &quot;dominates&quot; the other PDF (at every <code>x</code> 0 or greater) if we multiply it by 1.5, so that <code>PDF2</code> is now <code>1.5 * exp(-x)</code>.  Now we can generate numbers from our custom distribution by sampling exponential points until a point falls within <code>PDF</code>.  This is done by generating <code>n = -ln(RNDU01ZeroOneExc())</code> until <code>PDF(n) &gt;= RNDRANGEMaxExc(0, PDF2(n))</code>.</p></li>
<li><a href="https://en.wikipedia.org/wiki/Markov_chain_Monte_Carlo"><strong>Markov-chain Monte Carlo</strong></a> <strong>(MCMC).</strong> If many random numbers from the given PDF need to be generated, then an MCMC algorithm can be used, with the disadvantage that the resulting random numbers will not be chosen independently of each other.  MCMC algorithms include Metropolis&ndash;Hastings and slice sampling (Neal 2003)<sup><a href="#Note26"><strong>(26)</strong></a></sup>. Generally, as more numbers are generated, the MCMC algorithm converges to the given distribution; this is why usually, random numbers from the first few (e.g., first 1000) iterations are ignored (&quot;burn in&quot;).  MCMC can also be used to find a suitable sampling range for the Piecewise interpolation method, above.  The <a href="https://peteroupc.github.io/randomgen.zip"><strong>Python sample code</strong></a> includes methods called <code>mcmc</code> and <code>mcmc2</code> that implement Metropolis&ndash;Hastings for PDFs that take single numbers or two-dimensional points, respectively, and a method called <code>slicesample</code> that implements slice sampling.</li>
</ul></li>
<li><p><strong>PDF and a uniform random variable in the interval [0, 1) (<code>randomVariable</code>)</strong> are known: Create <code>list</code> and <code>weights</code> as given in the Piecewise interpolation method, above, then divide each item in <code>weights</code> by the sum<sup><a href="#Note12"><strong>(12)</strong></a></sup>
of <code>weights</code>&#39;s items, then generate <a href="#Continuous_Weighted_Choice"><strong><code>ContinuousWeightedChoice(list, weights)</code></strong></a> (except that method is modified to use <code>value = randomVariable</code> rather than <code>value = RNDRANGEMaxExc(0, sum)</code>).</p></li>
<li><p><strong>Inverse CDF is known:</strong> Generate <code>ICDF(RNDU01ZeroOneExc())</code>, where <code>ICDF(X)</code> is the inverse CDF (<a href="https://en.wikipedia.org/wiki/Inverse_transform_sampling"><strong><em>inverse transform sampling</em></strong></a>).</p></li>
<li><p><strong>Inverse CDF and a uniform random variable in the interval [0, 1) (<code>randomVariable</code>)</strong> are known: Generate <code>ICDF(randomVariable)</code>, where <code>ICDF(X)</code> is the inverse CDF.</p></li>
<li><p><strong>CDF is known</strong>: In this case, the CDF is usually numerically inverted to generate a random number from that distribution.  For example, see the <code>from_interp</code> and <code>numbers_from_cdf</code> methods in the <a href="https://peteroupc.github.io/randomgen.zip"><strong>Python sample code</strong></a>.</p></li>
</ul>

<blockquote>
<p><strong>Note:</strong> Lists of PDFs, CDFs, or inverse CDFs are outside the scope of this page.</p>
</blockquote>

<p><a id=Gibbs_Sampling></a></p>

<h3>Gibbs Sampling</h3>

<p><strong>Usually requires random real numbers.</strong></p>

<p>Gibbs sampling<sup><a href="#Note27"><strong>(27)</strong></a></sup> is a Markov-chain Monte Carlo algorithm.  It involves repeatedly generating random numbers from two or more distributions, each of which uses a random number from the previous distribution (<em>conditional distributions</em>); however, the resulting random numbers will not be chosen independently of each other.</p>

<blockquote>
<p><strong>Example:</strong> In one Gibbs sampler, an initial value for <code>y</code> is chosen, then multiple <code>x</code>, <code>y</code> pairs of random numbers are generated, where <code>x = BetaDist(y, 5)</code> then <code>y = Poisson(x * 10)</code>.</p>
</blockquote>

<p><a id=Dice_Optimization_for_Many_Dice></a></p>

<h3>Dice: Optimization for Many Dice</h3>

<p><strong>Requires random real numbers.</strong></p>

<p>If there are many dice to roll, the following pseudocode implements a faster approximation, which uses the fact that the dice-roll distribution approaches a &quot;discrete&quot; normal distribution as the number of dice increases.<sup><a href="#Note28"><strong>(28)</strong></a></sup></p>

<pre>METHOD DiceRoll2(dice, sides, bonus)
  if dice &lt; 50: return DiceRoll(dice,sides,bonus)
  mean = dice * (sides + 1) * 0.5
  sigma = sqrt(dice * (sides * sides - 1) / 12)
  ret = -1
  while ret &lt; dice or ret &gt; dice * sides
    ret = round(Normal(mean, sigma))
  end
  return max(0, ret + bonus)
END METHOD
</pre>

<p><a id=Normal_Gaussian_Distribution></a></p>

<h3>Normal (Gaussian) Distribution</h3>

<p><strong>Requires random real numbers.</strong></p>

<p>The <a href="https://en.wikipedia.org/wiki/Normal_distribution"><strong><em>normal distribution</em></strong></a> (also called the Gaussian distribution) takes the following two parameters:</p>

<ul>
<li><code>mu</code> (&mu;) is the mean (average), or where the peak of the distribution&#39;s &quot;bell curve&quot; is.</li>
<li><code>sigma</code> (&sigma;), the standard deviation, affects how wide the &quot;bell curve&quot; appears. The
probability that a normally-distributed random number will be within one standard deviation from the mean is about 68.3%; within two standard deviations (2 times <code>sigma</code>), about 95.4%; and within three standard deviations, about 99.7%.  (Some publications give &sigma;<sup>2</sup>, or variance, rather than standard deviation, as the second parameter.  In this case, the standard deviation is the variance&#39;s square root.)</li>
</ul>

<p>There are a number of methods for normal random number generation.<sup><a href="#Note29"><strong>(29)</strong></a></sup> The pseudocode below uses the polar method to generate two normal random numbers. (Ways to adapt the pseudocode to output only one random number at a time, rather than two, are outside the scope of this document.  In this document, the name <code>Normal</code> means a method that returns only one normally-distributed random number rather than two.)</p>

<pre>METHOD Normal2(mu, sigma)
  while true
    a = RNDU01ZeroExc()
    b = RNDU01ZeroExc()
    if RNDINT(1) == 0: a = 0 - a
    if RNDINT(1) == 0: b = 0 - b
    c = a * a + b * b
    if c != 0 and c &lt;= 1
       c = sqrt(-2 * ln(c) / c)
       return [a * mu * c + sigma, b * mu * c + sigma]
    end
  end
END METHOD
</pre>

<p>The following method implements a ratio-of-uniforms technique and can be used instead of or in addition to the polar method above.</p>

<pre>METHOD Normal(mu, sigma)
    bmp = sqrt(2.0/exp(1.0)) // about 0.8577638849607068
    while true
        a=RNDU01ZeroExc()
        b=RNDRANGE(-bmp,bmp)
        if b*b &lt;= -a * a * 4 * ln(a)
            return (b * sigma / a) + mu
        end
    end
END METHOD
</pre>

<p><a id=Binomial_Distribution_Optimization_for_Many_Trials></a></p>

<h3>Binomial Distribution: Optimization for Many Trials</h3>

<p>The <em>binomial distribution</em> models the number of successful trials among a fixed number of independently performed trials with a fixed probability of success.</p>

<p><strong>Requires random real numbers:</strong> The pseudocode below implements an optimization for many trials.  In the pseudocode&mdash;</p>

<ul>
<li><code>trials</code> is the number of independent trials, and</li>
<li><code>p</code> is the probability of success in each trial (where <code>p &lt;= 0</code> means never, <code>p &gt;= 1</code> means always, and <code>p = 0.5</code> means an equal chance of success or failure).</li>
</ul>

<p>&nbsp;</p>

<pre>METHOD Binomial(trials, p)
    if trials &lt; 0: return error
    if trials == 0: return 0
    // Always succeeds
    if p &gt;= 1.0: return trials
    // Always fails
    if p &lt;= 0.0: return 0
    count = 0
    // Suggested by Saucier, R. in &quot;Computer
    // generation of probability distributions&quot;,
    // 2000, p. 49
    tp = trials * p
    if tp &gt; 25 or (tp &gt; 5 and p &gt; 0.1 and p &lt; 0.9)
         countval = -1
         while countval &lt; 0 or countval &gt; trials
              countval = round(Normal(tp, sqrt(tp)))
         end
         return countval
    end
    if p == 0.5
      for i in 0...trials: count=count+RNDINT(1)
    else
        i = 0
        while i &lt; trials
            if RNDU01OneExc() &lt; p
                // Success
                count = count + 1
            end
            i = i + 1
        end
    end
    return count
END METHOD
</pre>

<p><a id=Poisson_Distribution></a></p>

<h3>Poisson Distribution</h3>

<p><strong>Requires random real numbers.</strong></p>

<p>The following method generates a random integer that follows a <em>Poisson distribution</em> and is based on Knuth&#39;s method from 1969.  In the method&mdash;</p>

<ul>
<li><code>mean</code> is the average number of independent events of a certain kind per fixed unit of time or space (for example, per day, hour, or square kilometer), and can be an integer or a non-integer (the method allows <code>mean</code> to be 0 mainly for convenience), and</li>
<li>the method&#39;s return value gives a random number of such events within one such unit.</li>
</ul>

<p>&nbsp;</p>

<pre>METHOD Poisson(mean)
    if mean &lt; 0: return error
    if mean == 0: return 0
    p = 1.0
    // Suggested by Saucier, R. in &quot;Computer
    // generation of probability distributions&quot;, 2000, p. 49
    if mean &gt; 9
        p = -1.0
        while p &lt; 0: p = round(
          Normal(mean, sqrt(mean)))
        return p
    end
    pn = exp(-mean)
    count = 0
    while true
        p = p * RNDU01OneExc()
        if p &lt;= pn: return count
        count = count + 1
    end
END METHOD
</pre>

<p><a id=Gamma_Distribution></a></p>

<h3>Gamma Distribution</h3>

<p><strong>Requires random real numbers.</strong></p>

<p>The following method generates a random number that follows a <em>gamma distribution</em> and is based on Marsaglia and Tsang&#39;s method from 2000.  Usually, the number expresses either&mdash;</p>

<ul>
<li>the lifetime (in days, hours, or other fixed units) of a random component with an average lifetime of <code>meanLifetime</code>, or</li>
<li>a random amount of time (in days, hours, or other fixed units) that passes until as many events as <code>meanLifetime</code> happen.</li>
</ul>

<p>Here, <code>meanLifetime</code> must be an integer or noninteger greater than 0, and <code>scale</code> is a scaling parameter that is greater than 0, but usually 1.</p>

<pre>METHOD GammaDist(meanLifetime, scale)
    // Needs to be greater than 0
    if meanLifetime &lt;= 0 or scale &lt;= 0: return error
    // Exponential distribution special case if
    // `meanLifetime` is 1 (see also Devroye 1986, p. 405)
    if meanLifetime == 1: return -ln(RNDU01ZeroOneExc()) * scale
    d = meanLifetime
    v = 0
    if meanLifetime &lt; 1: d = d + 1
    d = d - (1.0 / 3) // NOTE: 1.0 / 3 must be a fractional number
    c = 1.0 / sqrt(9 * d)
    while true
        x = 0
        while true
           x = Normal(0, 1)
           v = c * x + 1;
           v = v * v * v
           if v &gt; 0: break
        end
        u = RNDU01ZeroExc()
        x2 = x * x
        if u &lt; 1 - (0.0331 * x2 * x2): break
        if ln(u) &lt; (0.5 * x2) + (d * (1 - v + ln(v))): break
    end
    ret = d * v
    if meanLifetime &lt; 1
       ret = ret * exp(ln(RNDU01ZeroExc()) / meanLifetime)
    end
    return ret * scale
end
</pre>

<p>Distributions based on the gamma distribution:</p>

<ul>
<li><strong>3-parameter gamma distribution</strong>: <code>pow(GammaDist(a, 1), 1.0 / c) * b</code>, where <code>c</code> is another shape parameter.</li>
<li><strong>4-parameter gamma distribution</strong>: <code>pow(GammaDist(a, 1), 1.0 / c) * b + d</code>, where <code>d</code> is the minimum value.</li>
<li><strong>Exponential distribution</strong>: <code>GammaDist(1, 1.0 / lamda)</code> or <code>-ln(RNDU01ZeroOneExc()) / lamda</code>, where <code>lamda</code> is the inverse scale. Usually, <code>lamda</code> is the probability that an independent event of a given kind will occur in a given span of time (such as in a given day or year), and the random result is the number of spans of time until that event happens.  (This distribution is thus useful for modeling a <em>Poisson process</em>.) <code>1.0 / lamda</code> is the scale (mean), which is usually the average waiting time between two independent events of the same kind.</li>
<li><strong>Erlang distribution</strong>: <code>GammaDist(n, 1.0 / lamda)</code>.  Expresses a sum of <code>n</code> exponential random variables with the given <code>lamda</code> parameter.</li>
<li><strong>Max-of-uniform distribution</strong> (Devroye 1986, p. 675):  <code>1.0 - x/(x+GammaDist(n,1))</code>, where <code>n</code> is the number of uniform random variables, and <code>x</code> is <code>GammaDist(1,1)</code>.  Using <code>x/(x+GammaDist(n,1))</code> instead results in a <strong>min-of-uniform distribution</strong> (Devroye 1986, p. 210).</li>
</ul>

<p><a id=Beta_Distribution></a></p>

<h3>Beta Distribution</h3>

<p><strong>Requires random real numbers.</strong></p>

<p>In the following method, which generates a random number that follows a <em>beta distribution</em>, <code>a</code> and <code>b</code> are two parameters each greater than 0.  The range of the beta distribution is [0, 1).</p>

<pre>METHOD BetaDist(self, a, b)
  if b==1 and a==1: return RNDU01()
  if a==1: return 1.0-pow(RNDU01(),1.0/b)
  if b==1: return pow(RNDU01(),1.0/a)
  x=GammaDist(a,1)
  return x/(x+GammaDist(b,1))
END METHOD
</pre>

<p><a id=Negative_Binomial_Distribution></a></p>

<h3>Negative Binomial Distribution</h3>

<p><strong>Requires random real numbers.</strong></p>

<p>A <em>negative binomial distribution</em> models the number of failing trials that happen before a fixed number of successful trials (<code>successes</code>).  Each trial is independent and has a success probability of <code>p</code> (where <code>p &lt;= 0</code> means never, <code>p &gt;= 1</code> means always, and <code>p = 0.5</code> means an equal chance of success or failure).</p>

<pre>METHOD NegativeBinomial(successes, p)
    // Needs to be 0 or greater
    if successes &lt; 0: return error
    // No failures if no successes or if always succeeds
    if successes == 0 or p &gt;= 1.0: return 0
    // Always fails (NOTE: infinity can be the maximum possible
    // integer value if NegativeBinomial is implemented to return
    // an integer)
    if p &lt;= 0.0: return infinity
    // NOTE: If &#39;successes&#39; can be an integer only,
    // omit the following three lines:
    if floor(successes) != successes
        return Poisson(GammaDist(successes, (1 - p) / p))
    end
    count = 0
    total = 0
    if successes == 1
        if p == 0.5
          while RNDINT(1) == 0: count = count + 1
           return count
        end
        // Geometric distribution special case (see Saucier 2000)
        return floor(ln(RNDU01ZeroExc()) / ln(1.0 - p))
    end
    while true
        if RNDU01OneExc() &lt; p
            // Success
            total = total + 1
            if total &gt;= successes
                    return count
            end
        else
            // Failure
            count = count + 1
        end
    end
END METHOD
</pre>

<blockquote>
<p><strong>Note:</strong> A <strong>geometric distribution</strong> can be sampled by generating <code>NegativeBinomial(1, p)</code>, where <code>p</code> has the same meaning as in the negative binomial distribution.  Here, the sampled number is the number of failures that have happened before a success happens. (Saucier 2000, p. 44, also mentions an alternative definition that includes the success.)  For example, if <code>p</code> is 0.5, the geometric distribution models the task &quot;Flip a coin until you get tails, then count the number of heads.&quot;</p>
</blockquote>

<p><a id=von_Mises_Distribution></a></p>

<h3>von Mises Distribution</h3>

<p><strong>Requires random real numbers.</strong></p>

<p>The <em>von Mises distribution</em> describes a distribution of circular angles. In the following method, which generates a random number from that distribution&mdash;</p>

<ul>
<li><code>mean</code> is the mean angle,</li>
<li><code>kappa</code> is a shape parameter (the distribution is uniform at <code>kappa = 0</code> and approaches a normal distribution with increasing <code>kappa</code>), and</li>
<li>the method can return a number within &pi; of that mean.</li>
</ul>

<p>The algorithm below is based on the Best&ndash;Fisher algorithm from 1979 (as described in Devroye 1986 with errata incorporated).</p>

<pre>METHOD VonMises(mean, kappa)
    if kappa &lt; 0: return error
    if kappa == 0
        return RNDRANGEMinMaxExc(mean-pi, mean+pi)
    end
    r = 1.0 + sqrt(4 * kappa * kappa + 1)
    rho = (r - sqrt(2 * r)) / (kappa * 2)
    s = (1 + rho * rho) / (2 * rho)
    while true
        u = RNDRANGEMaxExc(-pi, pi)
        v = RNDU01ZeroOneExc()
        z = cos(u)
        w = (1 + s*z) / (s + z)
        y = kappa * (s - w)
        if y*(2 - y) - v &gt;=0 or ln(y / v) + 1 - y &gt;= 0
           if angle&lt;-1: angle=-1
           if angle&gt;1: angle=1
           // NOTE: Inverse cosine replaced here
           // with `atan2` equivalent
           angle = atan2(sqrt(1-w*w),w)
           if u &lt; 0: angle = -angle
           return mean + angle
        end
    end
END METHOD
</pre>

<p><a id=Stable_Distribution></a></p>

<h3>Stable Distribution</h3>

<p><strong>Requires random real numbers.</strong></p>

<p>As more and more independent random numbers from the same distribution are added together, their distribution tends to a <a href="https://en.wikipedia.org/wiki/Stable_distribution"><strong><em>stable distribution</em></strong></a>, which resembles a curve with a single peak, but with generally &quot;fatter&quot; tails than the normal distribution.  The pseudocode below uses the Chambers&ndash;Mallows&ndash;Stuck algorithm.  The <code>Stable</code> method, implemented below, takes two parameters:</p>

<ul>
<li><code>alpha</code> is a stability index in the interval (0, 2].</li>
<li><code>beta</code> is a skewness in the interval [-1, 1]; if <code>beta</code> is 0, the curve is symmetric.</li>
</ul>

<p>&nbsp;</p>

<pre>METHOD Stable(alpha, beta)
    if alpha &lt;=0 or alpha &gt; 2: return error
    if beta &lt; -1 or beta &gt; 1: return error
    halfpi = pi * 0.5
    unif=RNDRANGEMinMaxExc(-halfpi, halfpi)
    // Cauchy special case
    if alpha == 1 and beta == 0: return tan(unif)
    expo=-ln(RNDU01ZeroExc())
    c=cos(unif)
    if alpha == 1
       s=sin(unif)
       return 2.0*((unif*beta+halfpi)*s/c -
         beta * ln(halfpi*expo*c/(unif*beta+halfpi)))/pi
    end
    z=-tan(alpha*halfpi)*beta
    ug=unif+atan2(-z, 1)/alpha
    cpow=pow(c, -1.0 / alpha)
    return pow(1.0+z*z, 1.0 / (2*alpha))*
       (sin(alpha*ug)*cpow)*
       pow(cos(unif-alpha*ug)/expo, (1.0 - alpha) / alpha)
END METHOD
</pre>

<p>Extended versions of the stable distribution:</p>

<ul>
<li><strong>Four-parameter stable distribution</strong>: <code>Stable(alpha, beta) * sigma + mu</code>, where <code>mu</code> is the mean and <code>sigma</code> is the scale.  If <code>alpha</code> and <code>beta</code> are 1, the result is a <strong>Landau distribution</strong>.</li>
<li><strong>&quot;Type 0&quot; stable distribution</strong>: <code>Stable(alpha, beta) * sigma + (mu - sigma * beta * x)</code>, where <code>x</code> is <code>ln(sigma)*2.0/pi</code> if <code>alpha</code> is 1, and <code>tan(pi*0.5*alpha)</code> otherwise.</li>
</ul>

<p><a id=Multivariate_Normal_Multinormal_Distribution></a></p>

<h3>Multivariate Normal (Multinormal) Distribution</h3>

<p><strong>Requires random real numbers.</strong></p>

<p>The following pseudocode calculates a random point in space that follows a <a href="https://en.wikipedia.org/wiki/Multivariate_normal_distribution"><strong><em>multivariate normal (multinormal) distribution</em></strong></a>.  The method <code>MultivariateNormal</code> takes the following parameters:</p>

<ul>
<li>A list, <code>mu</code> (&mu;), which indicates the means to add to each component of the random point. <code>mu</code> can be <code>nothing</code>, in which case each component will have a mean of zero.</li>
<li>A list of lists <code>cov</code>, that specifies a <em>covariance matrix</em> (&Sigma;, a symmetric positive definite NxN matrix, where N is the number of components of the random point).</li>
</ul>

<p>&nbsp;</p>

<pre>METHOD Decompose(matrix)
  numrows = size(matrix)
  if size(matrix[0])!=numrows: return error
  // Does a Cholesky decomposition of a matrix
  // assuming it&#39;s positive definite and invertible
  ret=NewList()
  for i in 0...numrows
    submat = NewList()
    for j in 0...numrows: AddItem(submat, 0)
    AddItem(ret, submat)
  end
  s1 = sqrt(matrix[0][0])
  if s1==0: return ret // For robustness
  for i in 0...numrows
    ret[0][i]=matrix[0][i]*1.0/s1
  end
  for i in 0...numrows
    msum=0.0
    for j in 0...i: msum = msum + ret[j][i]*ret[j][i]
    sq=matrix[i][i]-msum
    if sq&lt;0: sq=0 // For robustness
    ret[i][i]=math.sqrt(sq)
  end
  for j in 0...numrows
    for i in (j + 1)...numrows
      // For robustness
      if ret[j][j]==0: ret[j][i]=0
      if ret[j][j]!=0
        msum=0
        for k in 0...j: msum = msum + ret[k][i]*ret[k][j]
        ret[j][i]=(matrix[j][i]-msum)*1.0/ret[j][j]
      end
    end
  end
  return ret
END METHOD

METHOD MultivariateNormal(mu, cov)
  mulen=size(cov)
  if mu != nothing
    mulen = size(mu)
    if mulen!=size(cov): return error
    if mulen!=size(cov[0]): return error
  end
  // NOTE: If multiple random points will
  // be generated using the same covariance
  // matrix, an implementation can consider
  // precalculating the decomposed matrix
  // in advance rather than calculating it here.
  cho=Decompose(cov)
  i=0
  ret=NewList()
  variables=NewList()
  for j in 0...mulen: AddItem(variables, Normal(0, 1))
  while i&lt;mulen
    nv=Normal(0,1)
    msum = 0
    if mu == nothing: msum=mu[i]
    for j in 0...mulen: msum=msum+variables[j]*cho[j][i]
    AddItem(ret, msum)
    i=i+1
  end
  return ret
end
</pre>

<blockquote>
<p><strong>Note:</strong> The Python sample code contains a variant of this
method for generating multiple random points in one call.</p>

<p><strong>Examples:</strong></p>

<ol>
<li>A <strong>binormal distribution</strong> (two-variable multinormal distribution) can be sampled using the following idiom: <code>MultivariateNormal([mu1, mu2], [[s1*s1, s1*s2*rho], [rho*s1*s2, s2*s2]])</code>, where <code>mu1</code> and <code>mu2</code> are the means of the two random variables, <code>s1</code> and <code>s2</code> are their standard deviations, and <code>rho</code> is a <em>correlation coefficient</em> greater than -1 and less than 1 (0 means no correlation).</li>
<li>A <strong>log-multinormal distribution</strong> can be sampled by generating numbers from a multinormal distribution, then applying <code>exp(n)</code> to the resulting numbers, where <code>n</code> is each number generated this way.</li>
<li>A <strong>Beckmann distribution</strong> can be sampled by calculating <code>sqrt(x*x+y*y)</code>, where <code>x</code> and <code>y</code> are the two numbers in a binormal random pair (see example 1).</li>
<li>A <strong>Rice (Rician) distribution</strong> is a Beckmann distribution in which the binormal random pair is generated with <code>m1 = m2 = a / sqrt(2)</code>, <code>rho = 0</code>, and <code>s1 = s2 = b</code>, where <code>a</code> and <code>b</code> are the parameters to the Rice distribution.</li>
<li>A <strong>Rice&ndash;Norton distributed</strong> random variable is the norm (see the appendix) of the following point: <code>MultivariateNormal([v,v,v],[[w,0,0],[0,w,0],[0,0,w]])</code>, where <code>v = a/sqrt(m*2)</code>, <code>w = b*b/m</code>, and <code>a</code>, <code>b</code>, and <code>m</code> are the parameters to the Rice&ndash;Norton distribution.</li>
<li>A <strong>standard <a href="https://en.wikipedia.org/wiki/Complex_normal_distribution"><strong>complex normal distribution</strong></a></strong> is a binormal distribution in which the binormal random pair is generated with <code>s1 = s2 = sqrt(0.5)</code> and <code>mu1 = mu2 = 0</code> and treated as the real and imaginary parts of a complex number.</li>
</ol>
</blockquote>

<p><a id=Random_Real_Numbers_with_a_Given_Positive_Sum></a></p>

<h3>Random Real Numbers with a Given Positive Sum</h3>

<p><strong>Requires random real numbers.</strong></p>

<p>Generating <em>n</em> <code>GammaDist(total, 1)</code> numbers and dividing them by their sum<sup><a href="#Note12"><strong>(12)</strong></a></sup>
 will result in <em>n</em> numbers that (approximately) sum to <code>total</code>, where the combination of numbers is chosen uniformly at random (see a <a href="https://en.wikipedia.org/wiki/Dirichlet_distribution#Gamma_distribution"><strong>Wikipedia article</strong></a>).  For example, if <code>total</code> is 1, the numbers will (approximately) sum to 1.  Note that in the exceptional case that all numbers are 0, the process should repeat.</p>

<blockquote>
<p><strong>Notes:</strong></p>

<ol>
<li>Notes 1 and 2 in the section &quot;Random Integers with a Given Positive Sum&quot; apply here.</li>
<li>The <strong>Dirichlet distribution</strong>, as defined in some places (e.g., <em>Mathematica</em>; Devroye 1986, p. 594), models a uniformly randomly chosen combination of <em>n</em> random numbers that sum to 1, and can be sampled by generating <em>n</em>+1 random <a href="#Gamma_Distribution"><strong>gamma-distributed</strong></a> numbers, each with separate parameters, taking their sum<sup><a href="#Note12"><strong>(12)</strong></a></sup>, and dividing the first <em>n</em> numbers by that sum.</li>
</ol>
</blockquote>

<p><a id=Gaussian_and_Other_Copulas></a></p>

<h3>Gaussian and Other Copulas</h3>

<p><strong>Requires random real numbers.</strong></p>

<p>A <em>copula</em> is a distribution describing the dependence between random numbers.</p>

<p>One example is a <em>Gaussian copula</em>; this copula is sampled by sampling from a <a href="#Multivariate_Normal_Multinormal_Distribution"><strong>multinormal distribution</strong></a>, then converting the resulting numbers to uniformly-distributed, but dependent, numbers. In the following pseudocode, which implements a Gaussian copula:</p>

<ul>
<li>The parameter <code>covar</code> is the covariance matrix for the multinormal distribution.</li>
<li><code>erf(v)</code> is the <a href="https://en.wikipedia.org/wiki/Error_function"><strong>error function</strong></a> of the variable <code>v</code> (see the appendix).</li>
</ul>

<p>&nbsp;</p>

<pre>METHOD GaussianCopula(covar)
   mvn=MultivariateNormal(nothing, covar)
   for i in 0...size(covar)
      // Apply the normal distribution&#39;s CDF
      // to get uniform variables
      mvn[i] = (erf(mvn[i]/(sqrt(2)*sqrt(covar[i][i])))+1)*0.5
   end
   return mvn
END METHOD
</pre>

<p>Each of the resulting uniform numbers will be in the interval [0, 1], and each one can be further transformed to any other probability distribution (which is called a <em>marginal distribution</em> here) by one of the methods given in &quot;<a href="#Random_Numbers_from_an_Arbitrary_Distribution"><strong>Random Numbers from an Arbitrary Distribution</strong></a>&quot;. (See also Cario and Nelson 1997.)</p>

<blockquote>
<p><strong>Examples:</strong></p>

<ol>
<li>To generate two dependent uniform variables with a Gaussian copula, generate <code>GaussianCopula([[1, rho], [rho, 1]])</code>, where <code>rho</code> is the Pearson correlation coefficient, in the interval [-1, 1]. (Other correlation coefficients besides <code>rho</code> exist. For example, for a two-variable Gaussian copula, the <a href="https://en.wikipedia.org/wiki/Rank_correlation"><strong>Spearman correlation coefficient</strong></a> <code>srho</code> can be converted to <code>rho</code> by <code>rho = sin(srho * pi / 6) * 2</code>.  Other correlation coefficients are not further discussed in this document.)</li>
<li><p>The following example generates two random numbers that follow a Gaussian copula with exponential marginals (<code>rho</code> is the Pearson correlation coefficient, and <code>rate1</code> and <code>rate2</code> are the rates of the two exponential marginals).</p>

<pre>METHOD CorrelatedExpo(rho, rate1, rate2)
   copula = GaussianCopula([[1, rho], [rho, 1]])
   // Transform to exponentials using that
   // distribution&#39;s inverse CDF
   return [-ln(copula[0]) / rate1,
     -ln(copula[1]) / rate2]
END METHOD
</pre></li>
</ol>
</blockquote>

<p>Other kinds of copulas describe different kinds of dependence between random numbers.  Examples of other copulas are&mdash;</p>

<ul>
<li>the <strong>Fr&eacute;chet&ndash;Hoeffding upper bound copula</strong> <em>[x, x, ..., x]</em> (e.g., <code>[x, x]</code>), where <code>x = RNDU01()</code>,</li>
<li>the <strong>Fr&eacute;chet&ndash;Hoeffding lower bound copula</strong> <code>[x, 1.0 - x]</code> where <code>x = RNDU01()</code>,</li>
<li>the <strong>product copula</strong>, where each number is a separately generated <code>RNDU01()</code> (indicating no dependence between the numbers), and</li>
<li>the <strong>Archimedean copulas</strong>, described by M. Hofert and M. M&auml;chler (2011)<sup><a href="#Note30"><strong>(30)</strong></a></sup>.</li>
</ul>

<p><a id=Index_of_Non_Uniform_Distributions></a></p>

<h3>Index of Non-Uniform Distributions</h3>

<p><strong>Many distributions here require random real numbers.</strong></p>

<p>Most commonly used:</p>

<ul>
<li><strong>Beta distribution</strong>: See <a href="#Beta_Distribution"><strong>Beta Distribution</strong></a>.</li>
<li><strong>Binomial distribution</strong>: See <a href="#Binomial_Distribution_Optimization_for_Many_Trials"><strong>Binomial Distribution: Optimization for Many Trials</strong></a>.</li>
<li><strong>Binormal distribution</strong>: See <a href="#Multivariate_Normal_Multinormal_Distribution"><strong>Multivariate Normal (Multinormal) Distribution</strong></a>.</li>
<li><strong>Cauchy (Lorentz) distribution</strong>: <code>scale * tan(RNDRANGEMinMaxExc(-pi*0.5, pi*0.5)) + mu</code>, where <code>scale</code> is the scale and <code>mu</code> is the location of the distribution&#39;s curve peak (mode).  This distribution is similar to the normal distribution, but with &quot;fatter&quot; tails.</li>
<li><strong>Chi-squared distribution</strong>: <code>GammaDist(df * 0.5 + Poisson(sms * 0.5), 2)</code>, where <code>df</code> is the number of degrees of freedom and <code>sms</code> is the sum of mean squares (where <code>sms</code> other than 0 indicates a <em>noncentral</em> distribution).</li>
<li><strong>Dice</strong>: See <a href="#Dice"><strong>Dice</strong></a>.</li>
<li><strong>Exponential distribution</strong>: See <a href="#Gamma_Distribution"><strong>Gamma Distribution</strong></a>.</li>
<li><strong>Extreme value distribution</strong>: <code>a - ln(-ln(RNDU01ZeroOneExc())) * b</code>, where <code>b</code> is the scale and <code>a</code> is the location of the distribution&#39;s curve peak (mode).  This expresses a distribution of maximum values.</li>
<li><strong>Gamma distribution</strong>: See <a href="#Gamma_Distribution"><strong>Gamma Distribution</strong></a>.</li>
<li><strong>Gaussian distribution</strong>: See <a href="#Normal_Gaussian_Distribution"><strong>Normal (Gaussian) Distribution</strong></a>.</li>
<li><strong>Geometric distribution</strong>: See <a href="#Negative_Binomial_Distribution"><strong>Negative Binomial Distribution</strong></a>.</li>
<li><strong>Gumbel distribution</strong>: <code>a + ln(-ln(RNDU01ZeroOneExc())) * b</code>, where <code>b</code> is the scale and <code>a</code> is the location of the distribution&#39;s curve peak (mode). This expresses a distribution of minimum values.</li>
<li><strong>Inverse gamma distribution</strong>: <code>b / GammaDist(a, 1)</code>, where <code>a</code> and <code>b</code> have the
same meaning as in the gamma distribution.  Alternatively, <code>1.0 / (pow(GammaDist(a, 1), 1.0 / c) / b + d)</code>, where <code>c</code> and <code>d</code> are shape and location parameters, respectively.</li>
<li><strong>Laplace (double exponential) distribution</strong>: <code>(ln(RNDU01ZeroExc()) - ln(RNDU01ZeroExc())) * beta + mu</code>, where <code>beta</code> is the scale and <code>mu</code> is the mean.</li>
<li><strong>Logarithmic distribution</strong>: <code>min + (max - min) * RNDU01OneExc() * RNDU01OneExc()</code>, where <code>min</code> is the minimum value and <code>max</code> is the maximum value (Saucier 2000, p. 26).  In this distribution, numbers closer to <code>min</code> are exponentially more likely than numbers closer to <code>max</code>.</li>
<li><strong>Logarithmic normal distribution</strong>: <code>exp(Normal(mu, sigma))</code>, where <code>mu</code> and <code>sigma</code>
have the same meaning as in the normal distribution.</li>
<li><strong>Multinormal distribution</strong>: See multivariate normal distribution.</li>
<li><strong>Multivariate normal distribution</strong>: See <a href="#Multivariate_Normal_Multinormal_Distribution"><strong>Multivariate Normal (Multinormal) Distribution</strong></a>.</li>
<li><strong>Normal distribution</strong>: See <a href="#Normal_Gaussian_Distribution"><strong>Normal (Gaussian) Distribution</strong></a>.</li>
<li><strong>Poisson distribution</strong>: See <a href="#Poisson_Distribution"><strong>Poisson Distribution</strong></a>.</li>
<li><strong>Pareto distribution</strong>: <code>pow(RNDU01ZeroOneExc(), -1.0 / alpha) * minimum</code>, where <code>alpha</code>  is the shape and <code>minimum</code> is the minimum.</li>
<li><strong>Rayleigh distribution</strong>: <code>a * sqrt(-2 * ln(RNDU01ZeroExc()))</code>, where <code>a</code> is the scale and is greater than 0.  If <code>a</code> follows a logarithmic normal distribution, the result is a <em>Suzuki distribution</em>.</li>
<li><strong>Standard normal distribution</strong>: <code>Normal(0, 1)</code>.  See also <a href="#Normal_Gaussian_Distribution"><strong>Normal (Gaussian) Distribution</strong></a>.</li>
<li><strong>Student&#39;s <em>t</em>-distribution</strong>: <code>Normal(cent, 1) / sqrt(GammaDist(df * 0.5, 2 / df))</code>, where <code>df</code> is the number of degrees of freedom, and <em>cent</em> is the mean of the normally-distributed random number.  A <code>cent</code> other than 0 indicates a <em>noncentral</em> distribution.</li>
<li><strong>Triangular distribution</strong>: <code>ContinuousWeightedChoice([startpt, midpt, endpt], [0, 1, 0])</code>. The distribution starts at <code>startpt</code>, peaks at <code>midpt</code>, and ends at <code>endpt</code>.</li>
<li><strong>Weibull distribution</strong>: <code>b * pow(-ln(RNDU01ZeroExc()),1.0 / a) + loc</code>, where <code>a</code> is the shape, <code>b</code> is the scale <code>loc</code> is the location, and <code>a</code> and <code>b</code> are greater than 0.</li>
</ul>

<p>Miscellaneous:</p>

<ul>
<li><strong>3-parameter gamma distribution</strong>: See <a href="#Gamma_Distribution"><strong>Gamma Distribution</strong></a>.</li>
<li><strong>4-parameter gamma distribution</strong>: See <a href="#Gamma_Distribution"><strong>Gamma Distribution</strong></a>.</li>
<li><strong>4-parameter stable distribution</strong>: See <a href="#Stable_Distribution"><strong>Stable Distribution</strong></a>.</li>
<li><strong>Archimedean copulas</strong>: See <a href="#Gaussian_and_Other_Copulas"><strong>Gaussian and Other Copulas</strong></a>.</li>
<li><strong>Arcsine distribution</strong>: <code>min + (max - min) * BetaDist(0.5, 0.5)</code>, where <code>min</code> is the minimum value and <code>max</code> is the maximum value (Saucier 2000, p. 14).</li>
<li><strong>Bates distribution</strong>: See <a href="#Transformations_of_Random_Numbers_Additional_Examples"><strong>Transformations of Random Numbers: Additional Examples</strong></a>.</li>
<li><strong>Beckmann distribution</strong>: See <a href="#Multivariate_Normal_Multinormal_Distribution"><strong>Multivariate Normal (Multinormal) Distribution</strong></a>.</li>
<li><strong>Beta binomial distribution</strong>: <code>Binomial(trials, BetaDist(a, b))</code>, where <code>a</code> and <code>b</code> are
the two parameters of the beta distribution, and <code>trials</code> is a parameter of the binomial distribution.</li>
<li><strong>Beta negative binomial distribution</strong>: <code>NegativeBinomial(successes, BetaDist(a, b))</code>, where <code>a</code> and <code>b</code> are the two parameters of the beta distribution, and <code>successes</code> is a parameter of the negative binomial distribution. If <em>successes</em> is 1, the result is a <em>Waring&ndash;Yule distribution</em>.</li>
<li><strong>Beta-PERT distribution</strong>: <code>startpt + size * BetaDist(1.0 + (midpt - startpt) * shape / size, 1.0 + (endpt - midpt) * shape / size)</code>. The distribution starts  at <code>startpt</code>, peaks at <code>midpt</code>, and ends at <code>endpt</code>, <code>size</code> is <code>endpt - startpt</code>, and <code>shape</code> is a shape parameter that&#39;s 0 or greater, but usually 4.  If the mean (<code>mean</code>) is known rather than the peak, <code>midpt = 3 * mean / 2 - (startpt + endpt) / 4</code>.</li>
<li><strong>Beta prime distribution</strong>: <code>pow(GammaDist(a, 1), 1.0 / alpha) * scale / pow(GammaDist(b, 1), 1.0 / alpha)</code>, where <code>a</code>, <code>b</code>, and <code>alpha</code> are shape parameters and <code>scale</code> is the scale. If <em>a</em> is 1, the result is a <em>Singh&ndash;Maddala distribution</em>; if <em>b</em> is 1, a <em>Dagum distribution</em>; if <em>a</em> and <em>b</em> are both 1, a <em>logarithmic logistic distribution</em>.</li>
<li><strong>Birnbaum&ndash;Saunders distribution</strong>: <code>pow(sqrt(4+x*x)+x,2)/(4.0*lamda)</code>, where <code>x = Normal(0,gamma)</code>, <code>gamma</code> is a shape parameter, and <code>lamda</code> is a scale parameter.</li>
<li><strong>Chi distribution</strong>: <code>sqrt(GammaDist(df * 0.5, 2))</code>, where <code>df</code> is the number of degrees of freedom.</li>
<li><strong>Compound Poisson distribution</strong>: See <a href="#Transformations_of_Random_Numbers_Additional_Examples"><strong>Transformations of Random Numbers: Additional Examples</strong></a>.</li>
<li><strong>Cosine distribution</strong>: <code>min + (max - min) * atan2(x, sqrt(1 - x * x)) / pi</code>, where <code>x = RNDRANGE(-1, 1)</code> and <code>min</code> is the minimum value and <code>max</code> is the maximum value (Saucier 2000, p. 17; inverse sine replaced with <code>atan2</code> equivalent).</li>
<li><strong>Dagum distribution</strong>: See beta prime distribution.</li>
<li><strong>Dirichlet distribution</strong>: See <a href="#Random_Real_Numbers_with_a_Given_Positive_Sum"><strong>Random Real Numbers with a Given Positive Sum</strong></a>.</li>
<li><strong>Double logarithmic distribution</strong>: <code>min + (max - min) * (0.5 + (RNDINT(1) * 2 - 1) * 0.5 * RNDU01OneExc() * RNDU01OneExc())</code>, where <code>min</code> is the minimum value and <code>max</code> is the maximum value (see also Saucier 2000, p. 15, which shows the wrong X axes).</li>
<li><strong>Erlang distribution</strong>: See <a href="#Gamma_Distribution"><strong>Gamma Distribution</strong></a>.</li>
<li><strong>Estoup distribution</strong>: See zeta distribution.</li>
<li><strong>Fr&eacute;chet distribution</strong>: <code>b*pow(-ln(RNDU01ZeroExc()),-1.0/a) + loc</code>, where <code>a</code> is the shape, <code>b</code> is the scale, and <code>loc</code> is the location of the distribution&#39;s curve peak (mode). This expresses a distribution of maximum values.</li>
<li><strong>Fr&eacute;chet&ndash;Hoeffding lower bound copula</strong>: See <a href="#Gaussian_and_Other_Copulas"><strong>Gaussian and Other Copulas</strong></a>.</li>
<li><strong>Fr&eacute;chet&ndash;Hoeffding upper bound copula</strong>: See <a href="#Gaussian_and_Other_Copulas"><strong>Gaussian and Other Copulas</strong></a>.</li>
<li><strong>Gaussian copula</strong>: See <a href="#Gaussian_and_Other_Copulas"><strong>Gaussian and Other Copulas</strong></a>.</li>
<li><strong>Generalized extreme value (Fisher&ndash;Tippett) distribution</strong>: <code>a - (pow(-ln(RNDU01ZeroOneExc()), -c) - 1) * b / c</code> if <code>c != 0</code>, or <code>a - ln(-ln(RNDU01ZeroOneExc())) * b</code> otherwise, where <code>b</code> is the scale, <code>a</code> is the location of the distribution&#39;s curve peak (mode), and <code>c</code> is a shape parameter. This expresses a distribution of maximum values.</li>
<li><strong>Generalized Tukey lambda distribution</strong>: <code>(s1 * (pow(x, lamda1)-1.0)/lamda1 - s2 * (pow(1.0-x, lamda2)-1.0)/lamda2) + loc</code>, where <code>x</code> is <code>RNDU01()</code>, <code>lamda1</code> and <code>lamda2</code> are shape parameters, <code>s1</code> and <code>s2</code> are scale parameters, and <code>loc</code> is a location parameter.</li>
<li><strong>Half-normal distribution</strong>. Parameterizations include:

<ul>
<li><em>Mathematica</em>: <code>abs(Normal(0, sqrt(pi * 0.5) / invscale)))</code>, where <code>invscale</code> is a parameter of the half-normal distribution.</li>
<li>MATLAB: <code>abs(Normal(mu, sigma)))</code>, where <code>mu</code> and <code>sigma</code> are the same as in the normal distribution.</li>
</ul></li>
<li><strong>Hyperexponential distribution</strong>: See <a href="#Mixtures_Additional_Examples"><strong>Mixtures: Additional Examples</strong></a>.</li>
<li><strong>Hypergeometric distribution</strong>: See <a href="#Hypergeometric_Distribution"><strong>Hypergeometric Distribution</strong></a>.</li>
<li><strong>Hypoexponential distribution</strong>: See <a href="#Transformations_of_Random_Numbers_Additional_Examples"><strong>Transformations of Random Numbers: Additional Examples</strong></a>.</li>
<li><strong>Inverse chi-squared distribution</strong>: <code>df * scale / (GammaDist(df * 0.5, 2))</code>, where <code>df</code> is the number of degrees of freedom and <code>scale</code> is the scale, usually <code>1.0 / df</code>.</li>
<li><strong>Inverse Gaussian distribution (Wald distribution)</strong>: Generate <code>n = mu + (mu*mu*y/(2*lamda)) - mu * sqrt(4 * mu * lamda * y + mu * mu * y * y) / (2 * lamda)</code>, where <code>y = pow(Normal(0, 1), 2)</code>, then return <code>n</code> if <code>RNDU01OneExc() &lt;= mu / (mu + n)</code>, or <code>mu * mu / n</code> otherwise. <code>mu</code> is the mean and <code>lamda</code> is the scale; both parameters are greater than 0. Based on method published in <a href="http://luc.devroye.org/rnbookindex.html"><strong>Devroye 1986</strong></a>.</li>
<li><strong>Kumaraswamy distribution</strong>: <code>min + (max - min) * pow(1-pow(RNDU01ZeroExc(),1.0/b),1.0/a)</code>, where <code>a</code> and <code>b</code> are shape parameters, <code>min</code> is the minimum value, and <code>max</code> is the maximum value.</li>
<li><strong>Landau distribution</strong>: See <a href="#Stable_Distribution"><strong>Stable Distribution</strong></a>.</li>
<li><strong>L&eacute;vy distribution</strong>: <code>sigma * 0.5 / GammaDist(0.5, 1) + mu</code>, where <code>mu</code> is the location and <code>sigma</code> is the dispersion.</li>
<li><strong>Logarithmic logistic distribution</strong>: See beta prime distribution.</li>
<li><strong>Logarithmic series distribution</strong>: <code>floor(1.0 + ln(RNDU01ZeroExc()) / ln(1.0 - pow(1.0 - param, RNDU01ZeroOneExc())))</code>, where <code>param</code> is a number greater than 0 and less than 1. Based on method described in Devroye 1986.</li>
<li><strong>Logistic distribution</strong>: <code>(ln(x)-ln(1.0 - x)) * scale + mean</code>, where <code>x</code> is <code>RNDU01ZeroOneExc()</code> and <code>mean</code> and <code>scale</code> are the mean and the scale, respectively.</li>
<li><strong>Log-multinormal distribution</strong>: See <a href="#Multivariate_Normal_Multinormal_Distribution"><strong>Multivariate Normal (Multinormal) Distribution</strong></a>.</li>
<li><strong>Max-of-uniform distribution</strong>: See <a href="#Gamma_Distribution"><strong>Gamma Distribution</strong></a>.</li>
<li><strong>Maxwell distribution</strong>: <code>scale * sqrt(GammaDist(1.5, 2))</code>, where <code>scale</code> is the scale.</li>
<li><strong>Min-of-uniform distribution</strong>: See <a href="#Gamma_Distribution"><strong>Gamma Distribution</strong></a>.</li>
<li><strong>Moyal distribution</strong>: See the <a href="https://peteroupc.github.io/randomgen.zip"><strong>Python sample code</strong></a>.</li>
<li><strong>Multinomial distribution</strong>: See <a href="#Multinomial_Distribution"><strong>Multinomial Distribution</strong></a>.</li>
<li><strong>Multivariate Poisson distribution</strong>: See the <a href="https://peteroupc.github.io/randomgen.zip"><strong>Python sample code</strong></a>.</li>
<li><strong>Multivariate <em>t</em>-copula</strong>: See the <a href="https://peteroupc.github.io/randomgen.zip"><strong>Python sample code</strong></a>.</li>
<li><strong>Multivariate <em>t</em>-distribution</strong>: See the <a href="https://peteroupc.github.io/randomgen.zip"><strong>Python sample code</strong></a>.</li>
<li><strong>Negative binomial distribution</strong>: See <a href="#Negative_Binomial_Distribution"><strong>Negative Binomial Distribution</strong></a>.</li>
<li><strong>Negative multinomial distribution</strong>: See the <a href="https://peteroupc.github.io/randomgen.zip"><strong>Python sample code</strong></a>.</li>
<li><strong>Noncentral beta distribution</strong>: <code>BetaDist(a + Poisson(nc), b)</code>, where <code>nc</code> (a noncentrality), <code>a</code>, and <code>b</code> are greater than 0.</li>
<li><strong>Parabolic distribution</strong>: <code>min + (max - min) * BetaDist(2, 2)</code>, where <code>min</code> is the minimum value and <code>max</code> is the maximum value (Saucier 2000, p. 30).</li>
<li><strong>Pascal distribution</strong>: <code>NegativeBinomial(successes, p) + successes</code>, where <code>successes</code> and <code>p</code> have the same meaning as in the negative binomial distribution, except <code>successes</code> is always an integer.</li>
<li><strong>Pearson VI distribution</strong>: <code>GammaDist(v, 1) / (GammaDist(w, 1))</code>, where <code>v</code> and <code>w</code> are shape parameters greater than 0 (Saucier 2000, p. 33; there, an additional <code>b</code> parameter is defined, but that parameter is canceled out in the source code).</li>
<li><strong>Piecewise constant distribution</strong>: See <a href="#Weighted_Choice_With_Replacement"><strong>Weighted Choice With Replacement</strong></a>.</li>
<li><strong>Piecewise linear distribution</strong>: See <a href="#Continuous_Weighted_Choice"><strong>Continuous Weighted Choice</strong></a>.</li>
<li><strong>P&oacute;lya&ndash;Aeppli distribution</strong>: See <a href="#Transformations_of_Random_Numbers_Additional_Examples"><strong>Transformations of Random Numbers: Additional Examples</strong></a>.</li>
<li><strong>Power distribution</strong>: <code>pow(RNDU01ZeroOneExc(), 1.0 / alpha) / b</code>, where <code>alpha</code>  is the shape and <code>b</code> is the domain.  Nominally in the interval (0, 1).</li>
<li><strong>Power law distribution</strong>: <code>pow(RNDRANGE(pow(mn,n+1),pow(mx,n+1)), 1.0 / (n+1))</code>, where <code>n</code>  is the exponent, <code>mn</code> is the minimum, and <code>mx</code> is the maximum.  <a href="http://mathworld.wolfram.com/RandomNumber.html"><strong>Reference</strong></a>.</li>
<li><strong>Power lognormal distribution</strong>: See the <a href="https://peteroupc.github.io/randomgen.zip"><strong>Python sample code</strong></a>.</li>
<li><strong>Power normal distribution</strong>: See the <a href="https://peteroupc.github.io/randomgen.zip"><strong>Python sample code</strong></a>.</li>
<li><strong>Product copula</strong>: See <a href="#Gaussian_and_Other_Copulas"><strong>Gaussian and Other Copulas</strong></a>.</li>
<li><strong>Rice distribution</strong>: See <a href="#Multivariate_Normal_Multinormal_Distribution"><strong>Multivariate Normal (Multinormal) Distribution</strong></a>.</li>
<li><strong>Rice&ndash;Norton distribution</strong>: See <a href="#Multivariate_Normal_Multinormal_Distribution"><strong>Multivariate Normal (Multinormal) Distribution</strong></a>.</li>
<li><strong>Singh&ndash;Maddala distribution</strong>: See beta prime distribution.</li>
<li><strong>Skellam distribution</strong>: <code>Poisson(mean1) - Poisson(mean2)</code>, where <code>mean1</code> and <code>mean2</code> are the means of the two Poisson variables.</li>
<li><strong>Skewed normal distribution</strong>: <code>Normal(0, x) + mu + alpha * abs(Normal(0, x))</code>, where <code>x</code> is <code>sigma / sqrt(alpha * alpha + 1.0)</code>, <code>mu</code> and <code>sigma</code> have the same meaning as in the normal distribution, and <code>alpha</code> is a shape parameter.</li>
<li><strong>Snedecor&#39;s (Fisher&#39;s) <em>F</em>-distribution</strong>: <code>GammaDist(m * 0.5, n) / (GammaDist(n * 0.5 + Poisson(sms * 0.5)) * m, 1)</code>, where <code>m</code> and <code>n</code> are the numbers of degrees of freedom of two random numbers with a chi-squared distribution, and if <code>sms</code> is other than 0, one of those distributions is <em>noncentral</em> with sum of mean squares equal to <code>sms</code>.</li>
<li><strong>Stable distribution</strong>: See <a href="#Stable_Distribution"><strong>Stable Distribution</strong></a>.</li>
<li><strong>Standard complex normal distribution</strong>: See <a href="#Multivariate_Normal_Multinormal_Distribution"><strong>Multivariate Normal (Multinormal) Distribution</strong></a>.</li>
<li><strong>Suzuki distribution</strong>: See Rayleigh distribution.</li>
<li><strong>Tukey lambda distribution</strong>: <code>(pow(x, lamda)-pow(1.0-x,lamda))/lamda</code>, where <code>x</code> is <code>RNDU01()</code> and <code>lamda</code> is a shape parameter (if 0, the result is a logistic distribution).</li>
<li><strong>&quot;Type 0&quot; stable distribution</strong>: See <a href="#Stable_Distribution"><strong>Stable Distribution</strong></a>.</li>
<li><strong>von Mises distribution</strong>: See <a href="#von_Mises_Distribution"><strong>von Mises Distribution</strong></a>.</li>
<li><strong>Waring&ndash;Yule distribution</strong>: See beta negative binomial distribution.</li>
<li><strong>Wigner (semicircle) distribution</strong>: <code>a + radius * (BetaDist(1.5, 1.5)*2-1)</code>, where <code>radius</code> is the semicircular radius and <code>a</code> is the location.</li>
<li><strong>Zeta distribution</strong>: Generate <code>n = floor(pow(RNDU01ZeroOneExc(), -1.0 / r))</code>, and if <code>d / pow(2, r) &lt; (d - 1) * RNDU01OneExc() * n / (pow(2, r) - 1.0)</code>, where <code>d = pow((1.0 / n) + 1, r)</code>, repeat this process. The parameter <code>r</code> is greater than 0. Based on method described in Devroye 1986. A zeta distribution <a href="#Censoring_and_Truncation"><strong>truncated</strong></a> by rejecting random values greater than some positive integer is called a <em>Zipf distribution</em> or <em>Estoup distribution</em>. (Note that Devroye uses &quot;Zipf distribution&quot; to refer to the untruncated zeta distribution.)</li>
<li><strong>Zipf distribution</strong>: See zeta distribution.</li>
</ul>

<p><a id=Geometric_Sampling></a></p>

<h3>Geometric Sampling</h3>

<p><strong>Requires random real numbers.</strong></p>

<p>This section contains ways to do independent and uniform random sampling of points in or on geometric shapes.</p>

<p><a id=Random_Points_Inside_a_Box></a></p>

<h4>Random Points Inside a Box</h4>

<p>To generate a random point inside an N-dimensional box, generate <code>RNDRANGEMaxExc(mn, mx)</code> for each coordinate, where <code>mn</code> and <code>mx</code> are the lower and upper bounds for that coordinate.  For example&mdash;</p>

<ul>
<li>to generate a random point inside a rectangle bounded in [0, 2) along the X axis and [3, 6) along the Y axis, generate <code>[RNDRANGEMaxExc(0,2), RNDRANGEMaxExc(3,6)]</code>, and</li>
<li>to generate a <em>complex number</em> with real and imaginary parts bounded in [0, 1], generate <code>[RNDU01(), RNDU01()]</code>.</li>
</ul>

<p><a id=Random_Points_Inside_a_Simplex></a></p>

<h4>Random Points Inside a Simplex</h4>

<p>The following pseudocode generates a random point inside an <em>n</em>-dimensional simplex (simplest convex figure, such as a line segment, triangle, or tetrahedron).  It takes an array <em>points</em>, a list consisting of the <em>n</em> plus one vertices of the simplex, all of a single dimension <em>n</em> or greater.</p>

<pre>METHOD RandomPointInSimplex(points):
   ret=NewList()
   if size(points) &gt; size(points[0])+1: return error
   if size(points)==1 // Return a copy of the point
     for i in 0...size(points[0]): AddItem(ret,points[0][i])
     return ret
   end
   gammas=NewList()
   // Sample from a Dirichlet distribution
   for i in 0...size(points): AddItem(gammas,
       -ln(RNDU01ZeroOneExc()))
   tsum=0
   for i in 0...size(gammas): tsum = tsum + gammas[i]
   tot = 0
   for i in 0...size(gammas) - 1
       gammas[i] = gammas[i] / tsum
       tot = tot + gammas[i]
   end
   tot = 1.0 - tot
   for i in 0...size(points[0]): AddItem(ret, points[0][i]*tot)
   for i in 1...size(points)
      for j in 0...size(points[0])
         ret[j]=ret[j]+points[i][j]*gammas[i-1]
      end
   end
   return ret
END METHOD
</pre>

<p><a id=Random_Points_on_the_Surface_of_a_Hypersphere></a></p>

<h4>Random Points on the Surface of a Hypersphere</h4>

<p>The following pseudocode shows how to generate a random N-dimensional point on the surface of an N-dimensional hypersphere, centered at the origin, of radius <code>radius</code> (if <code>radius</code> is 1, the result can also serve as a unit vector in N-dimensional space).  Here, <code>Norm</code> is given in the appendix.  See also (Weisstein)<sup><a href="#Note31"><strong>(31)</strong></a></sup>.</p>

<pre>METHOD RandomPointInHypersphere(dims, radius)
  x=0
  while x==0
    ret=[]
    for i in 0...dims: AddItem(ret, Normal(0, 1))
    x=Norm(ret)
  end
  invnorm=radius/x
  for i in 0...dims: ret[i]=ret[i]*invnorm
  return ret
END METHOD
</pre>

<blockquote>
<p><strong>Note:</strong> The Python sample code contains an optimized method for points on the edge of a circle.</p>

<p><strong>Example:</strong> To generate a random point on the surface of a cylinder running along the Z axis, generate random X and Y coordinates on the edge of a circle (2-dimensional hypersphere) and generate a random Z coordinate by <code>RNDRANGE(mn, mx)</code>, where <code>mn</code> and <code>mx</code> are the highest and lowest Z coordinates possible.</p>
</blockquote>

<p><a id=Random_Points_Inside_a_Ball_or_Shell></a></p>

<h4>Random Points Inside a Ball or Shell</h4>

<p>To generate a random N-dimensional point on or inside an N-dimensional ball, centered at the origin, of radius R, follow the pseudocode in <code>RandomPointInHypersphere</code>, except replace <code>Norm(ret)</code> with <code>sqrt( S - ln(RNDU01ZeroExc()))</code>, where <code>S</code> is the sum of squares of the numbers in <code>ret</code><sup><a href="#Note12"><strong>(12)</strong></a></sup>
.  For discs and spheres (2- or 3-dimensional balls), an alternative is to generate a vector (list) of N <code>RNDRANGE(-R, R)</code> random numbers<sup><a href="#Note32"><strong>(32)</strong></a></sup> until its <em>norm</em> is R or less (see the <a href="#Appendix"><strong>appendix</strong></a>).<sup><a href="#Note33"><strong>(33)</strong></a></sup></p>

<p>To generate a random point on or inside an N-dimensional spherical shell (a hollow ball), centered at the origin, with inner radius A and outer radius B (where A is less than B), either&mdash;</p>

<ul>
<li>generate a random point for a ball of radius B until the norm of that point is A or greater (see the <a href="#Appendix"><strong>appendix</strong></a>), or</li>
<li>generate a random point on the surface of an N-dimensional hypersphere with radius equal to <code>pow(RNDRANGE(pow(A, N), pow(B, N)), 1.0 / N)</code><sup><a href="#Note34"><strong>(34)</strong></a></sup>.</li>
</ul>

<blockquote>
<p><strong>Example:</strong> To generate a random point inside a cylinder running along the Z axis, generate random X and Y coordinates inside a disk (2-dimensional ball) and generate a random Z coordinate by <code>RNDRANGE(mn, mx)</code>, where <code>mn</code> and <code>mx</code> are the highest and lowest Z coordinates possible.</p>

<p><strong>Note:</strong> The Python sample code contains a method for generating a random point on the surface of an ellipsoid modeling the Earth.</p>
</blockquote>

<p><a id=Random_Latitude_and_Longitude></a></p>

<h4>Random Latitude and Longitude</h4>

<p>To generate a random point on the surface of a sphere in the form of a latitude and longitude (in radians with west and south coordinates negative)&mdash;</p>

<ul>
<li>generate the longitude <code>RNDRANGEMaxExc(-pi, pi)</code>, where the longitude is in the interval [-&pi;, &pi;), and</li>
<li>generate the latitude <code>atan2(sqrt(1 - x * x), x) - pi / 2</code>, where <code>x = RNDRANGE(-1, 1)</code> and the latitude is in the interval [-&pi;/2, &pi;/2] (the interval excludes the poles, which have many equivalent forms; if poles are not desired, generate <code>x</code> until neither -1 nor 1 is generated this way).</li>
</ul>

<p>Reference: <a href="http://mathworld.wolfram.com/SpherePointPicking.html"><strong>&quot;Sphere Point Picking&quot;</strong></a> in MathWorld (replacing inverse cosine with <code>atan2</code> equivalent).</p>

<p><a id=Acknowledgments></a></p>

<h2>Acknowledgments</h2>

<p>I acknowledge the commenters to the CodeProject version of this page, including George Swan, who referred me to the reservoir sampling method.</p>

<p><a id=Notes></a></p>

<h2>Notes</h2>

<p><small><sup id=Note1>(1)</sup> For the definition of an RNG, it is irrelevant&mdash;</p>

<ul>
<li>how hard it is to predict the numbers the item produces,</li>
<li>how well the item passes statistical randomness tests,</li>
<li>whether the item is initialized automatically or not,</li>
<li>whether the item uses only its input and its state to produce numbers, or</li>
<li>whether the item extracts uniformly distributed bits from one or more noise sources.</li>
</ul>

<p>If an item uses a nonuniform distribution, but otherwise meets this definition, it can be converted to use a uniform distribution, at least in theory, using <em>randomness extraction</em> techniques that are outside the scope of this document.</small></p>

<p><small><sup id=Note2>(2)</sup> For an exercise solved by the <code>RNDINT</code> pseudocode, see A. Koenig and B. E. Moo, <em>Accelerated C++</em>, 2000; see also a <a href="http://mathalope.co.uk/2014/10/26/accelerated-c-solution-to-exercise-7-9/"><strong>blog post by Johnny Chan</strong></a>.  In addition, M. O&#39;Neill discusses various methods, both biased and unbiased, for generating random integers in a range with an RNG in a <a href="http://www.pcg-random.org/posts/bounded-rands.html"><strong>blog post from July 2018</strong></a>.</small></p>

<p><small><sup id=Note3>(3)</sup> A na&iuml;ve <code>RNDINTEXC</code> implementation often seen in certain languages like JavaScript is the idiom <code>floor(Math.random()*maxExclusive)</code>, where <code>Math.random()</code> is any method that outputs an independent uniform random number in the interval [0, 1).  However:</p>

<ol>
<li>Depending on how <code>Math.random()</code> is implemented, this idiom can&#39;t choose from among all integers in its range or may bias some integers over others; this bias may or may not be negligible in a given application.  For example, if <code>Math.random()</code> is implemented as <code>RNDINT(255)/256</code>, not all numbers can &quot;randomly&quot; occur by this idiom with <code>maxExclusive</code> greater than 256.</li>
<li>Depending on the number format, rounding error can result in <code>maxExclusive</code> being returned in rare cases.  A more robust implementation could use a loop to check whether <code>maxExclusive</code> was generated and try again if so.  Where a loop is not possible, such as within an SQL query, the idiom above can be replaced with <code>min(floor(Math.random() * maxExclusive, maxExclusive - 1))</code>.  Neither modification addresses item 1, however.</li>
</ol>

<p>If an application is concerned about these issues, it should treat the <code>Math.random()</code> implementation as the underlying RNG for <code>RNDINT</code> and implement <code>RNDINTEXC</code> through <code>RNDINT</code> instead.</small></p>

<p><small><sup id=Note4>(4)</sup> Describing differences between SQL dialects is outside the scope of this document, but <a href="http://flourishlib.com/docs/FlourishSQL"><strong>Flourish SQL</strong></a> describes many such differences, including those concerning RNGs.</small></p>

<p><small><sup id=Note5>(5)</sup> Jeff Atwood, &quot;<a href="https://blog.codinghorror.com/the-danger-of-naivete/"><strong>The danger of na&iuml;vet&eacute;</strong></a>&quot;, Dec. 7, 2007.</small></p>

<p><small><sup id=Note6>(6)</sup> If the strings identify database records, file system paths, or other shared resources, special considerations apply, including the need to synchronize access to those resources.  For uniquely identifying database records, alternatives to random strings include auto-incrementing or sequentially assigned row numbers. The choice of underlying RNG is important when it comes to unique random strings; see my <a href="https://peteroupc.github.io/random.html#Unique_Random_Identifiers"><strong>RNG recommendation document</strong></a>.</small></p>

<p><small><sup id=Note7>(7)</sup> See also the <em>Stack Overflow</em> question &quot;Random index of a non zero value in a numpy array&quot;.</small></p>

<p><small><sup id=Note8>(8)</sup> Brownlee, J. &quot;<a href="https://machinelearningmastery.com/a-gentle-introduction-to-the-bootstrap-method/"><strong>A Gentle Introduction to the Bootstrap Method</strong></a>&quot;, <em>Machine Learning Mastery</em>, May 25, 2018.</small></p>

<p><small><sup id=Note9>(9)</sup> Jon Louis Bentley and James B. Saxe, &quot;Generating Sorted Lists of Random Numbers&quot;, <em>ACM Trans. Math. Softw.</em> 6 (1980), pp. 359-364, describes a way to generate random numbers in sorted order, but it&#39;s not given here because it relies on generating real numbers in the interval [0, 1], which is inherently imperfect because computers can&#39;t choose among all random numbers between 0 and 1, and there are infinitely many of them.</small></p>

<p><small><sup id=Note10>(10)</sup> The <a href="https://peteroupc.github.io/randomgen.zip"><strong>Python sample code</strong></a> includes a <code>ConvexPolygonSampler</code> class that implements this kind of sampling for convex polygons; unlike other polygons, convex polygons are trivial to decompose into triangles.</small></p>

<p><small><sup id=Note11>(11)</sup> That article also mentions a critical-hit distribution, which is actually a <a href="#Mixtures_of_Distributions"><strong>mixture</strong></a> of two distributions: one roll of dice and the sum of two rolls of dice.</small></p>

<p><small><sup id=Note12>(12)</sup> <a href="https://en.wikipedia.org/wiki/Kahan_summation_algorithm"><strong>Kahan summation</strong></a> can be a more robust way than the na&iuml;ve approach to compute the sum of three or more numbers.</small></p>

<p><small><sup id=Note13>(13)</sup> An <em>affine transformation</em> is one that keeps straight lines straight and parallel lines parallel.</small></p>

<p><small><sup id=Note14>(14)</sup> If <code>px</code>/<code>py</code> is <code>1</code>/<code>2</code>, the binomial distribution models the task &quot;Flip N coins, then count the number of heads&quot;, and the random sum is known as <a href="https://en.wikipedia.org/wiki/Hamming_distance"><strong><em>Hamming distance</em></strong></a> (treating each trial as a &quot;bit&quot; that&#39;s set to 1 for a success and 0 for a failure).  If <code>px</code> is <code>1</code>, then this distribution models the task &quot;Roll <code>n</code> <code>py</code>-sided dice, then count the number of dice that show the number 1.&quot;</small></p>

<p><small><sup id=Note15>(15)</sup> Smith and Tromble, &quot;<a href="http://www.cs.cmu.edu/%7Enasmith/papers/smith+tromble.tr04.pdf"><strong>Sampling Uniformly from the Unit Simplex</strong></a>&quot;, 2004.</small></p>

<p><small><sup id=Note16>(16)</sup> Downey, A. B. &quot;<a href="http://allendowney.com/research/rand/"><strong>Generating Pseudo-random Floating Point Values</strong></a>&quot;, 2007.</small></p>

<p><small><sup id=Note17>(17)</sup> See, for example, the <em>Stack Overflow</em> question &quot;How to generate a number in arbitrary range using random()={0..1} preserving uniformness and density?&quot;, <code>questions/8019589</code>.</small></p>

<p><small><sup id=Note18>(18)</sup> Spall, J.C., &quot;An Overview of the Simultaneous Perturbation Method for Efficient Optimization&quot;, <em>Johns Hopkins APL Technical Digest</em> 19(4), 1998, pp. 482-492.</small></p>

<p><small><sup id=Note19>(19)</sup> P. L&#39;Ecuyer, &quot;Tables of Linear Congruential Generators of Different Sizes and Good Lattice Structure&quot;, <em>Mathematics of Computation</em> 68(225), January 1999.</small></p>

<p><small><sup id=Note20>(20)</sup> Efraimidis, P. and Spirakis, P. &quot;<a href="http://utopia.duth.gr/%7Epefraimi/research/data/2007EncOfAlg.pdf"><strong>Weighted Random Sampling (2005; Efraimidis, Spirakis)</strong></a>&quot;, 2005.</small></p>

<p><small><sup id=Note21>(21)</sup> Efraimidis, P. &quot;Weighted Random Sampling over Data Streams&quot;. arXiv:1012.0256v2 [cs.DS], 2015.</small></p>

<p><small><sup id=Note22>(22)</sup> Saucier, R. &quot;Computer Generation of Statistical Distributions&quot;, March 2000.</small></p>

<p><small><sup id=Note23>(23)</sup> &quot;Jitter&quot;, as used in this step, follows a distribution formally called a <em>kernel</em>, of which the normal distribution is one example.  <em>Bandwidth</em> should be as low or as high as allows the estimated distribution to fit the data and remain smooth.  A more complex kind of &quot;jitter&quot; (for multi-component data points) consists of a point generated from a <a href="https://en.wikipedia.org/wiki/Multivariate_normal_distribution"><strong>multinormal distribution</strong></a> with all the means equal to 0 and a <em>covariance matrix</em> that, in this context, serves as a <em>bandwidth matrix</em>.  &quot;Jitter&quot; and bandwidth are not further discussed in this document.</small></p>

<p><small><sup id=Note24>(24)</sup> Other references on density estimation include <a href="https://en.wikipedia.org/wiki/Multivariate_kernel_density_estimation"><strong>a Wikipedia article on multiple-variable kernel density estimation</strong></a>, and a <a href="http://mark-kay.net/2013/12/24/kernel-density-estimation/"><strong>blog post by M. Kay</strong></a>.</small></p>

<p><small><sup id=Note25>(25)</sup> More formally&mdash;</p>

<ul>
<li>the PDF is the <em>derivative</em> (instantaneous rate of change) of the distribution&#39;s CDF (that is, PDF(x) = CDF&prime;(x)), and</li>
<li>the CDF is also defined as the <em>integral</em> (&quot;area under the curve&quot;) of the PDF,</li>
</ul>

<p>provided the PDF&#39;s values are all 0 or greater and the area under the PDF&#39;s curve is 1.</small></p>

<p><small><sup id=Note26>(26)</sup> Neal, R. M., <a href="https://projecteuclid.org/euclid.aos/1056562461"><strong>&quot;Slice sampling&quot;</strong></a>, <em>Annals of Statistics</em> 31(3), pp. 705-767 (2003).</small></p>

<p><small><sup id=Note27>(27)</sup> <em>See also</em> Casella, G., and George, E.I., &quot;Explaining the Gibbs Sampler&quot;, The American Statistician 46:3 (1992).</small></p>

<p><small><sup id=Note28>(28)</sup> The &quot;Dice&quot; and &quot;Dice: Optimization for Many Dice&quot; sections used the following sources:</p>

<ul>
<li>Red Blob Games, <a href="http://www.redblobgames.com/articles/probability/damage-rolls.html"><strong>&quot;Probability and Games: Damage Rolls&quot;</strong></a> was the main source for the dice-roll distribution.  The method <code>random(N)</code> in that document corresponds to <code>RNDINTEXC(N)</code> in this document.</li>
<li>The <a href="http://mathworld.wolfram.com/Dice.html"><strong>MathWorld article &quot;Dice&quot;</strong></a> provided the mean of the dice roll distribution.</li>
<li>S. Eger, &quot;Stirling&#39;s approximation for central extended binomial coefficients&quot;, 2014, helped suggest the variance of the dice roll distribution.</small></li>
</ul>

<p><small><sup id=Note29>(29)</sup> For example, besides the methods given in this section&#39;s main text:</p>

<ol>
<li>In the <em>Box&ndash;Muller transformation</em>, <code>mu + radius * cos(angle)</code> and <code>mu + radius * sin(angle)</code>, where <code>angle = RNDRANGEMaxExc(0, 2 * pi)</code> and <code>radius = sqrt(-2 * ln(RNDU01ZeroExc())) * sigma</code>, are two independent normally-distributed random numbers.</li>
<li>Computing the sum of twelve <code>RNDU01OneExc()</code> numbers (see Note 17) and subtracting the sum by 6 (see also <a href="https://en.wikipedia.org/wiki/Irwin%E2%80%93Hall_distribution"><strong>&quot;Irwin&ndash;Hall distribution&quot; on Wikipedia</strong></a>) results in approximate standard normal (<code>mu</code>=0, <code>sigma</code>=1) random numbers, whose values are not less than -6 or greater than 6; on the other hand, in a standard normal distribution, results less than -6 or greater than 6 will occur only with a generally negligible probability.</li>
<li>Generating <code>RNDU01ZeroOneExc()</code>, then running the standard normal distribution&#39;s inverse cumulative distribution function on that number, results in a random number from that distribution.  An approximation is found in M. Wichura, <em>Applied Statistics</em> 37(3), 1988.  See also <a href="https://www.johndcook.com/blog/normal_cdf_inverse/"><strong>&quot;A literate program to compute the inverse of the normal CDF&quot;</strong></a>.</li>
</ol>

<p>In 2007, Thomas, D., et al. gave a survey of normal random number methods in &quot;Gaussian Random Number Generators&quot;, <em>ACM Computing Surveys</em> 39(4), 2007, article 11.</small></p>

<p><small><sup id=Note30>(30)</sup> Hofert, M., and Maechler, M.  &quot;Nested Archimedean Copulas Meet R: The nacopula Package&quot;.  Journal of Statistical Software 39(9), 2011, pp. 1-20.</small></p>

<p><small><sup id=Note31>(31)</sup> Weisstein, Eric W.  &quot;<a href="http://mathworld.wolfram.com/HyperspherePointPicking.html"><strong>Hypersphere Point Picking</strong></a>&quot;.  From MathWorld&mdash;A Wolfram Web Resource.</small></p>

<p><small><sup id=Note32>(32)</sup> The N numbers generated this way will form a point inside an N-dimensional <em>hypercube</em> with length <code>2 * R</code> in each dimension and centered at the origin of space.</small></p>

<p><small><sup id=Note33>(33)</sup> See also a <a href="http://mathworld.wolfram.com/BallPointPicking.html"><strong>MathWorld article</strong></a>, which was the inspiration for these two methods, and the <em>Stack Overflow</em> question &quot;How to generate uniform random points in (arbitrary) N-dimension ball?&quot;, <code>questions/54544971</code>.</small></p>

<p><small><sup id=Note34>(34)</sup> See the <em>Mathematics Stack Exchange</em> question titled &quot;Random multivariate in hyperannulus&quot;, <code>questions/1885630</code>.</small></p>

<p><a id=Appendix></a></p>

<h2>Appendix</h2>

<p>&nbsp;</p>

<p><a id=Implementation_of_erf></a></p>

<h3>Implementation of <code>erf</code></h3>

<p>The pseudocode below shows how the <a href="https://en.wikipedia.org/wiki/Error_function"><strong>error function</strong></a> <code>erf</code> can be implemented, in case the programming language used doesn&#39;t include a built-in version of <code>erf</code> (such as JavaScript at the time of this writing).   In the pseudocode, <code>EPSILON</code> is a very small number to end the iterative calculation.</p>

<pre>METHOD erf(v)
    if v==0: return 0
    if v&lt;0: return -erf(-v)
    if v==infinity: return 1
    // NOTE: For Java `double`, the following
    // line can be added:
    // if v&gt;=6: return 1
    i=1
    ret=0
    zp=-(v*v)
    zval=1.0
    den=1.0
    while i &lt; 100
        r=v*zval/den
        den=den+2
        ret=ret+r
        // NOTE: EPSILON can be pow(10,14),
        // for example.
        if abs(r)&lt;EPSILON: break
        if i==1: zval=zp
        else: zval = zval*zp/i
        i = i + 1
    end
    return ret*2/sqrt(pi)
END METHOD
</pre>

<p><a id=Mean_and_Variance_Calculation></a></p>

<h3>Mean and Variance Calculation</h3>

<p>The following method calculates the mean and the <a href="http://mathworld.wolfram.com/Variance.html"><strong>bias-corrected sample variance</strong></a> of a list of real numbers, using the <a href="https://www.johndcook.com/blog/standard_deviation/"><strong>Welford method</strong></a> presented by J. D. Cook.  The method returns a two-item list containing the mean and that kind of variance in that order.  (Sample variance is the estimated variance of a population or distribution assuming <code>list</code> is a random sample of that population or distribution.)  The square root of the variance calculated here is what many APIs call a standard deviation (e.g. Python&#39;s <code>statistics.stdev</code>).</p>

<pre>METHOD MeanAndVariance(list)
    if size(list)==0: return [0, 0]
    if size(list)==1: return [list[0], 0]
    xm=list[0]
    xs=0
    i=1
    while i &lt; size(list)
        c = list[i]
        i = i + 1
        cxm = (c - xm)
        xm = xm + cxm *1.0/ i
        xs = xs + cxm * (c - xm)
    end
    return [xm, xs*1.0/(size(list)-1)]
END METHOD
</pre>

<blockquote>
<p><strong>Note:</strong> The population variance (or biased sample variance) is found by dividing by <code>size(list)</code> rather than <code>(size(list)-1)</code>, and the standard deviation of the population or a sample of it is the square root of that variance.</p>
</blockquote>

<p><a id=Norm_Calculation></a></p>

<h3>Norm Calculation</h3>

<p>The following method calculates the norm of a vector (list of numbers).</p>

<pre>METHOD Norm(vec)
  ret=0
  rc=0
  for i in 0...size(vec)
    rc=vec[i]*vec[i]-rc
    rt=rc+ret
    rc=(rt-ret)-rc
    ret=rt
  end
  return sqrt(ret)
END METHOD
</pre>

<p><a id=License></a></p>

<h2>License</h2>

<p>This page is licensed under <a href="https://creativecommons.org/publicdomain/zero/1.0/"><strong>Creative Commons Zero</strong></a>.</p>
</div><nav id="navigation"><ul>
<li><a href="/">Back to start site.</a>
<li><a href="https://github.com/peteroupc/peteroupc.github.io">This site's repository (source code)</a>
<li><a href="https://github.com/peteroupc/peteroupc.github.io/issues">Post an issue or comment</a></ul>
<p>
If you like this software, you should consider donating to me, Peter O., at the link below:</p>
<p class="printonly"><b>peteroupc.github.io</b></p>
<div class="noprint">
<a href="https://www.paypal.com/cgi-bin/webscr?cmd=_s-xclick&hosted_button_id=56E5T4FH7KD2S">
<img src="https://www.paypalobjects.com/en_US/i/btn/btn_donateCC_LG.gif"
name="submit" border="2" alt="PayPal - The safer, easier way to pay online!"></a>
<p>
<a href="//twitter.com/share">Share via Twitter</a>, <a href="//www.facebook.com/sharer/sharer.php" id="sharer">Share via Facebook</a>
</p>
</div>
</nav><script>
if("share" in navigator){
 document.getElementById("sharer").href="javascript:void(null)";
 document.getElementById("sharer").innerHTML="Share This Page";
 navigator.share({title:document.title,url:document.location.href}).then(
   function(){});
} else {
 document.getElementById("sharer").href="//www.facebook.com/sharer/sharer.php?u="+
    encodeURIComponent(document.location.href)
}
</script>
</body></html>
