<!DOCTYPE html><html xmlns:dc="http://purl.org/dc/terms/" itemscope itemtype="http://schema.org/Article"><head><meta http-equiv=Content-Type content="text/html; charset=utf-8"><title>Miscellaneous Observations on Randomization</title><meta name="citation_title" content="Miscellaneous Observations on Randomization"><meta name="og:title" content="Miscellaneous Observations on Randomization"><meta name="og:type" content="article"><meta name="og:site_name" content="peteroupc.github.io"><meta name="twitter:title" content="Miscellaneous Observations on Randomization"><meta name="author" content="Peter Occil"/><meta name="viewport" content="width=device-width"><link rel=stylesheet type="text/css" href="/style.css"></head><body>  <div class="header">
<nav><p><a href="#navigation">Menu</a> - <a href="#top">Top</a> - <a href="/">Home</a></nav></div>
<div class="mainarea" id="top">
<h1>Miscellaneous Observations on Randomization</h1>

<p><a href="mailto:poccil14@gmail.com"><strong>Peter Occil</strong></a></p>

<p><a id=On_a_Binomial_Sampler></a></p>

<h2>On a Binomial Sampler</h2>

<p>Take the following sampler of a binomial(<em>n</em>, 1/2) distribution (where <em>n</em> is even), which is equivalent to the one that appeared in (Bringmann et al. 2014)<sup><a href="#Note1"><strong>(1)</strong></a></sup>, and adapted to be more programmer-friendly.</p>

<ol>
<li>Set <em>m</em> to floor(sqrt(<em>n</em>)) + 1.</li>
<li>(First, sample from an envelope of the binomial curve.) Generate unbiased random bits (zeros or ones) until a zero is generated this way.  Set <em>k</em> to the number of ones generated this way.</li>
<li>Set <em>s</em> to an integer in [0, <em>m</em>) chosen uniformly at random, then set <em>i</em> to <em>k</em>*<em>m</em> + <em>s</em>.</li>
<li>Set <em>ret</em> to either <em>n</em>/2+<em>i</em> or <em>n</em>/2&minus;<em>i</em>&minus;1 with equal probability.</li>
<li>(Second, accept or reject <em>ret</em>.) If <em>ret</em> &lt; 0 or <em>ret</em> &gt; <em>n</em>, go to step 2.</li>
<li>With probability choose(<em>n</em>, <em>ret</em>)*<em>m</em>*2<sup><em>k</em>&minus;(<em>n</em>+2)</sup>, return <em>ret</em>.  Otherwise, go to step 2. (Here, choose(<em>n</em>, <em>k</em>) is a binomial coefficient.<sup><a href="#Note2"><strong>(2)</strong></a></sup>)</li>
</ol>

<p>This algorithm has an acceptance rate of 1/16 regardless of the value of <em>n</em>.  However, step 6 will generally require a growing amount of storage and time to exactly calculate the given probability as <em>n</em> gets large, notably due to the inherent factorial in the binomial coefficient.  The Bringmann paper suggests approximating this factorial via Spouge&#39;s approximation; however, it seems hard to do so without using floating-point arithmetic, which the paper ultimately resorts to. Alternatively, the logarithm of that probability can be calculated that is much more economical in terms of storage than the full exact probability.  Then, an exponential random number can be generated, negated, and compared with that logarithm to determine whether the step succeeds.</p>

<p>More specifically, step 6 can be changed as follows:</p>

<ul>
<li>(6.) Let <em>p</em> be loggamma(<em>n</em>+1)&minus;loggamma(<em>k</em>+1)&minus;loggamma((<em>n</em>&minus;<em>k</em>)+1)+ln(<em>m</em>)+ln(2)*<em>k</em>&minus;(<em>n</em>+2) (where loggamma(<em>x</em>) is the logarithm of the gamma function).</li>
<li>(6a.) Generate an exponential random number with rate 1 (which is the negative natural logarithm of a uniform(0,1) random number).  Set <em>e</em> to 0 minus that number.</li>
<li>(6b.) If <em>e</em> is greater than <em>p</em>, go to step 2.  Otherwise, return <em>ret</em>. (This step can be replaced by calculating lower and upper bounds that converge to <em>p</em>.  In that case, go to step 2 if <em>e</em> is greater than the upper bound, or return <em>ret</em> if <em>e</em> is less than the lower bound, or compute better bounds and repeat this step otherwise.  See also chapter 4 of (Devroye 1986)<sup><a href="#Note3"><strong>(3)</strong></a></sup>.)</li>
</ul>

<p>My implementation of loggamma and the natural logarithm (<a href="https://peteroupc.github.io/interval.py"><strong>interval.py</strong></a>) relies on rational interval arithmetic (Daumas et al. 2007)<sup><a href="#Note4"><strong>(4)</strong></a></sup> and a fast converging version of Stirling&#39;s formula for the factorial&#39;s natural logarithm (Schumacher 2016)<sup><a href="#Note5"><strong>(5)</strong></a></sup>.</p>

<p>Also, according to the Bringmann paper, <em>m</em> can be set such that <em>m</em> is in the interval [sqrt(<em>n</em>), sqrt(<em>n</em>)+3], so I implement step 1 by starting with <em>u</em> = 2<sup>floor((1+ceil(log2(<em>n</em>+1)))/2)</sup>, then calculating <em>v</em> = floor(<em>u</em>+floor(<em>n</em>/<em>u</em>)/2), <em>w</em> = <em>u</em>, <em>u</em> = <em>v</em>  until <em>v</em> &gt;= <em>w</em>, then setting <em>m</em> to <em>w</em> + 1.</p>

<blockquote>
<p><strong>Notes:</strong></p>

<ul>
<li>A binomial(<em>n</em>, 1/2) random number, where <em>n</em> is odd, can be generated by adding an unbiased random bit (zero or one) to a binomial(<em>n</em>&minus;1, 1/2) random number.</li>
<li>As pointed out by Farach-Colton and Tsai (2015)<sup><a href="#Note6"><strong>(6)</strong></a></sup>, a binomial(<em>n</em>, <em>p</em>) random number, where <em>p</em> is in the interval (0, 1), can be generated using binomial(<em>n</em>, 1/2) numbers using a procedure equivalent to the following:

<ol>
<li>Set <em>k</em> to 0 and <em>ret</em> to 0.</li>
<li>If the binary digit at position <em>k</em> after the point in <em>p</em>&#39;s binary expansion (that is, 0.bbbb... where each b is a zero or one) is 1, add a binomial(<em>n</em>, 1/2) random number to <em>ret</em> and subtract the same random number from <em>n</em>; otherwise, set <em>n</em> to a binomial(<em>n</em>, 1/2) random number.</li>
<li>If <em>n</em> is greater than 0, add 1 to <em>k</em> and go to step 2; otherwise, return <em>ret</em>. (Positions start at 0 where 0 is the most significant digit after the point, 1 is the next, etc.)</li>
</ol></li>
</ul>
</blockquote>

<p><a id=On_a_Geometric_Sampler></a></p>

<h2>On a Geometric Sampler</h2>

<p>The following algorithm is equivalent to the geometric(<em>px</em>/<em>py</em>) sampler that appeared in (Bringmann and Friedrich 2013)<sup><a href="#Note7"><strong>(7)</strong></a></sup>, but adapted to be more programmer-friendly.  As used in that paper, a geometric(<em>p</em>) random number expresses the number of failing trials before the first success, where each trial is independent and has success probability <em>p</em>. (Note that the terminology &quot;geometric random number&quot; has conflicting meanings in academic works.  Note also that the algorithm uses the rational number <em>px</em>/<em>py</em>, not an arbitrary real number <em>p</em>; some of the notes in this section indicate how to adapt the algorithm to an arbitrary <em>p</em>.)</p>

<ol>
<li>Set <em>pn</em> to <em>px</em>, <em>k</em> to 0, and <em>d</em> to 0.</li>
<li>While <em>pn</em>*2 &lt;= <em>py</em>, add 1 to <em>k</em> and multiply <em>pn</em> by 2.  (Equivalent to finding the largest <em>k</em> &gt;= 0 such that <em>p</em>*2<sup><em>k</em></sup> &lt;= 1.  For the case when <em>p</em> need not be rational, enough of its binary expansion can be calculated to carry out this step accurately, but in this case any <em>k</em> such that <em>p</em> is greater than 1/(2<sup><em>k</em>+2</sup>) and less than or equal to 1/(2<sup><em>k</em></sup>) will suffice, as the Bringmann paper points out.)</li>
<li>With probability (1&minus;<em>px</em>/<em>py</em>)<sup>2<sup><em>k</em></sup></sup>, add 1 to <em>d</em> and repeat this step. (To simulate this probability, the first sub-algorithm below can be used.)</li>
<li>Generate a uniform random integer in [0, 2<sup><em>k</em></sup>), call it <em>m</em>, then with probability (1&minus;<em>px</em>/<em>py</em>)<sup><em>m</em></sup>, return <em>d</em>*2<sup><em>k</em></sup>+<em>m</em>. (The Bringmann paper, though, suggests to simulate this probability by sampling only as many bits of <em>m</em> as needed to do so, rather than just generating <em>m</em> in one go, then using the first sub-algorithm on <em>m</em>.  However, the implementation, given as the second sub-algorithm below, is much more complicated and is not crucial for correctness.)</li>
</ol>

<p>The first sub-algorithm returns 1 with probability (1&minus;<em>px</em>/<em>py</em>)<sup><em>n</em></sup>, assuming that <em>n</em>*<em>px</em>/<em>py</em> &lt;= 1.  It implements the approach from the Bringmann paper by rewriting the probability using the binomial theorem. (For the case when <em>p</em> need not be rational, the probability (1&minus;<em>p</em>)<sup><em>n</em></sup> can be simulated using <em>Bernoulli factory</em> algorithms, or by calculating its digit expansion or series expansion and using the appropriate algorithm for <a href="https://peteroupc.github.io/bernoulli.html#Algorithms_for_Irrational_Constants"><strong>simulating irrational constants</strong></a>. Run that algorithm <em>n</em> times or until it outputs 1, whichever comes first.  This sub-algorithm returns 1 if all the runs return 0, or 1 otherwise.)</p>

<ol>
<li>Set <em>pnum</em>, <em>pden</em>, and <em>j</em>  to 1, then set <em>r</em> to 0, then set <em>qnum</em> to <em>px</em>, and <em>qden</em> to <em>py</em>, then set <em>i</em> to 2.</li>
<li>If <em>j</em> is greater than <em>n</em>, go to step 5.</li>
<li>If <em>j</em> is even, set <em>pnum</em> to <em>pnum</em>*<em>qden</em> + <em>pden</em>*<em>qnum</em>*choose(<em>n</em>,<em>j</em>). Otherwise, set <em>pnum</em> to <em>pnum</em>*<em>qden</em> &minus; <em>pden</em>*<em>qnum</em>*choose(<em>n</em>,<em>j</em>).</li>
<li>Multiply <em>pden</em> by <em>qden</em>, then multiply <em>qnum</em> by <em>px</em>, then multiply <em>qden</em> by <em>py</em>, then add 1 to <em>j</em>.</li>
<li>If <em>j</em> is less than or equal to 2 and less than or equal to <em>n</em>, go to step 2.</li>
<li>Multiply <em>r</em> by 2, then add an unbiased random bit (either 0 or 1 with equal probability) to <em>r</em>.</li>
<li>If <em>r</em> &lt;= floor((<em>pnum</em>*<em>i</em>)/<em>pden</em>) &minus; 2, return 1. If <em>r</em> &gt;= floor((<em>pnum</em>*<em>i</em>)/<em>pden</em>) + 1, return 0.  If neither is the case, multiply <em>i</em> by 2 and go to step 2.</li>
</ol>

<p>The second sub-algorithm returns an integer <em>m</em> in [0, 2<sup><em>k</em></sup>) with probability (1&minus;<em>px</em>/<em>py</em>)<sup><em>m</em></sup>, or &minus;1 with the opposite probability.  It assumes that 2<sup><em>k</em></sup>*<em>px</em>/<em>py</em> &lt;= 1.</p>

<ol>
<li>Set <em>r</em> and <em>m</em> to 0.</li>
<li>Set <em>b</em> to 0, then while <em>b</em> is less than <em>k</em>:

<ol>
<li>(Sum <em>b</em>+2 summands of the binomial equivalent of the desired probability.  First, append an additional bit to <em>m</em>, from most to least significant.) Generate either 0 or 2<sup><em>k</em>&minus;<em>b</em></sup> with equal probability, then add that number to <em>m</em>.</li>
<li>(Now build up the binomial probability.) Set <em>pnum</em>, <em>pden</em>, and <em>j</em>  to 1, then set <em>qnum</em> to <em>px</em>, and <em>qden</em> to <em>py</em>.</li>
<li>If <em>j</em> is greater than <em>m</em> or greater than <em>b</em> + 2, go to the sixth substep.</li>
<li>If <em>j</em> is even, set <em>pnum</em> to <em>pnum</em>*<em>qden</em> + <em>pden</em>*<em>qnum</em>*choose(<em>m</em>,<em>j</em>). Otherwise, set <em>pnum</em> to <em>pnum</em>*<em>qden</em> &minus; <em>pden</em>*<em>qnum</em>*choose(<em>m</em>,<em>j</em>).</li>
<li>Multiply <em>pden</em> by <em>qden</em>, then multiply <em>qnum</em> by <em>px</em>, then multiply <em>qden</em> by <em>py</em>, then add 1 to <em>j</em>, then go to the third substep.</li>
<li>(Now check the probability.) Multiply <em>r</em> by 2, then add an unbiased random bit (either 0 or 1 with equal probability) to <em>r</em>.</li>
<li>If <em>r</em> &lt;= floor((<em>pnum</em>*2<sup><em>b</em></sup>)/<em>pden</em>) &minus; 2, add a uniform random integer in [0, 2<sup><em>k</em>*<em>b</em></sup>) to <em>m</em> and return <em>m</em> (and, if requested, the number <em>k</em>&minus;<em>b</em>&minus;1). If <em>r</em> &gt;= floor((<em>pnum</em>*2<sup><em>b</em></sup>)/<em>pden</em>) + 1, return &minus;1 (and, if requested, an arbitrary value).  If neither is the case, add 1 to <em>b</em>.</li>
</ol></li>
<li>Add an unbiased random bit to <em>m</em>. (At this point, <em>m</em> is fully sampled.)</li>
<li>Run the first sub-algorithm with <em>n</em> = <em>m</em>, except in step 1 of that sub-algorithm, set <em>r</em> to the value of <em>r</em> built up by this algorithm, rather than 0, and set <em>i</em> to 2<sup><em>k</em></sup>, rather than 2.  If that sub-algorithm returns 1, return <em>m</em> (and, if requested, the number &minus;1).  Otherwise, return &minus;1 (and, if requested, an arbitrary value).</li>
</ol>

<p>As used in the Bringmann paper, a bounded geometric(<em>p</em>, <em>n</em>) random number is a geometric(<em>p</em>) random number or <em>n</em> (an integer greater than 0), whichever is less.  The following algorithm is equivalent to the algorithm given in that paper, but adapted to be more programmer-friendly.</p>

<ol>
<li>Set <em>pn</em> to <em>px</em>, <em>k</em> to 0, <em>d</em> to 0, and <em>m2</em> to the smallest power of 2 that is greater than <em>n</em> (or equivalently, 2<sup><em>bits</em></sup> where <em>bits</em> is the minimum number of bits needed to store <em>n</em>).</li>
<li>While <em>pn</em>*2 &lt;= <em>py</em>, add 1 to <em>k</em> and multiply <em>pn</em> by 2.</li>
<li>With probability (1&minus;<em>px</em>/<em>py</em>)<sup>2<sup><em>k</em></sup></sup>, add 1 to <em>d</em> and then either return <em>n</em> if <em>d</em>*2<sup><em>k</em></sup> is greater than or equal to <em>m2</em>, or repeat this step if less. (To simulate this probability, the first sub-algorithm above can be used.)</li>
<li>Generate a uniform random integer in [0, 2<sup><em>k</em></sup>), call it <em>m</em>, then with probability (1&minus;<em>px</em>/<em>py</em>)<sup><em>m</em></sup>, return min(<em>n</em>, <em>d</em>*2<sup><em>k</em></sup>+<em>m</em>). In the Bringmann paper, this step is implemented in a manner equivalent to the following (this alternative implementation, though, is not crucial for correctness):

<ol>
<li>Run the second sub-algorithm above, except return two values, rather than one, in the situations given in the sub-algorithm.  Call these two values <em>m</em> and <em>mbit</em>.</li>
<li>If <em>m</em> &lt; 0, go to the first substep.</li>
<li>If <em>mbit</em> &gt;= 0, add 2<sup><em>mbit</em></sup> times an unbiased random bit to <em>m</em> and subtract 1 from <em>mbit</em>.  If that bit is 1 or <em>mbit</em> &lt; 0, go to the next substep; otherwise, repeat this substep.</li>
<li>Return <em>n</em> if <em>d</em>*2<sup><em>k</em></sup> is greater than or equal to <em>m2</em>.</li>
<li>Add a uniform random integer in [0, 2<sup><em>mbit</em>+1</sup>) to <em>m</em>, then return min(<em>n</em>, <em>d</em>*2<sup><em>k</em></sup>+<em>m</em>).</li>
</ol></li>
</ol>

<p><a id=Sampling_Unbounded_Monotone_Density_Functions></a></p>

<h2>Sampling Unbounded Monotone Density Functions</h2>

<p>This section shows a preprocessing algorithm to generate a random number in [0, 1] from a distribution whose probability density function (PDF)&mdash;</p>

<ul>
<li>is continuous in the interval [0, 1],</li>
<li>is monotonically decreasing in [0, 1], and</li>
<li>has an unbounded peak at 0.</li>
</ul>

<p>The trick here is to sample the peak in such a way that the result is either forced to be 0 or forced to belong to the bounded part of the PDF.  This algorithm does not require the area under the curve of the PDF in [0, 1] to be 1; in other words, this algorithm works even if the PDF is known up to a normalizing constant.  The algorithm is as follows.</p>

<ol>
<li>Set <em>i</em> to 1.</li>
<li>Calculate the cumulative probability of the interval [0, 2<sup>&minus;<em>i</em></sup>] and that of [0, 2<sup>&minus;(<em>i</em> &minus; 1)</sup>], call them <em>p</em> and <em>t</em>, respectively.</li>
<li>With probability <em>p</em>/<em>t</em>, add 1 to <em>i</em> and go to step 2. (Alternatively, if <em>i</em> is equal to or higher than the desired number of fractional bits in the result, return 0 instead of adding 1 and going to step 2.)</li>
<li>At this point, the PDF at [2<sup>&minus;<em>i</em></sup>, 2<sup>&minus;(<em>i</em> &minus; 1)</sup>) is bounded from above, so sample a random number in this interval using any appropriate algorithm, including rejection sampling.  Because the PDF is monotonically decreasing, the peak of the PDF at this interval is located at 2<sup>&minus;<em>i</em></sup>, so that rejection sampling becomes trivial.</li>
</ol>

<p>It is relatively straightforward to adapt this algorithm for monotonically increasing PDFs with the unbounded peak at 1, or to PDFs with a different domain than [0, 1].</p>

<p>This algorithm is similar to the &quot;inversion-rejection&quot; algorithm mentioned in section 4.4 of chapter 7 of Devroye&#39;s <em>Non-Uniform Random Variate Generation</em> (1986)<sup><a href="#Note3"><strong>(3)</strong></a></sup>.  I was unaware of that algorithm at the time I started writing the text that became this section (Jul. 25, 2020).  The difference here is that it assumes the whole distribution (including its PDF and cumulative distribution function) is supported on the interval [0, 1], while the algorithm presented in this article doesn&#39;t make that assumption (e.g., the interval [0, 1] can cover only part of the PDF&#39;s support).</p>

<p>By the way, this algorithm arose while trying to devise an algorithm that can generate an integer power of a uniform random number, with arbitrary precision, without actually calculating that power (a naïve calculation that is merely an approximation and usually introduces bias); for more information, see my other article on <a href="https://peteroupc.github.io/exporand.html"><strong>partially-sampled random numbers</strong></a>.  Even so, the algorithm I have come up with in this note may be of independent interest.</p>

<p>In the case of powers of a uniform [0, 1] random number <em>X</em>, namely <em>X</em><sup><em>n</em></sup>, the ratio <em>p</em>/<em>t</em> in this algorithm has a very simple form, namely (1/2)<sup>1/<em>n</em></sup>, which is possible to simulate using a so-called <em>Bernoulli factory</em> algorithm without actually having to calculate this ratio.  Note that this formula is the same regardless of <em>i</em>.  This is found by taking the PDF f(<em>x</em>) = <em>x</em><sup>1/<em>n</em></sup>/(<em>x</em> * <em>n</em>)</sup> and finding the appropriate <em>p</em>/<em>t</em> ratios by integrating <em>f</em> over the two intervals mentioned in step 2 of the algorithm.</p>

<p><a id=Certain_Families_of_Distributions></a></p>

<h2>Certain Families of Distributions</h2>

<p>This section is a note on certain families of univariate (one-variable) distributions of random numbers, with
emphasis on sampling random numbers from them.  Some of these families are described in Ahmad et al. (2019)<sup><a href="#Note8"><strong>(8)</strong></a></sup>.</p>

<p>In general, families of the form &quot;X-G&quot; (such as &quot;beta-G&quot; (Eugene et al., 2002)<sup><a href="#Note9"><strong>(9)</strong></a></sup>) use two distributions, X and G, where X is a continuous distribution supported on the interval [0, 1] and G is a distribution with an easy-to-compute quantile function (also known as inverse cumulative distribution function or inverse CDF).  The following algorithm samples a random number following a distribution from this kind of family:</p>

<ol>
<li>Generate a random number that follows the distribution X. (Or generate a uniform <a href="https://peteroupc.github.io/exporand.html"><strong>partially-sampled random number (PSRN)</strong></a> that follows the distribution X.)  Call the number <em>x</em>.</li>
<li>Calculate the quantile for G of <em>x</em>, and return that quantile. (If <em>x</em> is a uniform PSRN, see the note at the end of this section.)</li>
</ol>

<p>In fact, the &quot;X-G&quot; families are a special case of the so-called &quot;transformed&ndash;transformer&quot; family of distributions introduced by Alzaatreh et al. (2013)<sup><a href="#Note10"><strong>(10)</strong></a></sup> that uses two distributions, X and G, where X (the &quot;transformed&quot;) is an arbitrary continuous distribution, G (the &quot;transformer&quot;) is a distribution with an easy-to-compute quantile function, and <em>W</em> is a nondecreasing function that maps a number in [0, 1] to a number with the same support as X (and meets certain conditions to ensure the target distribution has a proper CDF).  The following algorithm samples a random number from this kind of family:</p>

<ol>
<li>Generate a random number that follows the distribution X. (Or generate a uniform PSRN that follows X.) Call the number <em>x</em>.</li>
<li>Calculate the quantile for G of <em>W</em><sup>&minus;1</sup>(<em>x</em>) (where <em>W</em><sup>&minus;1</sup>(.) is the inverse of <em>W</em>), and return that quantile. (If <em>x</em> is a uniform PSRN, see the note at the end of this section.)</li>
</ol>

<p>The following are special cases of the &quot;transformed&ndash;transformer&quot; family:</p>

<ul>
<li>The &quot;T-R{<em>Y</em>}&quot; family (Aljarrah et al., 2014)<sup><a href="#Note11"><strong>(11)</strong></a></sup>, in which <em>T</em> is an arbitrary continuous distribution (X in the algorithm above), <em>R</em> is a distribution with an easy-to-compute quantile function (G in the algorithm above), and <em>W</em> is the quantile function for the distribution <em>Y</em>, whose support must be included in the support of <em>T</em> (so that <em>W</em><sup>&minus;1</sup>(<em>x</em>) is the CDF for <em>Y</em>).</li>
<li>Several versions of <em>W</em> have been proposed for the case when distribution X is supported on [0, &infin;), such as the Rayleigh and gamma distributions.  They include:

<ul>
<li><em>W</em>(<em>x</em>) = &minus;ln(1&minus;<em>x</em>) (<em>W</em><sup>&minus;1</sup>(<em>x</em>) = 1&minus;exp(&minus;<em>x</em>)).  Suggested in the original paper by Alzaatreh et al.</li>
<li><em>W</em>(<em>x</em>) = <em>x</em>/(1&minus;<em>x</em>) (<em>W</em><sup>&minus;1</sup>(<em>x</em>) = <em>x</em>/(1+<em>x</em>)).  Suggested in the original paper by Alzaatreh et al.  This choice forms the so-called &quot;odd X G&quot; family, examples of which include the &quot;odd log-logistic G&quot; family (Gleaton and Lynch 2006)<sup><a href="#Note12"><strong>(12)</strong></a></sup> and the &quot;generalized odd Weibull generated&quot; family (where X is the Weibull distribution and G is arbitrary) (Korkmaz et al. 2018)<sup><a href="#Note13"><strong>(13)</strong></a></sup>.</li>
</ul></li>
</ul>

<p>Many special cases of the &quot;transformed&ndash;transformer&quot; family have been proposed in many papers, and usually their names suggest the distributions that make up this family.  Some members of the &quot;odd X G&quot; family have names that begin with the word &quot;generalized&quot;, and in most such cases this corresponds to <em>W</em><sup>&minus;1</sup>(<em>x</em>) = (<em>x</em>/(1+<em>x</em>))<sup>1/<em>a</em></sup>, where <em>a</em> &gt; 0 is a shape parameter; an example is the &quot;generalized odd gamma-G&quot; family (Hosseini et al. 2018)<sup><a href="#Note14"><strong>(14)</strong></a></sup>.</p>

<p>A family very similar to the &quot;transformed&ndash;transformer&quot; family uses a <em>decreasing</em> <em>W</em>.  When distribution X is supported on [0, &infin;), one such <em>W</em> that has been proposed is <em>W</em>(<em>x</em>) = &minus;ln(<em>x</em>) (<em>W</em><sup>&minus;1</sup>(<em>x</em>) = exp(&minus;<em>x</em>); examples include the &quot;Rayleigh-G&quot; family or &quot;Rayleigh&ndash;Rayleigh&quot; distribution (Al Noor and Assi 2020)<sup><a href="#Note15"><strong>(15)</strong></a></sup>, as well as the &quot;generalized gamma-G&quot; family, where &quot;generalized gamma&quot; refers to the Stacy distribution (Boshi et al. 2020)<sup><a href="#Note16"><strong>(16)</strong></a></sup>).</p>

<p>Certain special cases of the &quot;X-G&quot; families use a specially designed distribution for X.  They include the following:</p>

<ul>
<li>The <em>alpha power</em> or <em>alpha power transformed</em> family (Mahdavi and Kundu 2017)<sup><a href="#Note17"><strong>(17)</strong></a></sup>. The family uses a shape parameter <em>&alpha;</em> &gt; 0, and the algorithm for the &quot;X-G&quot; families is used, except step 1 now reads: &quot;Generate a uniform(0, 1) random number <em>U</em>, then set <em>x</em> to ln((<em>&alpha;</em>&minus;1)*<em>U</em> + 1)/ln(<em>&alpha;</em>) if <em>&alpha;</em> != 1, and <em>U</em> otherwise.&quot;</li>
<li>The <em>exponentiated</em> family (Mudholkar and Srivastava 1993)<sup><a href="#Note18"><strong>(18)</strong></a></sup>. The family uses a shape parameter <em>a</em> &gt; 1; step 1 is modified to read: &quot;Generate a uniform(0, 1) random number <em>U</em>, then set <em>x</em> to <em>U</em><sup>1/<em>a</em></sup>.&quot;</li>
<li>The <em>transmuted-G</em> family (described, for example, by Tahir and Cordeiro (2016)<sup><a href="#Note19"><strong>(19)</strong></a></sup>). The family uses a shape parameter <em>&eta;</em> in the interval [&minus;1, 1]; step 1 is modified to read: &quot;Generate a piecewise linear random number in [0, 1] with weight 1&minus;<em>&eta;</em> at 0 and weight 1+<em>&eta;</em> at 1, call the number <em>x</em>.&quot;</li>
</ul>

<p>A <em>compound distribution</em> is simply the minimum of <em>N</em> random variables distributed as <em>X</em>, where <em>N</em> &gt;= 1 is an integer distributed as the discrete distribution <em>Y</em> (Tahir and Cordeiro 2016)<sup><a href="#Note19"><strong>(19)</strong></a></sup>.  For example, the &quot;beta-G-geometric&quot; family represents the minimum of <em>N</em> beta-G random variables, where <em>N</em> is a random number expressing 1 plus the number of failures before the first success, with each success having the same probability.</p>

<p>A <em>complementary compound distribution</em> is the maximum of <em>N</em> random variables distributed as <em>X</em>, where <em>N</em> &gt;= 1 is an integer distributed as the discrete distribution <em>Y</em>.  An example is the &quot;geometric zero-truncated Poisson distribution&quot;, where <em>X</em> is the distribution of 1 plus the number of failures before the first success, with each success having the same probability, and <em>Y</em> is the zero-truncated Poisson distribution (Akdoğan et al., 2020)<sup><a href="#Note20"><strong>(20)</strong></a></sup>.</p>

<p>An <em>inverse X distribution</em> (or <em>inverted X distribution</em>) is generally the distribution of the reciprocal of a random number distributed as <em>X</em>.  But an <em>inverse exponential distribution</em> (Keller and Kamath 1982)<sup><a href="#Note21"><strong>(21)</strong></a></sup> is distributed as &minus;<em>&theta;</em>/ln(<em>U</em>) where <em>&theta;</em> &gt; 0 and <em>U</em> is a uniform(0, 1) random number.</p>

<blockquote>
<p><strong>Note</strong>: This is a note on quantile generation using uniform <a href="https://peteroupc.github.io/exporand.html"><strong>partially-sampled random numbers (PSRNs)</strong></a>.</p>

<p>A uniform PSRN is ultimately a number that lies in an interval [<em>a</em>, <em>b</em>].  Let G be a distribution for which the quantile is wanted, and let <em>f</em>(.) be a function applied to <em>a</em> or <em>b</em> before calculating the quantile.  When a random number <em>x</em> is a uniform PSRN, then to implement this quantile calculation (see (Devroye and Gravel 2020)<sup><a href="#Note22"><strong>(22)</strong></a></sup>):</p>

<ol>
<li>Generate additional digits of <em>x</em> uniformly at random&mdash;thus shortening the interval [<em>a</em>, <em>b</em>]&mdash;until a lower bound of the quantile of <em>f</em>(<em>a</em>) and an upper bound of the quantile of <em>f</em>(<em>b</em>) differ by no more than 2*<em>&epsilon;</em>, where <em>&epsilon;</em> is the desired accuracy.  Call the two bounds <em>low</em> and <em>high</em>, respectively.</li>
<li>Return (<em>low</em>+<em>high</em>)/2.</li>
</ol>

<p>The disadvantage is that the desired accuracy has to be made known to the algorithm in advance.  To generate a quantile to any accuracy (even if the accuracy is not known in advance), a rejection sampling approach is needed, which requires knowing G&#39;s probability density function or a function proportional to it, and that the density function be continuous almost everywhere and bounded from above (see also (Devroye and Gravel 2020)<sup><a href="#Note22"><strong>(22)</strong></a></sup>).  This involves calculating lower and upper bounds of the quantiles of <em>f</em>(<em>a</em>) and <em>f</em>(<em>b</em>) (the bounds are [<em>alow</em>, <em>ahigh</em>] and [<em>blow</em>, <em>bhigh</em>] respectively) and applying an arbitrary-precision rejection sampler such as Oberhoff&#39;s method (described in an <a href="https://peteroupc.github.io/exporand.html#Oberhoff_s_Exact_Rejection_Sampling_Method"><strong>appendix to the PSRN article</strong></a>) to the distribution G limited to the interval [<em>alow</em>, <em>bhigh</em>] and accepting the resulting PSRN if it clearly lies in [<em>ahigh</em>, <em>blow</em>] or rejecting it if it clearly lies outside [<em>alow</em>, <em>bhigh</em>].  When neither of these is the case, then it gets more complicated; more digits of the input or output PSRN have to be generated (uniformly at random) until it&#39;s clear whether to accept or reject the output PSRN.</p>
</blockquote>

<p><a id=Certain_Distributions></a></p>

<h2>Certain Distributions</h2>

<p>A <em>power function(a, c) distribution</em> is distributed as <em>c</em>*<em>U</em><sup>1/<em>a</em></sup>, where <em>U</em> is a uniform(0,1) random number, <em>a</em> &gt; 0, and <em>c</em> is a scale parameter greater than 0.</p>

<p>A <em>right-truncated Weibull(a, b, c) distribution</em> (truncated at <em>c</em>) is distributed as the minimum of <em>N</em> power function(<em>b</em>, <em>c</em>) random variables, where <em>N</em> is distributed as the zero-truncated Poisson(<em>a</em>*<em>c</em><sup><em>b</em></sup>) distribution.  (Jodrá 2020)<sup><a href="#Note23"><strong>(23)</strong></a></sup>.</p>

<p><a id=Notes></a></p>

<h2>Notes</h2>

<ul>
<li><small><sup id=Note1>(1)</sup> K. Bringmann, F. Kuhn, et al., “Internal DLA: Efficient Simulation of a Physical Growth Model.” In: <em>Proc. 41st International Colloquium on Automata, Languages, and Programming (ICALP&#39;14)</em>, 2014.</small></li>
<li><small><sup id=Note2>(2)</sup> choose(<em>n</em>, <em>k</em>) = <em>n</em>!/(<em>k</em>! * (<em>n</em> &minus; <em>k</em>)!) is a binomial coefficient.  It can be calculated, for example, by calculating <em>i</em>/(<em>n</em>&minus;<em>i</em>+1) for each integer <em>i</em> in [<em>n</em>&minus;<em>k</em>+1, <em>n</em>], then multiplying the results (Yannis Manolopoulos. 2002. &quot;<a href="https://doi.org/10.1145/820127.820168"><strong>Binomial coefficient computation: recursion or iteration?</strong></a>&quot;, SIGCSE Bull. 34, 4 (December 2002), 65–67).  Note that for all <em>m</em>&gt;0, choose(<em>m</em>, 0) = choose(<em>m</em>, <em>m</em>) = 1 and choose(<em>m</em>, 1) = choose(<em>m</em>, <em>m</em>&minus;1) = <em>m</em>.</small></li>
<li><small><sup id=Note3>(3)</sup> Devroye, L., <a href="http://luc.devroye.org/rnbookindex.html"><strong><em>Non-Uniform Random Variate Generation</em></strong></a>, 1986.</small></li>
<li><small><sup id=Note4>(4)</sup> Daumas, M., Lester, D., Muñoz, C., &quot;<a href="https://arxiv.org/abs/0708.3721"><strong>Verified Real Number Calculations: A Library for Interval Arithmetic</strong></a>&quot;, arXiv:0708.3721 [cs.MS], 2007.</small></li>
<li><small><sup id=Note5>(5)</sup> R. Schumacher, &quot;<a href="https://arxiv.org/abs/1602.00336v1"><strong>Rapidly Convergent Summation Formulas involving Stirling Series</strong></a>&quot;, arXiv:1602.00336v1 [math.NT], 2016.</small></li>
<li><small><sup id=Note6>(6)</sup> Farach-Colton, M. and Tsai, M.T., 2015. Exact sublinear binomial sampling. <em>Algorithmica</em> 73(4), pp. 637-651.</small></li>
<li><small><sup id=Note7>(7)</sup> Bringmann, K., and Friedrich, T., 2013, July. Exact and efficient generation of geometric random variates and random graphs, in <em>International Colloquium on Automata, Languages, and Programming</em> (pp. 267-278).</small></li>
<li><small><sup id=Note8>(8)</sup> Ahmad, Z. et al. &quot;Recent Developments in Distribution Theory: A Brief Survey and Some New Generalized Classes of distributions.&quot; Pakistan Journal of Statistics and Operation Research 15 (2019): 87-110.</small></li>
<li><small><sup id=Note9>(9)</sup> Eugene, N., Lee, C., Famoye, F., &quot;Beta-normal distribution and its applications&quot;, <em>Commun. Stat. Theory Methods</em> 31, 2002.</small></li>
<li><small><sup id=Note10>(10)</sup> Alzaatreh, A., Famoye, F., Lee, C., &quot;A new method for generating families of continuous distributions&quot;, <em>Metron</em> 71:63–79 (2013).</small></li>
<li><small><sup id=Note11>(11)</sup> Aljarrah, M.A., Lee, C. and Famoye, F., &quot;On generating T-X family of distributions using quantile functions&quot;, Journal of Statistical Distributions and Applications,1(2), 2014.</small></li>
<li><small><sup id=Note12>(12)</sup> Gleaton, J.U., Lynch, J. D., &quot;Properties of generalized log-logistic families of lifetime distributions&quot;, <em>Journal of Probability and Statistical Science</em> 4(1), 2006.</small></li>
<li><small><sup id=Note13>(13)</sup> Korkmaz, M.Ç., Alizadeh, M., et al., &quot;The Generalized Odd Weibull Generated Family of Distributions: Statistical Properties and Applications&quot;, <em>Pak. J. Stat. Oper. Res.</em> XIV(3), 2018.</small></li>
<li><small><sup id=Note14>(14)</sup> Hosseini, B., Afshari, M., &quot;The Generalized Odd Gamma-G Family of Distributions:  Properties and Application&quot;, <em>Austrian Journal of Statistics</em> vol. 47, Feb. 2018.</small></li>
<li><small><sup id=Note15>(15)</sup> N.H. Al Noor and N.K. Assi, &quot;Rayleigh-Rayleigh Distribution: Properties and Applications&quot;, <em>Journal of Physics: Conference Series</em> 1591, 012038 (2020).</small></li>
<li><small><sup id=Note16>(16)</sup> Boshi, M.A.A., et al., &quot;Generalized Gamma – Generalized Gompertz Distribution&quot;, <em>Journal of Physics: Conference Series</em> 1591, 012043 (2020).</small></li>
<li><small><sup id=Note17>(17)</sup> Mahdavi, Abbas, and Debasis Kundu. &quot;A new method for generating distributions with an application to exponential distribution.&quot; Communications in Statistics-Theory and Methods 46, no. 13 (2017): 6543-6557.</small></li>
<li><small><sup id=Note18>(18)</sup> Mudholkar, G. S., Srivastava, D. K., &quot;Exponentiated Weibull family for analyzing bathtub failure-rate data&quot;, _IEEE Transactions on Reliability 42(2), 299-302, 1993.</small></li>
<li><small><sup id=Note19>(19)</sup> Tahir, M.H., Cordeiro, G.M., &quot;Compounding of distributions: a survey and new generalized classes&quot;, <em>Journal of Statistical Distributions and Applications</em> 3(13), 2016.</small></li>
<li><small><sup id=Note20>(20)</sup> Akdoğan, Y., Kus, C., et al., &quot;Geometric-Zero Truncated Poisson Distribution: Properties and Applications&quot;, <em>Gazi University Journal of Science</em> 32(4), 2019.</small></li>
<li><small><sup id=Note21>(21)</sup> Keller, A.Z., Kamath A.R., &quot;Reliability analysis of CNC machine tools&quot;, <em>Reliability Engineering</em> 3 (1982).</small></li>
<li><small><sup id=Note22>(22)</sup> Devroye, L., Gravel, C., &quot;<a href="https://arxiv.org/abs/1502.02539v6"><strong>Random variate generation using only finitely many unbiased, independently and identically distributed random bits</strong></a>&quot;, arXiv:1502.02539v6  [cs.IT], 2020.</small></li>
<li><small><sup id=Note23>(23)</sup> Jodrá, P., &quot;A note on the right truncated Weibull distribution and the minimum of power function distributions&quot;, 2020.</small></li>
</ul>

<p><a id=License></a></p>

<h2>License</h2>

<p>Any copyright to this page is released to the Public Domain.  In case this is not possible, this page is also licensed under <a href="https://creativecommons.org/publicdomain/zero/1.0/"><strong>Creative Commons Zero</strong></a>.</p>
</div><nav id="navigation"><ul>
<li><a href="/">Back to start site.</a>
<li><a href="https://github.com/peteroupc/peteroupc.github.io">This site's repository (source code)</a>
<li><a href="https://github.com/peteroupc/peteroupc.github.io/issues">Post an issue or comment</a></ul>
<p>
If you like this software, you should consider donating to me, Peter O., at the link below:</p>
<p class="printonly"><b>peteroupc.github.io</b></p>
<div class="noprint">
<a href="https://www.paypal.com/cgi-bin/webscr?cmd=_s-xclick&hosted_button_id=56E5T4FH7KD2S">
<img src="https://www.paypalobjects.com/en_US/i/btn/btn_donateCC_LG.gif"
name="submit" border="2" alt="PayPal - The safer, easier way to pay online!"></a>
<p>
<a href="//twitter.com/share">Share via Twitter</a>, <a href="//www.facebook.com/sharer/sharer.php" id="sharer">Share via Facebook</a>
</p>
</div>
</nav><script>
if("share" in navigator){
 document.getElementById("sharer").href="javascript:void(null)";
 document.getElementById("sharer").innerHTML="Share This Page";
 navigator.share({title:document.title,url:document.location.href}).then(
   function(){});
} else {
 document.getElementById("sharer").href="//www.facebook.com/sharer/sharer.php?u="+
    encodeURIComponent(document.location.href)
}
</script>
</body></html>
