<!DOCTYPE html><html xmlns:dc="http://purl.org/dc/terms/" itemscope itemtype="http://schema.org/Article"><head><meta http-equiv=Content-Type content="text/html; charset=utf-8"><title>Bernoulli Factory Algorithms</title><meta name="citation_title" content="Bernoulli Factory Algorithms"><meta name="citation_pdf_url" content="https://peteroupc.github.io/bernoulli.pdf"><meta name="citation_url" content="https://peteroupc.github.io/bernoulli.html"><meta name="citation_date" content="2021/11/15"><meta name="citation_online_date" content="2021/11/15"><meta name="og:title" content="Bernoulli Factory Algorithms"><meta name="og:description" content="This page catalogs algorithms to turn coins biased one way into coins biased another way, also known as _Bernoulli factories_.  It provides step-by-step instructions to help programmers implement these Bernoulli factory algorithms.  This page also contains algorithms to exactly sample probabilities that are irrational numbers, using only random bits, which is related to the Bernoulli factory problem. This page is focused on methods that _exactly_ sample a given probability without introducing new errors, assuming &quot;truly random&quot; numbers are available.  The page links to a Python module that implements several Bernoulli factories."><meta name="description" content="This page catalogs algorithms to turn coins biased one way into coins biased another way, also known as _Bernoulli factories_.  It provides step-by-step instructions to help programmers implement these Bernoulli factory algorithms.  This page also contains algorithms to exactly sample probabilities that are irrational numbers, using only random bits, which is related to the Bernoulli factory problem. This page is focused on methods that _exactly_ sample a given probability without introducing new errors, assuming &quot;truly random&quot; numbers are available.  The page links to a Python module that implements several Bernoulli factories."><meta name="twitter:description" content="This page catalogs algorithms to turn coins biased one way into coins biased another way, also known as _Bernoulli factories_.  It provides step-by-step instructions to help programmers implement these Bernoulli factory algorithms.  This page also contains algorithms to exactl..."><meta name="og:type" content="article"><meta name="og:url" content="https://peteroupc.github.io/bernoulli.html"><meta name="og:site_name" content="peteroupc.github.io"><meta name="twitter:title" content="Bernoulli Factory Algorithms"><meta name="author" content="Peter Occil"/><meta name="viewport" content="width=device-width"><link rel=stylesheet type="text/css" href="/style.css">
            <script type="text/x-mathjax-config"> MathJax.Hub.Config({"HTML-CSS": { availableFonts: ["STIX","TeX"], linebreaks: { automatic:true }, preferredFont: "TeX" },
                    tex2jax: { displayMath: [ ["$$","$$"], ["\\[", "\\]"] ], inlineMath: [ ["$", "$"], ["\\\\(","\\\\)"] ], processEscapes: true } });
            </script><script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS_HTML-full"></script></head><body>  <div class="header">
<nav><p><a href="#navigation">Menu</a> - <a href="#top">Top</a> - <a href="/">Home</a></nav></div>
<div class="mainarea" id="top">
<h1>Bernoulli Factory Algorithms</h1>

<p><a href="mailto:poccil14@gmail.com"><strong>Peter Occil</strong></a></p>

<p><strong>Abstract:</strong> This page catalogs algorithms to turn coins biased one way into coins biased another way, also known as <em>Bernoulli factories</em>.  It provides step-by-step instructions to help programmers implement these Bernoulli factory algorithms.  This page also contains algorithms to exactly sample probabilities that are irrational numbers, using only random bits, which is related to the Bernoulli factory problem. This page is focused on methods that <em>exactly</em> sample a given probability without introducing new errors, assuming &quot;truly random&quot; numbers are available.  The page links to a Python module that implements several Bernoulli factories.</p>

<p><strong>2020 Mathematics Subject Classification:</strong> 68W20, 60-08, 60-04.</p>

<p><a id=Introduction></a></p>

<h2>Introduction</h2>

<p>We&#39;re given a coin that shows heads with an unknown probability, <em>&lambda;</em>. The goal is to use that coin (and possibly also a fair coin) to build a &quot;new&quot; coin that shows heads with a probability that depends on <em>&lambda;</em>, call it <em>f</em>(<em>&lambda;</em>). This is the <em>Bernoulli factory problem</em>.</p>

<p>And this page catalogs algorithms to solve this problem for a wide variety of functions, algorithms known as <em>Bernoulli factories</em>.</p>

<p>Many of these algorithms were suggested in (Flajolet et al., 2010)[^1], but without step-by-step instructions in many cases.  This page provides these instructions to help programmers implement the Bernoulli factories they describe.  The Python module <a href="https://peteroupc.github.io/bernoulli.py"><strong><em>bernoulli.py</em></strong></a> includes implementations of several Bernoulli factories.</p>

<p>This page also contains algorithms to exactly sample probabilities that are irrational numbers, which is related to the Bernoulli factory problem.  (An <em>irrational number</em> is a number that can&#39;t be written as a ratio of two integers.) Again, many of these algorithms were suggested in (Flajolet et al., 2010)[^1].</p>

<p>This page is focused on methods that <em>exactly</em> sample the probability described, without introducing rounding errors or other errors beyond those already present in the inputs (and assuming that we have a source of independent and unbiased random bits).</p>

<p>For extra notes, see: <a href="https://peteroupc.github.io/bernsupp.html"><strong>Supplemental Notes for Bernoulli Factory Algorithms</strong></a></p>

<p><a id=About_This_Document></a></p>

<h3>About This Document</h3>

<p><strong>This is an open-source document; for an updated version, see the</strong> <a href="https://github.com/peteroupc/peteroupc.github.io/raw/master/bernoulli.md"><strong>source code</strong></a> <strong>or its</strong> <a href="https://github.com/peteroupc/peteroupc.github.io/blob/master/bernoulli.md"><strong>rendering on GitHub</strong></a><strong>.  You can send comments on this document on the</strong> <a href="https://github.com/peteroupc/peteroupc.github.io/issues"><strong>GitHub issues page</strong></a><strong>.  See</strong> &quot;<a href="#Requests_and_Open_Questions"><strong>Requests and Open Questions</strong></a>&quot; <strong>for a list of things about this document that I seek answers to.</strong></p>

<p><strong>I encourage readers to implement any of the algorithms given in this page, and report their implementation experiences.  This may help improve this page.</strong></p>

<p><a id=Contents></a></p>

<h2>Contents</h2>

<ul>
<li><a href="#Introduction"><strong>Introduction</strong></a>

<ul>
<li><a href="#About_This_Document"><strong>About This Document</strong></a></li>
</ul></li>
<li><a href="#Contents"><strong>Contents</strong></a></li>
<li><a href="#About_Bernoulli_Factories"><strong>About Bernoulli Factories</strong></a></li>
<li><a href="#Algorithms"><strong>Algorithms</strong></a>

<ul>
<li><a href="#Implementation_Notes"><strong>Implementation Notes</strong></a></li>
<li><a href="#Algorithms_for_General_Functions_of___lambda"><strong>Algorithms for General Functions of <em>&lambda;</em></strong></a>

<ul>
<li><a href="#Certain_Polynomials"><strong>Certain Polynomials</strong></a></li>
<li><a href="#Certain_Rational_Functions"><strong>Certain Rational Functions</strong></a></li>
<li><a href="#Certain_Algebraic_Functions"><strong>Certain Algebraic Functions</strong></a></li>
<li><a href="#Certain_Power_Series"><strong>Certain Power Series</strong></a></li>
<li><a href="#General_Factory_Functions"><strong>General Factory Functions</strong></a></li>
</ul></li>
<li><a href="#Algorithms_for_General_Irrational_Constants"><strong>Algorithms for General Irrational Constants</strong></a>

<ul>
<li><a href="#Digit_Expansions"><strong>Digit Expansions</strong></a></li>
<li><a href="#Continued_Fractions"><strong>Continued Fractions</strong></a></li>
<li><a href="#Continued_Logarithms"><strong>Continued Logarithms</strong></a></li>
<li><a href="#Certain_Algebraic_Numbers"><strong>Certain Algebraic Numbers</strong></a></li>
<li><a href="#Certain_Converging_Series"><strong>Certain Converging Series</strong></a></li>
</ul></li>
<li><a href="#Other_General_Algorithms"><strong>Other General Algorithms</strong></a>

<ul>
<li><a href="#Convex_Combinations"><strong>Convex Combinations</strong></a></li>
<li><a href="#Integrals"><strong>Integrals</strong></a></li>
<li><a href="#Generalized_Bernoulli_Race"><strong>Generalized Bernoulli Race</strong></a></li>
</ul></li>
<li><a href="#Algorithms_for_Specific_Functions_of___lambda"><strong>Algorithms for Specific Functions of <em>&lambda;</em></strong></a>

<ul>
<li><a href="#exp_minus___lambda"><strong>exp(&minus;<em>&lambda;</em>)</strong></a></li>
<li><a href="#exp_minus___lambda___k___c"><strong>exp(&minus;(<em>&lambda;</em><sup><em>k</em></sup> * <em>c</em>))</strong></a></li>
<li><a href="#exp_minus__m____lambda_____mu"><strong>exp(&minus;(<em>m</em> + <em>&lambda;</em>)*<em>&mu;</em>)</strong></a></li>
<li><a href="#exp_minus__m____lambda____k"><strong>exp(&minus;(<em>m</em> + <em>&lambda;</em>)<sup><em>k</em></sup>)</strong></a></li>
<li><a href="#exp___lambda___1_minus___lambda"><strong>exp(<em>&lambda;</em>)*(1&minus;<em>&lambda;</em>)</strong></a></li>
<li><a href="#exp___lambda___minus_1_exp_minus___lambda___or_exp___lambda___minus_1_exp___lambda"><strong>(exp(<em>&lambda;</em>)&minus;1) * exp(&minus;<em>&lambda;</em>) or (exp(<em>&lambda;</em>)&minus;1) / exp(<em>&lambda;</em>)</strong></a></li>
<li><a href="#1_2_k____lambda___or_exp_minus__k____lambda___ln_2"><strong>1/(2<sup><em>k</em> + <em>&lambda;</em></sup>) or exp(&minus;(<em>k</em> + <em>&lambda;</em>)*ln(2))</strong></a></li>
<li><a href="#1_2_m___k____lambda___or_1_2_m___k____lambda___or_exp_minus__k____lambda___ln_2_m"><strong>1/(2<sup><em>m</em>*(<em>k</em> + <em>&lambda;</em>)</sup>) or 1/((2<sup><em>m</em></sup>)*(<em>k</em> + <em>&lambda;</em>)) or exp(&minus;(<em>k</em> + <em>&lambda;</em>)*ln(2<sup><em>m</em></sup>))</strong></a></li>
<li><a href="#c____lambda_____beta_____beta____c____lambda____d____mu___minus___beta___minus_1__c___d"><strong><em>c</em> * <em>&lambda;</em> * <em>&beta;</em> / (<em>&beta;</em> * (<em>c</em> * <em>&lambda;</em> + <em>d</em> * <em>&mu;</em>) &minus; (<em>&beta;</em> &minus; 1) * (<em>c</em> + <em>d</em>))</strong></a></li>
<li><a href="#c____lambda____c____lambda____d__or__c___d____lambda___1__c___d____lambda"><strong><em>c</em> * <em>&lambda;</em> / (<em>c</em> * <em>&lambda;</em> + <em>d</em>) or (<em>c</em>/<em>d</em>) * <em>&lambda;</em> / (1 + (<em>c</em>/<em>d</em>) * <em>&lambda;</em>))</strong></a></li>
<li><a href="#d____lambda____c"><strong>(<em>d</em> + <em>&lambda;</em>) / <em>c</em></strong></a></li>
<li><a href="#d___c____lambda"><strong><em>d</em> / (<em>c</em> + <em>&lambda;</em>)</strong></a></li>
<li><a href="#d____mu____c____lambda"><strong>(<em>d</em> + <em>&mu;</em>) / (<em>c</em> + <em>&lambda;</em>)</strong></a></li>
<li><a href="#d____mu____d____mu____c____lambda"><strong>(<em>d</em> + <em>&mu;</em>) / ((<em>d</em> + <em>&mu;</em>) + (<em>c</em> + <em>&lambda;</em>))</strong></a></li>
<li><a href="#d__k___c____lambda____k__or__d___c____lambda____k"><strong><em>d</em><sup><em>k</em></sup> / (<em>c</em> + <em>&lambda;</em>)<sup><em>k</em></sup>, or (<em>d</em> / (<em>c</em> + <em>&lambda;</em>))<sup><em>k</em></sup></strong></a></li>
<li><a href="#1_1___lambda"><strong>1/(1+<em>&lambda;</em>)</strong></a></li>
<li><a href="#1_2_minus___lambda"><strong>1/(2 &minus; <em>&lambda;</em>)</strong></a></li>
<li><a href="#expit__m____lambda___or_1_minus_1_1_exp__m____lambda___or_exp__m____lambda___1_exp__m____lambda___or_1_1_exp_minus__m____lambda"><strong>expit(<em>m</em> + <em>&lambda;</em>) or 1&minus;1/(1+exp(<em>m</em> + <em>&lambda;</em>)) or exp(<em>m</em> + <em>&lambda;</em>)/(1+exp(<em>m</em> + <em>&lambda;</em>)) or 1/(1+exp(&minus;(<em>m</em> + <em>&lambda;</em>)))</strong></a></li>
<li><a href="#expit__m____lambda_____mu"><strong>expit((<em>m</em> + <em>&lambda;</em>)*<em>&mu;</em>)</strong></a></li>
<li><a href="#expit__m____lambda___2_minus_1_or_tanh__m____lambda___2"><strong>expit(<em>m</em> + <em>&lambda;</em>)*2 &minus; 1 or tanh((<em>m</em> + <em>&lambda;</em>)/2)</strong></a></li>
<li><a href="#lambda___exp__m____nu_____lambda___exp__m____nu___1_minus___lambda"><strong><em>&lambda;</em>*exp(<em>m</em> + <em>&nu;</em>) / (<em>&lambda;</em>*exp(<em>m</em> + <em>&nu;</em>) + (1 &minus; <em>&lambda;</em>))</strong></a></li>
<li><a href="#1_1__x___y____lambda"><strong>1 / (1 + (<em>x</em>/<em>y</em>)*<em>&lambda;</em>)</strong></a></li>
<li><a href="#lambda_____mu"><strong><em>&lambda;</em> + <em>&mu;</em></strong></a></li>
<li><a href="#lambda___minus___mu"><strong><em>&lambda;</em> &minus; <em>&mu;</em></strong></a></li>
<li><a href="#x03F5_____lambda"><strong><em>&#x03F5;</em> / <em>&lambda;</em></strong></a></li>
<li><a href="#mu_____lambda"><strong><em>&mu;</em> / <em>&lambda;</em></strong></a></li>
<li><a href="#lambda___x___y"><strong><em>&lambda;</em><sup><em>x</em>/<em>y</em></sup></strong></a></li>
<li><a href="#lambda____mu"><strong><em>&lambda;</em><sup><em>&mu;</em></sup></strong></a></li>
<li><a href="#sqrt___lambda"><strong>sqrt(<em>&lambda;</em>)</strong></a></li>
<li><a href="#lambda____x___y"><strong><em>&lambda;</em> * <em>x</em>/<em>y</em></strong></a></li>
<li><a href="#lambda____x___y___i"><strong>(<em>&lambda;</em> * <em>x</em>/<em>y</em>)<sup><em>i</em></sup></strong></a></li>
<li><a href="#Linear_Bernoulli_Factories"><strong>Linear Bernoulli Factories</strong></a></li>
<li><a href="#arctan___lambda_____lambda"><strong>arctan(<em>&lambda;</em>) /<em>&lambda;</em></strong></a></li>
<li><a href="#arctan___lambda"><strong>arctan(<em>&lambda;</em>)</strong></a></li>
<li><a href="#cos___lambda"><strong>cos(<em>&lambda;</em>)</strong></a></li>
<li><a href="#sin___lambda___sqrt__c____lambda___sqrt__c"><strong>sin(<em>&lambda;</em>*sqrt(<em>c</em>)) / (<em>&lambda;</em>*sqrt(<em>c</em>))</strong></a></li>
<li><a href="#sin___lambda"><strong>sin(<em>&lambda;</em>)</strong></a></li>
<li><a href="#1_minus___lambda___cos___lambda"><strong>(1&minus;<em>&lambda;</em>)/cos(<em>&lambda;</em>)</strong></a></li>
<li><a href="#1_minus___lambda___tan___lambda"><strong>(1&minus;<em>&lambda;</em>) * tan(<em>&lambda;</em>)</strong></a></li>
<li><a href="#ln_1___lambda"><strong>ln(1+<em>&lambda;</em>)</strong></a></li>
<li><a href="#ln__c___d____lambda____c"><strong>ln((<em>c</em> + <em>d</em> + <em>&lambda;</em>)/<em>c</em>)</strong></a></li>
<li><a href="#arcsin___lambda___sqrt_1_minus___lambda__2_minus_1"><strong>arcsin(<em>&lambda;</em>) + sqrt(1 &minus; <em>&lambda;</em><sup>2</sup>) &minus; 1</strong></a></li>
<li><a href="#arcsin___lambda___2"><strong>arcsin(<em>&lambda;</em>) / 2</strong></a></li>
<li><a href="#tanh__m____lambda"><strong>tanh(<em>m</em> + <em>&lambda;</em>)</strong></a></li>
<li><a href="#Expressions_Involving_Polylogarithms"><strong>Expressions Involving Polylogarithms</strong></a></li>
<li><a href="#Other_Factory_Functions"><strong>Other Factory Functions</strong></a></li>
</ul></li>
<li><a href="#Algorithms_for_Specific_Constants"><strong>Algorithms for Specific Constants</strong></a>

<ul>
<li><a href="#1___phi___1_divided_by_the_golden_ratio"><strong>1 / <em>&phi;</em> (1 divided by the golden ratio)</strong></a></li>
<li><a href="#sqrt_2_minus_1"><strong>sqrt(2) &minus; 1</strong></a></li>
<li><a href="#1_sqrt_2"><strong>1/sqrt(2)</strong></a></li>
<li><a href="#tanh_1_2_or_exp_1_minus_1_exp_1_1"><strong>tanh(1/2) or (exp(1) &minus; 1) / (exp(1) + 1)</strong></a></li>
<li><a href="#arctan__x___y___y___x"><strong>arctan(<em>x</em>/<em>y</em>) * <em>y</em>/<em>x</em></strong></a></li>
<li><a href="#pi___12"><strong><em>&pi;</em> / 12</strong></a></li>
<li><a href="#pi___4"><strong><em>&pi;</em> / 4</strong></a></li>
<li><a href="#1___pi"><strong>1 / <em>&pi;</em></strong></a></li>
<li><a href="#a___b___x___y"><strong>(<em>a</em>/<em>b</em>)<sup><em>x</em>/<em>y</em></sup></strong></a></li>
<li><a href="#exp_minus__x___y"><strong>exp(&minus;<em>x</em>/<em>y</em>)</strong></a></li>
<li><a href="#exp_minus__z"><strong>exp(&minus;<em>z</em>)</strong></a></li>
<li><a href="#a___b___z"><strong>(<em>a</em>/<em>b</em>)<sup><em>z</em></sup></strong></a></li>
<li><a href="#1_1_exp__x___y__2_prec__LogisticExp"><strong>1 / (1 + exp(<em>x</em> / (<em>y</em> * 2<sup><em>prec</em></sup>)) (LogisticExp)</strong></a></li>
<li><a href="#1_1_exp__z__2_prec__LogisticExp"><strong>1 / (1 + exp(<em>z</em> / 2<sup><em>prec</em></sup>)) (LogisticExp)</strong></a></li>
<li><a href="#zeta___3_3_4_and_Other_Zeta_Related_Constants"><strong><em>&zeta;</em>(3) * 3 / 4 and Other Zeta-Related Constants</strong></a></li>
<li><a href="#erf__x__erf_1"><strong>erf(<em>x</em>)/erf(1)</strong></a></li>
<li><a href="#2_1_exp_2_or_1_exp_0_1_exp_1"><strong>2 / (1 + exp(2)) or (1 + exp(0)) / (1 + exp(1))</strong></a></li>
<li><a href="#1_exp_1_1_exp_2"><strong>(1 + exp(1)) / (1 + exp(2))</strong></a></li>
<li><a href="#1_exp__k__1_exp__k__1"><strong>(1 + exp(<em>k</em>)) / (1 + exp(<em>k</em> + 1))</strong></a></li>
<li><a href="#Euler_ndash_Mascheroni_constant___gamma"><strong>Euler&ndash;Mascheroni constant <em>&gamma;</em></strong></a></li>
<li><a href="#exp_minus__x___y___z___t"><strong>exp(&minus;<em>x</em>/<em>y</em>) * <em>z</em>/<em>t</em></strong></a></li>
<li><a href="#ln_1__y___z"><strong>ln(1+<em>y</em>/<em>z</em>)</strong></a></li>
</ul></li>
</ul></li>
<li><a href="#Requests_and_Open_Questions"><strong>Requests and Open Questions</strong></a></li>
<li><a href="#Correctness_and_Performance_Charts"><strong>Correctness and Performance Charts</strong></a></li>
<li><a href="#Acknowledgments"><strong>Acknowledgments</strong></a></li>
<li><a href="#Notes"><strong>Notes</strong></a></li>
<li><a href="#Appendix"><strong>Appendix</strong></a>

<ul>
<li><a href="#Using_the_Biased_Coin_Alone_for_Randomness"><strong>Using the Biased Coin Alone for Randomness</strong></a></li>
<li><a href="#The_Entropy_Bound"><strong>The Entropy Bound</strong></a></li>
<li><a href="#Bernoulli_Factories_and_Unbiased_Estimation"><strong>Bernoulli Factories and Unbiased Estimation</strong></a></li>
<li><a href="#Correctness_Proof_for_the_Continued_Logarithm_Simulation_Algorithm"><strong>Correctness Proof for the Continued Logarithm Simulation Algorithm</strong></a></li>
<li><a href="#Correctness_Proof_for_Continued_Fraction_Simulation_Algorithm_3"><strong>Correctness Proof for Continued Fraction Simulation Algorithm 3</strong></a></li>
<li><a href="#The_von_Neumann_Schema"><strong>The von Neumann Schema</strong></a></li>
<li><a href="#Probabilities_Arising_from_Certain_Permutations"><strong>Probabilities Arising from Certain Permutations</strong></a></li>
<li><a href="#Sketch_of_Derivation_of_the_Algorithm_for_1___pi"><strong>Sketch of Derivation of the Algorithm for 1 / <em>&pi;</em></strong></a></li>
<li><a href="#Preparing_Rational_Functions"><strong>Preparing Rational Functions</strong></a></li>
</ul></li>
<li><a href="#License"><strong>License</strong></a></li>
</ul>

<p><a id=About_Bernoulli_Factories></a></p>

<h2>About Bernoulli Factories</h2>

<p>A <em>Bernoulli factory</em> (Keane and O&#39;Brien 1994)[^2] is an algorithm that takes an input coin (a method that returns 1, or heads, with an unknown probability, or 0, or tails, otherwise) and returns 0 or 1 with a probability that depends on the input coin&#39;s probability of heads.</p>

<ul>
<li>The Greek letter lambda (<em>&lambda;</em>) represents the unknown probability of heads.</li>
<li>The Bernoulli factory&#39;s outputs are statistically independent.</li>
<li>Many Bernoulli factories also use a <em>fair coin</em> in addition to the input coin.  A fair coin shows heads or tails with equal probability, and represents a source of randomness outside the biased coin.</li>
<li>A <em>factory function</em> is a known function that relates the old probability to the new one.  Its domain is the <em>closed</em> interval [0, 1] or a subset of that interval, and returns a probability in [0, 1].</li>
</ul>

<blockquote>
<p><strong>Example:</strong> A Bernoulli factory algorithm can take a coin that returns heads with probability <em>&lambda;</em> and produce a coin that returns heads with probability exp(&minus;<em>&lambda;</em>).  In this example, exp(&minus;<em>&lambda;</em>) is the factory function.</p>
</blockquote>

<p>Keane and O&#39;Brien (1994)[^2] showed that a function <em>f</em> that maps [0, 1] (or a subset of it) to [0, 1] admits a Bernoulli factory if and only if&mdash;</p>

<ul>
<li><em>f</em> is constant on its domain, or</li>
<li><em>f</em> is continuous and polynomially bounded on its domain (polynomially bounded means that both <em>f</em>(<em>&lambda;</em>) and 1&minus;<em>f</em>(<em>&lambda;</em>) are bounded from below by min(<em>&lambda;</em><sup><em>n</em></sup>, (1&minus;<em>&lambda;</em>)<sup><em>n</em></sup>) for some integer <em>n</em>).</li>
</ul>

<p>The following shows some functions that are factory functions and some that are not.  In the table below, <em>&#x03F5;</em> is a number greater than 0 and less than 1/2.</p>

<table><thead>
<tr>
<th>Function <em>f</em>(<em>&lambda;</em>)</th>
<th>Domain</th>
<th>Can <em>f</em> be a factory function?</th>
</tr>
</thead><tbody>
<tr>
<td>0</td>
<td>[0, 1]</td>
<td>Yes; constant.</td>
</tr>
<tr>
<td>1</td>
<td>[0, 1]</td>
<td>Yes; constant.</td>
</tr>
<tr>
<td>1/2</td>
<td>(0, 1)</td>
<td>Yes; constant.</td>
</tr>
<tr>
<td>1/4 if <em>&lambda;</em>&lt;1/2, and 3/4 elsewhere</td>
<td>(0, 1)</td>
<td>No; discontinuous.</td>
</tr>
<tr>
<td>2*<em>&lambda;</em></td>
<td>[0,&nbsp;1] or [0,&nbsp;1/2)</td>
<td>No; not polynomially bounded since its graph touches 1 somewhere in the interval (0,&nbsp;1) on its domain.[^3].</td>
</tr>
<tr>
<td>1&minus;2*<em>&lambda;</em></td>
<td>[0,&nbsp;1] or [0,&nbsp;1/2)</td>
<td>No; not polynomially bounded since its graph touches 0 somewhere in the interval (0, 1) on its domain.</td>
</tr>
<tr>
<td>2*<em>&lambda;</em></td>
<td>[0,&nbsp;1/2&minus;&#x03F5;]</td>
<td>Yes; continuous and polynomially bounded on domain (Keane and O&#39;Brien 1994)[^2].</td>
</tr>
<tr>
<td>min(2 * <em>&lambda;</em>, 1 &minus; <em>&#x03F5;</em>)</td>
<td>[0, 1]</td>
<td>Yes; continuous and polynomially bounded on domain (Huber 2014, introduction)[^4].</td>
</tr>
<tr>
<td>0 if <em>&lambda;</em> = 0, or exp(&minus;1/<em>&lambda;</em>) otherwise</td>
<td>(0, 1)</td>
<td>No; not polynomially bounded since it moves away from 0 more slowly than any polynomial.</td>
</tr>
<tr>
<td>&#x03F5; if <em>&lambda;</em> = 0, or exp(&minus;1/<em>&lambda;</em>) + &#x03F5; otherwise</td>
<td>(0, 1)</td>
<td>Yes; continuous and bounded away from 0 and 1.</td>
</tr>
</tbody></table>

<p>If <em>f</em>&#39;s domain includes 0 and/or 1 (so that the input coin is allowed to return 0 every time or 1 every time, respectively), then <em>f</em> can be a factory function only if&mdash;</p>

<ol>
<li><em>f</em> is constant on its domain, or is continuous and polynomially bounded on its domain, and</li>
<li><em>f</em>(0) equals 0 or 1 whenever 0 is in the domain of <em>f</em>, and</li>
<li><em>f</em>(1) equals 0 or 1 whenever 1 is in the domain of <em>f</em>,</li>
</ol>

<p>unless outside randomness (besides the input coin) is available.</p>

<p><a id=Algorithms></a></p>

<h2>Algorithms</h2>

<p>This section will show algorithms for a number of factory functions, allowing different kinds of probabilities to be sampled from input coins.</p>

<p>The algorithms as described here do not always lead to the best performance.  An implementation may change these algorithms as long as they produce the same results as the algorithms as described here.</p>

<blockquote>
<p><strong>Notes:</strong></p>

<ol>
<li>Most of the algorithms assume that a source of independent and unbiased random bits is available, in addition to the input coins.  But in many cases, they can be implemented using nothing but those coins as a source of randomness.  See the <a href="#Appendix"><strong>appendix</strong></a> for details.</li>
<li>Bernoulli factory algorithms that sample the probability <em>f</em>(<em>&lambda;</em>) act as unbiased estimators of <em>f</em>(<em>&lambda;</em>). See the <a href="#Bernoulli_Factories_and_Unbiased_Estimation"><strong>appendix</strong></a> for details.</li>
</ol>
</blockquote>

<p><a id=Implementation_Notes></a></p>

<h3>Implementation Notes</h3>

<p>This section shows implementation notes that apply to the algorithms in this article.  They should be followed to avoid introducing error in the algorithms.</p>

<p>In the following algorithms:</p>

<ul>
<li>The Greek letter lambda (<em>&lambda;</em>) represents the unknown probability of heads of the input coin.</li>
<li> choose(<em>n</em>, <em>k</em>) = (1*2*3*...*<em>n</em>)/((1*...*<em>k</em>)*(1*...*(<em>n</em>&minus;<em>k</em>))) =  <em>n</em>!/(<em>k</em>! * (<em>n</em> &minus; <em>k</em>)!) is a <em>binomial coefficient</em>, or the number of ways to choose <em>k</em> out of <em>n</em> labeled items.  It can be calculated, for example, by calculating <em>i</em>/(<em>n</em>&minus;<em>i</em>+1) for each integer <em>i</em> in [<em>n</em>&minus;<em>k</em>+1, <em>n</em>], then multiplying the results (Manolopoulos 2002)[^5].  For every <em>m</em>&gt;0, choose(<em>m</em>, 0) = choose(<em>m</em>, <em>m</em>) = 1 and choose(<em>m</em>, 1) = choose(<em>m</em>, <em>m</em>&minus;1) = <em>m</em>; also, in this document, choose(<em>n</em>, <em>k</em>) is 0 when <em>k</em> is less than 0 or greater than <em>n</em>.</li>
<li><em>n</em>! = 1*2*3*...*<em>n</em> is also known as <em>n</em> factorial.</li>
<li>The instruction to &quot;generate a uniform(0, 1) random variate&quot; can be implemented&mdash;

<ul>
<li>by creating a <a href="https://peteroupc.github.io/exporand.html"><strong>uniform partially-sampled random number (PSRN)</strong></a> with a positive sign, an integer part of 0, and an empty fractional part (most accurate), or</li>
<li>by generating a uniform random variate in the openopen interval [**0, 1) (e.g., <code>RNDRANGEMinMaxExc(0, 1)</code> in &quot;<a href="https://peteroupc.github.io/randomfunc.html"><strong>Randomization and Sampling Methods</strong></a>&quot; (less accurate).</li>
</ul></li>
<li>The instruction to &quot;generate an exponential random variate&quot; can be implemented&mdash;

<ul>
<li>by creating an empty <a href="https://peteroupc.github.io/exporand.html"><strong>exponential PSRN</strong></a> (most accurate), or</li>
<li>by getting the result of the <strong>ExpRand</strong> or <strong>ExpRand2</strong> algorithm (described in my article on PSRNs) with a rate of 1, or</li>
<li>by generating <code>-ln(1/X)</code>, where <code>X</code> is a uniform random variate in the open interval (0, 1], (e.g., <code>RNDRANGEMinMaxExc(0, 1)</code> in &quot;<a href="https://peteroupc.github.io/randomfunc.html#Uniform_Random_Real_Numbers"><strong>Randomization and Sampling Methods</strong></a>&quot;) (less accurate).</li>
</ul></li>
<li><p>The instruction to &quot;choose [integers] with probability proportional to [<em>weights</em>]&quot; can be implemented in one of the following ways:</p>

<ul>
<li>If the weights are rational numbers, take the result of <strong>WeightedChoice</strong>(<strong>NormalizeRatios</strong>(<em>weights</em>))), where <strong>WeightedChoice</strong> and <strong>NormalizeRatios</strong> are given in &quot;<a href="https://peteroupc.github.io/randomfunc.html#Weighted_Choice_With_Replacement"><strong>Randomization and Sampling Methods</strong></a>&quot;.</li>
<li>If the weights are uniform PSRNs, use the algorithm given in &quot;<a href="https://peteroupc.github.io/morealg.html"><strong>Weighted Choice Involving PSRNs</strong></a>&quot;.</li>
</ul>

<p>For example, &quot;Choose 0, 1, or 2 with probability proportional to the weights [A, B, C]&quot; means to choose 0, 1, or 2 at random so that 0 is chosen with probability A/(A+B+C), 1 with probability B/(A+B+C), and 2 with probability C/(A+B+C).</p></li>
<li>To <strong>sample from a number <em>u</em></strong> means to generate a number that is 1 with probability <em>u</em> and 0 otherwise.

<ul>
<li>If the number is a uniform PSRN, call the <strong>SampleGeometricBag</strong> algorithm with the PSRN and take the result of that call (which will be 0 or 1) (most accurate). (<strong>SampleGeometricBag</strong> is described in my <a href="https://peteroupc.github.io/exporand.html"><strong>article on PSRNs</strong></a>.)</li>
<li>Otherwise, this can be implemented by generating another uniform(0, 1) random variate <em>v</em> and generating 1 if <em>v</em> is less than <em>u</em> or 0 otherwise (less accurate).</li>
</ul></li>
<li>Where an algorithm says &quot;if <em>a</em> is less than <em>b</em>&quot;, where <em>a</em> and <em>b</em> are random variates, it means to run the <strong>RandLess</strong> algorithm on the two numbers (if they are both PSRNs), or do a less-than operation on <em>a</em> and <em>b</em>, as appropriate. (<strong>RandLess</strong> is described in my <a href="https://peteroupc.github.io/exporand.html"><strong>article on PSRNs</strong></a>.)</li>
<li>Where an algorithm says &quot;if <em>a</em> is less than (or equal to) <em>b</em>&quot;, where <em>a</em> and <em>b</em> are random variates, it means to run the <strong>RandLess</strong> algorithm on the two numbers (if they are both PSRNs), or do a less-than-or-equal operation on <em>a</em> and <em>b</em>, as appropriate.</li>
<li>Where a step in the algorithm says &quot;with probability <em>x</em>&quot; to refer to an event that may or may not happen, then this can be implemented in one of the following ways:

<ul>
<li>Generate a uniform(0, 1) random variate <em>v</em> (see above). The event occurs if <em>v</em> is less than <em>x</em> (see above).</li>
<li>Convert <em>x</em> to a rational number <em>y</em>/<em>z</em>, then call <code>ZeroOrOne(y, z)</code>.  The event occurs if the call returns 1. For example, if an instruction says &quot;With probability 3/5, return 1&quot;, then implement it as &quot;Call <code>ZeroOrOne(3, 5)</code>. If the call returns 1, return 1.&quot;  <code>ZeroOrOne</code> is described in my article on <a href="https://peteroupc.github.io/randomfunc.html#Boolean_True_False_Conditions"><strong>random sampling methods</strong></a>.  If <em>x</em> is not a rational number, then rounding error will result, however.</li>
</ul></li>
<li>For best results, the algorithms should be implemented using exact rational arithmetic (such as <code>Fraction</code> in Python or <code>Rational</code> in Ruby).  Floating-point arithmetic is discouraged because it can introduce errors due to fixed-precision calculations, such as rounding and cancellations.</li>
</ul>

<p><a id=Algorithms_for_General_Functions_of___lambda></a></p>

<h3>Algorithms for General Functions of <em>&lambda;</em></h3>

<p>This section describes general-purpose algorithms for sampling probabilities that are polynomials, rational
functions, or functions in general.</p>

<p><a id=Certain_Polynomials></a></p>

<h4>Certain Polynomials</h4>

<p>Any polynomial can be written in <em>Bernstein form</em> as &sum;<sub><em>i</em> = 0, ..., <em>n</em></sub> choose(<em>n</em>, <em>i</em>) * <em>&lambda;</em><sup><em>i</em></sup> * (1 &minus; <em>&lambda;</em>)<sup><em>n</em> &minus; <em>i</em></sup> * <em>a</em>[<em>i</em>], where <em>n</em> is the polynomial&#39;s <em>degree</em> and <em>a</em>[<em>i</em>] are its <em>n</em> plus one coefficients.</p>

<p>But the only polynomials that admit a Bernoulli factory are those whose coefficients are all in the interval [0, 1] (once the polynomials are written in Bernstein form), and these polynomials are the only functions that can be simulated with a fixed number of coin flips (Goyal and Sigman 2012[^6]; Qian et al. 2011)[^7]; see also Wästlund 1999, section 4[^8]).  Goyal and Sigman give an algorithm for simulating these polynomials, which is given below.</p>

<ol>
<li>Flip the input coin <em>n</em> times, and let <em>j</em> be the number of times the coin returned 1 this way.[^9]</li>
<li>Return a number that is 1 with probability <em>a</em>[<em>j</em>], or 0 otherwise.</li>
</ol>

<p>For certain polynomials with duplicate coefficients, the following is an optimized version of this algorithm, not given by Goyal and Sigman:</p>

<ol>
<li>Set <em>j</em> to 0 and <em>i</em> to 0.  If <em>n</em> is 0, return 0.</li>
<li>If <em>i</em> is <em>n</em> or greater, or if the coefficients <em>a</em>[<em>k</em>], with <em>k</em> in the interval [<em>j</em>, <em>j</em>+(<em>n</em>&minus;<em>i</em>)], are all equal, return a number that is 1 with probability <em>a</em>[<em>j</em>], or 0 otherwise.</li>
<li>Flip the input coin.  If it returns 1, add 1 to <em>j</em>.</li>
<li>Add 1 to <em>i</em> and go to step 2.</li>
</ol>

<p>And here is another optimized algorithm:</p>

<ol>
<li>Set <em>j</em> to 0 and <em>i</em> to 0.  If <em>n</em> is 0, return 0.  Otherwise, generate a uniform(0, 1) random variate, call it <em>u</em>.</li>
<li>If <em>u</em> is less than a lower bound of the lowest coefficient, return 1.  Otherwise, if <em>u</em> is less than (or equal to) an upper bound of the highest coefficient, go to the next step.  Otherwise, return 0.</li>
<li>If <em>i</em> is <em>n</em> or greater, or if the coefficients <em>a</em>[<em>k</em>], with <em>k</em> in the interval [<em>j</em>, <em>j</em>+(<em>n</em>&minus;<em>i</em>)], are all equal, return a number that is 1 if <em>u</em> is less than <em>a</em>[<em>j</em>], or 0 otherwise.</li>
<li>Flip the input coin.  If it returns 1, add 1 to <em>j</em>.</li>
<li>Add 1 to <em>i</em> and go to step 3.</li>
</ol>

<p>Because the coefficients <em>a</em>[<em>i</em>] must be in the interval [0, 1], some or all of them can themselves be coins with unknown probability of heads.  In that case, the first algorithm can read as follows:</p>

<ol>
<li>Flip the input coin <em>n</em> times, and let <em>j</em> be the number of times the coin returned 1 this way.</li>
<li>If <em>a</em>[<em>j</em>] is a coin, flip it and return the result.  Otherwise, return a number that is 1 with probability <em>a</em>[<em>j</em>], or 0 otherwise.</li>
</ol>

<blockquote>
<p><strong>Notes</strong>:</p>

<ol>
<li>Each <em>a</em>[<em>i</em>] acts as a control point for a 1-dimensional <a href="https://en.wikipedia.org/wiki/B%C3%A9zier_curve"><strong>Bézier curve</strong></a>, where <em>&lambda;</em> is the relative position on that curve, the curve begins at  <em>a</em>[0], and the curve ends at <em>a</em>[<em>n</em>].  For example, given control points 0.2, 0.3, and 0.6, the curve is at 0.2 when <em>&lambda;</em> = 0, and 0.6 when <em>&lambda;</em> = 1.  (The curve, however, is not at 0.3 when <em>&lambda;</em> = 1/2; in general, Bézier curves do not cross their control points other than the first and the last.)</li>
<li>The problem of simulating polynomials in Bernstein form is related to <em>stochastic logic</em>, which involves simulating probabilities that arise out of Boolean functions (functions that use only AND, OR, NOT, and XOR operations) that take a fixed number of bits as input, where each bit has a separate probability of being 1 rather than 0, and output a single bit (for further discussion see (Qian et al. 2011)[^7], Qian and Riedel 2008[^10]).</li>
<li>These algorithms can serve as an approximate way to simulate any function <em>f</em> that maps the interval [0, 1] to [0, 1], whether continuous or not.  In this case, <em>a</em>[<em>j</em>] is calculated as <em>f</em>(<em>j</em>/<em>n</em>), so that the resulting polynomial closely approximates the function.  In fact, if <em>f</em> is continuous, it&#39;s possible to choose <em>n</em> high enough to achieve a given maximum error (this is a result of the so-called &quot;Weierstrass approximation theorem&quot;).  For more information, see my <a href="https://peteroupc.github.io/bernsupp.html"><strong>Supplemental Notes on Bernoulli Factories</strong></a>.</li>
</ol>

<p><strong>Examples:</strong></p>

<ol>
<li>Take the following parabolic function discussed in Thomas and Blanchet (2012)[^11]: (1&minus;4*(<em>&lambda;</em>&minus;1/2)<sup>2</sup>)*<em>c</em>, where <em>c</em> is in the interval (0, 1).  This is a polynomial of degree 2 that can be rewritten as &minus;4*<em>c</em>*<em>&lambda;</em><sup>2</sup>+4*<em>c</em>*<em>&lambda;</em>, so that this <em>power form</em> has coefficients (0, 4*<em>c</em>, &minus;4*<em>c</em>) and a degree (<em>n</em>) of 2. By rewriting the polynomial in Bernstein form (such as via the matrix method by Ray and Nataraj (2012)[^12]), we get coefficients (0, 2*<em>c</em>, 0).  Thus, for this polynomial, <em>a</em>[0] is 0,  <em>a</em>[1] is 2*<em>c</em>, and  <em>a</em>[2] is 0.  Thus, if <em>c</em> is in the interval (0, 1/2], we can simulate this function as follows: &quot;Flip the input coin twice.  If exactly one of the flips returns 1, return a number that is 1 with probability 2*<em>c</em> and 0 otherwise.  Otherwise, return 0.&quot;  For other values of <em>c</em>, the algorithm requires rewriting the polynomial in Bernstein form, then elevating the degree of the rewritten polynomial enough times to bring its coefficients in [0, 1]; the required degree approaches infinity as <em>c</em> approaches 1.[^13]</li>
<li>The <em>conditional</em> construction, mentioned in Flajolet et al. (2010)[^1], has the form&mdash;<br>(<em>&lambda;</em>) * <em>a</em>[0] + (1 &minus; <em>&lambda;</em>) * <em>a</em>[1].<br>This is a degree-1 polynomial in Bernstein form with variable <em>&lambda;</em> and coefficients <em>a</em>[0] and <em>a</em>[1]. The following algorithm simulates this polynomial: &quot;Flip the <em>&lambda;</em> input coin.  If the result is 0, flip the <em>a</em>[0] input coin and return the result.  Otherwise, flip the <em>a</em>[1] input coin and return the result.&quot;  Special cases of the conditional construction include complement, mean, product, and logical OR; see &quot;<a href="#Other_Factory_Functions"><strong>Other Factory Functions</strong></a>&quot;.</li>
</ol>
</blockquote>

<p>&nbsp;</p>

<p><strong>Multiple coins.</strong> Niazadeh et al. (2021)[^14] describes monomials (involving one or more coins) of the form <em>&lambda;</em>[1]<sup><em>a</em>[1]</sup> * (1&minus;<em>&lambda;</em>[1])<sup><em>b</em>[1]</sup>*<em>&lambda;</em>[2]<sup><em>a</em>[2]</sup> * (1&minus;<em>&lambda;</em>[2])<sup><em>b</em>[2]</sup>* ... * <em>&lambda;</em>[<em>n</em>]<sup><em>a</em>[<em>n</em>]</sup> * (1&minus;<em>&lambda;</em>[<em>n</em>])<sup><em>b</em>[<em>n</em>]</sup>, where there are <em>n</em> coins, <em>&lambda;</em>[<em>i</em>] is the probability of heads of coin <em>i</em>, and <em>a</em>[<em>i</em>] &ge; 0 and <em>b</em>[<em>i</em>] &ge; 0 are parameters for coin <em>i</em> (specifically, of <em>a</em>+<em>b</em> flips, the first <em>a</em> flips must return heads and the rest must return tails to succeed).</p>

<ol>
<li>For each <em>i</em> in [1, <em>n</em>]:

<ol>
<li>Flip the <em>&lambda;</em>[<em>i</em>] input coin <em>a</em>[<em>i</em>] times.  If any of the flips returns 0, return 0.</li>
<li>Flip the <em>&lambda;</em>[<em>i</em>] input coin <em>b</em>[<em>i</em>] times.  If any of the flips returns 1, return 0.</li>
</ol></li>
<li>Return 1.</li>
</ol>

<p>The same paper also describes polynomials that are weighted sums of this kind of monomials, namely polynomials of the form <em>P</em> = &sum;<sub><em>j</em> = 1, ..., <em>k</em></sub> <em>c</em>[<em>j</em>]*<em>M</em>[<em>j</em>](<strong><em>&lambda;</em></strong>), where there are <em>k</em> monomials, <em>M</em>[<em>j</em>](.) identifies monomial <em>j</em>, <strong><em>&lambda;</em></strong> identifies the coins&#39; probabilities of heads, and <em>c</em>[<em>j</em>] &ge; 0 is the weight for monomial <em>j</em>.</p>

<p>Let <em>C</em> be the sum of all <em>c</em>[<em>j</em>].  To simulate the probability <em>P</em>/<em>C</em>, choose one of the monomials with probability proportional to its weight (see &quot;<a href="https://peteroupc.github.io/randomfunc.html#Weighted_Choice_With_Replacement"><strong>Weighted Choice With Replacement</strong></a>&quot;), then run the algorithm above on that monomial (see also &quot;<a href="#Convex_Combinations"><strong>Convex Combinations</strong></a>&quot;, later).</p>

<p>The following is a special case:</p>

<ul>
<li>If there is only one coin, the polynomials <em>P</em> are in Bernstein form if <em>c</em>[<em>j</em>] is <em>&alpha;</em>[<em>j</em>]*choose(<em>k</em>&minus;1, <em>j</em>&minus;1) where <em>&alpha;</em>[<em>j</em>] is a coefficient in the interval [0, 1], and if <em>a</em>[1] = <em>j</em>&minus;1 and <em>b</em>[1] = <em>k</em>&minus;<em>j</em> for each monomial <em>j</em>.</li>
</ul>

<p><a id=Certain_Rational_Functions></a></p>

<h4>Certain Rational Functions</h4>

<p>A <em>rational function</em> is a ratio of polynomials.</p>

<p>According to Mossel and Peres (2005)[^15], a function that maps the open interval (0, 1) to (0, 1) can be simulated by a finite-state machine if and only if the function can be written as a rational function whose coefficients are rational numbers.</p>

<p>The following algorithm is suggested from the Mossel and Peres paper and from (Thomas and Blanchet 2012)[^11].  It assumes the rational function is written as <em>D</em>(<em>&lambda;</em>)/<em>E</em>(<em>&lambda;</em>), where&mdash;</p>

<ul>
<li><em>D</em>(<em>&lambda;</em>) = &sum;<sub><em>i</em> = 0, ..., <em>n</em></sub> <em>&lambda;</em><sup><em>i</em></sup> * (1 &minus; <em>&lambda;</em>)<sup><em>n</em> &minus; <em>i</em></sup> * <em>d</em>[<em>i</em>],</li>
<li><em>E</em>(<em>&lambda;</em>) = &sum;<sub><em>i</em> = 0, ..., <em>n</em></sub> <em>&lambda;</em><sup><em>i</em></sup> * (1 &minus; <em>&lambda;</em>)<sup><em>n</em> &minus; <em>i</em></sup> * <em>e</em>[<em>i</em>],</li>
<li>every <em>d</em>[<em>i</em>] is less than or equal to the corresponding <em>e</em>[<em>i</em>], and</li>
<li>each <em>d</em>[<em>i</em>] and each <em>e</em>[<em>i</em>] is an integer or rational number in the interval [0, choose(<em>n</em>, <em>i</em>)], where the upper bound is the total number of <em>n</em>-bit words with <em>i</em> ones.</li>
</ul>

<p>Here, <em>d</em>[<em>i</em>] is akin to the number of &quot;passing&quot; <em>n</em>-bit words with <em>i</em> ones, and <em>e</em>[<em>i</em>] is akin to that number plus the number of &quot;failing&quot; <em>n</em>-bit words with <em>i</em> ones.</p>

<p>The algorithm follows.</p>

<ol>
<li>Flip the input coin <em>n</em> times, and let <em>j</em> be the number of times the coin returned 1 this way.</li>
<li>Choose 0, 1, or 2 with probability proportional to these weights: [<em>e</em>[<em>j</em>] &minus; <em>d</em>[<em>j</em>], <em>d</em>[<em>j</em>], choose(<em>n</em>, <em>j</em>) &minus; <em>e</em>[<em>j</em>]].  If 0 or 1 is chosen this way, return it.  Otherwise, go to step 1.</li>
</ol>

<blockquote>
<p><strong>Notes:</strong></p>

<ol>
<li><p>In the formulas above&mdash;</p>

<ul>
<li><em>d</em>[<em>i</em>] can be replaced with <em>&delta;</em>[<em>i</em>] * choose(<em>n</em>,<em>i</em>), where <em>&delta;</em>[<em>i</em>] is a rational number in the interval [0, 1] (and thus expresses the probability that a given word is a &quot;passing&quot; word among all <em>n</em>-bit words with <em>i</em> ones), and</li>
<li><em>e</em>[<em>i</em>] can be replaced with <em>&eta;</em>[<em>i</em>] * choose(<em>n</em>,<em>i</em>), where <em>&eta;</em>[<em>i</em>] is a rational number in the interval [0, 1] (and thus expresses the probability that a given word is a &quot;passing&quot; or &quot;failing&quot; word among all <em>n</em>-bit words with <em>i</em> ones),</li>
</ul>

<p>and then <em>&delta;</em>[<em>i</em>] and <em>&eta;</em>[<em>i</em>] can be seen as control points for two different 1-dimensional <a href="https://en.wikipedia.org/wiki/B%C3%A9zier_curve"><strong>Bézier curves</strong></a>, where the <em>&delta;</em> curve is always on or &quot;below&quot; the <em>&eta;</em> curve.  For each curve, <em>&lambda;</em> is the relative position on that curve, the curve begins at  <em>&delta;</em>[0] or <em>&eta;</em>[0], and the curve ends at <em>&delta;</em>[<em>n</em>] or <em>&eta;</em>[<em>n</em>]. See also the next section.</p></li>
<li><p>This algorithm could be modified to avoid additional randomness besides the input coin flips by packing the coin flips into an <em>n</em>-bit word and looking up whether that word is &quot;passing&quot;, &quot;failing&quot;, or neither, among all <em>n</em>-bit words with <em>j</em> ones, but this can be impractical (in general, a lookup table of size 2<sup><em>n</em></sup> first has to be built in a setup step; as <em>n</em> grows, the table size grows exponentially).  Moreover, this approach works only if <em>d</em>[<em>i</em>] and <em>e</em>[<em>i</em>] are integers (or if <em>d</em>[<em>i</em>] is replaced with floor(<em>d</em>[<em>i</em>]) and <em>e</em>[<em>i</em>] with ceil(<em>e</em>[<em>i</em>]) (Nacu and Peres 2005)[^16], but this, of course, suffers from rounding error when done in this algorithm).  See also (Thomas and Blanchet 2012)[^11].</p></li>
<li>As with polynomials, this algorithm (or the one given later) can serve as an approximate way to simulate any factory function, via a rational function that closely approximates that function.  The higher <em>n</em> is, the better this approximation, and in general, a degree-<em>n</em> rational function approximates a given function better than a degree-<em>n</em> polynomial.  However, to achieve a given error tolerance with a rational function, the degree <em>n</em> as well as <em>d</em>[<em>i</em>] and <em>e</em>[<em>i</em>] have to be optimized.  This is unlike the polynomial case where only the degree <em>n</em> has to be optimized.</li>
</ol>

<p><strong>Example</strong>: Take the function <em>f</em>(<em>&lambda;</em>) = 1/(<em>&lambda;</em>&minus;2)<sup>2</sup>.  This is a rational function, in this case a ratio of two polynomials that are both non-negative on the interval [0, 1].  One algorithm to simulate <em>f</em> is:<br>(1) Flip the input coin twice, and let <em>heads</em> be the number of times the coin returned 1 this way.<br>(2) Depending on <em>heads</em>, choose 0, 1, or 2 with probability proportional to the following weights: <em>heads</em>=0 &rarr; [3, 1, 0], <em>heads</em>=1 &rarr; [1, 1, 2], <em>heads</em>=2 &rarr; [0, 1, 3]; if 0 or 1 is chosen this way, return it; otherwise, go to step 1.<br>Here is how <em>f</em> was prepared to derive this algorithm:<br>(1) Take the numerator 1, and the denominator (<em>&lambda;</em>&minus;2)<sup>2</sup>.  Rewrite the denominator as 1*<em>&lambda;</em><sup>2</sup> &minus; 4*<em>&lambda;</em> + 4.<br>(2) Rewrite the numerator and denominator into homogeneous polynomials (polynomials whose terms have the same degree) of degree 2; see the &quot;homogenizing&quot; section in &quot;<a href="#Preparing_Rational_Functions"><strong>Preparing Rational Functions</strong></a>&quot;.  The result is (1, 2, 1) and (4, 4, 1) respectively.<br>(3) Divide both polynomials by 4 (the maximum coefficient) so that they are all 1 or less.  The result is <em>d</em> = (1/4, 1/2, 1/4), <em>e</em> = (1, 1, 1/4).<br>(4) Prepare the weights as given in step 2 of the original algorithm.  The result is [3/4, 1/4, 0], [1/2, 1/2, 1], and [0, 1/4, 3/4], for different counts of heads.  These weights can be simplified in this case to integers without affecting the algorithm: [3, 1, 0], [1, 1, 2], [0, 1, 3], respectively.</p>
</blockquote>

<p><strong>&quot;Dice Enterprise&quot; special case.</strong> The following algorithm implements a special case of the &quot;Dice Enterprise&quot; method of Morina et al. (2019)[^17].  The algorithm returns one of <em>m</em> outcomes (namely <em>X</em>, an integer in [0, <em>m</em>)) with probability <em>P</em><sub><em>X</em></sub>(<em>&lambda;</em>) / (<em>P</em><sub>0</sub>(<em>&lambda;</em>) + <em>P</em><sub>1</sub>(<em>&lambda;</em>) + ... + <em>P</em><sub><em>m</em>&minus;1</sub>(<em>&lambda;</em>)), where <em>&lambda;</em> is the input coin&#39;s probability of heads and <em>m</em> is 2 or greater.  Specifically, the probability is a <em>rational function</em>, or ratio of polynomials.  Here, all the <em>P</em><sub><em>k</em></sub>(<em>&lambda;</em>) are in the form of polynomials as follows:</p>

<ul>
<li>The polynomials are <em>homogeneous</em>, that is, they are written as &sum;<sub><em>i</em> = 0, ..., <em>n</em></sub> <em>&lambda;</em><sup><em>i</em></sup> * (1 &minus; <em>&lambda;</em>)<sup><em>n</em> &minus; <em>i</em></sup> * <em>a</em>[<em>i</em>], where <em>n</em> is the polynomial&#39;s degree and <em>a</em>[<em>i</em>] is a coefficient.</li>
<li>The polynomials have the same degree (namely <em>n</em>) and all <em>a</em>[<em>i</em>] are 0 or greater.</li>
<li>The sum of <em>j</em><sup>th</sup> coefficients is greater than 0, for each <em>j</em> starting at 0 and ending at <em>n</em>, except that the list of sums may begin and/or end with zeros.  Call this list <em>R</em>.  For example, this condition holds true if <em>R</em> is (2, 4, 4, 2) or (0, 2, 4, 0), but not if <em>R</em> is (2, 0, 4, 3).</li>
</ul>

<p>Any rational function that admits a Bernoulli factory can be brought into the form just described, as detailed in the appendix under &quot;<a href="#Preparing_Rational_Functions"><strong>Preparing Rational Functions</strong></a>&quot;.  In this algorithm, let <em>R</em>[<em>j</em>] be the sum of <em>j</em><sup>th</sup> coefficients of the polynomials (with <em>j</em> starting at 0).  First, define the following operation:</p>

<ul>
<li><strong>Get the new state given <em>state</em>, <em>b</em>, <em>u</em>, and <em>n</em></strong>:

<ol>
<li>If <em>state</em> &gt; 0 and <em>b</em> is 0, return either <em>state&minus;1</em> if <em>u</em> is less than (or equal to) <em>PA</em>, or <em>state</em> otherwise, where <em>PA</em> is <em>R</em>[<em>state</em>&minus;1]/max(<em>R</em>[<em>state</em>], <em>R</em>[<em>state</em>&minus;1]).</li>
<li>If <em>state</em> &lt; <em>n</em> and <em>b</em> is 1, return either <em>state+1</em> if <em>u</em> is less than (or equal to) <em>PB</em>, or <em>state</em> otherwise, where <em>PB</em> is <em>R</em>[<em>state</em>+1]/max(<em>R</em>[<em>state</em>], <em>R</em>[<em>state</em>+1]).</li>
<li>Return <em>state</em>.</li>
</ol></li>
</ul>

<p>Then the algorithm is as follows:</p>

<ol>
<li>Create two empty lists: <em>blist</em> and <em>ulist</em>.</li>
<li>Set <em>state1</em> to the position of the first non-zero item in <em>R</em>.  Set <em>state2</em> to the position of the last non-zero item in <em>R</em>.  In both cases, positions start at 0.  If all the items in <em>R</em> are zeros, return 0.</li>
<li>Flip the input coin and append the result (which is 0 or 1) to the end of <em>blist</em>.  Generate a uniform(0, 1) random variate and append it to the end of <em>ulist</em>.</li>
<li>(Monotonic coupling from the past (Morina et al., 2019)[^17], (Propp and Wilson 1996)[^18].) Set <em>i</em> to the number of items in <em>blist</em> minus 1, then while <em>i</em> is 0 or greater:

<ol>
<li>Let <em>b</em> be the item at position <em>i</em> (starting at 0) in <em>blist</em>, and let <em>u</em> be the item at that position in <em>ulist</em>.</li>
<li><strong>Get the new state given <em>state1</em>, <em>b</em>, <em>u</em>, and <em>n</em></strong>, and set <em>state1</em> to the new state.</li>
<li><strong>Get the new state given <em>state2</em>, <em>b</em>, <em>u</em>, and <em>n</em></strong>, and set <em>state2</em> to the new state.</li>
<li>Subtract 1 from <em>i</em>.</li>
</ol></li>
<li>If <em>state1</em> and <em>state2</em> are not equal, go to step 2.</li>
<li>Let  <em>b</em>(<em>j</em>) be coefficient <em>a</em>[<em>state1</em>] of the polynomial for <em>j</em>. Choose an integer in [0, <em>m</em>) with probability proportional to these weights: [<em>b</em>(0), <em>b</em>(1), ..., <em>b</em>(<em>m</em>&minus;1)].  Then return the chosen integer.</li>
</ol>

<blockquote>
<p><strong>Notes:</strong></p>

<ol>
<li>If there are only two outcomes, then this is the special Bernoulli factory case; the algorithm would then return 1 with probability <em>P</em><sub>1</sub>(<em>&lambda;</em>) / (<em>P</em><sub>0</sub>(<em>&lambda;</em>) + <em>P</em><sub>1</sub>(<em>&lambda;</em>)).</li>
<li>If <em>R</em>[<em>j</em>] = choose(<em>n</em>, <em>j</em>), steps 1 through 5 have the same effect as counting the number of ones from <em>n</em> input coin flips (which would be stored in <em>state1</em> in this case), but unfortunately, these steps wouldn&#39;t be more efficient.  In this case, <em>PA</em> is equivalent to &quot;1 if <em>state</em> is greater than floor(<em>n</em>/2), and <em>state</em>/(<em>n</em>+1&minus;<em>state</em>) otherwise&quot;, and <em>PB</em> is equivalent to &quot;1 if <em>state</em> is less than floor(<em>n</em>/2), and (<em>n</em>&minus;<em>state</em>)/(<em>state</em>+1) otherwise&quot;.</li>
</ol>

<p><strong>Example:</strong> Let <em>P</em><sub>0</sub>(<em>&lambda;</em>) = 2*<em>&lambda;</em>*(1&minus;<em>&lambda;</em>) and <em>P</em><sub>1</sub>(<em>&lambda;</em>) = (4*<em>&lambda;</em>*(1&minus;<em>&lambda;</em>))<sup>2</sup>/2.  The goal is to produce 1 with probability <em>P</em><sub>1</sub>(<em>&lambda;</em>) / (<em>P</em><sub>0</sub>(<em>&lambda;</em>) + <em>P</em><sub>1</sub>(<em>&lambda;</em>)). After <a href="#Preparing_Rational_Functions"><strong>preparing this function</strong></a> (and noting that the maximum degree is <em>n</em> = 4), we get the coefficient sums <em>R</em> = (0, 2, 12, 2, 0).  Since <em>R</em> begins and ends with 0, step 2 of the algorithm sets <em>state1</em> and <em>state2</em>, respectively, to the position of the first or last nonzero item, namely 1 or 3.  (Alternatively, because <em>R</em> begins and ends with 0, we could include a third polynomial, namely the constant <em>P</em><sub>2</sub>(<em>&lambda;</em>) = 0.001, so that the new coefficient sums would be <em>R&prime;</em> = (0.001, 10.004, 12.006, 2.006, 0.001) [formed by adding the coefficient 0.001*choose(<em>n</em>, <em>i</em>) to the sum at <em>i</em>, starting at <em>i</em> = 0].  Now we would run the algorithm using <em>R&prime;</em>, and if it returns 2 [meaning that the constant polynomial was chosen], we would try again until the algorithm no longer returns 2.)</p>
</blockquote>

<p><a id=Certain_Algebraic_Functions></a></p>

<h4>Certain Algebraic Functions</h4>

<p>(Flajolet et al., 2010)[^1] showed how certain functions can be simulated by generating a bitstring and determining whether that bitstring belongs to a certain class of bitstrings.  The rules for determining whether a bitstring belongs to that class are called a <em>binary stochastic grammar</em>, which uses an alphabet of only two &quot;letters&quot;, or more generally a <em>stochastic grammar</em>.   The functions belong to a class called <em>algebraic functions</em> (functions that can be a solution of a nonzero polynomial equation).</p>

<p>According to (Mossel and Peres 2005)[^15], a factory function can be simulated by a <em>pushdown automaton</em> (a state machine with a stack) only if that function can be a solution of a polynomial equation whose coefficients are rational numbers not all zero.</p>

<p>The following algorithm simulates the following algebraic function:</p>

<ul>
<li>&sum;<sub><em>k</em> = 0, 1, 2, ...</sub> (<em>&lambda;</em><sup><em>k</em></sup> * (1 &minus; <em>&lambda;</em>) * W(<em>k</em>) / <em>&beta;</em><sup><em>k</em></sup>), or alternatively,</li>
<li>(1 &minus; <em>&lambda;</em>) * OGF(<em>&lambda;</em>/<em>&beta;</em>),</li>
</ul>

<p>where&mdash;</p>

<ul>
<li>W(<em>k</em>) is a number in the interval [0, <em>&beta;</em><sup><em>k</em></sup>], and in many cases is the number of <em>k</em>-letter words that can be produced by the stochastic grammar in question,</li>
<li><em>&beta;</em> is the alphabet size, or the number of &quot;letters&quot; in the alphabet (e.g., 2 for the cases discussed in the Flajolet paper), and is an integer 2 or greater,</li>
<li>the <em>ordinary generating function</em> OGF(<em>x</em>) = W(0) + W(1) * <em>x</em> + W(2) * <em>x</em><sup>2</sup> + W(3) * <em>x</em><sup>3</sup> + ..., and</li>
<li>the second formula incorporates a correction to Theorem 3.2 of the paper[^19].</li>
</ul>

<p>(Here, the <em>k</em><sup>th</sup> coefficient of OGF(<em>x</em>) corresponds to W(<em>k</em>).)  The algorithm follows.</p>

<ol>
<li>Flip the input coin repeatedly until it returns 0.  Set <em>g</em> to the number of times the coin returned 1 this way.</li>
<li>Return a number that is 1 with probability W(<em>g</em>)/<em>&beta;</em><sup><em>g</em></sup>, and 0 otherwise.  (In the Flajolet paper, this is done by generating a <em>g</em>-letter word uniformly at random and &quot;parsing&quot; that word using a binary stochastic grammar to determine whether that word can be produced by that grammar.  In fact, this determination can be made this way as each of the word&#39;s &quot;letters&quot; is generated.)</li>
</ol>

<p>An extension to this algorithm, not mentioned in the Flajolet et al. paper, is the use of stochastic grammars with a bigger alphabet than two &quot;letters&quot;.  For example, in the case of <em>ternary stochastic grammars</em>, the alphabet size is 3 and <em>&beta;</em> is 3 in the algorithm above.  In general, for <em><em>&beta;</em>-ary stochastic grammars</em>, the alphabet size is <em>&beta;</em>, which can be any integer 2 or greater.</p>

<blockquote>
<p><strong>Notes:</strong></p>

<ol>
<li>The <em>radius of convergence</em> of OGF is the greatest number <em>&rho;</em> such that OGF is defined at every point less than <em>&rho;</em> away from the origin (0, 0).  In this algorithm, the radius of convergence is in the interval [1/<em>&beta;</em>, 1] (Flajolet 1987)[^20].  For example, the OGF involved in the square root construction given in the examples below has radius of convergence 1/2.</li>
<li>The number of flips used by this algorithm grows without bound as <em>&lambda;</em> approaches 1.</li>
</ol>

<p><strong>Examples:</strong></p>

<ol>
<li>The following is an example from the Flajolet et al. paper. A <em>g</em>-letter binary word can be &quot;parsed&quot; as follows to determine whether that word encodes a ternary tree: &quot;2. If <em>g</em> is 0, return 0.  Otherwise, set <em>i</em> to 1 and <em>d</em> to 1.; 2a. Generate an unbiased random bit (that is, either 0 or 1, chosen with equal probability), then subtract 1 from <em>d</em> if that bit is 0, or add 2 to <em>d</em> otherwise.; 2b. Add 1 to <em>i</em>. Then, if <em>i</em> &lt; <em>g</em> and <em>d</em> &gt; 0, go to step 3a.; 2c. Return 1 if <em>d</em> is 0 and <em>i</em> is <em>g</em>, or 0 otherwise.&quot;</li>
<li><p>If W(<em>g</em>), the number of <em>g</em>-letter words that can be produced by the stochastic grammar in question, has the form&mdash;</p>

<ul>
<li>choose(<em>g</em>, <em>g</em>/<em>t</em>) * (<em>&beta;</em>&minus;1)<sup><em>g</em>&minus;<em>g</em>/<em>t</em></sup> (the number of <em>g</em>-letter words with exactly <em>g</em>/<em>t</em> A&#39;s, for an alphabet size of <em>&beta;</em>) if <em>g</em> is divisible by <em>t</em>[^21], and</li>
<li>0 otherwise,</li>
</ul>

<p>where <em>t</em> is an integer 2 or greater and <em>&beta;</em> is the alphabet size and is an integer 2 or greater, step 2 of the algorithm can be done as follows: &quot;2. If <em>g</em> is not divisible by <em>t</em>, return 0. Otherwise, generate <em>g</em> uniform random integers in the interval [0, <em>&beta;</em>) (e.g., <em>g</em> unbiased random bits if <em>&beta;</em> is 2), then return 1 if exactly <em>g</em>/<em>t</em> zeros were generated this way, or 0 otherwise.&quot;  If <em>&beta;</em> = 2, then this reproduces another example from the Flajolet paper.</p></li>
<li><p>If W(<em>g</em>) has the form&mdash;<br/>&nbsp;&nbsp;&nbsp;&nbsp;choose(<em>g</em> * <em>&alpha;</em>, <em>g</em>) * (<em>&beta;</em>&minus;1)<sup><em>g</em>*<em>&alpha;&minus;g</em></sup> / <em>&beta;</em><sup><em>g</em>*<em>&alpha;&minus;g</em></sup>,<br/>where <em>&alpha;</em> is an integer 1 or greater and <em>&beta;</em> is the alphabet size and is an integer 2 or greater [^22], step 2 of the algorithm can be done as follows: &quot;2. Generate <em>g</em> * <em>&alpha;</em> uniform random integers in the interval [0, <em>&beta;</em>) (e.g., <em>g</em> * <em>&alpha;</em> unbiased random bits if <em>&beta;</em> is 2), then return 1 if exactly <em>g</em> zeros were generated this way, or 0 otherwise.&quot;  If <em>&alpha;</em> = 2 and <em>&beta;</em> = 2, then this expresses the <em>square-root construction</em> sqrt(1 &minus; <em>&lambda;</em>), mentioned in the Flajolet et al. paper.  If <em>&alpha;</em> is 1, the modified algorithm simulates the following probability: (<em>&beta;</em>*(<em>&lambda;</em>&minus;1))/(<em>&lambda;</em>&minus;<em>&beta;</em>).  And interestingly, I have found that if <em>&alpha;</em> is 2 or greater, the probability simplifies to involve a hypergeometric function.  Specifically, the probability becomes&mdash;</p>

<ul>
<li>(1 &minus; <em>&lambda;</em>) * <sub><em>&alpha;</em>&minus;1</sub><em>F</em><sub><em>&alpha;</em>&minus;2</sub>(1/<em>&alpha;</em>, 2/<em>&alpha;</em>, ..., (<em>&alpha;</em>&minus;1)/<em>&alpha;</em>; 1/(<em>&alpha;</em>&minus;1), ..., (<em>&alpha;</em>&minus;2)/(<em>&alpha;</em>&minus;1); <em>&lambda;</em> * <em>&alpha;</em><sup><em>&alpha;</em></sup>/((<em>&alpha;</em>&minus;1)<sup><em>&alpha;</em>&minus;1</sup> * 2<sup><em>&alpha;</em></sup>)) if <em>&beta;</em> = 2, or more generally,</li>
<li>(1 &minus; <em>&lambda;</em>) * <sub><em>&alpha;</em>&minus;1</sub><em>F</em><sub><em>&alpha;</em>&minus;2</sub>(1/<em>&alpha;</em>, 2/<em>&alpha;</em>, ..., (<em>&alpha;</em>&minus;1)/<em>&alpha;</em>; 1/(<em>&alpha;</em>&minus;1), ..., (<em>&alpha;</em>&minus;2)/(<em>&alpha;</em>&minus;1); <em>&lambda;</em>*<em>&alpha;</em><sup><em>&alpha;</em></sup>*(<em>&beta;</em>&minus;1)<sup><em>&alpha;</em>&minus;1</sup>/((<em>&alpha;</em>&minus;1)<sup><em>&alpha;</em>&minus;1</sup> * <em>&beta;</em><sup><em>&alpha;</em></sup>)).</li>
</ul>

<p>The ordinary generating function for this modified algorithm is thus&mdash;<br/>&nbsp;&nbsp;&nbsp;&nbsp;OGF(<em>z</em>) = <sub><em>&alpha;</em>&minus;1</sub><em>F</em><sub><em>&alpha;</em>&minus;2</sub>(1/<em>&alpha;</em>, 2/<em>&alpha;</em>, ..., (<em>&alpha;</em>&minus;1)/<em>&alpha;</em>; 1/(<em>&alpha;</em>&minus;1), ..., (<em>&alpha;</em>&minus;2)/(<em>&alpha;</em>&minus;1); <em>z</em>*<em>&alpha;</em><sup><em>&alpha;</em></sup>*(<em>&beta;</em>&minus;1)<sup><em>&alpha;</em>&minus;1</sup>/((<em>&alpha;</em>&minus;1)<sup><em>&alpha;</em>&minus;1</sup> * <em>&beta;</em><sup><em>&alpha;</em>&minus;1</sup>)).</p></li>
<li><p>The probability involved in example 2 likewise involves hypergeometric functions:</p>

<ul>
<li>(1 &minus; <em>&lambda;</em>) * <sub><em>t</em>&minus;1</sub><em>F</em><sub><em>t</em>&minus;2</sub>(1/<em>t</em>, 2/<em>t</em>, ..., (<em>t</em>&minus;1)/<em>t</em>; 1/(<em>t</em>&minus;1), ..., (<em>t</em>&minus;2)/(<em>t</em>&minus;1); <em>&lambda;</em><sup><em>t</em></sup>*<em>t</em><sup><em>t</em></sup>*(<em>&beta;</em>&minus;1)<sup><em>t</em>&minus;1</sup>/((<em>t</em>&minus;1)<sup><em>t</em>&minus;1</sup> * <em>&beta;</em><sup><em>t</em></sup>)).</li>
</ul></li>
</ol>
</blockquote>

<p><a id=Certain_Power_Series></a></p>

<h4>Certain Power Series</h4>

<p>Mendo (2019)[^23] gave a Bernoulli factory algorithm for certain functions that can be rewritten as a <em>power series</em>.  The algorithm uses parameter <em>v</em> and is given below.  A table of supported power series will follow the algorithm.</p>

<ol>
<li>Set <em>dsum</em> to 0 and <em>i</em> to 1.</li>
<li>Do the following process repeatedly, until this algorithm returns a value:

<ol>
<li>Flip the input coin.  If it returns <em>v</em>, return 1.</li>
<li>If this is an infinite series or if <em>i</em> is equal to or less than the number of coefficients:

<ul>
<li>With probability <em>c</em>[<em>i</em>]/(<em>CS</em> &minus; <em>dsum</em>), return 0.  Otherwise, add <em>c</em>[<em>i</em>] to <em>dsum</em>. (<em>CS</em> is defined later.)</li>
</ul></li>
<li>Add 1 to <em>i</em>.</li>
</ol></li>
</ol>

<p>A table of supported power series follows:</p>

<table><thead>
<tr>
<th>No.</th>
<th>Power Series</th>
<th>Algorithm</th>
</tr>
</thead><tbody>
<tr>
<td>1</td>
<td><em>f</em>(<em>&lambda;</em>) = 1 &minus; (<em>c</em>[1] * (1 &minus; <em>&lambda;</em>) + ... + <em>c</em>[<em>i</em>] * (1 &minus; <em>&lambda;</em>)<sup><em>i</em></sup> + ...)</td>
<td>With probability <em>CS</em>, run the algorithm above with <em>v</em>=1 and return the result.  Otherwise, return 0.</td>
</tr>
<tr>
<td>2</td>
<td><em>f</em>(<em>&lambda;</em>) = (<em>c</em>[1] * (1 &minus; <em>&lambda;</em>) + ... + <em>c</em>[<em>i</em>] * (1 &minus; <em>&lambda;</em>)<sup><em>i</em></sup> + ...)</td>
<td>With probability <em>CS</em>, run the algorithm above with <em>v</em>=1 and return 1 minus the result.  Otherwise, return 1.</td>
</tr>
<tr>
<td>3</td>
<td><em>f</em>(<em>&lambda;</em>) = (<em>c</em>[1] * <em>&lambda;</em> + ... + <em>c</em>[<em>i</em>] * <em>&lambda;</em><sup><em>i</em></sup> + ...)</td>
<td>With probability <em>CS</em>, run the algorithm above with <em>v</em>=0 and return 1 minus the result.  Otherwise, return 0.</td>
</tr>
<tr>
<td>4</td>
<td><em>f</em>(<em>&lambda;</em>) = 1 &minus; (<em>c</em>[1] * <em>&lambda;</em> + ... + <em>c</em>[<em>i</em>] * <em>&lambda;</em><sup><em>i</em></sup> + ...)</td>
<td>With probability <em>CS</em>, run the algorithm above with <em>v</em>=0 and return the result.  Otherwise, return 1.</td>
</tr>
</tbody></table>

<p>In the table above, <em>c</em>[<em>i</em>] &ge; 0 are the coefficients of the series.  <em>CS</em> is the sum of all the coefficients, must be 1 or less, and should be a rational number.  This implies that&mdash;</p>

<ul>
<li><em>f</em>(0) is either 0 for series 1 and 3, or 1 for series 2 and 4, and</li>
<li><em>f</em>(1) is either <em>CS</em> for series 1 and 3, or 1&minus;<em>CS</em> for series 2 and 4.</li>
</ul>

<hr>

<p>(Łatuszyński et al. 2009/2011)[^24] gave an algorithm that works for a wide class of series and other constructs that converge to the desired probability from above and from below.</p>

<p>One of these cases is when <em>f</em>(<em>&lambda;</em>) can be written as&mdash;</p>

<p><em>f</em>(<em>&lambda;</em>) = <em>d[0]</em> &minus; <em>d[1]</em> * <em>&lambda;</em><sup>1</sup> + <em>d[2]</em> * <em>&lambda;</em><sup>2</sup> &minus; ...,</p>

<p>which is an alternating series, where <em>d</em>[<em>i</em>] must all be in the interval [0, 1] and form a nonincreasing sequence of coefficients, and <em>f</em>(1) must converge to a number in the half-open interval [0, 1).</p>

<p>The following is the general algorithm for this kind of series, called the <strong>general martingale algorithm</strong>.  It takes a list of coefficients and an input coin, and returns 1 with the probability given by the series above, and 0 otherwise.</p>

<ol>
<li>Let <em>d[0]</em>, <em>d[1]</em>, etc. be the first, second, etc. coefficients of the alternating series.  Set <em>u</em> to <em>d[0]</em>, set <em>w</em> to 1, set <em>&#x2113;</em> to 0, and set <em>n</em> to 1.</li>
<li>Generate a uniform(0, 1) random variate <em>ret</em>.</li>
<li>If <em>w</em> is not 0, flip the input coin and multiply <em>w</em> by the result of the flip.</li>
<li>If <em>n</em> is even, set <em>u</em> to <em>&#x2113;</em> + <em>w</em> * <em>d[n]</em>.  Otherwise, set <em>&#x2113;</em> to <em>u</em> &minus; <em>w</em> * <em>d[n]</em>.</li>
<li>If <em>ret</em> is less than (or equal to) <em>&#x2113;</em>, return 1.  If <em>ret</em> is less than <em>u</em>, go to the next step.  If neither is the case, return 0.  (If <em>ret</em> is a uniform PSRN, these comparisons should be done via the <strong>URandLessThanReal algorithm</strong>, which is described in my <a href="https://peteroupc.github.io/exporand.html"><strong>article on PSRNs</strong></a>.)</li>
<li>Add 1 to <em>n</em> and go to step 3.</li>
</ol>

<p>More generally, if <em>f</em>(<em>&lambda;</em>) can be written as&mdash;</p>

<p><em>f</em>(<em>&lambda;</em>) = <em>d[0]</em> &minus; <em>d[1]</em> * (<em>g</em>(<em>&lambda;</em>))<sup>1</sup> + <em>d[2]</em> * (<em>g</em>(<em>&lambda;</em>))<sup>2</sup> &minus; ...,</p>

<p>where <em>d</em>[<em>i</em>] are as before and <em>g</em>(<em>&lambda;</em>) is a factory function, step 3 is rewritten as &quot;3. If <em>w</em> is not 0, run a Bernoulli factory algorithm for <em>g</em>(<em>&lambda;</em>) using the input coin, and multiply <em>w</em> by the result.&quot;</p>

<blockquote>
<p><strong>Example:</strong> If <em>f</em> can be written as&mdash;<br><em>f</em>(<em>&lambda;</em>) = <em>d[0]</em> &minus; <em>d[1]</em> * <em>&lambda;</em><sup>2</sup> + <em>d[2]</em> * <em>&lambda;</em><sup>4</sup> &minus; ...<br>= <em>d[0]</em> &minus; <em>d[1]</em> * (<em>&lambda;</em><sup>2</sup>)<sup>1</sup> + <em>d[2]</em> * (<em>&lambda;</em><sup>2</sup>)<sup>2</sup> &minus; ...,<br> then <em>g</em>(<em>&lambda;</em>) = <em>&lambda;</em><sup>2</sup>, so that the algorithm above can be used, except step 3 is &quot;3. If <em>w</em> is not 0, flip the input coin twice and multiply <em>w</em> by each result of the flip.&quot;</p>
</blockquote>

<hr>

<p>(Nacu and Peres 2005, proposition 16)[^16].  The algorithm below simulates a function of the form&mdash;</p>

<p><em>f</em>(<em>&lambda;</em>) = <em>d[0]</em> + <em>d[1]</em> * <em>&lambda;</em> + <em>d[2]</em> * <em>&lambda;</em><sup>2</sup> + ...,</p>

<p>where each <em>d</em>[<em>i</em>] is 0 or greater, and takes the following parameters:</p>

<ul>
<li><em>t</em> is a rational number in the interval (<em>B</em>, 1] such that <em>f</em>(<em>t</em>) &lt; 1.</li>
<li><em>&#x03F5;</em> is a rational number in the interval (0, (<em>t</em> &minus; <em>B</em>)/2].</li>
</ul>

<p><em>B</em> is not a parameter, but is the maximum allowed value for <em>&lambda;</em> (probability of heads) and in the interval (0, 1).</p>

<ol>
<li>Create a <em>&nu;</em> input coin that does the following: &quot;(1) Set <em>n</em> to 0. (2) With probability <em>&#x03F5;</em>/<em>t</em>, go to the next substep.  Otherwise, add 1 to <em>n</em> and repeat this substep. (3) With probability 1 &minus; <em>d</em>[<em>n</em>]*<em>t</em><sup><em>n</em></sup>, return 0. (4) Run a <a href="#Linear_Bernoulli_Factories"><strong>linear Bernoulli factory</strong></a> <em>n</em> times, using the (<em>&lambda;</em>) input coin, <em>x</em>/<em>y</em> = 1/(<em>t</em> &minus; <em>&#x03F5;</em>), and <em>&#x03F5;</em> = <em>&#x03F5;</em>.  If any of these runs returns 0, return 0.  Otherwise, return 1.&quot;</li>
<li>Run a <a href="#Linear_Bernoulli_Factories"><strong>linear Bernoulli factory</strong></a> once, using the <em>&nu;</em> input coin described earlier, <em>x</em>/<em>y</em> = <em>t</em>/<em>&#x03F5;</em>, and <em>&#x03F5;</em> = <em>&#x03F5;</em>, and return the result.</li>
</ol>

<p><a id=General_Factory_Functions></a></p>

<h4>General Factory Functions</h4>

<p>A coin with unknown probability of heads of <em>&lambda;</em> can be turned into a coin with probability of heads of <em>f</em>(<em>&lambda;</em>), where <em>f</em> is any factory function, via an algorithm that builds randomized bounds on <em>f</em>(<em>&lambda;</em>) based on the outcomes of the coin flips.  These randomized bounds come from two sequences of polynomials:</p>

<ul>
<li>One sequence of polynomials converges from above to <em>f</em>, the other from below.</li>
<li>For each sequence, the polynomials must have increasing degree.</li>
<li>The polynomials are written in <em>Bernstein form</em> (see &quot;<a href="#Certain_Polynomials"><strong>Certain Polynomials</strong></a>&quot;).</li>
<li>For each sequence, the degree-<em>n</em> polynomials&#39; coefficients must lie at or &quot;inside&quot; those of the previous upper polynomial and the previous lower one (once the polynomials are elevated to degree <em>n</em>).  This is also called the <em>consistency requirement</em>.</li>
</ul>

<p>This section sets forth two algorithms to simulate factory functions via polynomials.  In both algorithms:</p>

<ul>
<li><strong>fbelow</strong>(<em>n</em>, <em>k</em>) is a lower bound of the <em>k</em><sup>th</sup> coefficient for a degree-<em>n</em> polynomial in Bernstein form that approximates <em>f</em> from below, where <em>k</em> is in the interval [0, <em>n</em>].  For example, this can be <em>f</em>(<em>k</em>/<em>n</em>) minus a constant that depends on <em>n</em>. (See note 3 below.)</li>
<li><strong>fabove</strong>(<em>n</em>, <em>k</em>) is an upper bound of the <em>k</em><sup>th</sup> coefficient for a degree-<em>n</em> polynomial in Bernstein form  that approximates <em>f</em> from above.  For example, this can be <em>f</em>(<em>k</em>/<em>n</em>) plus a constant that depends on <em>n</em>. (See note 3.)</li>
</ul>

<p>The first algorithm implements the reverse-time martingale framework (Algorithm 4) in Łatuszyński et al. (2009/2011)[^24] and the degree-doubling suggestion in Algorithm I of Flegal and Herbei (2012)[^25], although an error in Algorithm I is noted below.  The first algorithm follows.</p>

<ol>
<li>Generate a uniform(0, 1) random variate, call it <em>ret</em>.</li>
<li>Set <em>&#x2113;</em> and <em>&#x2113;t</em> to 0.  Set <em>u</em> and <em>ut</em> to 1. Set <em>lastdegree</em> to 0, and set <em>ones</em> to 0.</li>
<li>Set <em>degree</em> so that the first pair of polynomials has degree equal to <em>degree</em> and has coefficients all lying in [0, 1].  For example, this can be done as follows: Let <strong>fbound</strong>(<em>n</em>) be the minimum value for <strong>fbelow</strong>(<em>n</em>, <em>k</em>) and the maximum value for <strong>fabove</strong>(<em>n</em>,<em>k</em>) for any <em>k</em> in the interval [0, <em>n</em>]; then set <em>degree</em> to 1; then while <strong>fbound</strong>(<em>degree</em>) returns an upper or lower bound that is less than 0 or greater than 1, multiply <em>degree</em> by 2; then go to the next step.</li>
<li>Set <em>startdegree</em> to <em>degree</em>.</li>
<li>(The remaining steps are now done repeatedly until the algorithm finishes by returning a value.) Flip the input coin <em>t</em> times, where <em>t</em> is <em>degree</em> &minus; <em>lastdegree</em>.  For each time the coin returns 1 this way, add 1 to <em>ones</em>.</li>
<li>Calculate <em>&#x2113;</em> and <em>u</em> as follows:

<ol>
<li>Define <strong>FB</strong>(<em>a</em>, <em>b</em>) as follows: Let <em>c</em> be choose(<em>a</em>, <em>b</em>).  Calculate <strong>fbelow</strong>(<em>a</em>, <em>b</em>) as lower and upper bounds <em>LB</em> and <em>UB</em> that are accurate enough that floor(<em>LB</em>*<em>c</em>) = floor(<em>UB</em>*<em>c</em>), then return floor(<em>LB</em>*<em>c</em>).</li>
<li>Define <strong>FA</strong>(<em>a</em>, <em>b</em>) as follows: Let <em>c</em> be choose(<em>a</em>, <em>b</em>).  Calculate <strong>fabove</strong>(<em>a</em>, <em>b</em>) as lower and upper bounds <em>LB</em> and <em>UB</em> that are accurate enough that ceil(<em>LB</em>*<em>c</em>) = ceil(<em>UB</em>*<em>c</em>), then return ceil(<em>LB</em>*<em>c</em>).</li>
<li>Let <em>c</em> be choose(<em>degree</em>, <em>ones</em>).  Set <em>&#x2113;</em> to (<strong>FB</strong>(<em>degree</em>, <em>ones</em>))/<em>c</em> and set <em>u</em> to (<strong>FA</strong>(<em>degree</em>, <em>ones</em>))/<em>c</em>.</li>
</ol></li>
<li>(This step and the next find the expected values of the previous <em>&#x2113;</em> and <em>u</em> given the current coin flips.) If <em>degree</em> equals <em>startdegree</em>, set <em>&#x2113;s</em> to 0 and <em>us</em> to 1. (Algorithm I of Flegal and Herbei 2012 doesn&#39;t take this into account.)</li>
<li>If <em>degree</em> is greater than <em>startdegree</em>: Let <em>nh</em> be choose(<em>degree</em>, <em>ones</em>), and let <em>od</em> be <em>degree</em>/2.  Set <em>&#x2113;s</em> to &sum;<sub><em>j</em>=0,...,<em>ones</em></sub> <strong>FB</strong>(<em>od</em>,<em>j</em>)*choose(<em>degree</em>&minus;<em>od</em>, <em>ones</em>&minus;<em>j</em>)/<em>nh</em>, and set <em>us</em> to &sum;<sub><em>j</em>=0,...,<em>ones</em></sub> <strong>FA</strong>(<em>od</em>,<em>j</em>)*choose(<em>degree</em>&minus;<em>od</em>, <em>ones</em>&minus;<em>j</em>)/<em>nh</em>.</li>
<li>Let <em>m</em> be (<em>ut</em>&minus;<em>&#x2113;t</em>)/(<em>us</em>&minus;<em>&#x2113;s</em>).  Set <em>&#x2113;t</em> to <em>&#x2113;t</em>+(<em>&#x2113;</em>&minus;<em>&#x2113;s</em>)*<em>m</em>, and set <em>ut</em> to <em>ut</em>&minus;(<em>us</em>&minus;<em>u</em>)*<em>m</em>.</li>
<li>If <em>ret</em> is less than (or equal to) <em>&#x2113;t</em>, return 1.  If <em>ret</em> is less than <em>ut</em>, go to the next step.  If neither is the case, return 0.  (If <em>ret</em> is a uniform PSRN, these comparisons should be done via the <strong>URandLessThanReal algorithm</strong>, which is described in my <a href="https://peteroupc.github.io/exporand.html"><strong>article on PSRNs</strong></a>.)</li>
<li>(Find the next pair of polynomials and restart the loop.) Increase <em>degree</em> so that the next pair of polynomials has degree equal to a higher value of <em>degree</em> and gets closer to the target function (for example, multiply <em>degree</em> by 2).  Then, go to step 5.</li>
</ol>

<p>The second algorithm was given in Thomas and Blanchet (2012)[^11]; it assumes the same sequences of polynomials are available as in the previous algorithm.   An algorithm equivalent to that algorithm is given below.</p>

<ol>
<li>Set <em>ones</em> to 0, and set <em>lastdegree</em> to 0.</li>
<li>Set <em>degree</em> so that the first pair of polynomials has degree equal to <em>degree</em> and has coefficients all lying in [0, 1].  For example, this can be done as follows: Let <strong>fbound</strong>(<em>n</em>) be the minimum value for <strong>fbelow</strong>(<em>n</em>, <em>k</em>) and the maximum value for <strong>fabove</strong>(<em>n</em>,<em>k</em>) for any <em>k</em> in the interval [0, <em>n</em>]; then set <em>degree</em> to 1; then while <strong>fbound</strong>(<em>degree</em>) returns an upper or lower bound that is less than 0 or greater than 1, multiply <em>degree</em> by 2; then go to the next step.</li>
<li>Set <em>startdegree</em> to <em>degree</em>.</li>
<li>(The remaining steps are now done repeatedly until the algorithm finishes by returning a value.) Flip the input coin <em>t</em> times, where <em>t</em> is <em>degree</em> &minus; <em>lastdegree</em>.  For each time the coin returns 1 this way, add 1 to <em>ones</em>.</li>
<li>Set <em>c</em> to choose(<em>degree</em>, <em>ones</em>).  Optionally, multiply <em>c</em> by 2<sup><em>degree</em></sup> (see note 3 below).</li>
<li>Find <em>acount</em> and <em>bcount</em> as follows:

<ol>
<li>Calculate <strong>fbelow</strong>(<em>degree</em>, <em>ones</em>) as lower and upper bounds <em>LB</em> and <em>UB</em> that are accurate enough that floor(<em>LB</em>*<em>c</em>) = floor(<em>UB</em>*<em>c</em>).  Then set <em>a</em>[<em>degree</em>,<em>ones</em>] and <em>acount</em> to floor(<em>LB</em>*<em>c</em>).</li>
<li>Calculate 1&minus;<strong>fabove</strong>(<em>degree</em>, <em>ones</em>) as lower and upper bounds <em>LB</em> and <em>UB</em> that are accurate enough that floor(<em>LB</em>*<em>c</em>) = floor(<em>UB</em>*<em>c</em>).  Then set <em>b</em>[<em>degree</em>,<em>ones</em>] and <em>bcount</em> to floor(<em>LB</em>*<em>c</em>).</li>
<li>Subtract (<em>acount</em> + <em>bcount</em>) from <em>c</em>.</li>
</ol></li>
<li>If <em>degree</em> is greater than <em>startdegree</em>, then:

<ol>
<li>Let <em>diff</em> be <em>degree</em>&minus;<em>lastdegree</em>, let <em>u</em> be max(0, <em>ones</em>&minus;<em>lastdegree</em>),
and let <em>v</em> be min(<em>ones</em>, <em>diff</em>).  (The following substeps remove outcomes from <em>acount</em> and <em>bcount</em> that would have terminated the algorithm earlier.  The procedure differs from step (f) of section 3 of the paper, which appears to be incorrect, and the procedure was derived from the <a href="https://github.com/acthomasca/rberfac/blob/main/rberfac-public-2.R"><strong>supplemental source code</strong></a> uploaded by A. C. Thomas at my request.)</li>
<li>Set <em>g</em> to choose(<em>lastdegree</em>, <em>ones</em>&minus;<em>u</em>).  Set <em>h</em> to 1.  If <em>c</em> was multiplied as in step 5, multiply <em>h</em> by 2<sup><em>lastdegree</em></sup> (see note 3 below).</li>
<li>For each integer <em>k</em> in the interval [<em>u</em>, <em>v</em>]:

<ol>
<li>Set <em>d</em> to choose(<em>diff</em>, <em>k</em>).  Let <em>&omega;</em> be <em>ones</em>&minus;<em>k</em>.</li>
<li>If not already calculated: Calculate <strong>fbelow</strong>(<em>lastdegree</em>, <em>&omega;</em>) as lower and upper bounds <em>LB</em> and <em>UB</em> that are accurate enough that floor(<em>LB</em>*<em>g</em>*<em>h</em>) = floor(<em>UB</em>*<em>g</em>*<em>h</em>).  Then set <em>a</em>[<em>lastdegree</em>, <em>&omega;</em>] to floor(<em>LB</em>*<em>g</em>*<em>h</em>).</li>
<li>If not already calculated: Calculate 1&minus;<strong>fabove</strong>(<em>lastdegree</em>, <em>&omega;</em>) as lower and upper bounds <em>LB</em> and <em>UB</em> that are accurate enough that floor(<em>LB</em>*<em>g</em>*<em>h</em>) = floor(<em>UB</em>*<em>g</em>*<em>h</em>).  Then set <em>b</em>[<em>lastdegree</em>, <em>&omega;</em>] to floor(<em>LB</em>*<em>g</em>*<em>h</em>).</li>
<li>Subtract (<em>a</em>[<em>lastdegree</em>, <em>&omega;</em>]*<em>d</em>) from <em>acount</em>.</li>
<li>Subtract (<em>b</em>[<em>lastdegree</em>, <em>&omega;</em>]*<em>d</em>) from <em>bcount</em>.</li>
<li>Multiply <em>g</em> by <em>&omega;</em>, then divide <em>g</em> by (<em>lastdegree</em>+1&minus;<em>&omega;</em>). (Sets <em>g</em> to choose(<em>lastdegree</em>, (<em>ones</em>&minus;<em>k</em>)&minus;1).)</li>
</ol></li>
</ol></li>
<li>Choose 0, 1, or 2 with probability proportional to the following weights: [<em>acount</em>, <em>bcount</em>, <em>c</em>].</li>
<li>If the number chosen by the previous step is 0, return 1.  If the number chosen by that step is 1, return 0.</li>
<li>(Find the next pair of polynomials and restart the loop.) Set <em>lastdegree</em> to <em>degree</em>, then increase <em>degree</em> so that the next pair of polynomials has degree equal to a higher value of <em>degree</em> and gets closer to the target function (for example, multiply <em>degree</em> by 2).  Then, go to step 4.</li>
</ol>

<blockquote>
<p><strong>Notes:</strong></p>

<ol>
<li>The efficiency of these two algorithms depends on many things, including how &quot;smooth&quot; <em>f</em> is and how easy it is to calculate the appropriate values for <strong>fbelow</strong> and <strong>fabove</strong>.  The best way to implement <strong>fbelow</strong> and <strong>fabove</strong> for a given function <em>f</em> will require a deep mathematical analysis of that function.  For more information, see my <a href="https://peteroupc.github.io/bernsupp.html"><strong>Supplemental Notes on Bernoulli Factories</strong></a>.</li>
<li>In some cases, a single pair of polynomial sequences may not converge quickly to the desired function <em>f</em>, especially when <em>f</em> is not &quot;smooth&quot; enough.  An intriguing suggestion from Thomas and Blanchet (2012)[^11] is to use multiple pairs of polynomial sequences that converge to <em>f</em>, where each pair is optimized for particular ranges of <em>&lambda;</em>: first flip the input coin several times to get a rough estimate of <em>&lambda;</em>, then choose the pair that&#39;s optimized for the estimated <em>&lambda;</em>, and run either algorithm in this section on that pair.</li>
<li>The second algorithm, as presented in Thomas and Blanchet (2012)[^11], was based on the one from Nacu and Peres (2005)[^16].  In both papers, the algorithm works only if <em>&lambda;</em> is in the interval (0, 1).  If <em>&lambda;</em> can be 0 or 1 (meaning the input coin is allowed to return 1 every time or 0 every time), then based on a suggestion in Holtz et al. (2011)[^26], the <em>c</em> in step 5 can be multiplied by 2<sup><em>degree</em></sup> and the <em>h</em> in step 7, substep 2, multiplied by 2<sup><em>lastdegree</em></sup> to ensure correctness for every value of <em>&lambda;</em>.</li>
</ol>
</blockquote>

<p><a id=Algorithms_for_General_Irrational_Constants></a></p>

<h3>Algorithms for General Irrational Constants</h3>

<p>This section shows general-purpose algorithms to generate heads with a probability equal to an <em>irrational number</em> (a number that isn&#39;t a ratio of two integers), when that number is known by its digit or series expansion, continued fraction, or continued logarithm.</p>

<p>But on the other hand, probabilities that are <em>rational</em> constants are trivial to simulate.  If fair coins are available, the <code>ZeroOrOne</code> method, which is described in my article on <a href="https://peteroupc.github.io/randomfunc.html#Boolean_True_False_Conditions"><strong>random sampling methods</strong></a>, should be used.  If coins with unknown probability of heads are available, then a <a href="https://peteroupc.github.io/randextract.html"><strong><em>randomness extraction</em></strong></a> method should be used to turn them into fair coins.</p>

<p><a id=Digit_Expansions></a></p>

<h4>Digit Expansions</h4>

<p>Probabilities can be expressed as a digit expansion (of the form <code>0.dddddd...</code>).  The following algorithm returns 1 with probability <code>p</code> and 0 otherwise, where <code>p</code> is a probability in the half-open interval [0, 1).  (The number 0 is also an infinite digit expansion of zeros, and the number 1 is also an infinite digit expansion of base-minus-ones.)  Irrational numbers always have infinite digit expansions, which must be calculated &quot;on-the-fly&quot;.</p>

<p>In the algorithm (see also (Brassard et al., 2019)[^27], (Devroye 1986, p. 769)[^28]), <code>BASE</code> is the digit base, such as 2 for binary or 10 for decimal.</p>

<ol>
<li>Set <code>u</code> to 0 and <code>k</code> to 1.</li>
<li>Set <code>u</code> to <code>(u * BASE) + v</code>, where <code>v</code> is a uniform random integer in the interval [0, <code>BASE</code>) (if <code>BASE</code> is 2, then <code>v</code> is simply an unbiased random bit).  Calculate <code>pa</code>, which is an approximation to <code>p</code> such that abs(<code>p</code>&minus;<code>pa</code>) &le; <code>BASE</code><sup>&minus;<code>k</code></sup>.  Set <code>pk</code> to <code>pa</code>&#39;s digit expansion up to the <code>k</code> digits after the point.  Example: If <code>p</code> is <em>&pi;</em>/4, <code>BASE</code> is 10, and <code>k</code> is 5, then <code>pk = 78539</code>.</li>
<li>If <code>pk + 1 &lt;= u</code>, return 0.  If <code>pk - 2 &gt;= u</code>, return 1.  If neither is the case, add 1 to <code>k</code> and go to step 2.</li>
</ol>

<p><a id=Continued_Fractions></a></p>

<h4>Continued Fractions</h4>

<p>The following algorithm simulates a probability expressed as a simple continued fraction of the following form: 0 + 1 / (<em>a</em>[1] + 1 / (<em>a</em>[2] + 1 / (<em>a</em>[3] + ... ))).  The <em>a</em>[<em>i</em>] are the <em>partial denominators</em>, none of which may have an absolute value less than 1.  Inspired by (Flajolet et al., 2010, &quot;Finite graphs (Markov chains) and rational functions&quot;)[^1], I developed the following algorithm.</p>

<p><strong>Algorithm 1.</strong> This algorithm works only if each <em>a</em>[<em>i</em>]&#39;s absolute value is 1 or greater and <em>a</em>[1] is greater than 0, but otherwise, each  <em>a</em>[<em>i</em>] may be negative and/or a non-integer.  The algorithm begins with <em>pos</em> equal to 1.  Then the following steps are taken.</p>

<ol>
<li>Set <em>k</em> to <em>a</em>[<em>pos</em>].</li>
<li>If the partial denominator at <em>pos</em> is the last, return a number that is 1 with probability 1/<em>k</em> and 0 otherwise.</li>
<li>If <em>a</em>[<em>pos</em>] is less than 0, set <em>kp</em> to <em>k</em> &minus; 1 and <em>s</em> to 0.  Otherwise, set <em>kp</em> to <em>k</em> and <em>s</em> to 1. (This step accounts for negative partial denominators.)</li>
<li>Do the following process repeatedly until this run of the algorithm returns a value:

<ol>
<li>With probability <em>kp</em>/(1+<em>kp</em>), return a number that is 1 with probability 1/<em>kp</em> and 0 otherwise.</li>
<li>Do a separate run of the currently running algorithm, but with <em>pos</em> = <em>pos</em> + 1.  If the separate run returns <em>s</em>, return 0.</li>
</ol></li>
</ol>

<p><strong>Algorithm 2.</strong></p>

<p>A <em>generalized continued fraction</em> has the form 0 + <em>b</em>[1] / (<em>a</em>[1] + <em>b</em>[2] / (<em>a</em>[2] + <em>b</em>[3] / (<em>a</em>[3] + ... ))).  The <em>a</em>[<em>i</em>] are the same as before, but the <em>b</em>[<em>i</em>] are the <em>partial numerators</em>. The following are two algorithms to simulate a probability in the form of a generalized continued fraction.</p>

<p>The following algorithm works only if each ratio <em>b</em>[<em>i</em>]/<em>a</em>[<em>i</em>] has an absolute value of 1 or less, but otherwise, each <em>b</em>[<em>i</em>] and each  <em>a</em>[<em>i</em>] may be negative and/or a non-integer.  This algorithm employs an equivalence transform from generalized to simple continued fractions.  The algorithm begins with <em>pos</em> and <em>r</em> both equal to 1.  Then the following steps are taken.</p>

<ol>
<li>Set <em>r</em> to 1 / (<em>r</em> * <em>b</em>[<em>pos</em>]), then set <em>k</em> to <em>a</em>[<em>pos</em>] * <em>r</em>. (<em>k</em> is the partial denominator for the equivalent simple continued fraction.)</li>
<li>If the partial numerator/denominator pair at <em>pos</em> is the last, return a number that is 1 with probability 1/abs(<em>k</em>) and 0 otherwise.</li>
<li>Set <em>kp</em> to abs(<em>k</em>) and <em>s</em> to 1.</li>
<li>Set <em>r2</em> to 1 / (<em>r</em> * <em>b</em>[<em>pos</em> + 1]).  If <em>a</em>[<em>pos</em> + 1] * <em>r2</em> is less than 0, set <em>kp</em> to <em>kp</em> &minus; 1 and <em>s</em> to 0. (This step accounts for negative partial numerators and denominators.)</li>
<li>Do the following process repeatedly until this run of the algorithm returns a value:

<ol>
<li>With probability <em>kp</em>/(1+<em>kp</em>), return a number that is 1 with probability 1/<em>kp</em> and 0 otherwise.</li>
<li>Do a separate run of the currently running algorithm, but with <em>pos</em> = <em>pos</em> + 1 and <em>r</em> = <em>r</em>.  If the separate run returns <em>s</em>, return 0.</li>
</ol></li>
</ol>

<p><strong>Algorithm 3.</strong> This algorithm works only if each ratio <em>b</em>[<em>i</em>]/<em>a</em>[<em>i</em>] is 1 or less and if each <em>b</em>[<em>i</em>] and each  <em>a</em>[<em>i</em>] is greater than 0, but otherwise, each <em>b</em>[<em>i</em>] and each <em>a</em>[<em>i</em>] may be a non-integer.  The algorithm begins with <em>pos</em> equal to 1.  Then the following steps are taken.</p>

<ol>
<li>If the partial numerator/denominator pair at <em>pos</em> is the last, return a number that is 1 with probability <em>b</em>[<em>pos</em>]/<em>a</em>[<em>pos</em>] and 0 otherwise.</li>
<li>Do the following process repeatedly until this run of the algorithm returns a value:

<ol>
<li>With probability <em>a</em>[<em>pos</em>]/(1 + <em>a</em>[<em>pos</em>]), return a number that is 1 with probability <em>b</em>[<em>pos</em>]/<em>a</em>[<em>pos</em>] and 0 otherwise.</li>
<li>Do a separate run of the currently running algorithm, but with <em>pos</em> = <em>pos</em> + 1.  If the separate run returns 1, return 0.</li>
</ol></li>
</ol>

<p>See the appendix for a correctness proof of Algorithm 3.</p>

<blockquote>
<p><strong>Notes:</strong></p>

<ul>
<li><p>If any of these algorithms encounters a probability outside the interval [0, 1], the entire algorithm will fail for that continued fraction.</p></li>
<li><p>These algorithms will work for continued fractions of the form &quot;1 &minus; ...&quot; (rather than &quot;0 + ...&quot;) if&mdash;</p>

<ul>
<li>before running the algorithm, the first partial numerator and denominator have their sign removed, and</li>
<li>after running the algorithm, 1 minus the result (rather than just the result) is taken.</li>
</ul></li>
<li><p>These algorithms are designed to allow the partial numerators and denominators to be calculated &quot;on the fly&quot;.</p></li>
<li>The following is an alternative way to write Algorithm 1, which better shows the inspiration because it shows how the &quot;even parity construction&quot; (or the two-coin algorithm) as well as the &quot;1 &minus; <em>x</em>&quot; construction can be used to develop rational number simulators that are as big as their continued fraction expansions, as suggested in the cited part of the Flajolet paper.  However, it only works if the size of the continued fraction expansion (here, <em>size</em>) is known in advance.

<ol>
<li>Set <em>i</em> to <em>size</em>.</li>
<li>Create an input coin that does the following: &quot;Return a number that is 1 with probability 1/<em>a</em>[<em>size</em>] or 0 otherwise&quot;.</li>
<li>While <em>i</em> is 1 or greater:

<ol>
<li>Set <em>k</em> to <em>a</em>[<em>i</em>].</li>
<li>Create an input coin that takes the previous input coin and <em>k</em> and does the following: &quot;(a) With probability <em>k</em>/(1+<em>k</em>), return a number that is 1 with probability 1/<em>k</em> and 0 otherwise; (b) Flip the previous input coin.  If the result is 1, return 0.  Otherwise, go to step (a)&quot;.  (The probability <em>k</em>/(1+<em>k</em>) is related to <em>&lambda;</em>/(1+<em>&lambda;</em>) = 1 &minus; 1/(1+<em>&lambda;</em>), which involves the even-parity construction&mdash;or the two-coin algorithm&mdash;for 1/(1+<em>&lambda;</em>) as well as complementation for &quot;1 &minus; <em>x</em>&quot;.)</li>
<li>Subtract 1 from <em>i</em>.</li>
</ol></li>
<li>Flip the last input coin created by this algorithm, and return the result.</li>
</ol></li>
</ul>
</blockquote>

<p><a id=Continued_Logarithms></a></p>

<h4>Continued Logarithms</h4>

<p>The <em>continued logarithm</em> (Gosper 1978)[^29], (Borwein et al., 2016)[^30] of a number in the open interval (0, 1) has the following continued fraction form: 0 + (1 / 2<sup><em>c</em>[1]</sup>) / (1 + (1 / 2<sup><em>c</em>[2]</sup>) / (1 + ...)), where <em>c</em>[<em>i</em>] are the coefficients of the continued logarithm and all 0 or greater.  I have come up with the following algorithm that simulates a probability expressed as a continued logarithm expansion.</p>

<p>The algorithm begins with <em>pos</em> equal to 1.  Then the following steps are taken.</p>

<ol>
<li>If the coefficient at <em>pos</em> is the last, return a number that is 1 with probability 1/(2<sup><em>c</em>[<em>pos</em>]</sup>) and 0 otherwise.</li>
<li>Do the following process repeatedly until this run of the algorithm returns a value:

<ol>
<li>Generate an unbiased random bit.  If that bit is 1 (which happens with probability 1/2), return a number that is 1 with probability 1/(2<sup><em>c</em>[<em>pos</em>]</sup>) and 0 otherwise.</li>
<li>Do a separate run of the currently running algorithm, but with <em>pos</em> = <em>pos</em> + 1.  If the separate run returns 1, return 0.</li>
</ol></li>
</ol>

<p>For a correctness proof, see the appendix.</p>

<p><a id=Certain_Algebraic_Numbers></a></p>

<h4>Certain Algebraic Numbers</h4>

<p>A method to sample a probability equal to a polynomial&#39;s root appears in a French-language article by Penaud and Roques (2002)[^31].  The following is an implementation of that method, using the discussion in the paper&#39;s section 1 and Algorithm 2, and incorporates a correction to Algorithm 2.  The algorithm takes a polynomial as follows:</p>

<ul>
<li>It has the form <em>P</em>(<em>x</em>) = <em>a</em>[0]*<em>x</em><sup>0</sup> + <em>a</em>[1]*<em>x</em><sup>1</sup> + ... + <em>a</em>[<em>n</em>]*<em>x</em><sup><em>n</em></sup>, where <em>a</em>[<em>i</em>], the <em>coefficients</em>, are all rational numbers.</li>
<li>It equals 0 (has a <em>root</em>) at exactly one point on [0, 1].</li>
</ul>

<p>And the algorithm returns 1 with probability equal to the root, and 0 otherwise.  The root <em>R</em> is known as an <em>algebraic number</em> because it satisfies the polynomial equation <em>P</em>(<em>R</em>) = 0.  The algorithm follows.</p>

<ol>
<li>Set <em>r</em> to 0 and <em>d</em> to 2.</li>
<li>Do the following process repeatedly, until this algorithm returns a value:

<ol>
<li>Generate an unbiased random bit, call it <em>z</em>.</li>
<li>Set <em>t</em> to (<em>r</em>*2+1)/<em>d</em>.</li>
<li>If <em>P</em>(0) &gt; 0:

<ol>
<li>If <em>z</em> is 1 and <em>P</em>(<em>t</em>) is less than 0, return 0.</li>
<li>If <em>z</em> is 0 and <em>P</em>(<em>t</em>) is greater than 0, return 1.</li>
</ol></li>
<li>If <em>P</em>(0) &lt; 0:

<ol>
<li>If <em>z</em> is 1 and <em>P</em>(<em>t</em>) is greater than 0, return 0.</li>
<li>If <em>z</em> is 0 and <em>P</em>(<em>t</em>) is less than 0, return 1.</li>
</ol></li>
<li>Set <em>r</em> to <em>r</em>*2+<em>z</em>, then multiply <em>d</em> by 2.</li>
</ol></li>
</ol>

<blockquote>
<p><strong>Example</strong> (Penaud and Roques 2002)[^31]:  Let <em>P</em>(<em>x</em>) = 1 &minus; <em>x</em> &minus; <em>x</em><sup>2</sup>.  This is a polynomial whose only root on [0, 1] is 2/(1+sqrt(5)), that is, 1 divided by the golden ratio or 1/<em>&phi;</em> or about 0.618, and <em>P</em>(0) &gt; 0.  Then given <em>P</em>, the algorithm above samples the probability 1/<em>&phi;</em> exactly.</p>
</blockquote>

<p><a id=Certain_Converging_Series></a></p>

<h4>Certain Converging Series</h4>

<p>A general-purpose algorithm was given by Mendo (2020)[^32] that can simulate any probability in the open interval (0, 1), as long as it can be rewritten as a series&mdash;</p>

<ul>
<li>that has the form <em>a</em>[0] + <em>a</em>[1] + ..., where <em>a</em>[<em>n</em>] are all rational numbers greater than 0 and sum to <em>p</em> (in other words, the series <em>converges</em> to <em>p</em>)</li>
<li>for which a sequence <em>err</em>[0], <em>err</em>[1], ... is available that is nonincreasing and has a limit of 0 (<em>converges</em> to 0), where <em>err</em>[<em>n</em>] is an upper bound on the error from truncating the series <em>a</em> after summing the first <em>n</em>+1 terms.</li>
</ul>

<p>The algorithm follows.</p>

<ol>
<li>Set <em>&#x03F5;</em> to 1, then set <em>n</em>, <em>lamunq</em>, <em>lam</em>, <em>s</em>, and <em>k</em> to 0 each.</li>
<li>Add 1 to <em>k</em>, then add <em>s</em>/(2<sup><em>k</em></sup>) to <em>lam</em>.</li>
<li>If <em>lamunq</em>+<em>&#x03F5;</em> &le; <em>lam</em> + 1/(2<sup><em>k</em></sup>), go to step 8.</li>
<li>If <em>lamunq</em> &gt; <em>lam</em> + 1/(2<sup><em>k</em></sup>), go to step 8.</li>
<li>If <em>lamunq</em> &gt; <em>lam</em> + 1/(2<sup><em>k</em>+1</sup>) and <em>lamunq</em>+<em>&#x03F5;</em> &lt; 3/(2<sup><em>k</em>+1</sup>), go to step 8.</li>
<li>Add <em>a</em>[<em>n</em>] to <em>lamunq</em> and set <em>&#x03F5;</em> to <em>err</em>[<em>n</em>].</li>
<li>Add 1 to <em>n</em>, then go to step 3.</li>
<li>Let <em>bound</em> be <em>lam</em>+1/(2<sup><em>k</em></sup>).  If <em>lamunq</em>+<em>&#x03F5;</em> &le; <em>bound</em>, set <em>s</em> to 0.  Otherwise, if <em>lamunq</em> &gt; <em>bound</em>, set <em>s</em> to 2.  Otherwise, set <em>s</em> to 1.</li>
<li>Generate an unbiased random bit.  If that bit is 1 (which happens with probability 1/2), go to step 2.  Otherwise, return a number that is 0 if <em>s</em> is 0, 1 if <em>s</em> is 2, or an unbiased random bit (either 0 or 1 with equal probability) otherwise.</li>
</ol>

<p>If <em>a</em>, given above, is instead a sequence that converges to the <em>base-2 logarithm</em> of a probability in the open interval (0, 1), the following algorithm I developed simulates that probability.  For simplicity&#39;s sake, even though logarithms for such probabilities are negative, all the <em>a</em>[<em>i</em>] must be 0 or greater (and thus are the negated values of the already negative logarithm approximations) and must form a nondecreasing sequence, and all the <em>err</em>[<em>i</em>] must be 0 or greater.</p>

<ol>
<li>Set <em>intinf</em> to floor(max(0, abs(<em>a</em>[0]))).  (This is the absolute integer part of the first term in the series, or 0, whichever is greater.)</li>
<li>If <em>intinf</em> is greater than 0, generate unbiased random bits until a zero bit or <em>intinf</em> bits were generated this way.  If a zero was generated this way, return 0.</li>
<li>Generate an exponential random variate <em>E</em> with rate ln(2).  This can be done, for example, by using the algorithm given in &quot;<a href="https://peteroupc.github.io/morealg.html"><strong>More Algorithms for Arbitrary-Precision Sampling</strong></a>&quot;. (We take advantage of the exponential distribution&#39;s <em>memoryless property</em>: given that an exponential random variate <em>E</em> is greater than <em>intinf</em>, <em>E</em> minus <em>intinf</em> has the same distribution.)</li>
<li>Set <em>n</em> to 0.</li>
<li>Do the following process repeatedly until the algorithm returns a value:

<ol>
<li>Set <em>inf</em> to max(0, <em>a</em>[<em>n</em>]), then set <em>sup</em> to min(0, <em>inf</em>+<em>err</em>[<em>n</em>]).</li>
<li>If <em>E</em> is less than <em>inf</em>+<em>intinf</em>, return 0.  If <em>E</em> is less than <em>sup</em>+<em>intinf</em>, go to the next step.  If neither is the case, return 1.</li>
<li>Set <em>n</em> to 1.</li>
</ol></li>
</ol>

<p>The case when the sequence <em>a</em> converges to a <em>natural logarithm</em> rather than a base-2 logarithm is trivial by comparison.  Again for this algorithm, all the <em>a</em>[<em>i</em>] must be 0 or greater and form a nondecreasing sequence, and all the <em>err</em>[<em>i</em>] must be 0 or greater.</p>

<ol>
<li>Generate an exponential random variate <em>E</em> (with rate 1).</li>
<li>Set <em>n</em> to 0.</li>
<li>Do the following process repeatedly until the algorithm returns a value:

<ol>
<li>Set <em>inf</em> to max(0, <em>a</em>[<em>n</em>]), then set <em>sup</em> to min(0, <em>inf</em>+<em>err</em>[<em>n</em>]).</li>
<li>If <em>E</em> is less than <em>inf</em>+<em>intinf</em>, return 0.  If <em>E</em> is less than <em>sup</em>+<em>intinf</em>, go to the next step.  If  neither is the case, return 1.</li>
<li>Set <em>n</em> to 1.</li>
</ol></li>
</ol>

<blockquote>
<p><strong>Examples</strong>:</p>

<ul>
<li>Let <em>f</em>(<em>&lambda;</em>) = cosh(1)&minus;1.  This function can be rewritten as a series required by the first algorithm in this section, namely <em>f</em>&#39;s <em>Taylor series</em> at 0.  That algorithm can simulate this constant if step 6 is modified to read: &quot;Let <em>m</em> be ((<em>n</em>+1)*2), and let <em>&alpha;</em> be 1/(<em>m</em>!) (a term of the series).  Add <em>&alpha;</em> to <em>lamunq</em> and set <em>&#x03F5;</em> to 2/((<em>m</em>+1)!) (the error term).&quot;.[^33]</li>
<li>Logarithms can form the basis of efficient algorithms to simulate the probability <em>z</em> = choose(<em>n</em>, <em>k</em>)/2<sup><em>n</em></sup> when <em>n</em> can be very large (e.g., as large as 2<sup>30</sup>), without relying on floating-point arithmetic.  In this example, the trivial algorithm for choose(<em>n</em>, <em>k</em>), the binomial coefficient, will generally require a growing amount of storage that depends on <em>n</em> and <em>k</em>. On the other hand, any constant can be simulated using up to two unbiased random bits on average, and even slightly less than that for the constants at hand here (Kozen 2014)[^34].  Instead of calculating the binomial coefficient directly, a series can be calculated that sums to that coefficient&#39;s logarithm, such as ln(choose(<em>n</em>, <em>k</em>)), which is economical in space even for large <em>n</em> and <em>k</em>.  Then the algorithm above can be used with that series to simulate the probability <em>z</em>.  A similar approach has been implemented (see <a href="https://github.com/peteroupc/peteroupc.github.io/blob/master/interval.py#L694"><strong>interval.py</strong></a> and <a href="https://github.com/peteroupc/peteroupc.github.io/blob/master/betadist.py#L700"><strong>betadist.py</strong></a>).  See also an appendix in (Bringmann et al. 2014)[^35].</li>
</ul>
</blockquote>

<p><a id=Other_General_Algorithms></a></p>

<h3>Other General Algorithms</h3>

<p>&nbsp;</p>

<p><a id=Convex_Combinations></a></p>

<h4>Convex Combinations</h4>

<p>Assume we have one or more input coins <em>h</em><sub><em>i</em></sub>(<em>&lambda;</em>) that return heads with a probability that depends on <em>&lambda;</em>.  (The number of coins may be infinite.) The following algorithm chooses one of these coins at random then flips that coin.  Specifically, the algorithm generates 1 with probability equal to the following weighted sum: <em>g</em>(0) * <em>h</em><sub>0</sub>(<em>&lambda;</em>) + <em>g</em>(1) * <em>h</em><sub>1</sub>(<em>&lambda;</em>) + ..., where <em>g</em>(<em>i</em>) is the probability that coin <em>i</em> will be chosen, <em>h</em><sub><em>i</em></sub> is the function simulated by coin <em>i</em>, and all the <em>g</em>(<em>i</em>) sum to 1.  See (Wästlund 1999, Theorem 2.7)[^8].  (Alternatively, the algorithm can be seen as returning heads with probability <strong>E</strong>[<em>h</em><sub><em>X</em></sub>(<em>&lambda;</em>)], that is, the expected or average value of <em>h</em><sub><em>X</em></sub> where <em>X</em> is the number that identifies the randomly chosen coin.)</p>

<ol>
<li>Generate a random integer <em>X</em> in some way.  For example, it could be a uniform random integer in [1, 6], or it could be a Poisson random variate.  (Specifically, the number <em>X</em> is generated with probability <em>g</em>(<em>X</em>).)</li>
<li>Flip the coin represented by <em>X</em> and return the result.</li>
</ol>

<blockquote>
<p><strong>Notes:</strong></p>

<ol>
<li><p><strong>Building convex combinations.</strong> Assume we have a function of the form <em>f</em>(<em>&lambda;</em>) = &sum;<sub><em>n</em>=0,1,...</sub> <em>w</em><sub><em>n</em></sub>(<em>&lambda;</em>), where <em>w</em><sub><em>n</em></sub> are continuous functions whose maximum values in the domain [0, 1] sum to 1 or less.  Let <em>g</em>(<em>n</em>) be the probability that a randomly chosen number <em>X</em> is <em>n</em>.  Then by <strong>generating <em>X</em> and flipping a coin with probability of heads of <em>w</em><sub><em>X</em></sub>(<em>&lambda;</em>)/<em>g</em>(<em>X</em>)</strong>, we can simulate the probability <em>f</em>(<em>&lambda;</em>) as the convex combination&mdash;<br><br><em>f</em>(<em>&lambda;</em>) = &sum;<sub><em>n</em>=0,1,...</sub> <em>g</em>(<em>n</em>) * (<em>w</em><sub><em>n</em></sub>(<em>&lambda;</em>) / <em>g</em>(<em>n</em>)),<br><br>but this works only if the following two conditions are met for each integer <em>n</em>&ge;0:</p>

<ul>
<li><em>g</em>(<em>n</em>) &ge; <em>w</em><sub><em>n</em></sub>(<em>&lambda;</em>) &ge; 0 for every <em>&lambda;</em> in the interval [0, 1] (which roughly means that <em>w</em><sub><em>n</em></sub> is bounded from above or &quot;dominated&quot; by <em>g</em>(<em>n</em>)).</li>
<li>The function <em>w</em><sub><em>n</em></sub>(<em>&lambda;</em>)/<em>g</em>(<em>n</em>) admits a Bernoulli factory (which it won&#39;t if it touches 0 or 1 inside the interval (0, 1), but isn&#39;t constant, for example).</li>
</ul>

<p>See also Mendo (2019)[^23].</p></li>
<li><p><strong>Constants with non-negative series expansions.</strong> A special case of note 1.  Let <em>g</em> be as in note 1.  Assume we have a constant with the following series expansion: <em>c</em> = <em>a</em><sub>0</sub> + <em>a</em><sub>1</sub> + <em>a</em><sub>2</sub> + ..., where&mdash;</p>

<ul>
<li><em>a</em><sub><em>n</em></sub> are each 0 or greater and sum to 1 or less, and</li>
<li><em>g</em>(<em>n</em>) &ge; <em>a</em><sub><em>n</em></sub> &ge; 0 for each integer <em>n</em>&ge;0.</li>
</ul>

<p>Then by <strong>generating <em>X</em> and flipping a coin with probability of heads of <em>a</em><sub><em>X</em></sub>/<em>g</em>(<em>X</em>)</strong>, we can simulate the probability  <em>c</em> as the convex combination&mdash;<br><br><em>c</em> = &sum;<sub><em>n</em>=0,1,...</sub> <em>g</em>(<em>n</em>) * (<em>a</em><sub><em>n</em></sub> / <em>g</em>(<em>n</em>)).</p></li>
</ol>

<p><strong>Examples:</strong></p>

<ol>
<li>Generate <em>X</em>, a Poisson random variate with mean <em>&mu;</em>, then flip the input coin.  With probability 1/(1+<em>X</em>), return the result of the coin flip; otherwise, return 0.  This corresponds to <em>g</em>(<em>i</em>) being the Poisson probabilities and the coin for <em>h</em><sub><em>i</em></sub> returning 1 with probability 1/(1+<em>i</em>), and 0 otherwise.  The probability that this method returns 1 is <strong>E</strong>[1/(1+<em>X</em>)], or (exp(<em>&mu;</em>)&minus;1)/(exp(<em>&mu;</em>)*<em>&mu;</em>).</li>
<li>Generate <em>X</em>, a Poisson random variate with mean <em>&mu;</em>, and return 1 if <em>X</em> is 0, or 0 otherwise.  This is a Bernoulli factory for exp(&minus;<em>&mu;</em>) mentioned earlier, and corresponds to <em>g</em>(<em>i</em>) being the Poisson probabilities and the coin for <em>h</em><sub><em>i</em></sub> returning 1 if <em>i</em> is 0, and 0 otherwise.</li>
<li>Generate <em>X</em>, a Poisson random variate with mean <em>&mu;</em>, run the <strong>algorithm for exp(&minus;<em>z</em>)</strong> with <em>z</em> = <em>X</em>, and return the result.  The probability of returning 1 this way is <strong>E</strong>[exp(&minus;<em>X</em>)], or exp(<em>&mu;</em>*exp(&minus;1)&minus;<em>&mu;</em>).  The following Python code uses the computer algebra library SymPy to find this probability: <code>from sympy.stats import *; E(exp(-Poisson(&#39;P&#39;, x))).simplify()</code>.</li>
<li><em>Bernoulli Race</em> (Dughmi et al. 2017)[^36]: Say we have <em>n</em> coins, then choose one of them uniformly at random and flip that coin. If the flip returns 1, return <em>X</em>; otherwise, repeat this algorithm.  This algorithm chooses a random coin based on its probability of heads.  Each iteration corresponds to <em>g</em>(<em>i</em>) being 1/<em>n</em> and <em>h</em><sub><em>i</em></sub>() being the probability for the corresponding coin <em>i</em>.</li>
<li>(Wästlund 1999)[^8]: Generate a Poisson random variate <em>X</em> with mean 1, then flip the input coin <em>X</em> times.  Return 0 if any of the flips returns 1, or 1 otherwise.  This is a Bernoulli factory for exp(&minus;<em>&lambda;</em>), and corresponds to <em>g</em>(<em>i</em>) being the Poisson probabilities, namely 1/(<em>i</em>!*exp(1)), and <em>h</em><sub><em>i</em></sub>() being (1&minus;<em>&lambda;</em>)<sup><em>i</em></sup>.</li>
<li>Multivariate Bernoulli factory (Huber 2016)[^37] of the form <em>R</em> = <em>C</em><sub>0</sub>*<em>&lambda;</em><sub>0</sub> + <em>C</em><sub>1</sub>*<em>&lambda;</em><sub>1</sub> + ... + <em>C</em><sub><em>m</em>&minus;1</sub>*<em>&lambda;</em><sub><em>m</em>&minus;1</sub>, where <em>C</em><sub><em>i</em></sub> are known constants greater than 0, and <em>R</em> &le; 1 &minus; <em>&#x03F5;</em> for any <em>&#x03F5;</em> &gt; 0: Choose an integer in [0, <em>m</em>) uniformly at random, call it <em>i</em>, then run a linear Bernoulli factory for (<em>m</em>*<em>C</em><sub><em>i</em></sub>)*<em>&lambda;</em><sub><em>i</em></sub>.  This differs from Huber&#39;s suggestion of &quot;thinning&quot; a Poisson process driven by multiple input coins.</li>
<li><strong>Probability generating function</strong> (PGF) (Dughmi et al. 2017)[^36]. Generates heads with probability <strong>E</strong>[<em>&lambda;</em><sup><em>X</em></sup>], that is, the expected or average value of <em>&lambda;</em><sup><em>X</em></sup>.  <strong>E</strong>[<em>&lambda;</em><sup><em>X</em></sup>] is the PGF for the distribution of <em>X</em>.  The algorithm follows: (1) Generate a random integer <em>X</em> in some way; (2) Flip the input coin until the flip returns 0 or the coin is flipped <em>X</em> times, whichever comes first.  Return 1 if all the coin flips, including the last, returned 1 (or if <em>X</em> is 0); or return 0 otherwise.</li>
<li>Assume <em>X</em> is the number of unbiased random bits that show 0 before the first 1 is generated.  Then <em>g</em>(<em>n</em>) = 1/(2<sup><em>n</em>+1</sup>).</li>
</ol>
</blockquote>

<p><a id=Integrals></a></p>

<h4>Integrals</h4>

<p>Roughly speaking, the <em>integral</em> of <em>f</em>(<em>x</em>) on an interval [<em>a</em>, <em>b</em>] is the area under that function&#39;s graph when the function is restricted to that interval.</p>

<p><strong>Algorithm 1.</strong> (Flajolet et al., 2010)[^1] showed how to turn an algorithm that simulates <em>f</em>(<em>&lambda;</em>) into an algorithm that simulates the probability&mdash;</p>

<ul>
<li>(1/<em>&lambda;</em>) * &int;<sub>[0, <em>&lambda;</em>]</sub> <em>f</em>(<em>u</em>) <em>du</em>, or equivalently,</li>
<li>&int;<sub>[0, 1]</sub> <em>f</em>(<em>u</em> * <em>&lambda;</em>) <em>du</em> (an integral),</li>
</ul>

<p>namely the following algorithm:</p>

<ol>
<li>Generate a uniform(0, 1) random variate <em>u</em>.</li>
<li>Create an input coin that does the following: &quot;Flip the original input coin, then <a href="#Implementation_Notes"><strong>sample from the number <em>u</em></strong></a>.  Return 1 if both the call and the flip return 1, and return 0 otherwise.&quot;</li>
<li>Run the original Bernoulli factory algorithm, using the input coin described in step 2 rather than the original input coin.  Return the result of that run.</li>
</ol>

<p><strong>Algorithm 2.</strong> A special case of Algorithm 1 is the integral &int;<sub>[0, 1]</sub> <em>f</em>(<em>u</em>) <em>du</em>, when the original input coin always returns 1:</p>

<ol>
<li>Generate a uniform(0, 1) random variate <em>u</em>.</li>
<li>Create an input coin that does the following: &quot;<a href="#Implementation_Notes"><strong>Sample from the number <em>u</em></strong></a> and return the result.&quot;</li>
<li>Run the original Bernoulli factory algorithm, using the input coin described in step 2 rather than the original input coin.  Return the result of that run.</li>
</ol>

<p><strong>Algorithm 3.</strong> I have found that it&#39;s possible to simulate the following integral, namely&mdash;</p>

<ul>
<li>&int;<sub>[<em>a</em>, <em>b</em>]</sub> <em>f</em>(<em>u</em>) <em>du</em>,</li>
</ul>

<p>where [<em>a</em>, <em>b</em>] is [0, 1] or a closed interval therein, using the following algorithm:</p>

<ol>
<li>Generate a uniform(0, 1) random variate <em>u</em>.  Then if <em>u</em> is less than <em>a</em> or is greater than <em>b</em>, repeat this step. (If <em>u</em> is a uniform PSRN, these comparisons should be done via the <strong>URandLessThanReal</strong> algorithm.)</li>
<li>Create an input coin that does the following: &quot;<a href="#Implementation_Notes"><strong>Sample from the number <em>u</em></strong></a> and return the result.&quot;</li>
<li>Run the original Bernoulli factory algorithm, using the input coin described in step 2.  If the run returns 0, return 0.  Otherwise, generate a uniform(0, 1) random variate <em>v</em> and return a number that is 0 if <em>v</em> is less than <em>a</em> or is greater than <em>b</em>, or 1 otherwise.</li>
</ol>

<blockquote>
<p><strong>Note</strong>: If <em>a</em> is 0 and <em>b</em> is 1, the probability simulated by this algorithm will be monotonically increasing (will keep going up), have a slope no greater than 1, and equal 0 at the point 0.</p>
</blockquote>

<p><a id=Generalized_Bernoulli_Race></a></p>

<h4>Generalized Bernoulli Race</h4>

<p>The Bernoulli factory approach, which simulates a coin with unknown heads probability, leads to an algorithm to roll an <em>n</em>-face die where the chance of each face is unknown.  Here is one such die-rolling algorithm (Schmon et al. 2019)[^38].  It generalizes the Bernoulli Race from the &quot;Convex Combinations&quot; section, and returns <em>i</em> with probability&mdash;</p>

<ul>
<li><em>&phi;</em><sub><em>i</em></sub> = <em>g</em>(<em>i</em>)*<em>h</em><sub><em>i</em></sub>(<strong><em>&lambda;</em></strong>) / &sum;<sub><em>k</em>=0,...,<em>r</em></sub> <em>g</em>(<em>k</em>)*<em>h</em><sub><em>k</em></sub>(<strong><em>&lambda;</em></strong>),</li>
</ul>

<p>where:</p>

<ul>
<li><em>r</em> is an integer greater than 0.  There are <em>r</em>+1 values this algorithm can choose from.</li>
<li><em>g</em>(<em>i</em>) takes an integer <em>i</em> and returns a number 0 or greater.  This serves as a <em>weight</em> for the &quot;coin&quot; labeled <em>i</em>; the higher the weight, the more likely the &quot;coin&quot; will be &quot;flipped&quot;.</li>
<li><em>h</em><sub><em>i</em></sub>(<strong><em>&lambda;</em></strong>) takes in a number <em>i</em> and the probabilities of heads of one or more input coins, and returns a number in the interval [0, 1].  This represents the &quot;coin&quot; for one of the <em>r</em>+1 choices.</li>
</ul>

<p>The algorithm follows.</p>

<ol>
<li>Choose an integer in [0, <em>r</em>] with probability proportional to the following weights: [<em>g</em>(0), <em>g</em>(1), ..., <em>g</em>(<em>r</em>)].  Call the chosen integer <em>i</em>.</li>
<li>Run a Bernoulli factory algorithm for <em>h</em><sub><em>i</em></sub>(<strong><em>&lambda;</em></strong>).  If the run returns 0, go to step 1.</li>
<li>Return <em>i</em>.</li>
</ol>

<blockquote>
<p><strong>Notes:</strong></p>

<ol>
<li>The Bernoulli Race (see &quot;<a href="#Convex_Combinations"><strong>Convex Combinations</strong></a>&quot;) is a special case of this algorithm with <em>g</em>(<em>k</em>) = 1 for every <em>k</em>.</li>
<li>If we define <em>S</em> to be a subset of integers in [0, <em>r</em>] and replace step 3 with &quot;If <em>i</em> is in the set <em>S</em>, return 1.  Otherwise, return 0.&quot;, the algorithm returns 1 with probability &sum;<sub><em>k</em>&nbsp;in&nbsp;<em>S</em></sub>&nbsp;<em>&phi;</em><sub><em>k</em></sub>, and 0 otherwise.  In that case, the modified algorithm has the so-called &quot;die-coin algorithm&quot; of Agrawal et al. (2021, Appendix D)[^39] as a special case with&mdash;<br><em>g</em>(<em>k</em>) = <em>c</em><sup><em>k</em></sup>*<em>d</em><sup><em>r</em>&minus;<em>k</em></sup>,<br><em>h</em><sub><em>k</em></sub>(<em>&lambda;</em>, <em>&mu;</em>) = <em>&lambda;</em><sup><em>k</em></sup>*<em>&mu;</em><sup><em>r</em>&minus;<em>k</em></sup> (for the following algorithm: flip the <em>&lambda;</em> coin <em>k</em> times and the <em>&mu;</em> coin <em>r</em>&minus;<em>k</em> times; return 1 if all flips return 1, or 0 otherwise), and<br><em>S</em> is the closed interval [1, <em>r</em>],<br>where <em>c</em>&ge;0, <em>d</em>&ge;0, and <em>&lambda;</em> and <em>&mu;</em> are the probabilities of heads of two input coins.  In that paper, <em>c</em>, <em>d</em>, <em>&lambda;</em>, and <em>&mu;</em> correspond to <em>c</em><sub><em>y</em></sub>, <em>c</em><sub><em>x</em></sub>, <em>p</em><sub><em>y</em></sub>, and <em>p</em><sub><em>x</em></sub>, respectively.</li>
<li>Although not noted in the Schmon paper, the <em>r</em> in the algorithm can be infinity (see also Wästlund 1999, Theorem 2.7[^8]).  In that case, Step 1 is changed to say &quot;Choose an integer 0 or greater at random with probability <em>g</em>(<em>k</em>) for integer <em>k</em>.  Call the chosen integer <em>i</em>.&quot;  As an example, step 1 can sample from a Poisson distribution, which can take on any integer 0 or greater.</li>
</ol>
</blockquote>

<p><a id=Algorithms_for_Specific_Functions_of___lambda></a></p>

<h3>Algorithms for Specific Functions of <em>&lambda;</em></h3>

<p>This section describes algorithms for specific functions, especially when they have a more convenient simulation than the general-purpose algorithms given earlier.  They can be grouped as follows:</p>

<ul>
<li>Functions involving the exponential function exp(<em>x</em>).</li>
<li>Rational functions of several variables.</li>
<li>Addition, subtraction, and division.</li>
<li>Powers and roots.</li>
<li>Linear Bernoulli factories.</li>
<li>Transcendental functions.</li>
<li>Other factory functions.</li>
</ul>

<p><a id=exp_minus___lambda></a></p>

<h4>exp(&minus;<em>&lambda;</em>)</h4>

<p>This algorithm is adapted from the general martingale algorithm (in &quot;Certain Power Series&quot;, above), and makes use of the fact that exp(&minus;<em>&lambda;</em>) can be rewritten as 1 &minus; <em>&lambda;</em> + <em>&lambda;</em><sup>2</sup>/2 &minus; <em>&lambda;</em><sup>3</sup>/6 + <em>&lambda;</em><sup>4</sup>/24 &minus; ..., which is an alternating series whose coefficients are 1, 1, 1/(2!), 1/(3!), 1/(4!), .... This algorithm converges quickly everywhere in the open interval (0, 1).  (In other words, the algorithm is <em>uniformly fast</em>, meaning the average running time is finite for every choice of <em>&lambda;</em> and other parameters (Devroye 1986, esp. p. 717)[^28].[^40])</p>

<ol>
<li>Set <em>u</em> to 1, set <em>w</em> to 1, set <em>&#x2113;</em> to 0, and set <em>n</em> <strong>to 1</strong>.</li>
<li>Generate a uniform(0, 1) random variate <em>ret</em>.</li>
<li>Do the following process repeatedly until this algorithm returns a value:

<ol>
<li>If <em>w</em> is not 0, flip the input coin, multiply <em>w</em> by the result of the flip, and divide <em>w</em> by <em>n</em>. (This is changed from the general martingale algorithm to take account of the factorial more efficiently in the second and later coefficients.)</li>
<li>If <em>n</em> is even, set <em>u</em> to <em>&#x2113;</em> + <em>w</em>.  Otherwise, set <em>&#x2113;</em> to <em>u</em> &minus; <em>w</em>.</li>
<li>If <em>ret</em> is less than (or equal to) <em>&#x2113;</em>, return 1.  If <em>ret</em> is less than <em>u</em>, go to the next substep.  If neither is the case, return 0.  (If <em>ret</em> is a uniform PSRN, these comparisons should be done via the <strong>URandLessThanReal algorithm</strong>, which is described in my <a href="https://peteroupc.github.io/exporand.html"><strong>article on PSRNs</strong></a>.)</li>
<li>Add 1 to <em>n</em>.</li>
</ol></li>
</ol>

<blockquote>
<p><strong>Note:</strong> exp(&minus;<em>&lambda;</em>) = exp(1&minus;<em>&lambda;</em>)/exp(1).</p>
</blockquote>

<p><a id=exp_minus___lambda___k___c></a></p>

<h4>exp(&minus;(<em>&lambda;</em><sup><em>k</em></sup> * <em>c</em>))</h4>

<p>In the algorithms in this section, <em>k</em> is an integer 0 or greater, and <em>c</em> &ge; 0 is a real number.</p>

<p><strong>Algorithm 1.</strong> Works when <strong><em>c</em> is 0 or greater</strong>.  (See also algorithm for exp(&minus;((1&minus;<em>&lambda;</em>)<sup>1</sup> * <em>c</em>)) in &quot;Other Factory Functions&quot;.)</p>

<ol>
<li>Special case: If <em>c</em> is 0, return 1.  If <em>k</em> is 0, run the <strong>algorithm for exp(&minus;<em>z</em>)</strong> (given later in this page) with <em>z</em> = <em>c</em>, and return the result.</li>
<li>Generate <em>N</em>, a Poisson random variate with mean <em>c</em>. (See the appendix on the von Neumann schema for information on generating this variate exactly.)</li>
<li>Set <em>i</em> to 0, then while <em>i</em> &lt; <em>N</em>:

<ol>
<li>Flip the input coin until the flip returns 0 or the coin is flipped <em>k</em> times, whichever comes first.  Return 0 if all of the coin flips (including the last) return 1.</li>
<li>Add 1 to <em>i</em>.</li>
</ol></li>
<li>Return 1.</li>
</ol>

<p><strong>Algorithm 2.</strong>  Applies the general martingale algorithm, but works only when <strong><em>c</em> is a rational number in the interval [0, 1]</strong>.  The target function is represented as a series 1 &minus; <em>&lambda;</em><sup><em>k</em></sup>*<em>c</em> + <em>&lambda;</em><sup>2*<em>k</em></sup>*<em>c</em>/2! &minus; <em>&lambda;</em><sup>3*<em>k</em></sup>*<em>x</em>/3!, ..., and the coefficients are 1, <em>c</em>, <em>c</em>/(2!), <em>c</em>/(3!), ....</p>

<ol>
<li>Special cases: If <em>c</em> is 0, return 1.  If <em>k</em> is 0, run the <strong>algorithm for exp(&minus;<em>x</em>/<em>y</em>)</strong> (given later in this page) with <em>x</em>/<em>y</em> = <em>c</em>, and return the result.</li>
<li>Set <em>u</em> to 1, set <em>w</em> to 1, set <em>&#x2113;</em> to 0, and set <em>n</em> to 1.</li>
<li>Generate a uniform(0, 1) random variate <em>ret</em>.</li>
<li>If <em>w</em> is not 0, flip the input coin <em>k</em> times or until the flip returns 0.  If any of the flips returns 0, set <em>w</em> to 0, or if all the flips return 1, divide <em>w</em> by <em>n</em>.  Then, multiply <em>w</em> by a number that is 1 with probability <em>c</em> and 0 otherwise.</li>
<li>If <em>n</em> is even, set <em>u</em> to <em>&#x2113;</em> + <em>w</em>.  Otherwise, set <em>&#x2113;</em> to <em>u</em> &minus; <em>w</em>.</li>
<li>If <em>ret</em> is less than (or equal to) <em>&#x2113;</em>, return 1.  If <em>ret</em> is less than <em>u</em>, go to the next step.  If neither is the case, return 0.  (If <em>ret</em> is a uniform PSRN, these comparisons should be done via the <strong>URandLessThanReal algorithm</strong>, which is described in my <a href="https://peteroupc.github.io/exporand.html"><strong>article on PSRNs</strong></a>.)</li>
<li>Add 1 to <em>n</em> and go to step 4.</li>
</ol>

<p><strong>Algorithm 3.</strong> Builds on Algorithm 3 and works when <strong><em>c</em> is a rational number 0 or greater</strong>.</p>

<ol>
<li>Let <em>m</em> be floor(<em>c</em>).  Call the second algorithm <em>m</em> times with <em>k</em> = <em>k</em> and <em>c</em> = 1.  If any of these calls returns 0, return 0.</li>
<li>If <em>c</em> is an integer, return 1.</li>
<li>Call the second algorithm once, with <em>k</em> = <em>k</em> and <em>c</em> = <em>c</em> &minus; floor(<em>c</em>).  Return the result of this call.</li>
</ol>

<p><a id=exp_minus__m____lambda_____mu></a></p>

<h4>exp(&minus;(<em>m</em> + <em>&lambda;</em>)*<em>&mu;</em>)</h4>

<p>In the following algorithm, <em>m</em> is an integer 0 or greater, and <em>&lambda;</em> and <em>&mu;</em> are the probabilities of heads of two input coins.</p>

<ol>
<li>Set <em>j</em> to 0, then while <em>j</em> &lt; <em>m</em>+1:

<ol>
<li>Generate <em>N</em>, a Poisson random variate with mean 1.</li>
<li>If <em>j</em> = <em>m</em>, flip the <em>&lambda;</em> input coin <em>N</em> times and set <em>N</em> to the number of flips that return 1 this way.  (This transforms a Poisson variate with mean 1 to one with mean <em>&lambda;</em>; see (Devroye 1986, p. 487)[^28].)</li>
<li>Flip the <em>&mu;</em> input coin until a flip returns 1 or the coin is flipped <em>N</em> times, whichever comes first.  Return 0 if any of the flips, including the last, returns 1.</li>
<li>Add 1 to <em>j</em>.</li>
</ol></li>
<li>Return 1.</li>
</ol>

<p><a id=exp_minus__m____lambda____k></a></p>

<h4>exp(&minus;(<em>m</em> + <em>&lambda;</em>)<sup><em>k</em></sup>)</h4>

<p>In the following algorithm, <em>m</em> and <em>k</em> are both integers 0 or greater unless noted otherwise.</p>

<ol>
<li>If <em>k</em> is 0, run the <strong>algorithm for exp(&minus;<em>x</em>/<em>y</em>)</strong> (given later on this page) with <em>x</em>/<em>y</em> = 1/1, and return the result.</li>
<li>If <em>k</em> is 1 and <em>m</em> is 0, run the <strong>algorithm for exp(&minus;<em>&lambda;</em>)</strong> and return the result.</li>
<li>If <em>k</em> is 1 and <em>m</em> is greater than 0 (and in this case, <em>m</em> can be any rational number):

<ul>
<li>Run the <strong>algorithm for exp(&minus;<em>x</em>/<em>y</em>)</strong> with <em>x</em>/<em>y</em> = <em>m</em>.  If the algorithm returns 0, return 0.  Otherwise, return the result of the <strong>algorithm for exp(&minus;<em>&lambda;</em>)</strong>.</li>
</ul></li>
<li>Run the <strong>algorithm for exp(&minus;<em>x</em>/<em>y</em>)</strong> with <em>x</em>/<em>y</em> = <em>m</em><sup><em>k</em></sup> / 1.  If the algorithm returns 0, return 0.</li>
<li>Run the <strong>algorithm for exp(&minus;(<em>&lambda;</em><sup><em>k</em></sup> * <em>c</em>))</strong>, with <em>k</em> = <em>k</em> and <em>x</em> = 1.  If the algorithm returns 0, return 0.</li>
<li>If <em>m</em> is 0, return 1.</li>
<li>Set <em>i</em> to 1, then while <em>i</em> &lt; <em>k</em>:

<ol>
<li>Set <em>z</em> to choose(<em>k</em>, <em>i</em>) * <em>m</em><sup><em>k</em> &minus; <em>i</em></sup>.</li>
<li>Run the <strong>algorithm for exp(&minus;(<em>&lambda;</em><sup><em>k</em></sup> * <em>c</em>))</strong> <em>z</em> times, with <em>k</em> = <em>i</em> and <em>x</em> = 1.  If any of these calls returns 0, return 0.</li>
<li>Add 1 to <em>i</em>.</li>
</ol></li>
<li>Return 1.</li>
</ol>

<p><a id=exp___lambda___1_minus___lambda></a></p>

<h4>exp(<em>&lambda;</em>)*(1&minus;<em>&lambda;</em>)</h4>

<p>(Flajolet et al., 2010)[^1]:</p>

<ol>
<li>Set <em>k</em> and <em>w</em> each to 0.</li>
<li>Flip the input coin.  If it returns 0, return 1.</li>
<li>Generate a uniform(0, 1) random variate <em>U</em>.</li>
<li>If <em>k</em> &gt; 0 and <em>w</em> is less than <em>U</em>, return 0.</li>
<li>Set <em>w</em> to <em>U</em>, add 1 to <em>k</em>, and go to step 2.</li>
</ol>

<p><a id=exp___lambda___minus_1_exp_minus___lambda___or_exp___lambda___minus_1_exp___lambda></a></p>

<h4>(exp(<em>&lambda;</em>)&minus;1) * exp(&minus;<em>&lambda;</em>) or (exp(<em>&lambda;</em>)&minus;1) / exp(<em>&lambda;</em>)</h4>

<p>This algorithm uses the general martingale algorithm; this function can be rewritten as <em>&lambda;</em>*(1 &minus; <em>&lambda;</em>/2 + <em>&lambda;</em><sup>2</sup>/6 &minus; <em>&lambda;</em><sup>3</sup>/24 + ...), which includes an alternating series whose coefficients are 1, 1/(2!), 1/(3!), 1/(4!), ....</p>

<ol>
<li>Flip the input coin.  If it returns 0, return 0.</li>
<li>Set <em>u</em> to 1, set <em>w</em> to 1, set <em>&#x2113;</em> to 0, and set <em>n</em> <strong>to 2</strong>.</li>
<li>Generate a uniform(0, 1) random variate <em>ret</em>.</li>
<li>Do the following process repeatedly until this algorithm returns a value:

<ol>
<li>If <em>w</em> is not 0, flip the input coin, multiply <em>w</em> by the result of the flip, and divide <em>w</em> by <em>n</em>. (This is changed from the general martingale algorithm to take account of the factorial more efficiently in the second and later coefficients.)</li>
<li>If <em>n</em> is even, set <em>u</em> to <em>&#x2113;</em> + <em>w</em>.  Otherwise, set <em>&#x2113;</em> to <em>u</em> &minus; <em>w</em>.</li>
<li>If <em>ret</em> is less than (or equal to) <em>&#x2113;</em>, return 1.  If <em>ret</em> is less than <em>u</em>, go to the next substep.  If neither is the case, return 0.  (If <em>ret</em> is a uniform PSRN, these comparisons should be done via the <strong>URandLessThanReal algorithm</strong>, which is described in my <a href="https://peteroupc.github.io/exporand.html"><strong>article on PSRNs</strong></a>.)</li>
<li>Add 1 to <em>n</em>.</li>
</ol></li>
</ol>

<p><a id=1_2_k____lambda___or_exp_minus__k____lambda___ln_2></a></p>

<h4>1/(2<sup><em>k</em> + <em>&lambda;</em></sup>) or exp(&minus;(<em>k</em> + <em>&lambda;</em>)*ln(2))</h4>

<p>This new algorithm uses the base-2 logarithm <em>k</em> + <em>&lambda;</em>, where <em>k</em> is an integer 0 or greater, and is useful when this logarithm is very large.</p>

<ol>
<li>If <em>k</em> &gt; 0, generate unbiased random bits until a zero bit or <em>k</em> bits were generated this way, whichever comes first.  If a zero bit was generated this way, return 0.</li>
<li>Create an input coin <em>&mu;</em> that does the following: &quot;Flip the input coin, then run the <strong>algorithm for ln(1+<em>y</em>/<em>z</em>)</strong> (given later) with <em>y</em>/<em>z</em> = 1/1.  If both the call and the flip return 1, return 1.  Otherwise, return 0.&quot;</li>
<li>Run the <strong>algorithm for exp(&minus;&mu;)</strong> using the <em>&mu;</em> input coin, and return the result.</li>
</ol>

<p><a id=1_2_m___k____lambda___or_1_2_m___k____lambda___or_exp_minus__k____lambda___ln_2_m></a></p>

<h4>1/(2<sup><em>m</em>*(<em>k</em> + <em>&lambda;</em>)</sup>) or 1/((2<sup><em>m</em></sup>)*(<em>k</em> + <em>&lambda;</em>)) or exp(&minus;(<em>k</em> + <em>&lambda;</em>)*ln(2<sup><em>m</em></sup>))</h4>

<p>An extension of the previous algorithm.  Here, <em>m</em> is an integer greater than 0.</p>

<ol>
<li>If <em>k</em> &gt; 0, generate unbiased random bits until a zero bit or <em>k</em>*<em>m</em> bits were generated this way, whichever comes first.  If a zero bit was generated this way, return 0.</li>
<li>Create an input coin <em>&mu;</em> that does the following: &quot;Flip the input coin, then run the <strong>algorithm for ln(1+<em>y</em>/<em>z</em>)</strong> (given later) with <em>y</em>/<em>z</em> = 1/1.  If both the call and the flip return 1, return 1.  Otherwise, return 0.&quot;</li>
<li>Run the <strong>algorithm for exp(&minus;&mu;)</strong> <em>m</em> times, using the <em>&mu;</em> input coin.  If any of the calls returns 0, return 0.  Otherwise, return 1.</li>
</ol>

<p><a id=c____lambda_____beta_____beta____c____lambda____d____mu___minus___beta___minus_1__c___d></a></p>

<h4><em>c</em> * <em>&lambda;</em> * <em>&beta;</em> / (<em>&beta;</em> * (<em>c</em> * <em>&lambda;</em> + <em>d</em> * <em>&mu;</em>) &minus; (<em>&beta;</em> &minus; 1) * (<em>c</em> + <em>d</em>))</h4>

<p>This is the general <strong>two-coin algorithm</strong> of (Gonçalves et al., 2017)[^41] and (Vats et al. 2020)[^42].  It takes two input coins that each output heads (1) with probability <em>&lambda;</em> or <em>&mu;</em>, respectively.  It also takes parameters <em>c</em> and <em>d</em>, each 0 or greater, and <em>&beta;</em> in the interval [0, 1], which is a so-called &quot;portkey&quot; or early rejection parameter (when <em>&beta;</em> = 1, the formula simplifies to <em>c</em> * <em>&lambda;</em> / (<em>c</em> * <em>&lambda;</em> + <em>d</em> * <em>&mu;</em>)).  In Vats et al. (2020)[^42], <em>&beta;</em>, <em>c</em>, <em>d</em>, <em>&lambda;</em> and <em>&mu;</em> correspond to <em>&beta;</em>, <em>c</em><sub><em>y</em></sub>, <em>c</em><sub><em>x</em></sub>, <em>p</em><sub><em>y</em></sub>, and <em>p</em><sub><em>x</em></sub>, respectively, in the &quot;portkey&quot; algorithm, or to <em>&beta;</em>, <em>c̃</em><sub><em>x</em></sub>, <em>c̃</em><sub><em>y</em></sub>, <em>p̃</em><sub><em>x</em></sub>, and <em>p̃</em><sub><em>y</em></sub>, respectively, in the &quot;flipped portkey&quot; algorithm.</p>

<ol>
<li>With probability <em>&beta;</em>, go to step 2.  Otherwise, return 0. (For example, call <code>ZeroOrOne</code> with <em>&beta;</em>&#39;s numerator and denominator, and return 0 if that call returns 0, or go to step 2 otherwise.  <code>ZeroOrOne</code> is described in my article on <a href="https://peteroupc.github.io/randomfunc.html#Boolean_True_False_Conditions"><strong>random sampling methods</strong></a>.)</li>
<li>With probability <em>c</em> / (<em>c</em> + <em>d</em>), flip the <em>&lambda;</em> input coin.  Otherwise, flip the <em>&mu;</em> input coin.  If the <em>&lambda;</em> input coin returns 1, return 1.  If the <em>&mu;</em> input coin returns 1, return 0.  If the corresponding coin returns 0, go to step 1.</li>
</ol>

<p><a id=c____lambda____c____lambda____d__or__c___d____lambda___1__c___d____lambda></a></p>

<h4><em>c</em> * <em>&lambda;</em> / (<em>c</em> * <em>&lambda;</em> + <em>d</em>) or (<em>c</em>/<em>d</em>) * <em>&lambda;</em> / (1 + (<em>c</em>/<em>d</em>) * <em>&lambda;</em>))</h4>

<p>This algorithm, also known as the <strong>logistic Bernoulli factory</strong> (Huber 2016)[^37], (Morina et al., 2019)[^17], is a special case of the two-coin algorithm above, but this time uses only one input coin.</p>

<ol>
<li>With probability <em>d</em> / (<em>c</em> + <em>d</em>), return 0.</li>
<li>Flip the input coin.  If the flip returns 1, return 1.  Otherwise, go to step 1.</li>
</ol>

<blockquote>
<p><strong>Note:</strong> Huber (2016) specifies this Bernoulli factory in terms of a Poisson point process, which seems to require much more randomness on average.</p>
</blockquote>

<p><a id=d____lambda____c></a></p>

<h4>(<em>d</em> + <em>&lambda;</em>) / <em>c</em></h4>

<p>In this algorithm, <em>d</em> and <em>c</em> must be integers, and 0 &le; <em>d</em> &lt; <em>c</em>.</p>

<ol>
<li>Generate an integer in [0, <em>c</em>) uniformly at random, call it <em>i</em>.</li>
<li>If <em>i</em> &lt; <em>d</em>, return 1.  If <em>i</em> = <em>d</em>, flip the input coin and return the result.  If neither is the case, return 0.</li>
</ol>

<p><a id=d___c____lambda></a></p>

<h4><em>d</em> / (<em>c</em> + <em>&lambda;</em>)</h4>

<p>In this algorithm, <em>c</em> and <em>d</em> must be rational numbers, <em>c</em> &ge; 1, and 0 &le; <em>d</em> &le; <em>c</em>.  See also the algorithms for continued fractions.  (For example, when <em>d</em> = 1, this algorithm can simulate a probability of the form 1 / <em>z</em>, where <em>z</em> is 1 or greater and made up of an integer part (<em>c</em>) and a fractional part (<em>&lambda;</em>) that can be simulated by a Bernoulli factory.)</p>

<ol>
<li>With probability <em>c</em> / (1 + <em>c</em>), return a number that is 1 with probability <em>d</em>/<em>c</em> and 0 otherwise.</li>
<li>Flip the input coin.  If the flip returns 1, return 0.  Otherwise, go to step 1.</li>
</ol>

<blockquote>
<p><strong>Note</strong>: A quick proof this algorithm works: Let <em>x</em> be the desired probability.  Then&mdash;<br><em>x</em> = (<em>c</em> / (1 + <em>c</em>)) * (<em>d</em>/<em>c</em>) +<br>(1&minus;<em>c</em> / (1 + <em>c</em>)) * (<em>&lambda;</em>*0 + (1&minus;<em>&lambda;</em>)*<em>x</em>),<br>and solving for <em>x</em> leads to <em>x</em>=<em>d</em>/(<em>c</em>+<em>&lambda;</em>).</p>
</blockquote>

<p><a id=d____mu____c____lambda></a></p>

<h4>(<em>d</em> + <em>&mu;</em>) / (<em>c</em> + <em>&lambda;</em>)</h4>

<p>Combines the algorithms in the previous two sections.</p>

<p>In this algorithm, <em>c</em> and <em>d</em> must be integers, and 0 &le; <em>d</em> &lt; <em>c</em>.</p>

<ol>
<li>With probability <em>c</em> / (1 + <em>c</em>), do the following:

<ol>
<li>Generate an integer in [0, <em>c</em>) uniformly at random, call it <em>i</em>.</li>
<li>If <em>i</em> &lt; <em>d</em>, return 1.  If <em>i</em> = <em>d</em>, flip the <em>&mu;</em> input coin and return the result.  If neither is the case, return 0.</li>
</ol></li>
<li>Flip the <em>&lambda;</em> input coin.  If the flip returns 1, return 0.  Otherwise, go to step 1.</li>
</ol>

<p><a id=d____mu____d____mu____c____lambda></a></p>

<h4>(<em>d</em> + <em>&mu;</em>) / ((<em>d</em> + <em>&mu;</em>) + (<em>c</em> + <em>&lambda;</em>))</h4>

<p>In this algorithm, <em>c</em> and <em>d</em> are integers 0 or greater, and <em>&lambda;</em> and <em>&mu;</em> are the probabilities of heads of two different input coins.  In the intended use of this algorithm, <em>&lambda;</em> and <em>&mu;</em> are backed by the fractional parts of two uniform PSRNs, and <em>c</em> and <em>d</em> are their integer parts, respectively.</p>

<ol>
<li>Let <em>D</em> = <em>d</em> and <em>C</em> = <em>c</em>. Run the algorithm for <strong>(<em>d</em> + <em>&mu;</em>) / (<em>c</em> + <em>&lambda;</em>)</strong> with <em>&lambda;</em> and <em>&mu;</em> both being the <em>&mu;</em> input coin, with <em>d</em> = <em>D</em>+<em>C</em>, and with <em>c</em> = 1+<em>D</em> + <em>C</em>.  If the run returns 1:

<ol>
<li>If <em>c</em> is 0, return 1.</li>
<li>Run the algorithm for <strong>(<em>d</em> + <em>&mu;</em>) / (<em>c</em> + <em>&lambda;</em>)</strong> with <em>&lambda;</em> and <em>&mu;</em> both being the <em>&mu;</em> input coin, with <em>d</em> = <em>D</em>, and with <em>c</em> = <em>D</em> + <em>C</em>.  If the run returns 1, return 1.  Otherwise, return 0.</li>
</ol></li>
<li>Flip the <em>&lambda;</em> input coin. If the flip returns 1, return 0. Otherwise, go to step 1.</li>
</ol>

<p><a id=d__k___c____lambda____k__or__d___c____lambda____k></a></p>

<h4><em>d</em><sup><em>k</em></sup> / (<em>c</em> + <em>&lambda;</em>)<sup><em>k</em></sup>, or (<em>d</em> / (<em>c</em> + <em>&lambda;</em>))<sup><em>k</em></sup></h4>

<p>In this algorithm, <em>c</em> and <em>d</em> must be rational numbers, <em>c</em> &ge; 1, and 0 &le; <em>d</em> &le; <em>c</em>, and <em>k</em> must be an integer 0 or greater.</p>

<ol>
<li>Set <em>i</em> to 0.</li>
<li>If <em>k</em> is 0, return 1.</li>
<li>With probability <em>c</em> / (1 + <em>c</em>), do the following:

<ol>
<li>With probability <em>d</em>/<em>c</em>, add 1 to <em>i</em> and then either return 1 if <em>i</em> is now <em>k</em> or greater, or abort these substeps and go to step 2 otherwise.</li>
<li>Return 0.</li>
</ol></li>
<li>Flip the input coin.  If the flip returns 1, return 0.  Otherwise, go to step 2.</li>
</ol>

<p><a id=1_1___lambda></a></p>

<h4>1/(1+<em>&lambda;</em>)</h4>

<p>This algorithm is a special case of the two-coin algorithm of (Gonçalves et al., 2017)[^41] and is uniformly fast.[^43]</p>

<ol>
<li>Generate an unbiased random bit.  If that bit is 1 (which happens with probability 1/2), return 1.</li>
<li>Flip the input coin.  If it returns 1, return 0.  Otherwise, go to step 1.</li>
</ol>

<blockquote>
<p><strong>Note:</strong> In this special case of the two-coin algorithm, <em>&beta;</em>=1, <em>c</em>=1, <em>d</em>=1, old <em>&lambda;</em> equals 1, and <em>&mu;</em> equals new <em>&lambda;</em>.</p>
</blockquote>

<p><a id=1_2_minus___lambda></a></p>

<h4>1/(2 &minus; <em>&lambda;</em>)</h4>

<ol>
<li>Generate an unbiased random bit.  If that bit is 1 (which happens with probability 1/2), return 1.</li>
<li>Flip the input coin.  <strong>If it returns 0</strong>, return 0.  Otherwise, go to step 1.</li>
</ol>

<blockquote>
<p><strong>Note:</strong> Can be derived from the previous algorithm by observing that 1/(2 &minus; <em>&lambda;</em>) = 1/(1 + (1 &minus; <em>&lambda;</em>)).</p>
</blockquote>

<p><a id=expit__m____lambda___or_1_minus_1_1_exp__m____lambda___or_exp__m____lambda___1_exp__m____lambda___or_1_1_exp_minus__m____lambda></a></p>

<h4>expit(<em>m</em> + <em>&lambda;</em>) or 1&minus;1/(1+exp(<em>m</em> + <em>&lambda;</em>)) or exp(<em>m</em> + <em>&lambda;</em>)/(1+exp(<em>m</em> + <em>&lambda;</em>)) or 1/(1+exp(&minus;(<em>m</em> + <em>&lambda;</em>)))</h4>

<p>expit(<em>x</em>), also known as the <em>logistic function</em>, is the probability that a random variate from the logistic distribution is <em>x</em> or less.</p>

<p>In this algorithm, <em>m</em> is an integer and can be positive or not.</p>

<ul>
<li>If <em>m</em> = 0:

<ol>
<li>Create a <em>&mu;</em> coin that runs the algorithm for <strong>exp(&minus;<em>&lambda;</em>)</strong>.</li>
<li>Run the algorithm for <strong><em>d</em>/(<em>c</em>+<em>&lambda;</em>)</strong> with <em>d</em>=1, <em>c</em>=1, and with <em>&lambda;</em> being the <em>&mu;</em> coin, and return the result of that run.</li>
</ol></li>
<li>If <em>m</em> &gt; 0:

<ol>
<li>Create a <em>&mu;</em> coin that runs the algorithm for <strong>exp(&minus;(<em>m</em> + <em>&lambda;</em>)<sup><em>k</em></sup>)</strong> with <em>k</em>=1 and <em>m</em>=<em>m</em>.</li>
<li>Run the algorithm for <strong><em>d</em>/(<em>c</em>+<em>&lambda;</em>)</strong> with <em>d</em>=1, <em>c</em>=1, and with  <em>&lambda;</em> being the <em>&mu;</em> coin, and return the result of that run.</li>
</ol></li>
<li>If <em>m</em> &lt; 0:

<ol>
<li>Create a <em>&nu;</em> input coin that flips the (<em>&lambda;</em>) input coin and returns 1 minus the result.</li>
<li>Create a <em>&mu;</em> input coin that runs the algorithm for <strong>exp(&minus;(<em>m</em> + <em>&lambda;</em>)<sup><em>k</em></sup>)</strong> with <em>k</em>=1, <em>m</em>=abs(<em>m</em>)&minus;1, and <em>&lambda;</em> being the <em>&nu;</em> input coin.</li>
<li>Run the algorithm for <strong><em>d</em>/(<em>c</em>+<em>&lambda;</em>)</strong> with <em>d</em>=1, <em>c</em>=1, and <em>&lambda;</em> being the <em>&mu;</em> coin, and return <strong>1 minus the result</strong> of that run.</li>
</ol></li>
</ul>

<p><a id=expit__m____lambda_____mu></a></p>

<h4>expit((<em>m</em> + <em>&lambda;</em>)*<em>&mu;</em>)</h4>

<p>In this algorithm, <em>m</em> is an integer and can be positive or not, and <em>&lambda;</em> and <em>&mu;</em> are the probabilities of heads of two input coins.</p>

<ul>
<li>If <em>m</em> &ge; 0:

<ol>
<li>Create a <em>&nu;</em> coin that runs the algorithm for <strong>exp(&minus;(<em>m</em> + <em>&lambda;</em>)*<em>&mu;</em>)</strong> with <em>m</em>=<em>m</em>.</li>
<li>Run the algorithm for <strong><em>d</em>/(<em>c</em>+<em>&lambda;</em>)</strong> with <em>d</em>=1, <em>c</em>=1, and with  <em>&lambda;</em> being the <em>&nu;</em> coin, and return the result of that run.</li>
</ol></li>
<li>If <em>m</em> &lt; 0:

<ol>
<li>Create a <em>&beta;</em> input coin that flips the <em>&lambda;</em> input coin and returns 1 minus the result.</li>
<li>Create a <em>&nu;</em> input coin that runs the algorithm for <strong>exp(&minus;(<em>m</em> + <em>&lambda;</em>)*<em>&mu;</em>)</strong> with <em>m</em>=abs(<em>m</em>)&minus;1, <em>&mu;</em> being the <em>&mu;</em> input coin, and <em>&lambda;</em> being the <em>&beta;</em> input coin.</li>
<li>Run the algorithm for <strong><em>d</em>/(<em>c</em>+<em>&lambda;</em>)</strong> with <em>d</em>=1, <em>c</em>=1, and <em>&lambda;</em> being the <em>&nu;</em> coin, and return <strong>1 minus the result</strong> of that run.</li>
</ol></li>
</ul>

<p><a id=expit__m____lambda___2_minus_1_or_tanh__m____lambda___2></a></p>

<h4>expit(<em>m</em> + <em>&lambda;</em>)*2 &minus; 1 or tanh((<em>m</em> + <em>&lambda;</em>)/2)</h4>

<p>In this algorithm, <em>m</em> is an integer 0 or greater, and <em>&lambda;</em> is the probability of heads of an input coin.</p>

<ul>
<li>Do the following process repeatedly, until this algorithm returns a value:

<ol>
<li>Run the algorithm for <strong>exp(&minus;(<em>m</em> + <em>&lambda;</em>)<sup><em>k</em></sup>)</strong> with <em>k</em>=1 and <em>m</em>=<em>m</em>.  Let <em>r</em> be the result of that run.</li>
<li>Generate an unbiased random bit.  If that bit is 1 (which happens with probability 1/2), return 1&minus;<em>r</em>.  Otherwise, if <em>r</em> is 1, return 0.</li>
</ol></li>
</ul>

<blockquote>
<p><strong>Note:</strong> Follows from observing that tanh((<em>m</em>+<em>&lambda;</em>)/2) = (<em>d</em> + (1 &minus; <em>&mu;</em>)) / (<em>c</em> + <em>&mu;</em>), where <em>&mu;</em> = exp(&minus;(<em>m</em>+<em>&lambda;</em>)), <em>d</em> = 0, and <em>c</em> = 1.</p>
</blockquote>

<p><a id=lambda___exp__m____nu_____lambda___exp__m____nu___1_minus___lambda></a></p>

<h4><em>&lambda;</em>*exp(<em>m</em> + <em>&nu;</em>) / (<em>&lambda;</em>*exp(<em>m</em> + <em>&nu;</em>) + (1 &minus; <em>&lambda;</em>))</h4>

<p>In this algorithm:</p>

<ul>
<li><em>m</em> + <em>&nu;</em> is an &quot;exponential shift&quot; (Peres et al. 2021)[^44], where <em>m</em> is an integer and <em>&nu;</em> is a coin that shows heads with probability equal to the shift minus <em>m</em>.</li>
<li><em>&lambda;</em> is a coin that shows heads with probability equal to the probability to be shifted.</li>
</ul>

<p>The algorithm follows:</p>

<ul>
<li>Do the following process repeatedly, until this algorithm returns a value:

<ol>
<li>Flip the <em>&lambda;</em> input coin.  Let <em>flip</em> be the result of that flip.</li>
<li>Run the algorithm for <strong>expit(<em>m</em> + <em>&lambda;</em>)</strong> with <em>m</em>=<em>m</em>, and with  <em>&lambda;</em> being the <em>&nu;</em> input coin. If the run returns 1 and if <em>flip</em> is 1, return 1.  If the run returns 0 and if <em>flip</em> is 0, return 0.</li>
</ol></li>
</ul>

<blockquote>
<p><strong>Note:</strong> This is also a special case of the two-coin algorithm, where <em>&beta;</em>=1, <em>c</em>=exp(<em>m</em> + <em>&nu;</em>), <em>d</em>=1, <em>&lambda;</em> = <em>&lambda;</em>, and <em>&mu;</em> = 1 &minus; <em>&lambda;</em>.</p>
</blockquote>

<p><a id=1_1__x___y____lambda></a></p>

<h4>1 / (1 + (<em>x</em>/<em>y</em>)*<em>&lambda;</em>)</h4>

<p>Another special case of the two-coin algorithm.  In this algorithm, <em>x</em>/<em>y</em> must be 0 or greater.</p>

<ol>
<li>If <em>x</em> is 0, flip the <em>&mu;</em> input coin and return the result.</li>
<li>With probability <em>y</em>/(<em>x</em>+<em>y</em>), flip the <em>&mu;</em> input coin and return the result.</li>
<li>Flip the input coin.  If the flip returns 1, return 0.  Otherwise, go to step 2.</li>
</ol>

<blockquote>
<p><strong>Note:</strong> In this special case of the two-coin algorithm, <em>&beta;</em>=1, <em>c</em>=1, <em>d</em>=<em>x</em>/<em>y</em>, old <em>&lambda;</em> equals 1, and <em>&mu;</em> equals new <em>&lambda;</em>.</p>

<p><strong>Example</strong>:  <strong><em>&mu;</em> / (1 + (<em>x</em>/<em>y</em>)*<em>&lambda;</em>)</strong> (takes two input coins that simulate <em>&lambda;</em> or <em>&mu;</em>, respectively): Run the <strong>algorithm for 1 / (1 + (<em>x</em>/<em>y</em>)*<em>&lambda;</em>)</strong> using the <em>&lambda;</em> input coin.  If it returns 0, return 0.  Otherwise, flip the <em>&mu;</em> input coin and return the result.</p>
</blockquote>

<p><a id=lambda_____mu></a></p>

<h4><em>&lambda;</em> + <em>&mu;</em></h4>

<p>(Nacu and Peres 2005, proposition 14(iii))[^16].  This algorithm takes two input coins that simulate <em>&lambda;</em> or <em>&mu;</em>, respectively, and a parameter <em>&#x03F5;</em> in the half-open interval (0, 1 &minus; <em>&lambda;</em> &minus; <em>&mu;</em>].</p>

<ol>
<li>Create a <em>&nu;</em> input coin that does the following: &quot;Generate an unbiased random bit.  If that bit is 1 (which happens with probability 1/2), flip the <em>&lambda;</em> input coin and return the result.  Otherwise, flip the <em>&mu;</em> input coin and return the result.&quot;</li>
<li>Run a <a href="#Linear_Bernoulli_Factories"><strong>linear Bernoulli factory</strong></a> using the <em>&nu;</em> input coin, <em>x</em>/<em>y</em> = 2/1, and <em>&#x03F5;</em> = <em>&#x03F5;</em>, and return the result.</li>
</ol>

<p><a id=lambda___minus___mu></a></p>

<h4><em>&lambda;</em> &minus; <em>&mu;</em></h4>

<p>(Nacu and Peres 2005, proposition 14(iii-iv))[^16].  This algorithm takes two input coins that simulate <em>&lambda;</em> or <em>&mu;</em>, respectively, and a parameter <em>&#x03F5;</em> in the half-open interval (0, <em>&lambda;</em> &minus; <em>&mu;</em>] (the greater <em>&#x03F5;</em> is, the more efficient).</p>

<ol>
<li>Create a <em>&nu;</em> input coin that does the following: &quot;Generate an unbiased random bit.  If that bit is 1 (which happens with probability 1/2), flip the <em>&lambda;</em> input coin and return <strong>1 minus the result</strong>.  Otherwise, flip the <em>&mu;</em> input coin and return the result.&quot;</li>
<li>Run a <a href="#Linear_Bernoulli_Factories"><strong>linear Bernoulli factory</strong></a> using the <em>&nu;</em> input coin, <em>x</em>/<em>y</em> = 2/1, and <em>&#x03F5;</em> = <em>&#x03F5;</em>, and return 1 minus the result.</li>
</ol>

<p><a id=x03F5_____lambda></a></p>

<h4><em>&#x03F5;</em> / <em>&lambda;</em></h4>

<p>(Lee et al. 2014)[^45].  This algorithm, in addition to the input coin, takes a parameter <em>&#x03F5;</em> in the half-open interval (0, <em>&lambda;</em>].</p>

<ol>
<li>Set <em>&beta;</em> to max(<em>&#x03F5;</em>, 1/2) and set <em>&gamma;</em> to 1 &minus; (1 &minus; <em>&beta;</em>) / (1 &minus; (<em>&beta;</em> / 2)).</li>
<li>Create a <em>&mu;</em> input coin that flips the input coin and returns 1 minus the result.</li>
<li>With probability <em>&#x03F5;</em>, return 1.</li>
<li>Run a <a href="#Linear_Bernoulli_Factories"><strong>linear Bernoulli factory</strong></a> with the <em>&mu;</em> input coin, <em>x</em>/<em>y</em> = 1 / (1 &minus; <em>&#x03F5;</em>), and <em>&#x03F5;</em> = <em>&gamma;</em>. If the result is 0, return 0.  Otherwise, go to step 3.  (Running the linear Bernoulli factory this way simulates the probability (<em>&lambda;</em> &minus; <em>&#x03F5;</em>)/(1 &minus; <em>&#x03F5;</em>) or 1 &minus; (1 &minus; <em>&lambda;</em>)/(1 &minus; <em>&#x03F5;</em>)).</li>
</ol>

<p><a id=mu_____lambda></a></p>

<h4><em>&mu;</em> / <em>&lambda;</em></h4>

<p>(Morina 2021)[^46].  This division algorithm takes two input coins, namely a coin simulating the dividend <em>&mu;</em> and a coin simulating the divisor <em>&lambda;</em>, and a parameter <em>&#x03F5;</em> in the half-open interval (0, <em>&lambda;</em> &minus; <em>&mu;</em>].  In this algorithm, <em>&mu;</em> must be less than <em>&lambda;</em>.</p>

<ul>
<li>Do the following process repeatedly, until this algorithm returns a value:

<ol>
<li>Generate an unbiased random bit (either 0 or 1 with equal probability).</li>
<li>If the bit generated in step 1 is 1, flip the <em>&mu;</em> input coin.  If it returns 1, return 1.</li>
<li>If the bit generated in step 1 is 0, run the <strong>algorithm for <em>&lambda;</em> &minus; <em>&mu;</em></strong> with <em>&#x03F5;</em> = <em>&#x03F5;</em>. If it returns 1, return 0.</li>
</ol></li>
</ul>

<p><a id=lambda___x___y></a></p>

<h4><em>&lambda;</em><sup><em>x</em>/<em>y</em></sup></h4>

<p>In the algorithm below, the case where <em>x</em>/<em>y</em> is in the open interval (0, 1) is due to Mendo (2019)[^23].  The algorithm works only when <em>x</em>/<em>y</em> is 0 or greater.</p>

<ol>
<li>If <em>x</em>/<em>y</em> is 0, return 1.</li>
<li>If <em>x</em>/<em>y</em> is equal to 1, flip the input coin and return the result.</li>
<li>If <em>x</em>/<em>y</em> is greater than 1:

<ol>
<li>Set <em>ipart</em> to floor(<em>x</em>/<em>y</em>) and <em>fpart</em> to rem(<em>x</em>, <em>y</em>) (equivalent to <em>x</em> - <em>y</em>*floor(<em>x</em>/<em>y</em>)).</li>
<li>If <em>fpart</em> is greater than 0, subtract 1 from <em>ipart</em>, then call this algorithm recursively with <em>x</em> = floor(<em>fpart</em>/2) and <em>y</em> = <em>y</em>, then call this algorithm, again recursively, with <em>x</em> = <em>fpart</em> &minus; floor(<em>fpart</em>/2) and <em>y</em> = <em>y</em>. Return 0 if either call returns 0.  (This is done rather than the more obvious approach in order to avoid calling this algorithm with fractional parts very close to 0, because the algorithm runs much more slowly than for fractional parts closer to 1.)</li>
<li>If <em>ipart</em> is 1 or greater, flip the input coin <em>ipart</em> many times.  Return 0 if any of these flips returns 1.</li>
<li>Return 1.</li>
</ol></li>
<li><em>x</em>/<em>y</em> is less than 1, so set <em>i</em> to 1.</li>
<li>Do the following process repeatedly, until this algorithm returns a value:

<ol>
<li>Flip the input coin; if it returns 1, return 1.</li>
<li>With probability <em>x</em>/(<em>y</em>*<em>i</em>), return 0. (Note: <em>x</em>/(<em>y</em>*<em>i</em>) = (<em>x</em>/<em>y</em>) * (1/<em>i</em>).)</li>
<li>Add 1 to <em>i</em>.</li>
</ol></li>
</ol>

<blockquote>
<p><strong>Notes:</strong></p>

<ol>
<li>When <em>x</em>/<em>y</em> is less than 1, the expected number of flips grows without bound as <em>&lambda;</em> approaches 0.  In fact, no fast Bernoulli factory algorithm can avoid this unbounded growth without additional information on <em>&lambda;</em> (Mendo 2019)[^23].</li>
<li>Another algorithm is discussed in the online community <a href="https://stats.stackexchange.com/questions/50272"><strong>Cross Validated</strong></a>.</li>
</ol>
</blockquote>

<p><a id=lambda____mu></a></p>

<h4><em>&lambda;</em><sup><em>&mu;</em></sup></h4>

<p>This algorithm is based on the previous one, but changed to accept a second input coin (which outputs heads with probability <em>&mu;</em>) rather than a fixed value for the exponent.</p>

<ul>
<li>Set <em>i</em> to 1.  Then do the following process repeatedly, until this algorithm returns a value:

<ol>
<li>Flip the input coin that simulates the base, <em>&lambda;</em>; if it returns 1, return 1.</li>
<li>Flip the input coin that simulates the exponent, <em>&mu;</em>; if it returns 1, return 0 with probability 1/<em>i</em>.</li>
<li>Add 1 to <em>i</em>.</li>
</ol></li>
</ul>

<p><a id=sqrt___lambda></a></p>

<h4>sqrt(<em>&lambda;</em>)</h4>

<p>Special case of the previous algorithm with <em>&mu;</em> = 1/2.</p>

<ul>
<li>Set <em>i</em> to 1.  Then do the following process repeatedly, until this algorithm returns a value:

<ol>
<li>Flip the input coin. If it returns 1, return 1.</li>
<li>With probability 1/(<em>i</em>*2), return 0.</li>
<li>Add 1 to <em>i</em> and go to step 1.</li>
</ol></li>
</ul>

<p><a id=lambda____x___y></a></p>

<h4><em>&lambda;</em> * <em>x</em>/<em>y</em></h4>

<p>In general, this function will touch 0 or 1 somewhere in the open interval (0, 1), when <em>x</em>/<em>y</em> &gt; 1.  This makes the function relatively non-trivial to simulate in this case.</p>

<p>Huber has suggested several algorithms for this function over the years.</p>

<p>The first algorithm in this document comes from Huber (2014)[^4].  It uses three parameters:</p>

<ul>
<li><em>x</em> and <em>y</em> are integers such that <em>x</em>/<em>y</em> &gt; 0 and <em>y</em>!=0.</li>
<li><em>&#x03F5;</em> is a rational number in the open interval (0, 1).  If <em>x</em>/<em>y</em> is greater than 1, <em>&#x03F5;</em> must be in the half-open interval (0, 1 &minus; <em>&lambda;</em> * <em>x</em>/<em>y</em>], in order to bound the function away from 0 and 1.  The greater <em>&#x03F5;</em> is, the more efficient.</li>
</ul>

<p>As a result, some knowledge of <em>&lambda;</em> has to be available to the algorithm. The algorithm as described below also includes certain special cases, not mentioned in Huber, to make it more general.</p>

<ol>
<li>Special cases: If <em>x</em> is 0, return 0.  Otherwise, if <em>x</em> equals <em>y</em>, flip the input coin and return the result.  Otherwise, if <em>x</em> is less than <em>y</em>, then do the following: &quot;With probability <em>x</em>/<em>y</em>, flip the input coin and return the result; otherwise return 0.&quot;</li>
<li>Set <em>c</em> to <em>x</em>/<em>y</em>, and set <em>k</em> to 23 / (5 * <em>&#x03F5;</em>).</li>
<li>If <em>&#x03F5;</em> is greater than 644/1000, set <em>&#x03F5;</em> to 644/1000.</li>
<li>Set <em>i</em> to 1.</li>
<li>While <em>i</em> is not 0:

<ol>
<li>Flip the input coin.  If it returns 0, then generate numbers that are each 1 with probability (<em>c</em> &minus; 1) / <em>c</em> and 0 otherwise, until 1 is generated this way, then add 1 to <em>i</em> for each number generated this way (including the last).</li>
<li>Subtract 1 from <em>i</em>.</li>
<li>If <em>i</em> is <em>k</em> or greater:

<ol>
<li>Generate <em>i</em> numbers that are each 1 with probability 2 / (<em>&#x03F5;</em> + 2) or 0 otherwise.  If any of those numbers is 0, return 0.</li>
<li>Multiply <em>c</em> by 2 / (<em>&#x03F5;</em> + 2), then divide <em>&#x03F5;</em> by 2, then multiply <em>k</em> by 2.</li>
</ol></li>
</ol></li>
<li>(<em>i</em> is 0.) Return 1.</li>
</ol>

<p>Huber (2016)[^37] presented a second algorithm using the same three parameters, but it&#39;s omitted here because it appears to perform worse than the algorithm given above and the <strong>algorithm for (<em>&lambda;</em> * <em>x</em>/<em>y</em>)<sup><em>i</em></sup></strong> below (see also Morina 2021[^46]).</p>

<p>Huber (2016) also included a third algorithm that simulates <em>&lambda;</em> * <em>x</em> / <em>y</em>.  The algorithm works only if <em>&lambda;</em> * <em>x</em> / <em>y</em> is known to be less than 1/2.  This third algorithm takes three parameters:</p>

<ul>
<li><em>x</em> and <em>y</em> are integers such that <em>x</em>/<em>y</em> &gt; 0 and <em>y</em>!=0.</li>
<li><em>m</em> is a rational number in the half-open interval [<em>&lambda;</em> * <em>x</em> / <em>y</em>, 1/2).</li>
</ul>

<p>The algorithm follows.</p>

<ol>
<li>The same special cases as for the first algorithm in this section apply.</li>
<li>Run the <strong>logistic Bernoulli factory</strong> algorithm with <em>c</em>/<em>d</em> = (<em>x</em>/<em>y</em>) / (1 &minus; 2 * <em>m</em>).  If it returns 0, return 0.</li>
<li>With probability 1 &minus; 2 * <em>m</em>, return 1.</li>
<li>Run a <a href="#Linear_Bernoulli_Factories"><strong>linear Bernoulli factory</strong></a> with <em>x</em>/<em>y</em> = (<em>x</em>/<em>y</em>) / (2 * <em>m</em>) and <em>&#x03F5;</em> = 1 &minus; <em>m</em>.</li>
</ol>

<blockquote>
<p><strong>Note:</strong> For approximate methods to simulate <em>&lambda;</em>*(<em>x</em>/<em>y</em>), see the page &quot;<a href="https://peteroupc.github.io/bernsupp.html"><strong>Supplemental Notes for Bernoulli Factory Algorithms</strong></a>&quot;.</p>
</blockquote>

<p><a id=lambda____x___y___i></a></p>

<h4>(<em>&lambda;</em> * <em>x</em>/<em>y</em>)<sup><em>i</em></sup></h4>

<p>(Huber 2019)[^47].  This algorithm uses four parameters:</p>

<ul>
<li><em>x</em> and <em>y</em> are integers such that <em>x</em>/<em>y</em> &gt; 0 and <em>y</em>!=0.</li>
<li><em>i</em> is an integer 0 or greater.</li>
<li><em>&#x03F5;</em> is a rational number in the open interval (0, 1).  If <em>x</em>/<em>y</em> is greater than 1, <em>&#x03F5;</em> must be in the half-open interval (0, 1 &minus; <em>&lambda;</em> * <em>x</em>/<em>y</em>].</li>
</ul>

<p>The algorithm also has special cases not mentioned in Huber 2019.</p>

<ol>
<li> Special cases: If <em>i</em> is 0, return 1.  If <em>x</em> is 0, return 0.  Otherwise, if <em>x</em> equals <em>y</em> and <em>i</em> equals 1, flip the input coin and return the result.</li>
<li>Special case: If <em>x</em> is less than <em>y</em> and <em>i</em> = 1, then do the following: &quot;With probability <em>x</em>/<em>y</em>, flip the input coin and return the result; otherwise return 0.&quot;</li>
<li>Special case: If <em>x</em> is less than <em>y</em>, then create a secondary coin that does the following: &quot;With probability <em>x</em>/<em>y</em>, flip the input coin and return the result; otherwise return 0&quot;, then run the <strong>algorithm for</strong> <a href="#lambda___x___y"><strong><em>&lambda;</em><sup><em>x</em>/<em>y</em></sup></strong></a> with <em>x</em>=<em>i</em>, <em>y</em>=1, and <em>&lambda;</em> being the secondary coin, then return the result of that run.</li>
<li>Set <em>t</em> to 355/100 and <em>c</em> to <em>x</em>/<em>y</em>.</li>
<li>While <em>i</em> is not 0:

<ol>
<li>While <em>i</em> &gt; <em>t</em> / <em>&#x03F5;</em>:

<ol>
<li>Set <em>&beta;</em> to (1 &minus; <em>&#x03F5;</em> / 2) / (1 &minus; <em>&#x03F5;</em>).</li>
<li>Run the <strong>algorithm for (<em>a</em>/<em>b</em>)<sup><em>x</em>/<em>y</em></sup></strong> (given in the irrational constants section) with <em>a</em>=1, <em>b</em>=<em>&beta;</em>, <em>x</em>=<em>i</em>, and <em>y</em>=1.  If the run returns 0, return 0.</li>
<li>Multiply <em>c</em> by <em>&beta;</em>, then divide <em>&#x03F5;</em> by 2.</li>
</ol></li>
<li>Run the <strong>logistic Bernoulli factory</strong> with <em>c</em>/<em>d</em> = <em>c</em>, then set <em>z</em> to the result.  Set <em>i</em> to <em>i</em> + 1 &minus; <em>z</em> * 2.</li>
</ol></li>
<li>(<em>i</em> is 0.) Return 1.</li>
</ol>

<p><a id=Linear_Bernoulli_Factories></a></p>

<h4>Linear Bernoulli Factories</h4>

<p>In this document, a <strong>linear Bernoulli factory</strong> refers to one of the following:</p>

<ul>
<li>The first algorithm for <a href="#lambda____x___y"><strong><em>&lambda;</em> * <em>x</em>/<em>y</em></strong></a> with the stated parameters <em>x</em>, <em>y</em>, and <em>&#x03F5;</em>.</li>
<li>The <a href="#lambda____x___y___i"><strong>algorithm for (<em>&lambda;</em> * <em>x</em>/<em>y</em>)<sup><em>i</em></sup></strong></a> with the stated parameters <em>x</em>, <em>y</em>, and <em>&#x03F5;</em>, and with <em>i</em> = 1 (see previous section).</li>
</ul>

<p><a id=arctan___lambda_____lambda></a></p>

<h4>arctan(<em>&lambda;</em>) /<em>&lambda;</em></h4>

<p>Based on the algorithm from Flajolet et al. (2010)[^1], but uses the two-coin algorithm (which is uniformly fast for every <em>&lambda;</em> parameter) rather than the even-parity construction (which is not).[^48]</p>

<ul>
<li>Do the following process repeatedly, until this algorithm returns a value:

<ol>
<li>Generate an unbiased random bit.  If that bit is 1 (which happens with probability 1/2), return 1.</li>
<li>Generate a uniform(0, 1) random variate <em>u</em>, if it wasn&#39;t generated yet.</li>
<li><a href="#Implementation_Notes"><strong>Sample from the number <em>u</em></strong></a> twice, and flip the input coin twice.  If all of these calls and flips return 1, return 0.</li>
</ol></li>
</ul>

<p><a id=arctan___lambda></a></p>

<h4>arctan(<em>&lambda;</em>)</h4>

<p>(Flajolet et al., 2010)[^1]: Call the <strong>algorithm for arctan(<em>&lambda;</em>) /<em>&lambda;</em></strong> and flip the input coin.  Return 1 if the call and flip both return 1, or 0 otherwise.</p>

<p><a id=cos___lambda></a></p>

<h4>cos(<em>&lambda;</em>)</h4>

<p>This algorithm adapts the general martingale algorithm for this function&#39;s series expansion.  In fact, this is a special case of Algorithm 3 of (Łatuszyński et al. 2009/2011)[^24] (which is more general than Proposition 3.4, the general martingale algorithm). The series expansion for cos(<em>&lambda;</em>) is 1 &minus; <em>&lambda;</em><sup>2</sup>/(2!) + <em>&lambda;</em><sup>4</sup>/(4!) &minus; ..., which is an alternating series except the exponent is increased by 2 (rather than 1) with each term.  The coefficients are thus 1, 1/(2!), 1/(4!), ....  A <em>lower truncation</em> of the series is a truncation of that series that ends with a minus term, and the corresponding <em>upper truncation</em> is the same truncation but without the last minus term.  This series expansion meets the requirements of Algorithm 3 because, with probability 1&mdash;</p>

<ul>
<li>the lower truncation is less than or equal to its corresponding upper truncation,</li>
<li>the lower and upper truncations are in the interval [0, 1],</li>
<li>each lower truncation is greater than or equal to the previous lower truncation,</li>
<li>each upper truncation is less than or equal to the previous upper truncation, and</li>
<li>the lower and upper truncations have an expected value that approaches <em>&lambda;</em> from below and above.</li>
</ul>

<p>The algorithm to simulate cos(<em>&lambda;</em>) follows.</p>

<ol>
<li>Set <em>u</em> to 1, set <em>w</em> to 1, set <em>&#x2113;</em> to 0, set <em>n</em> to 1, and set <em>fac</em> to 2.</li>
<li>Generate a uniform(0, 1) random variate <em>ret</em>.</li>
<li>If <em>w</em> is not 0, flip the input coin. If the flip returns 0, set <em>w</em> to 0. Do this step again. (Usually, in the general martingale algorithm, only one coin is flipped in this step. Up to two coins are flipped instead because the exponent increases by 2 rather than 1.)</li>
<li>If <em>n</em> is even, set <em>u</em> to <em>&#x2113;</em> + <em>w</em> / <em>fac</em>.  Otherwise, set <em>&#x2113;</em> to <em>u</em> &minus; <em>w</em> / <em>fac</em>. (Here we divide by the factorial of 2-times-<em>n</em>.)</li>
<li>If <em>ret</em> is less than (or equal to) <em>&#x2113;</em>, return 1.  If <em>ret</em> is less than <em>u</em>, go to the next step.  If neither is the case, return 0.  (If <em>ret</em> is a uniform PSRN, these comparisons should be done via the <strong>URandLessThanReal algorithm</strong>, which is described in my <a href="https://peteroupc.github.io/exporand.html"><strong>article on PSRNs</strong></a>.)</li>
<li>Add 1 to <em>n</em>, then multiply <em>fac</em> by (<em>n</em> * 2 &minus; 1) * (<em>n</em> * 2), then go to step 3.</li>
</ol>

<p><a id=sin___lambda___sqrt__c____lambda___sqrt__c></a></p>

<h4>sin(<em>&lambda;</em>*sqrt(<em>c</em>)) / (<em>&lambda;</em>*sqrt(<em>c</em>))</h4>

<p>This function can be rewritten as 1 &minus; <em>&lambda;</em><sup>2</sup>/(3!) + <em>&lambda;</em><sup>4</sup>/(5!) &minus; ..., which is an alternating series where the exponent is increased by 2 (rather than 1) with each term.  The coefficients are thus 1, <em>c</em><sup>1</sup>/(3!), <em>c</em><sup>2</sup>/(5!), ....  Thus, there is an algorithm to simulate this alternating series (see &quot;<a href="#Certain_Power_Series"><strong>Certain Power Series</strong></a>&quot;).</p>

<p>In this algorithm, <em>c</em> is a rational number that must be in the interval (0, 6], since the algorithm requires a nonincreasing sequence of coefficients.</p>

<ol>
<li>Set <em>u</em> to 1, set <em>w</em> to 1, set <em>&#x2113;</em> to 0, set <em>n</em> to 1, set <em>cprod</em> to <em>c</em>, and set <em>fac</em> to 6.</li>
<li>Generate a uniform(0, 1) random variate <em>ret</em>.</li>
<li>If <em>w</em> is not 0, flip the input coin. If the flip returns 0, set <em>w</em> to 0. Do this step again.</li>
<li>If <em>n</em> is even, set <em>u</em> to <em>&#x2113;</em> + <em>w</em> * <em>cprod</em> / <em>fac</em>.  Otherwise, set <em>&#x2113;</em> to <em>u</em> &minus; <em>w</em> * <em>cprod</em> / <em>fac</em>.</li>
<li>If <em>ret</em> is less than (or equal to) <em>&#x2113;</em>, return 1.  If <em>ret</em> is less than <em>u</em>, go to the next step.  If neither is the case, return 0.  (If <em>ret</em> is a uniform PSRN, these comparisons should be done via the <strong>URandLessThanReal algorithm</strong>, which is described in my <a href="https://peteroupc.github.io/exporand.html"><strong>article on PSRNs</strong></a>.)</li>
<li>Add 1 to <em>n</em>, then multiply <em>fac</em> by (<em>n</em> * 2) * (<em>n</em> * 2 + 1), then multiply <em>cprod</em> by <em>c</em>, then go to step 3.</li>
</ol>

<p><a id=sin___lambda></a></p>

<h4>sin(<em>&lambda;</em>)</h4>

<p>Equals the previous function times <em>&lambda;</em>, with <em>c</em> = 1.</p>

<ul>
<li>Flip the input coin.  If it returns 0, return 0.  Otherwise, run the algorithm for <strong>sin(<em>&lambda;</em>*sqrt(<em>c</em>)) / (<em>&lambda;</em>*sqrt(<em>c</em>))</strong> with <em>c</em> = 1, then return the result.</li>
</ul>

<p><a id=1_minus___lambda___cos___lambda></a></p>

<h4>(1&minus;<em>&lambda;</em>)/cos(<em>&lambda;</em>)</h4>

<p>(Flajolet et al., 2010)[^1].  Uses an average number of flips that grows without bound as <em>&lambda;</em> goes to 1.</p>

<ol>
<li>Flip the input coin until the flip returns 0.  Then set <em>G</em> to the number of times the flip returns 1 this way.</li>
<li>If <em>G</em> is <strong>odd</strong>, return 0.</li>
<li>Generate a uniform(0, 1) random variate <em>U</em>, then set <em>i</em> to 1.</li>
<li>While <em>i</em> is less than <em>G</em>:

<ol>
<li>Generate a uniform(0, 1) random variate <em>V</em>.</li>
<li>If <em>i</em> is odd and <em>V</em> is less than <em>U</em>, return 0.</li>
<li>If <em>i</em> is even and <em>U</em> is less than <em>V</em>, return 0.</li>
<li>Add 1 to <em>i</em>, then set <em>U</em> to <em>V</em>.</li>
</ol></li>
<li>Return 1.</li>
</ol>

<p><a id=1_minus___lambda___tan___lambda></a></p>

<h4>(1&minus;<em>&lambda;</em>) * tan(<em>&lambda;</em>)</h4>

<p>(Flajolet et al., 2010)[^1].  Uses an average number of flips that grows without bound as <em>&lambda;</em> goes to 1.</p>

<ol>
<li>Flip the input coin until the flip returns 0.  Then set <em>G</em> to the number of times the flip returns 1 this way.</li>
<li>If <em>G</em> is <strong>even</strong>, return 0.</li>
<li>Generate a uniform(0, 1) random variate <em>U</em>, then set <em>i</em> to 1.</li>
<li>While <em>i</em> is less than <em>G</em>:

<ol>
<li>Generate a uniform(0, 1) random variate <em>V</em>.</li>
<li>If <em>i</em> is odd and <em>V</em> is less than <em>U</em>, return 0.</li>
<li>If <em>i</em> is even and <em>U</em> is less than <em>V</em>, return 0.</li>
<li>Add 1 to <em>i</em>, then set <em>U</em> to <em>V</em>.</li>
</ol></li>
<li>Return 1.</li>
</ol>

<p><a id=ln_1___lambda></a></p>

<h4>ln(1+<em>&lambda;</em>)</h4>

<p>Based on the algorithm from Flajolet et al. (2010)[^1], but uses the two-coin algorithm (which is uniformly fast for every <em>&lambda;</em> parameter) rather than the even-parity construction (which is not).[^49]</p>

<ul>
<li>Do the following process repeatedly, until this algorithm returns a value:

<ol>
<li>Generate an unbiased random bit.  If that bit is 1 (which happens with probability 1/2), flip the input coin and return the result.</li>
<li>Generate a uniform(0, 1) random variate <em>u</em>, if <em>u</em> wasn&#39;t generated yet.</li>
<li><a href="#Implementation_Notes"><strong>Sample from the number <em>u</em></strong></a>, then flip the input coin.  If the call and the flip both return 1, return 0.</li>
</ol></li>
</ul>

<p><a id=ln__c___d____lambda____c></a></p>

<h4>ln((<em>c</em> + <em>d</em> + <em>&lambda;</em>)/<em>c</em>)</h4>

<p>In this algorithm, <em>d</em> and <em>c</em> are integers, 0 &lt; <em>c</em> &lt; <em>d</em>, and <em>d</em> &ge; 0, and (<em>c</em> + <em>d</em> + <em>&lambda;</em>)/<em>c</em> &le; exp(1).</p>

<ul>
<li>Do the following process repeatedly, until this algorithm returns a value:

<ol>
<li>Generate an unbiased random bit.  If that bit is 1 (which happens with probability 1/2), run the <strong>algorithm for (<em>d</em> + <em>&lambda;</em>) / <em>c</em></strong> with <em>d</em> = <em>d</em> and <em>c</em> = <em>c</em>, and return the result.</li>
<li>Generate a uniform(0, 1) random variate <em>u</em>, if <em>u</em> wasn&#39;t generated yet.</li>
<li><a href="#Implementation_Notes"><strong>Sample from the number <em>u</em></strong></a>, then run the <strong>algorithm for (<em>d</em> + <em>&lambda;</em>) / <em>c</em></strong> with <em>d</em> = <em>d</em> and <em>c</em> = <em>c</em>.  If both calls return 1, return 0.</li>
</ol></li>
</ul>

<p><a id=arcsin___lambda___sqrt_1_minus___lambda__2_minus_1></a></p>

<h4>arcsin(<em>&lambda;</em>) + sqrt(1 &minus; <em>&lambda;</em><sup>2</sup>) &minus; 1</h4>

<p>(Flajolet et al., 2010)[^1].  The algorithm given here uses the two-coin algorithm rather than the even-parity construction.</p>

<ol>
<li>Generate a uniform(0, 1) random variate <em>u</em>.</li>
<li>Create a secondary coin <em>&mu;</em> that does the following: &quot;<a href="#Implementation_Notes"><strong>Sample from the number <em>u</em></strong></a> twice, and flip the input coin twice.  If all of these calls and flips return 1, return 0.  Otherwise, return 1.&quot;</li>
<li>Call the <strong>algorithm for <em>&mu;</em><sup>1/2</sup></strong> using the secondary coin <em>&mu;</em>.  If it returns 0, return 0.</li>
<li>Generate an unbiased random bit.  If that bit is 1 (which happens with probability 1/2), flip the input coin and return the result.</li>
<li><a href="#Implementation_Notes"><strong>Sample from the number <em>u</em></strong></a> once, and flip the input coin once.  If both the call and flip return 1, return 0.  Otherwise, go to step 4.</li>
</ol>

<p><a id=arcsin___lambda___2></a></p>

<h4>arcsin(<em>&lambda;</em>) / 2</h4>

<p>The Flajolet paper doesn&#39;t explain in detail how arcsin(<em>&lambda;</em>)/2 arises out of arcsin(<em>&lambda;</em>) + sqrt(1 &minus; <em>&lambda;</em><sup>2</sup>) &minus; 1 via Bernoulli factory constructions, but here is an algorithm.[^50] However, the number of input coin flips is expected to grow without bound as <em>&lambda;</em> approaches 1.</p>

<ol>
<li>Generate an unbiased random bit.  If that bit is 1 (which happens with probability 1/2), run the <strong>algorithm for arcsin(<em>&lambda;</em>) + sqrt(1 &minus; <em>&lambda;</em><sup>2</sup>) &minus; 1</strong> and return the result.</li>
<li>Create a secondary coin <em>&mu;</em> that does the following: &quot;Flip the input coin twice.  If both flips return 1, return 0.  Otherwise, return 1.&quot; (The coin simulates 1 &minus; <em>&lambda;</em><sup>2</sup>.)</li>
<li>Call the <strong>algorithm for <em>&mu;</em><sup>1/2</sup></strong> using the secondary coin <em>&mu;</em>.  If it returns 0, return 1; otherwise, return 0. (This step effectively cancels out the sqrt(1 &minus; <em>&lambda;</em><sup>2</sup>) &minus; 1 part and divides by 2.)</li>
</ol>

<p><a id=tanh__m____lambda></a></p>

<h4>tanh(<em>m</em> + <em>&lambda;</em>)</h4>

<p>In this algorithm, <em>m</em> is an integer 0 or greater, and <em>&lambda;</em> is the probability of heads of an input coin.[^61]</p>

<ul>
<li>Do the following process repeatedly, until this algorithm returns a value:

<ol>
<li>Run the algorithm for <strong>exp(&minus;(<em>m</em> + <em>&lambda;</em>)<sup><em>k</em></sup>)</strong> twice, with <em>k</em>=1 and <em>m</em>=<em>m</em>.  Let <em>r</em> be a number that is 1 if both runs returned 1, or 0 otherwise.</li>
<li>Generate an unbiased random bit.  If that bit is 1 (which happens with probability 1/2), return 1&minus;<em>r</em>.  Otherwise, if <em>r</em> is 1, return 0.</li>
</ol></li>
</ul>

<blockquote>
<p><strong>Note:</strong> Follows from observing that tanh(<em>m</em>+<em>&lambda;</em>) = (<em>d</em> + (1 &minus; <em>&mu;</em>)) / (<em>c</em> + <em>&mu;</em>), where <em>&mu;</em> = exp(&minus;(<em>m</em>+<em>&lambda;</em>))<sup>2</sup>, <em>d</em> = 0, and <em>c</em> = 1.</p>
</blockquote>

<p><a id=Expressions_Involving_Polylogarithms></a></p>

<h4>Expressions Involving Polylogarithms</h4>

<p>The following algorithm simulates the expression Li<sub><em>r</em></sub>(<em>&lambda;</em>) * (1 / <em>&lambda;</em> &minus; 1), where Li<sub><em>r</em></sub>(.) is a polylogarithm of order <em>r</em>, and <em>r</em> is an integer 1 or greater.    However, even with a relatively small <em>r</em> such as 6, the expression quickly approaches a straight line.</p>

<p>If <em>&lambda;</em> is 1/2, this expression simplifies to Li<sub><em>r</em></sub>(1/2). See also (Flajolet et al., 2010)[^1].  See also &quot;<a href="#Convex_Combinations"><strong>Convex Combinations</strong></a>&quot; (the case of 1/2 works by decomposing the series forming the polylogarithmic constant into <em>g</em>(<em>i</em>) = (1/2)<sup><em>i</em></sup>, which sums to 1, and <em>h</em><sub><em>i</em></sub>() = 1/<em>i</em><sup><em>r</em></sup>, where <em>i</em> &ge; 1).</p>

<ol>
<li>Flip the input coin until it returns 0, and let <em>t</em> be 1 plus the number of times the coin returned 1 this way.</li>
<li>Return a number that is 1 with probability 1/<em>t</em><sup><em>r</em></sup> and 0 otherwise.</li>
</ol>

<p><a id=Other_Factory_Functions></a></p>

<h4>Other Factory Functions</h4>

<p>Algorithms in bold are given in this page.</p>

<table><thead>
<tr>
<th>To simulate:</th>
<th>Follow this algorithm:</th>
</tr>
</thead><tbody>
<tr>
<td>1/sqrt(<em>&pi;</em>)</td>
<td>Create <em>&lambda;</em> coin for algorithm <strong>1/<em>&pi;</em></strong>.<br>Run algorithm for <strong>sqrt(<em>&lambda;</em>)</strong>.</td>
</tr>
<tr>
<td>1/sqrt(<em>h</em>+<em>&lambda;</em>)</td>
<td>(<em>&lambda;</em> is unknown heads probability of a coin; <em>h</em>&ge;1 is a rational number.)<br>Create <em>&mu;</em> coin for algorithm <strong><em>d</em>/(<em>c</em>+<em>&lambda;</em>)</strong> with <em>c</em>=<em>h</em> and <em>d</em>=1.<br>Run algorithm for <strong>sqrt(<em>&lambda;</em>)</strong> with <em>&lambda;</em> being the <em>&mu;</em> coin.</td>
</tr>
<tr>
<td>1 / (<em>c</em> + <em>&lambda;</em>)</td>
<td>(<em>&lambda;</em> is unknown heads probability of a coin; <em>c</em>&ge;1 is a rational number.)<br>Run algorithm for <strong><em>d</em> / (<em>c</em> + <em>&lambda;</em>)</strong> with <em>d</em> = 1.</td>
</tr>
<tr>
<td>1 / (1 + <em>&lambda;</em><sup>2</sup>)</td>
<td>(Slope function of arctan(<em>&lambda;</em>).  <em>&lambda;</em> is unknown heads probability of a coin.)<br>Create <em>&mu;</em> coin that flips <em>&lambda;</em> coin twice and returns either 1 if both flips return 1, or 0 otherwise.<br>Run algorithm for <strong><em>d</em> / (<em>c</em> + <em>&lambda;</em>)</strong> with <em>d</em>=1, <em>c</em>=1, and <em>&lambda;</em> being the <em>&mu;</em> coin.</td>
</tr>
<tr>
<td>1 / (<em>c</em> + exp(&minus; <em>&lambda;</em>))</td>
<td>(<em>&lambda;</em> is unknown heads probability of a coin; <em>c</em>&ge;1 is a rational number.)<br>Create <em>&mu;</em> coin for algorithm <strong>exp(&minus; <em>&lambda;</em>)</strong>.<br>Run algorithm for <strong><em>d</em> / (<em>c</em> + <em>&lambda;</em>)</strong> with <em>d</em>=1, <em>c</em>=<em>c</em>, and <em>&lambda;</em> being the <em>&mu;</em> coin.</td>
</tr>
<tr>
<td>exp(&minus;((1&minus;<em>&lambda;</em>)<sup>1</sup> * <em>c</em>))</td>
<td>((Dughmi et al. 2017)[^36]; applies an exponential weight&mdash;here, <em>c</em>&mdash;to an input coin)<br>(1) If <em>c</em> is 0, return 1.<br>(2) Generate <em>N</em>, a Poisson random variate with mean <em>c</em>.<br>(3) Flip the input coin until the flip returns 0 or the coin is flipped <em>N</em> times, whichever comes first, then return a number that is 1 if <em>N</em> is 0 or all of the coin flips (including the last) return 1, or 0 otherwise.</td>
</tr>
<tr>
<td>1 &minus; 1 / (1+(<em>&mu;</em>*<em>&lambda;</em>/(1 &minus; <em>&mu;</em>)) =<br>(<em>&mu;</em>*<em>&lambda;</em>/(1 &minus; <em>&mu;</em>) / (1+(<em>&mu;</em>*<em>&lambda;</em>/(1 &minus; <em>&mu;</em>))</td>
<td>(Special case of <strong>logistic Bernoulli factory</strong>; <em>&lambda;</em> is in [0, 1], <em>&mu;</em> is in [0, 1), and both are unknown heads probabilities of two coins.)<br>(1) Flip the <em>&mu;</em> coin.  If it returns 0, return 0. (Coin samples probability <em>&mu;</em>/(<em>&mu;</em> + (1 &minus; <em>&mu;</em>)) = <em>&mu;</em>.) <br>(2) Flip the <em>&lambda;</em> coin.  If it returns 1, return 1.  Otherwise, go to step 1.</td>
</tr>
<tr>
<td><em>&lambda;</em>/(1+<em>&lambda;</em>)</td>
<td>Run algorithm for <strong>1/(1+<em>&lambda;</em>)</strong>, then return 1 minus the result.</td>
</tr>
<tr>
<td>exp(<em>m</em> + <em>&lambda;</em>)/(1+exp(<em>m</em> + <em>&lambda;</em>))<sup>2</sup></td>
<td>(Equals expit(<em>m</em> + <em>&lambda;</em>)*(1&minus;expit(<em>m</em> + <em>&lambda;</em>)).  <em>&lambda;</em> is unknown heads probability of a coin.)<br>Run the algorithm for <strong>expit(<em>m</em> + <em>&lambda;</em>)</strong> twice, with <em>m</em>=0. If the first run returns 1 and the second returns 0, return 1.  Otherwise, return 0.</td>
</tr>
<tr>
<td><em>&nu;</em> * 1 + (1 &minus; <em>&nu;</em>) * <em>&mu;</em> = <em>&nu;</em> + <em>&mu;</em> &minus; (<em>&nu;</em>*<em>&mu;</em>)</td>
<td>(<em>Logical OR</em>. Flajolet et al., 2010[^1].  Special case of <em>&nu;</em> * <em>&lambda;</em> + (1 &minus; <em>&nu;</em>) * <em>&mu;</em> with <em>&lambda;</em> = 1. <em>&nu;</em> and <em>&mu;</em> are unknown heads probabilities of two coins.)<br>Flip the <em>&nu;</em> input coin and the <em>&mu;</em> input coin.  Return 1 if either flip returns 1, and 0 otherwise.</td>
</tr>
<tr>
<td>1 &minus; <em>&nu;</em></td>
<td>(<em>Complement</em>. Flajolet et al., 2010[^1].  Special case of <em>&nu;</em> * <em>&lambda;</em> + (1 &minus; <em>&nu;</em>) * <em>&mu;</em> with <em>&lambda;</em> = 0 and <em>&mu;</em> = 1. <em>&nu;</em> is unknown heads probability of a coin.)<br>Flip the <em>&nu;</em> input coin and return 1 minus the result.</td>
</tr>
<tr>
<td><em>&nu;</em> * <em>&lambda;</em></td>
<td>(<em>Logical AND</em> or <em>Product</em>. Flajolet et al., 2010[^1].  Special case of <em>&nu;</em> * <em>&lambda;</em> + (1 &minus; <em>&nu;</em>) * <em>&mu;</em> with <em>&mu;</em> = 0. <em>&nu;</em> and <em>&lambda;</em> are unknown heads probabilities of two coins.)<br>Flip the <em>&nu;</em> input coin and the <em>&lambda;</em> input coin.  Return 1 if both flips return 1, and 0 otherwise.</td>
</tr>
<tr>
<td>(<em>&lambda;</em> + <em>&mu;</em>)/2 = (1/2)*<em>&lambda;</em> + (1/2)*<em>&mu;</em></td>
<td>(<em>Mean</em>. Nacu and Peres 2005, proposition 14(iii)[^16]; Flajolet et al., 2010[^1].  Special case of <em>&nu;</em> * <em>&lambda;</em> + (1 &minus; <em>&nu;</em>) * <em>&mu;</em> with <em>&nu;</em> = 1/2. <em>&lambda;</em> and <em>&mu;</em> are unknown heads probabilities of two coins.)<br> Generate an unbiased random bit.  If that bit is 1 (which happens with probability 1/2), flip the <em>&lambda;</em> input coin and return the result.  Otherwise, flip the <em>&mu;</em> input coin and return the result.</td>
</tr>
<tr>
<td>1 &minus; ln(1+<em>&lambda;</em>)</td>
<td>Run algorithm for <strong>ln(1+<em>&lambda;</em>)</strong>, then return 1 minus the result.[^51]</td>
</tr>
<tr>
<td>(1&minus;<em>&lambda;</em>)*exp(<em>&lambda;</em>)</td>
<td>(<em>&lambda;</em> is unknown heads probability of a coin.)<br>Run algorithm for power series 1, with <em>c</em>[<em>i</em>] = (<em>i</em>&minus;1)/(<em>i</em>!), and <em>CS</em> = 1 (see &quot;<a href="#Certain_Power_Series"><strong>Certain Power Series</strong></a>).</td>
</tr>
<tr>
<td>sin(sqrt(<em>&lambda;</em>)*sqrt(<em>c</em>)) / (sqrt(<em>&lambda;</em>)*sqrt(<em>c</em>))</td>
<td>(<em>c</em> is a rational number in (0, 6].  <em>&lambda;</em> is unknown heads probability of a coin.)<br>Run algorithm for  <strong>sin(<em>&lambda;</em>*sqrt(<em>c</em>)) / (<em>&lambda;</em>*sqrt(<em>c</em>))</strong>, except delete the sentence &quot;Do this step again.&quot;</td>
</tr>
</tbody></table>

<p><a id=Algorithms_for_Specific_Constants></a></p>

<h3>Algorithms for Specific Constants</h3>

<p>This section shows algorithms to simulate a probability equal to a specific
kind of irrational number.</p>

<p><a id=1___phi___1_divided_by_the_golden_ratio></a></p>

<h4>1 / <em>&phi;</em> (1 divided by the golden ratio)</h4>

<p>This algorithm uses the algorithm described in the section on <a href="#Continued_Fractions"><strong>continued fractions</strong></a> to simulate 1 divided by the golden ratio (about 0.618), whose continued fraction&#39;s partial denominators are 1, 1, 1, 1, ....</p>

<ol>
<li>Generate an unbiased random bit.  If that bit is 1 (which happens with probability 1/2), return 1.</li>
<li>Do a separate run of the currently running algorithm.  If the separate run returns 1, return 0.  Otherwise, go to step 1.</li>
</ol>

<p><a id=sqrt_2_minus_1></a></p>

<h4>sqrt(2) &minus; 1</h4>

<p>Another example of a continued fraction is that of the fractional part of the square root of 2, where the partial denominators are 2, 2, 2, 2, .... The algorithm to simulate this number is as follows:</p>

<ol>
<li>With probability 2/3, generate an unbiased random bit and return that bit.</li>
<li>Do a separate run of the currently running algorithm.  If the separate run returns 1, return 0.  Otherwise, go to step 1.</li>
</ol>

<p><a id=1_sqrt_2></a></p>

<h4>1/sqrt(2)</h4>

<p>This third example of a continued fraction shows how to simulate a probability 1/<em>z</em>, where <em>z</em> &gt; 1 has a known simple continued fraction expansion.  In this case, the partial denominators are as follows: floor(<em>z</em>), <em>a</em>[1], <em>a</em>[2], ..., where the <em>a</em>[<em>i</em>] are <em>z</em>&#39;s partial denominators (not including <em>z</em>&#39;s integer part).  In the example of 1/sqrt(2), the partial denominators are 1, 2, 2, 2, ..., where 1 comes first since floor(sqrt(2)) = 1.  The algorithm to simulate 1/sqrt(2) is as follows:</p>

<p>The algorithm begins with <em>pos</em> equal to 1.  Then the following steps are taken.</p>

<ol>
<li>If <em>pos</em> is 1, return 1 with probability 1/2.  If <em>pos</em> is greater than 1, then with probability 2/3, generate an unbiased random bit and return that bit.</li>
<li>Do a separate run of the currently running algorithm, but with <em>pos</em> = <em>pos</em> + 1.  If the separate run returns 1, return 0.  Otherwise, go to step 1.</li>
</ol>

<p><a id=tanh_1_2_or_exp_1_minus_1_exp_1_1></a></p>

<h4>tanh(1/2) or (exp(1) &minus; 1) / (exp(1) + 1)</h4>

<p>The algorithm begins with <em>k</em> equal to 2.  Then the following steps are taken.</p>

<ol>
<li>With probability <em>k</em>/(1+<em>k</em>), return a number that is 1 with probability 1/<em>k</em> and 0 otherwise.</li>
<li>Do a separate run of the currently running algorithm, but with <em>k</em> = <em>k</em> + 4.  If the separate run returns 1, return 0.  Otherwise, go to step 1.</li>
</ol>

<p><a id=arctan__x___y___y___x></a></p>

<h4>arctan(<em>x</em>/<em>y</em>) * <em>y</em>/<em>x</em></h4>

<p>(Flajolet et al., 2010)[^1]:</p>

<ol>
<li>Generate a uniform(0, 1) random variate <em>u</em>.</li>
<li>Generate a number that is 1 with probability <em>x</em> * <em>x</em>/(<em>y</em> * <em>y</em>), or 0 otherwise.  If the number is 0, return 1.</li>
<li><a href="#Implementation_Notes"><strong>Sample from the number <em>u</em></strong></a> twice.  If either of these calls returns 0, return 1.</li>
<li>Generate a number that is 1 with probability <em>x</em> * <em>x</em>/(<em>y</em> * <em>y</em>), or 0 otherwise.  If the number is 0, return 0.</li>
<li><a href="#Implementation_Notes"><strong>Sample from the number <em>u</em></strong></a> twice.  If either of these calls returns 0, return 0.  Otherwise, go to step 2.</li>
</ol>

<p>Observing that the even-parity construction used in the Flajolet paper is equivalent to the two-coin algorithm, which is uniformly fast, the algorithm above can be made uniformly fast as follows:</p>

<ol>
<li>Generate an unbiased random bit.  If that bit is 1 (which happens with probability 1/2), return 1.</li>
<li>Generate a uniform(0, 1) random variate <em>u</em>, if it wasn&#39;t generated yet.</li>
<li>With probability <em>x</em> * <em>x</em>/(<em>y</em> * <em>y</em>), <a href="#Implementation_Notes"><strong>sample from the number <em>u</em></strong></a> twice.  If both of these calls return 1, return 0.</li>
<li>Go to step 1.</li>
</ol>

<p><a id=pi___12></a></p>

<h4><em>&pi;</em> / 12</h4>

<p>Two algorithms:</p>

<ul>
<li>First algorithm: Use the algorithm for <strong>arcsin(<em>&lambda;</em>) / 2</strong>, but where the algorithm says to &quot;flip the input coin&quot;, instead generate an unbiased random bit.</li>
<li>Second algorithm: With probability 2/3, return 0.  Otherwise, run the algorithm for <strong>&pi; / 4</strong> and return the result.</li>
</ul>

<p><a id=pi___4></a></p>

<h4><em>&pi;</em> / 4</h4>

<p>(Flajolet et al., 2010)[^1]:</p>

<ol>
<li>Generate a random integer in the interval [0, 6), call it <em>n</em>.</li>
<li>If <em>n</em> is less than 3, return the result of the <strong>algorithm for arctan(1/2) * 2</strong>.  Otherwise, if <em>n</em> is 3, return 0.  Otherwise, return the result of the <strong>algorithm for arctan(1/3) * 3</strong>.</li>
</ol>

<p><a id=1___pi></a></p>

<h4>1 / <em>&pi;</em></h4>

<p>(Flajolet et al., 2010)[^1]:</p>

<ol>
<li>Set <em>t</em> to 0.</li>
<li>With probability 1/4, add 1 to <em>t</em> and repeat this step.  Otherwise, go to step 3.</li>
<li>With probability 1/4, add 1 to <em>t</em> and repeat this step.  Otherwise, go to step 4.</li>
<li>With probability 5/9, add 1 to <em>t</em>.</li>
<li>Generate 2*<em>t</em> unbiased random bits (that is, either 0 or 1, chosen with equal probability), and return 0 if there are more zeros than ones generated this way or more ones than zeros.  (In fact, this condition can be checked even before all the bits are generated this way.)  Do this step two more times.</li>
<li>Return 1.</li>
</ol>

<p>For a sketch of how this algorithm is derived, see the appendix.</p>

<p><a id=a___b___x___y></a></p>

<h4>(<em>a</em>/<em>b</em>)<sup><em>x</em>/<em>y</em></sup></h4>

<p>In the algorithm below, <em>a</em>, <em>b</em>, <em>x</em>, and <em>y</em> are integers, and the case where <em>x</em>/<em>y</em> is in the open interval (0, 1) is due to recent work by Mendo (2019)[^23].  This algorithm works only if&mdash;</p>

<ul>
<li> <em>x</em>/<em>y</em> is 0 or greater and <em>a</em>/<em>b</em> is in the interval [0, 1], or</li>
<li> <em>x</em>/<em>y</em> is less than 0 and <em>a</em>/<em>b</em> is 1 or greater.</li>
</ul>

<p>The algorithm follows.</p>

<ol>
<li>If <em>x</em>/<em>y</em> is less than 0, swap <em>a</em> and <em>b</em>, and remove the sign from <em>x</em>/<em>y</em>.  If <em>a</em>/<em>b</em> is now no longer in the interval [0, 1], return an error.</li>
<li>If <em>x</em>/<em>y</em> is equal to 1, return 1 with probability <em>a</em>/<em>b</em> and 0 otherwise.</li>
<li>If <em>x</em> is 0, return 1.  Otherwise, if <em>a</em> is 0, return 0.  Otherwise, if <em>a</em> equals <em>b</em>, return 1.</li>
<li>If <em>x</em>/<em>y</em> is greater than 1:

<ol>
<li>Set <em>ipart</em> to floor(<em>x</em>/<em>y</em>) and <em>fpart</em> to rem(<em>x</em>, <em>y</em>) (equivalent to <em>x</em> - <em>y</em>*floor(<em>x</em>/<em>y</em>)).</li>
<li>If <em>fpart</em> is greater than 0, subtract 1 from <em>ipart</em>, then call this algorithm recursively with <em>x</em> = floor(<em>fpart</em>/2) and <em>y</em> = <em>y</em>, then call this algorithm, again recursively, with <em>x</em> = <em>fpart</em> &minus; floor(<em>fpart</em>/2) and <em>y</em> = <em>y</em>. Return 0 if either call returns 0.  (This is done rather than the more obvious approach in order to avoid calling this algorithm with fractional parts very close to 0, because the algorithm runs much more slowly than for fractional parts closer to 1.)</li>
<li>If <em>ipart</em> is 1 or greater, generate at random a number that is 1 with probability <em>a</em><sup><em>ipart</em></sup>/<em>b</em><sup><em>ipart</em></sup> or 0 otherwise. (Or generate, at random, <em>ipart</em> many numbers that are each 1 with probability <em>a</em>/<em>b</em> or 0 otherwise, then multiply them all into one number.)  If that number is 0, return 0.</li>
<li>Return 1.</li>
</ol></li>
<li>Set <em>i</em> to 1.</li>
<li>With probability <em>a</em>/<em>b</em>, return 1.</li>
<li>Otherwise, with probability <em>x</em>/(<em>y</em>*<em>i</em>), return 0.</li>
<li>Add 1 to <em>i</em> and go to step 6.</li>
</ol>

<p><a id=exp_minus__x___y></a></p>

<h4>exp(&minus;<em>x</em>/<em>y</em>)</h4>

<p>This algorithm takes integers <em>x</em> &ge; 0 and <em>y</em> &gt; 0 and outputs 1 with probability <code>exp(-x/y)</code> or 0 otherwise. It originates from (Canonne et al. 2020)[^52].</p>

<ol>
<li>Special case: If <em>x</em> is 0, return 1. (This is because the probability becomes <code>exp(0) = 1</code>.)</li>
<li>If <code>x &gt; y</code> (so <em>x</em>/<em>y</em> is greater than 1), call this algorithm (recursively) <code>floor(x/y)</code> times with <em>x</em> = <em>y</em> = 1 and once with <em>x</em> = <em>x</em> &minus; floor(<em>x</em>/<em>y</em>) * <em>y</em> and <em>y</em> = <em>y</em>.  Return 1 if all these calls return 1; otherwise, return 0.</li>
<li>Set <em>r</em> to 1 and <em>i</em> to 1.</li>
<li>Return <em>r</em> with probability (<em>y</em> * <em>i</em> &minus; <em>x</em>) / (<em>y</em> * <em>i</em>).</li>
<li>Set <em>r</em> to 1 &minus; <em>r</em>, add 1 to <em>i</em>, and go to step 4.</li>
</ol>

<p><a id=exp_minus__z></a></p>

<h4>exp(&minus;<em>z</em>)</h4>

<p>This algorithm is similar to the previous algorithm, except that the exponent, <em>z</em>, can be any real number 0 or greater, as long as <em>z</em> can be rewritten as the sum of one or more components whose fractional parts can each be simulated by a Bernoulli factory algorithm that outputs heads with probability equal to that fractional part. (This makes use of the identity exp(&minus;a) = exp(&minus;b) * exp(&minus;c).)</p>

<p>More specifically:</p>

<ol>
<li>Decompose <em>z</em> into <em>n</em> &gt; 0 components that sum to <em>z</em>, all of which are greater than 0.  For example, if <em>z</em> = 3.5, it can be decomposed into only one component, 3.5 (whose fractional part is trivial to simulate), and if <em>z</em> = <em>&pi;</em>, it can be decomposed into four components that are all (&pi; / 4), which has a not-so-trivial simulation described earlier on this page.</li>
<li>For each component <em>LC</em>[<em>i</em>] found this way (where <em>i</em> is in [1, <em>n</em>]), let <em>LI</em>[<em>i</em>] be floor(<em>LC</em>[<em>i</em>]) and let <em>LF</em>[<em>i</em>] be <em>LC</em>[<em>i</em>] &minus; floor(<em>LC</em>[<em>i</em>]) (<em>LC</em>[<em>i</em>]&#39;s fractional part).</li>
</ol>

<p>The algorithm is then as follows:</p>

<ul>
<li>For each component <em>LC</em>[<em>i</em>], call the <strong>algorithm for exp(&minus; <em>LI</em>[<em>i</em>]/1)</strong>, and call the <strong>general martingale algorithm</strong> adapted for <strong>exp(&minus;<em>&lambda;</em>)</strong> using the input coin that simulates  <em>LF</em>[<em>i</em>].  If any of these calls returns 0, return 0; otherwise, return 1. (See also (Canonne et al. 2020)[^52].)</li>
</ul>

<p><a id=a___b___z></a></p>

<h4>(<em>a</em>/<em>b</em>)<sup><em>z</em></sup></h4>

<p>This algorithm is similar to the previous algorithm for powering, except that the exponent, <em>z</em>,  can be any real number 0 or greater, as long as <em>z</em> can be rewritten as the sum of one or more components whose fractional parts can each be simulated by a Bernoulli factory algorithm that outputs heads with probability equal to that fractional part. This algorithm makes use of a similar identity as for <code>exp</code> and works only if <em>z</em> is 0 or greater and <em>a</em>/<em>b</em> is in the interval [0, 1].</p>

<p>Decompose <em>z</em> into <em>LC</em>[<em>i</em>], <em>LI</em>[<em>i</em>], and <em>LF</em>[<em>i</em>] just as for the <strong>exp(&minus; <em>z</em>)</strong> algorithm.  The algorithm is then as follows.</p>

<ul>
<li>If <em>z</em> is 0, return 1.  Otherwise, if <em>a</em> is 0, return 0.  Otherwise, for each component <em>LC</em>[<em>i</em>] (until the algorithm returns a number):

<ol>
<li>Call the <strong>algorithm for  (<em>a</em>/<em>b</em>)<sup><em>x</em>/<em>y</em></sup></strong> with <em>a</em> = <em>a</em>, <em>b</em> = <em>b</em>, <em>x</em> = <em>LI</em>[<em>i</em>] and <em>y</em> = 1.  If it returns 0, return 0.</li>
<li>Set <em>j</em> to 1.</li>
<li>Generate a number that is 1 with probability <em>a</em>/<em>b</em> and 0 otherwise.  If that number is 1, abort these steps and move on to the next component or, if there are no more components, return 1.</li>
<li>Flip the input coin that simulates  <em>LF</em>[<em>i</em>] (which is the exponent); if it returns 1, return 0 with probability 1/<em>j</em>.</li>
<li>Add 1 to <em>j</em> and go to substep 2.</li>
</ol></li>
</ul>

<p><a id=1_1_exp__x___y__2_prec__LogisticExp></a></p>

<h4>1 / (1 + exp(<em>x</em> / (<em>y</em> * 2<sup><em>prec</em></sup>)) (LogisticExp)</h4>

<p>This is the probability that the bit at <em>prec</em> (the <em>prec</em><sup>th</sup> bit after the point) is set for an exponential random variate with rate <em>x</em>/<em>y</em>.  This algorithm is a special case of the <strong>logistic Bernoulli factory</strong>.</p>

<ol>
<li>Generate an unbiased random bit.  If that bit is 1 (which happens with probability 1/2), return 1.</li>
<li>Call the <strong>algorithm for exp(&minus; <em>x</em>/(<em>y</em> * 2<sup><em>prec</em></sup>))</strong>.  If the call returns 1, return 1.  Otherwise, go to step 1.</li>
</ol>

<p><a id=1_1_exp__z__2_prec__LogisticExp></a></p>

<h4>1 / (1 + exp(<em>z</em> / 2<sup><em>prec</em></sup>)) (LogisticExp)</h4>

<p>This is similar to the previous algorithm, except that <em>z</em> can be any real number described in the <strong>algorithm for exp(&minus;<em>z</em>)</strong>.</p>

<p>Decompose <em>z</em> into <em>LC</em>[<em>i</em>], <em>LI</em>[<em>i</em>], and <em>LF</em>[<em>i</em>] just as for the <strong>exp(&minus;<em>z</em>)</strong> algorithm.  The algorithm is then as follows.</p>

<ol>
<li>For each component <em>LC</em>[<em>i</em>], create an input coin that does the following: &quot;(a) With probability 1/(2<sup><em>prec</em></sup>), return 1 if the input coin that simulates <em>LF</em>[<em>i</em>] returns 1; (b) Return 0&quot;.</li>
<li>Return 0 with probability 1/2.</li>
<li>Call the <strong>algorithm for exp(&minus; <em>x</em>/<em>y</em>)</strong> with <em>x</em> = <em>LI</em>[1] + <em>LI</em>[2] + ... + <em>LI</em>[<em>n</em>] and <em>y</em> = 2<sup><em>prec</em></sup>.  If this call returns 0, go to step 2.</li>
<li>For each component <em>LC</em>[<em>i</em>], call the <strong>algorithm for exp(&minus;<em>&lambda;</em>)</strong>, using the corresponding input coin for  <em>LC</em>[<em>i</em>] created in step 1. If any of these calls returns 0, go to step 2.  Otherwise, return 1.</li>
</ol>

<p><a id=zeta___3_3_4_and_Other_Zeta_Related_Constants></a></p>

<h4><em>&zeta;</em>(3) * 3 / 4 and Other Zeta-Related Constants</h4>

<p>(Flajolet et al., 2010)[^1].  It can be seen as a triple integral of the function 1/(1 + <em>a</em> * <em>b</em> * <em>c</em>), where <em>a</em>, <em>b</em>, and <em>c</em> are uniform(0, 1) random variates.  This algorithm is given below, but using the two-coin algorithm instead of the even-parity construction.  Here, <em>&zeta;</em>(<em>x</em>) is the Riemann zeta function.</p>

<ol>
<li>Generate three uniform(0, 1) random variates.</li>
<li>Generate an unbiased random bit.  If that bit is 1 (which happens with probability 1/2), return 1.</li>
<li><a href="#Implementation_Notes"><strong>Sample from each of the three numbers</strong></a> generated in step 1.  If all three calls return 1, return 0.  Otherwise, go to step 2. (This implements a triple integral involving the uniform random variates.)</li>
</ol>

<blockquote>
<p><strong>Note:</strong> The triple integral in section 5 of the paper is <em>&zeta;</em>(3) * 3 / 4, not <em>&zeta;</em>(3) * 7 / 8.</p>
</blockquote>

<p>This can be extended to cover any constant of the form <em>&zeta;</em>(<em>k</em>) * (1 &minus; 2<sup>&minus;(<em>k</em> &minus; 1)</sup>) where <em>k</em> &ge; 2 is an integer, as suggested slightly by the Flajolet paper when it mentions <em>&zeta;</em>(5) * 31 / 32 (which should probably read <em>&zeta;</em>(5) * 15 / 16 instead), using the following algorithm.</p>

<ol>
<li>Generate <em>k</em> uniform(0, 1) random variates.</li>
<li>Generate an unbiased random bit.  If that bit is 1 (which happens with probability 1/2), return 1.</li>
<li><a href="#Implementation_Notes"><strong>Sample from each of the <em>k</em> numbers</strong></a> generated in step 1.  If all <em>k</em> calls return 1, return 0.  Otherwise, go to step 2.</li>
</ol>

<p><a id=erf__x__erf_1></a></p>

<h4>erf(<em>x</em>)/erf(1)</h4>

<p>In the following algorithm, <em>x</em> is a real number in the interval [0, 1].</p>

<ol>
<li>Generate a uniform(0, 1) random variate, call it <em>ret</em>.</li>
<li>Set <em>u</em> to point to the same value as <em>ret</em>, and set <em>k</em> to 1.</li>
<li>(In this and the next step, we create <em>v</em>, which is the maximum of two uniform [0, 1] random variates.) Generate two uniform(0, 1) random variates, call them <em>a</em> and <em>b</em>.</li>
<li>If <em>a</em> is less than <em>b</em>, set <em>v</em> to <em>b</em>. Otherwise, set <em>v</em> to <em>a</em>.</li>
<li>If <em>v</em> is less than <em>u</em>, set <em>u</em> to <em>v</em>, then add 1 to <em>k</em>, then go to step 3.</li>
<li>If <em>k</em> is odd, return 1 if <em>ret</em> is less than <em>x</em>, or 0 otherwise. (If <em>ret</em> is implemented as a uniform PSRN, this comparison should be done via the <strong>URandLessThanReal algorithm</strong>, which is described in my <a href="https://peteroupc.github.io/exporand.html"><strong>article on PSRNs</strong></a>.)</li>
<li>Go to step 1.</li>
</ol>

<p>In fact, this algorithm takes advantage of a theorem related to the Forsythe method of random sampling (Forsythe 1972)[^53].  See the section &quot;<a href="#Probabilities_Arising_from_Certain_Permutations"><strong>Probabilities Arising from Certain Permutations</strong></a>&quot; in the appendix for more information.</p>

<blockquote>
<p><strong>Note:</strong> If the last step in the algorithm reads &quot;Return 0&quot; rather than &quot;Go to step 1&quot;, then the algorithm simulates the probability erf(<em>x</em>)*sqrt(&pi;)/2 instead.</p>
</blockquote>

<p><a id=2_1_exp_2_or_1_exp_0_1_exp_1></a></p>

<h4>2 / (1 + exp(2)) or (1 + exp(0)) / (1 + exp(1))</h4>

<p>This algorithm takes advantage of formula 2 mentioned in the section &quot;<a href="#Probabilities_Arising_from_Certain_Permutations"><strong>Probabilities Arising from Certain Permutations</strong></a>&quot; in the appendix.  Here, the relevant probability is rewritten as 1 &minus; (&int;<sub>(&minus;&infin;, 1)</sub> (1 &minus; exp(&minus;max(0, min(1, <em>z</em>)))) * exp(&minus;<em>z</em>) <em>dz</em>) / (&int;<sub>(&minus;&infin;, &infin;)</sub> (1 &minus; exp(&minus;max(0, min(1, <em>z</em>))) * exp(&minus;<em>z</em>) <em>dz</em>).</p>

<ol>
<li>Generate an <strong>exponential</strong> random variate <em>ex</em>, then set <em>k</em> to 1.</li>
<li>Set <em>u</em> to point to the same value as <em>ex</em>.</li>
<li>Generate a <strong>uniform(0,1)</strong> random variate <em>v</em>.</li>
<li>Set <em>stop</em> to 1 if <em>u</em> is less than <em>v</em>, and 0 otherwise.</li>
<li>If <em>stop</em> is 1 and <em>k</em> <strong>is even</strong>, return a number that is 0 if <em>ex</em> is <strong>less than 1</strong>, and 1 otherwise.  Otherwise, if <em>stop</em> is 1, go to step 1.</li>
<li>Set <em>u</em> to <em>v</em>, then add 1 to <em>k</em>, then go to step 3.</li>
</ol>

<p><a id=1_exp_1_1_exp_2></a></p>

<h4>(1 + exp(1)) / (1 + exp(2))</h4>

<p>This algorithm takes advantage of the theorem mentioned in the section &quot;<a href="#Probabilities_Arising_from_Certain_Permutations"><strong>Probabilities Arising from Certain Permutations</strong></a>&quot; in the appendix.  Here, the relevant probability is rewritten as 1 &minus; (&int;<sub>(&minus;&infin;, 1/2)</sub> exp(&minus;max(0, min(1, <em>z</em>))) * exp(&minus;<em>z</em>) <em>dz</em>) / (&int;<sub>(&minus;&infin;, &infin;)</sub> exp(&minus;max(0, min(1, <em>z</em>)) * exp(&minus;<em>z</em>) <em>dz</em>).</p>

<ol>
<li>Generate an <strong>exponential</strong> random variate <em>ex</em>, then set <em>k</em> to 1.</li>
<li>Set <em>u</em> to point to the same value as <em>ex</em>.</li>
<li>Generate a <strong>uniform(0,1)</strong> random variate <em>v</em>.</li>
<li>Set <em>stop</em> to 1 if <em>u</em> is less than <em>v</em>, and 0 otherwise.</li>
<li>If <em>stop</em> is 1 and <em>k</em> <strong>is odd</strong>, return a number that is 0 if <em>ex</em> is <strong>less than 1/2</strong>, and 1 otherwise.  Otherwise, if <em>stop</em> is 1, go to step 1.</li>
<li>Set <em>u</em> to <em>v</em>, then add 1 to <em>k</em>, then go to step 3.</li>
</ol>

<p><a id=1_exp__k__1_exp__k__1></a></p>

<h4>(1 + exp(<em>k</em>)) / (1 + exp(<em>k</em> + 1))</h4>

<p>In this algorithm, <em>k</em> must be an integer 0 or greater.</p>

<ol>
<li>If <em>k</em> is 0, run the <strong>algorithm for 2 / (1 + exp(2))</strong> and return the result.  If <em>k</em> is 1, run the <strong>algorithm for (1 + exp(1)) / (1 + exp(2))</strong> and return the result.</li>
<li>Create a <em>&mu;</em> input coin that runs the sub-algorithm given below.</li>
<li>Run a <a href="#Linear_Bernoulli_Factories"><strong>linear Bernoulli factory</strong></a> using the <em>&mu;</em> input coin, <em>x</em>=2, <em>y</em>=1, and <em>&#x03F5;</em> = 6/10 (6/10 because it&#39;s less than 1 minus (1 + exp(2)) / (1 + exp(2+1))), and return the result of that run.</li>
</ol>

<p>The sub-algorithm referred to is the following (which simulates the probability (1/(1+exp(<em>k</em>+1)) + exp(<em>k</em>)/(1+exp(<em>k</em>+1)))/2):</p>

<ol>
<li>Generate an unbiased random bit.  If that bit is 1, simulate the probability 1/(1+exp(<em>k</em>+1)) as follows:  Do the following process repeatedly, until this algorithm returns a value:

<ol>
<li>Generate an unbiased random bit.  If that bit is 1, return 0.</li>
<li>Run the algorithm for <strong>exp(&minus;<em>x</em>/<em>y</em>)</strong> with <em>x</em>/<em>y</em> = (<em>k</em>+1)/1.  If it returns 1, return 1.</li>
</ol></li>
<li>The bit is 0, so simulate the probability exp(<em>k</em>)/(1+exp(<em>k</em>+1)) as follows:  Do the following process repeatedly, until this algorithm returns a value:

<ol>
<li>Generate an unbiased random bit.  If that bit is 1, run the algorithm for <strong>exp(&minus;<em>x</em>/<em>y</em>)</strong> with <em>x</em>/<em>y</em> = 1/1 and return the result.</li>
<li>Run the algorithm for <strong>exp(&minus;<em>x</em>/<em>y</em>)</strong> with <em>x</em>/<em>y</em> = (<em>k</em>+1)/1.  If it returns 1, return 0.</li>
</ol></li>
</ol>

<p>See &quot;More Algorithms for Arbitrary-Precision Sampling&quot; for another way to sample this probability.</p>

<p><a id=Euler_ndash_Mascheroni_constant___gamma></a></p>

<h4>Euler&ndash;Mascheroni constant <em>&gamma;</em></h4>

<p>The following algorithm to simulate the Euler&ndash;Mascheroni constant <em>&gamma;</em> (about 0.5772) is due to Mendo (2020)[^32].  This solves an open question given in (Flajolet et al., 2010)[^1].   The series used was given by Sondow (2005)[^54]. An algorithm for <em>&gamma;</em> appears here even though it is not yet known whether this constant is irrational.</p>

<ol>
<li>Set <em>&#x03F5;</em> to 1, then set <em>n</em>, <em>lamunq</em>, <em>lam</em>, <em>s</em>, <em>k</em>, and <em>prev</em> to 0 each.</li>
<li>Add 1 to <em>k</em>, then add <em>s</em>/(2<sup><em>k</em></sup>) to <em>lam</em>.</li>
<li>If <em>lamunq</em>+<em>&#x03F5;</em> &le; <em>lam</em> + 1/(2<sup><em>k</em></sup>), go to step 8.</li>
<li>If <em>lamunq</em> &gt; <em>lam</em> + 1/(2<sup><em>k</em></sup>), go to step 8.</li>
<li>If <em>lamunq</em> &gt; <em>lam</em> + 1/(2<sup><em>k</em>+1</sup>) and <em>lamunq</em>+<em>&#x03F5;</em> &lt; 3/(2<sup><em>k</em>+1</sup>), go to step 8.</li>
<li>(This step adds a term of the series for <em>&gamma;</em> to <em>lamunq</em>, and sets <em>&#x03F5;</em> to an upper bound on the error that results if the series is truncated after summing this and the previous terms.) If <em>n</em> is 0, add 1/2 to <em>lamunq</em> and set <em>&#x03F5;</em> to 1/2.  Otherwise, add <em>B</em>(<em>n</em>)/(2*<em>n</em>*(2*<em>n</em>+1)*(2*<em>n</em>+2)) to <em>lamunq</em> and set <em>&#x03F5;</em> to min(<em>prev</em>, (2+<em>B</em>(<em>n</em>)+(1/<em>n</em>))/(16*<em>n</em>*<em>n</em>)), where <em>B</em>(<em>n</em>) is the minimum number of bits needed to store <em>n</em> (or the smallest integer <em>b</em>&ge;1 such that <em>n</em> &lt; 2<sup><em>b</em></sup>).</li>
<li>Add 1 to <em>n</em>, then set <em>prev</em> to <em>&#x03F5;</em>, then go to step 3.</li>
<li>Let <em>bound</em> be <em>lam</em>+1/(2<sup><em>k</em></sup>).  If <em>lamunq</em>+<em>&#x03F5;</em> &le; <em>bound</em>, set <em>s</em> to 0.  Otherwise, if <em>lamunq</em> &gt; <em>bound</em>, set <em>s</em> to 2.  Otherwise, set <em>s</em> to 1.</li>
<li>Generate an unbiased random bit.  If that bit is 1 (which happens with probability 1/2), go to step 2.  Otherwise, return a number that is 0 if <em>s</em> is 0, 1 if <em>s</em> is 2, or an unbiased random bit (either 0 or 1 with equal probability) otherwise.</li>
</ol>

<p><a id=exp_minus__x___y___z___t></a></p>

<h4>exp(&minus;<em>x</em>/<em>y</em>) * <em>z</em>/<em>t</em></h4>

<p>This algorithm is again based on an algorithm due to Mendo (2020)[^32].  In this algorithm, <em>x</em>, <em>y</em>, <em>z</em>, and <em>t</em> are integers greater than 0, except <em>x</em> and/or <em>z</em> may be 0, and must be such that exp(&minus;<em>x</em>/<em>y</em>) * <em>z</em>/<em>t</em> is in the interval [0, 1].</p>

<ol>
<li>If <em>z</em> is 0, return 0.  If <em>x</em> is 0, return a number that is 1 with probability <em>z</em>/<em>t</em> and 0 otherwise.</li>
<li>Set <em>&#x03F5;</em> to 1, then set <em>n</em>, <em>lamunq</em>, <em>lam</em>, <em>s</em>, and <em>k</em> to 0 each.</li>
<li>Add 1 to <em>k</em>, then add <em>s</em>/(2<sup><em>k</em></sup>) to <em>lam</em>.</li>
<li>If <em>lamunq</em>+<em>&#x03F5;</em> &le; <em>lam</em> + 1/(2<sup><em>k</em></sup>), go to step 9.</li>
<li>If <em>lamunq</em> &gt; <em>lam</em> + 1/(2<sup><em>k</em></sup>), go to step 9.</li>
<li>If <em>lamunq</em> &gt; <em>lam</em> + 1/(2<sup><em>k</em>+1</sup>) and <em>lamunq</em>+<em>&#x03F5;</em> &lt; 3/(2<sup><em>k</em>+1</sup>), go to step 8.</li>
<li>(This step adds two terms of exp(&minus;<em>x</em>/<em>y</em>)&#39;s alternating series, multiplied by <em>z</em>/<em>t</em>, to <em>lamunq</em>, and sets <em>&#x03F5;</em> to an upper bound on how close the current sum is to the desired probability.)  Let <em>m</em> be <em>n</em>*2.  Set <em>&#x03F5;</em> to <em>z</em>*<em>x</em><sup><em>m</em></sup>/(<em>t</em>*(<em>m</em>!)*<em>y</em><sup><em>m</em></sup>).  If <em>m</em> is 0, add <em>z</em>*(<em>y</em>&minus;<em>x</em>)/(<em>t</em>*<em>y</em>) to <em>lamunq</em>. Otherwise, add <em>z</em>*<em>x</em><sup><em>m</em></sup>*(<em>m</em>*<em>y</em>&minus;<em>x</em>+<em>y</em>) / (<em>t</em>*<em>y</em><sup><em>m</em>+1</sup>*((<em>m</em>+1)!)) to <em>lamunq</em>.</li>
<li>Add 1 to <em>n</em> and go to step 4.</li>
<li>Let <em>bound</em> be <em>lam</em>+1/(2<sup><em>k</em></sup>).  If <em>lamunq</em>+<em>&#x03F5;</em> &le; <em>bound</em>, set <em>s</em> to 0.  Otherwise, if <em>lamunq</em> &gt; <em>bound</em>, set <em>s</em> to 2.  Otherwise, set <em>s</em> to 1.</li>
<li>Generate an unbiased random bit.  If that bit is 1 (which happens with probability 1/2), go to step 3.  Otherwise, return a number that is 0 if <em>s</em> is 0, 1 if <em>s</em> is 2, or an unbiased random bit (either 0 or 1 with equal probability) otherwise.</li>
</ol>

<p><a id=ln_1__y___z></a></p>

<h4>ln(1+<em>y</em>/<em>z</em>)</h4>

<p>See also the algorithm given earlier for ln(1+<em>&lambda;</em>).  In this algorithm, <em>y</em>/<em>z</em> is a rational number in the interval [0, 1].  (Thus, the special case ln(2) results when <em>y</em>/<em>z</em> = 1/1.)</p>

<ol>
<li>If <em>y</em>/<em>z</em> is 0, return 0.</li>
<li>Do the following process repeatedly, until this algorithm returns a value:

<ol>
<li>Generate an unbiased random bit.  If that bit is 1 (which happens with probability 1/2), return a number that is 1 with probability <em>y</em>/<em>z</em> and 0 otherwise.</li>
<li>Generate a uniform(0, 1) random variate <em>u</em>, if <em>u</em> wasn&#39;t generated yet.</li>
<li><a href="#Implementation_Notes"><strong>Sample from the number <em>u</em></strong></a>, then generate a number that is 1 with probability <em>y</em>/<em>z</em> and 0 otherwise.  If the call returns 1 and the number generated is 1, return 0.</li>
</ol></li>
</ol>

<p><a id=Requests_and_Open_Questions></a></p>

<h2>Requests and Open Questions</h2>

<ol>
<li><p>Besides the algorithms on this page, what simulations exist that are &quot;relatively simple&quot; and succeed with an irrational probability between 0 and 1? What about &quot;relatively simple&quot; Bernoulli factory algorithms for factory functions?  Here, &quot;relatively simple&quot; means that the algorithm:</p>

<ul>
<li>Should use only uniform random integers (or bits) and integer arithmetic.</li>
<li>Does not use floating-point arithmetic or make direct use of square root or transcendental functions.</li>
<li>Does not calculate base-<em>n</em> expansions directly.</li>
<li>Should not use rational arithmetic or increasingly complex approximations, except as a last resort.</li>
</ul>

<p>See also Flajolet et al. (2010)[^1].  There are many ways to describe the irrational probability or factory function. I seek references to papers or books that describe irrational constants or factory functions in any of the following ways:</p>

<ul>
<li>For irrational constants:

<ul>
<li>Simple <a href="#Continued_Fractions"><strong>continued fraction</strong></a> expansions.</li>
<li>Closed shapes inside the unit square whose area is an irrational number.  (Includes algorithms that tell whether a box lies inside, outside, or partly inside or outside the shape.)    <a href="https://peteroupc.github.io/morealg.html#pi___4"><strong>Example.</strong></a></li>
<li>Generate a uniform (<em>x</em>, <em>y</em>) point inside a closed shape, then return 1 with probability <em>x</em>.  For what shapes is the expected value of <em>x</em> an irrational number?  <a href="https://peteroupc.github.io/morealg.html#4_3___pi"><strong>Example.</strong></a></li>
<li>Functions that map [0, 1] to [0, 1] whose integral (area under curve) is an irrational number.</li>
</ul></li>
<li>For Bernoulli factory functions:

<ul>
<li>Functions with any of the following series expansions, using rational arithmetic only:

<ul>
<li>Power series where <em>f</em>(0) is 0 and <em>f</em>(1) is rational or vice versa (see &quot;<a href="https://peteroupc.github.io/bernoulli.html#Certain_Power_Series"><strong>Certain Power Series</strong></a>&quot;).</li>
<li>Series with non-negative terms that can be &quot;tucked&quot; under a discrete probability mass function (see &quot;<a href="https://peteroupc.github.io/bernoulli.html#Convex_Combinations"><strong>Convex Combinations</strong></a>&quot;).</li>
<li>Alternating power series (see &quot;<a href="https://peteroupc.github.io/bernoulli.html#Certain_Power_Series"><strong>Certain Power Series</strong></a>&quot;).</li>
<li>Series with non-negative terms and bounds on the truncation error (see &quot;<a href="https://peteroupc.github.io/bernoulli.html#Certain_Converging_Series"><strong>Certain Converging Series</strong></a>&quot;).</li>
</ul></li>
<li>A way to compute two sequences of polynomials written in Bernstein form that converge from above and below to a factory function as follows: (a) Each sequence&#39;s polynomials must have coefficients lying in [0, 1], and be of increasing degree; (b) the degree-<em>n</em> polynomials&#39; coefficients must lie at or &quot;inside&quot; those of the previous upper polynomial and the previous lower one (once the polynomials are elevated to degree <em>n</em>).  For a formal statement of these polynomials, see my <a href="https://mathoverflow.net/questions/379858"><strong>question on MathOverflow</strong></a>.<br><br>The <a href="https://peteroupc.github.io/bernsupp.html"><strong>supplemental notes</strong></a> include formulas for computing these polynomials for large classes of factory functions, but none of them ensure a finite expected number of coin flips in general, and it is suspected that a finite number of flips isn&#39;t possible unless the factory function is C<sup>2</sup> continuous (has two or more continuous &quot;slope&quot; functions).  Thus one question is: Given a C<sup>2</sup> continuous factory function, are there practical algorithms for building polynomials described here, where the expected number of coin flips is finite (besides the algorithms in this article or the supplemental notes)?</li>
</ul></li>
</ul></li>
<li><p>Let a permutation class (such as numbers in descending order) and two continuous probability distributions D and E be given.  Consider the following algorithm: Generate a sequence of independent random variates (where the first is distributed as D and the rest as E) until the sequence no longer follows the permutation class, then return <em>n</em>, which is how many numbers were generated this way minus 1.  In this case:</p>

<ol>
<li>What is the probability that <em>n</em> is returned?</li>
<li>What is the probability that <em>n</em> is odd or even or belongs to a certain class of numbers?</li>
<li>For each <em>x</em>, what is the probability that the first generated number is <em>x</em> or less given that <em>n</em> is odd? ...given that <em>n</em> is even?</li>
</ol>

<p>Obviously, these answers depend on the specific permutation class and/or distributions <em>D</em> and <em>E</em>. See also my Stack Exchange question <a href="https://stats.stackexchange.com/questions/499864/probabilities-arising-from-permutations"><strong>Probabilities arising from permutations</strong></a>.</p></li>
<li>Is there a simpler or faster way to implement the base-2 or natural logarithm of binomial coefficients?  See the example in the section &quot;<a href="#Certain_Converging_Series"><strong>Certain Converging Series</strong></a>&quot;.</li>
<li><p>Part of the reverse-time martingale algorithm of Łatuszyński et al. (2009/2011)[^24] (see &quot;<a href="#General_Factory_Functions"><strong>General Factory Functions</strong></a>&quot;) to simulate a factory function <em>f</em>(<em>&lambda;</em>) is as follows.  For each <em>n</em> starting with 1:</p>

<ol>
<li>Flip the input coin, and compute the <em>n</em><sup>th</sup> upper and lower bounds of <em>f</em> given the number of heads so far, call them <em>L</em> and <em>U</em>.</li>
<li>Compute the (<em>n</em>&minus;1)<sup>th</sup> upper and lower bounds of <em>f</em> given the number of heads so far, call them <em>L&prime;</em> and <em>U&prime;</em>.  (These bounds must be the same regardless of the outcomes of future coin flips, and the interval [<em>L&prime;</em>, <em>U&prime;</em>] must equal or entirely contain the interval [<em>L</em>, <em>U</em>].)</li>
</ol>

<p>These parts of the algorithm appear to work for any two sequences of functions (not just polynomials) that converge to <em>f</em>, where <em>L</em> or <em>L&prime;</em> and <em>U</em> or <em>U&prime;</em> are their lower and upper bound approximations.  The section on general factory functions shows how this algorithm can be implemented for polynomials.  But how do these steps work when the approximating functions (the functions that converge to <em>f</em>) are rational functions whose coefficients are integers? Rational functions whose coefficients are rational numbers? Arbitrary approximating functions?</p></li>
<li>A <em>pushdown automaton</em> is a state machine that holds a stack of symbols.  Mossel and Peres (2005)[^3] investigated which functions (<em>f</em>(<em>&lambda;</em>)) can be simulated by these machines when they&#39;re given an infinite &quot;tape&quot; of flips of a coin that shows heads with probability <em>&lambda;</em>.  They showed that pushdown automata can simulate only <em>algebraic functions</em>, but perhaps not all of them. (See &quot;<a href="https://peteroupc.github.io/bernoulli.html#Certain_Algebraic_Functions"><strong>Certain Algebraic Functions</strong></a>&quot;.)  The question is: What is the exact class of algebraic functions a pushdown automaton can simulate?  Can it simulate the functions min(<em>&lambda;</em>, 1&minus;<em>&lambda;</em>) and <em>&lambda;</em><sup>1/<em>p</em></sup> where <em>p</em>&gt;2 is a prime number?  I have written an <a href="https://peteroupc.github.io/morealg.html#Pushdown_Automata_and_Algebraic_Functions"><strong>article appendix</strong></a> showing my progress, but are there other results on this question?</li>
<li>A factory function <em>f</em>(<em>&lambda;</em>) is <em>strongly simulable</em> if there is an algorithm to toss heads with probability <em>f</em>(<em>&lambda;</em>) using only a coin that shows heads with probability <em>&lambda;</em> and no other randomness.  Keane and O&#39;Brien (1994) showed already that <em>f</em>(<em>&lambda;</em>) is strongly simulable if neither 0 nor 1 is in <em>f</em>&#39;s domain.  It&#39;s also easy to show that if <em>f</em> is strongly simulable, then <em>f</em>(0) and <em>f</em>(1) must each be 0, 1, or undefined.  Is this a <em>sufficient condition</em> to be strongly simulable?  I have written an <a href="https://peteroupc.github.io/bernsupp.html#Which_functions_don_t_require_outside_randomness_to_simulate"><strong>article appendix</strong></a> showing my progress, but are there other results on this question?</li>
</ol>

<p><a id=Correctness_and_Performance_Charts></a></p>

<h2>Correctness and Performance Charts</h2>

<p>Charts showing the correctness and performance of some of these algorithms are found in a <a href="https://peteroupc.github.io/bernoullicorrect.html"><strong>separate page</strong></a>.</p>

<p><a id=Acknowledgments></a></p>

<h2>Acknowledgments</h2>

<p>I acknowledge Luis Mendo, who responded to one of my open questions, as well as C. Karney.</p>

<p><a id=Notes></a></p>

<h2>Notes</h2>

<p>[^1]: Flajolet, P., Pelletier, M., Soria, M., &quot;<a href="https://arxiv.org/abs/0906.5560"><strong>On Buffon machines and numbers</strong></a>&quot;, arXiv:0906.5560  [math.PR], 2010.</p>

<p>[^2]: Keane,  M.  S.,  and  O&#39;Brien,  G.  L., &quot;A Bernoulli factory&quot;, <em>ACM Transactions on Modeling and Computer Simulation</em> 4(2), 1994.</p>

<p>[^3]: There is an analogue to the Bernoulli factory problem called the <em>quantum Bernoulli factory</em>, with the same goal of simulating functions of unknown probabilities, but this time with algorithms that employ quantum-mechanical operations (unlike <em>classical</em> algorithms that employ no such operations).  However, quantum-mechanical programming is far from being accessible to most programmers at the same level as classical programming, and will likely remain so for the foreseeable future.  For this reason, the <em>quantum Bernoulli factory</em> is outside the scope of this document, but it should be noted that more factory functions can be &quot;constructed&quot; using quantum-mechanical operations than by classical algorithms.  For example, a factory function defined in [0, 1] has to meet the requirements proved by Keane and O&#39;Brien except it can touch 0 and/or 1 at a finite number of points in the domain (Dale, H., Jennings, D. and Rudolph, T., 2015, &quot;Provable quantum advantage in randomness processing&quot;, <em>Nature communications</em> 6(1), pp. 1-4).</p>

<p>[^4]: Huber, M., &quot;<a href="https://arxiv.org/abs/1308.1562v2"><strong>Nearly optimal Bernoulli factories for linear functions</strong></a>&quot;, arXiv:1308.1562v2  [math.PR], 2014.</p>

<p>[^5]: Yannis Manolopoulos. 2002. &quot;Binomial coefficient computation: recursion or iteration?&quot;, SIGCSE Bull. 34, 4 (December 2002), 65–67. DOI: <a href="https://doi.org/10.1145/820127.820168."><strong>https://doi.org/10.1145/820127.820168.</strong></a></p>

<p>[^6]: Goyal, V. and Sigman, K., 2012. On simulating a class of Bernstein polynomials. ACM Transactions on Modeling and Computer Simulation (TOMACS), 22(2), pp.1-5.</p>

<p>[^7]: Weikang Qian, Marc D. Riedel, Ivo Rosenberg, &quot;Uniform approximation and Bernstein polynomials with coefficients in the unit interval&quot;, <em>European Journal of Combinatorics</em> 32(3), 2011,
<a href="https://doi.org/10.1016/j.ejc.2010.11.004"><strong>https://doi.org/10.1016/j.ejc.2010.11.004</strong></a> <a href="http://www.sciencedirect.com/science/article/pii/S0195669810001666"><strong>http://www.sciencedirect.com/science/article/pii/S0195669810001666</strong></a></p>

<p>[^8]: Wästlund, J., &quot;<a href="http://www.math.chalmers.se/%7Ewastlund/coinFlip.pdf"><strong>Functions arising by coin flipping</strong></a>&quot;, 1999.</p>

<p>[^9]: Then <em>j</em> is a <em>binomial</em> random variate expressing the number of successes in <em>n</em> trials that each succeed with probability <em>&lambda;</em>.</p>

<p>[^10]: Qian, W. and Riedel, M.D., 2008, June. The synthesis of robust polynomial arithmetic with stochastic logic. In 2008 45th ACM/IEEE Design Automation Conference (pp. 648-653). IEEE.</p>

<p>[^11]: Thomas, A.C., Blanchet, J., &quot;<a href="https://arxiv.org/abs/1106.2508v3"><strong>A Practical Implementation of the Bernoulli Factory</strong></a>&quot;, arXiv:1106.2508v3  [stat.AP], 2012.</p>

<p>[^12]: S. Ray, P.S.V. Nataraj, &quot;A Matrix Method for Efficient Computation of Bernstein Coefficients&quot;, Reliable Computing 17(1), 2012.</p>

<p>[^13]: And this shows that the polynomial couldn&#39;t be simulated if <em>c</em> were allowed to be 1, since the required degree would be infinity; in fact, the polynomial would touch 1 at the point 0.5 in this case, ruling out its simulation by any algorithm (see &quot;About Bernoulli Factories&quot;, earlier).</p>

<p>[^14]: Niazadeh, R., Leme, R.P., Schneider, J., &quot;<a href="https://dl.acm.org/doi/10.1145/3406325.3451072"><strong>Combinatorial Bernoulli Factories: Matchings, Flows, and Polytopes</strong></a>&quot;, in <em>Proceedings of the 53rd Annual ACM SIGACT Symposium on Theory of Computing</em>, pp. 833-846, June 2021; also at <a href="https://arxiv.org/abs/2011.03865"><strong>https://arxiv.org/abs/2011.03865.pdf</strong></a>.</p>

<p>[^15]: Mossel, Elchanan, and Yuval Peres. New coins from old: computing with unknown bias. Combinatorica, 25(6), pp.707-724, 2005.</p>

<p>[^16]: Nacu, Şerban, and Yuval Peres. &quot;<a href="https://projecteuclid.org/euclid.aoap/1106922322"><strong>Fast simulation of new coins from old</strong></a>&quot;, The Annals of Applied Probability 15, no. 1A (2005): 93-115.</p>

<p>[^17]: Morina, G., Łatuszyński, K., et al., &quot;<a href="https://arxiv.org/abs/1912.09229"><strong>From the Bernoulli Factory to a Dice Enterprise via Perfect Sampling of Markov Chains</strong></a>&quot;, arXiv:1912.09229 [math.PR], 2019/2020.</p>

<p>[^18]: Propp, J.G., Wilson, D.B., &quot;Exact sampling with coupled Markov chains and applications to statistical mechanics&quot;, 1996.</p>

<p>[^19]: The probability given in Theorem 3.2 of the Flajolet paper, namely just &quot;&sum; <sub><em>k</em> = 0, 1, 2, ... </sub> (W(<em>k</em>) * (<em>&lambda;</em>/2)<sup><em>k</em></sup>)&quot;, appears to be incorrect in conjunction with Figure 4 of that paper.</p>

<p>[^20]: Flajolet, Ph., &quot;Analytic models and ambiguity of context-free languages&quot;, <em>Theoretical Computer Science</em> 49, pp. 283-309, 1987</p>

<p>[^21]: Here, &quot;choose(<em>g</em>, <em>g</em>/<em>t</em>)&quot; means that out of <em>g</em> letters, <em>g</em>/<em>t</em> of them must be A&#39;s, and &quot;(<em>&beta;</em>&minus;1)<sup><em>g</em>&minus;<em>g</em>/<em>t</em></sup>&quot; is the number of words that have <em>g</em>&minus;<em>g</em>/<em>t</em> letters other than A, given that the remaining letters were A&#39;s.</p>

<p>[^22]: In this formula, which is similar to Example 2&#39;s, the division by <em>&beta;</em><sup><em>g</em>*<em>&alpha;&minus;g</em></sup> brings W(<em>g</em>) from the interval [0, <em>&beta;</em><sup><em>g</em>*<em>&alpha;</em></sup>] ((<em>g</em>*<em>&alpha;</em>)-letter words) to the interval [0, <em>&beta;</em><sup><em>g</em></sup>] (<em>g</em>-letter words), as required by the main algorithm.</p>

<p>[^23]: Mendo, Luis. &quot;An asymptotically optimal Bernoulli factory for certain functions that can be expressed as power series.&quot; Stochastic Processes and their Applications 129, no. 11 (2019): 4366-4384.</p>

<p>[^24]: Łatuszyński, K., Kosmidis, I.,  Papaspiliopoulos, O., Roberts, G.O., &quot;<a href="https://arxiv.org/abs/0907.4018v2"><strong>Simulating events of unknown probabilities via reverse time martingales</strong></a>&quot;, arXiv:0907.4018v2 [stat.CO], 2009/2011.</p>

<p>[^25]: Flegal, J.M., Herbei, R., &quot;Exact sampling from intractible probability distributions via a Bernoulli factory&quot;, <em>Electronic Journal of Statistics</em> 6, 10-37, 2012.</p>

<p>[^26]: Holtz, O., Nazarov, F., Peres, Y., &quot;New Coins from Old, Smoothly&quot;, <em>Constructive Approximation</em> 33 (2011).</p>

<p>[^27]: Brassard, G., Devroye, L., Gravel, C., &quot;Remote Sampling with Applications to General Entanglement Simulation&quot;, <em>Entropy</em> 2019(21)(92), <a href="https://doi.org/10.3390/e21010092"><strong>https://doi.org/10.3390/e21010092</strong></a> .</p>

<p>[^28]: Devroye, L., <a href="http://luc.devroye.org/rnbookindex.html"><strong><em>Non-Uniform Random Variate Generation</em></strong></a>, 1986.</p>

<p>[^29]: Bill Gosper, &quot;Continued Fraction Arithmetic&quot;, 1978.</p>

<p>[^30]: Borwein, J. et al. “Continued Logarithms and Associated Continued Fractions.” <em>Experimental Mathematics</em> 26 (2017): 412 - 429.</p>

<p>[^31]: Penaud, J.G., Roques, O., &quot;Tirage à pile ou face de mots de Fibonacci&quot;, <em>Discrete Mathematics</em> 256, 2002.</p>

<p>[^32]: Mendo, L., &quot;<a href="https://arxiv.org/abs/2010.14901"><strong>Simulating a coin with irrational bias using rational arithmetic</strong></a>&quot;, arXiv:2010.14901 [math.PR], 2020.</p>

<p>[^33]: The error term, which follows from the so-called Lagrange remainder for Taylor series, has a numerator of 2 because 2 is higher than the maximum value at the point 1 (in cosh(1)) that <em>f</em>&#39;s slope, slope-of-slope, etc. functions can achieve.</p>

<p>[^34]: Kozen, D., <a href="http://www.cs.cornell.edu/%7Ekozen/Papers/Coinflip.pdf"><strong>&quot;Optimal Coin Flipping&quot;</strong></a>, 2014.</p>

<p>[^35]: K. Bringmann, F. Kuhn, et al., “Internal DLA: Efficient Simulation of a Physical Growth Model.” In: <em>Proc. 41st International Colloquium on Automata, Languages, and Programming (ICALP&#39;14)</em>, 2014.</p>

<p>[^36]: Shaddin Dughmi, Jason D. Hartline, Robert Kleinberg, and Rad Niazadeh. 2017. Bernoulli Factories and Black-Box Reductions in Mechanism Design. In <em>Proceedings of 49th Annual ACM SIGACT Symposium on the Theory of Computing</em>, Montreal, Canada, June 2017 (STOC’17).</p>

<p>[^37]: Huber, M., &quot;<a href="https://arxiv.org/abs/1507.00843v2"><strong>Optimal linear Bernoulli factories for small mean problems</strong></a>&quot;, arXiv:1507.00843v2 [math.PR], 2016.</p>

<p>[^38]: Schmon, S.M., Doucet, A. and Deligiannidis, G., 2019, April. Bernoulli race particle filters. In The 22nd International Conference on Artificial Intelligence and Statistics (pp. 2350-2358).</p>

<p>[^39]: Agrawal, S., Vats, D., Łatuszyński, K. and Roberts, G.O., 2021. &quot;<a href="https://arxiv.org/abs/2104.02020."><strong>Optimal Scaling of MCMC Beyond Metropolis</strong></a>&quot;, arXiv:2104.02020.</p>

<p>[^40]: Another algorithm for exp(&minus;<em>&lambda;</em>) involves the von Neumann schema described in the appendix, but unfortunately, it converges slowly as <em>&lambda;</em> approaches 1.</p>

<p>[^41]: Gonçalves, F. B., Łatuszyński, K. G., Roberts, G. O. (2017).  Exact Monte Carlo likelihood-based inference for jump-diffusion processes.</p>

<p>[^42]: Vats, D., Gonçalves, F. B., Łatuszyński, K. G., Roberts, G. O., &quot;Efficient Bernoulli factory MCMC for intractable posteriors&quot;, <em>Biometrika</em>, 2021 (also in arXiv:2004.07471 [stat.CO]).</p>

<p>[^43]: There are two other algorithms for this function, but they both converge very slowly when <em>&lambda;</em> is very close to 1.  One is the general martingale algorithm, since when <em>&lambda;</em> is in [0, 1], this function is an alternating series of the form <code>1 - x + x^2 - x^3 + ...</code>, whose coefficients are 1, 1, 1, 1, ....  The other is the so-called &quot;even-parity&quot; construction from Flajolet et al. 2010: &quot;(1) Flip the input coin.  If it returns 0, return 1. (2) Flip the input coin.  If it returns 0, return 0.  Otherwise, go to step 1.&quot;</p>

<p>[^44]: Peres, N., Lee, A.R. and Keich, U., 2021. Exactly computing the tail of the Poisson-Binomial Distribution. ACM Transactions on Mathematical Software (TOMS), 47(4), pp.1-19.</p>

<p>[^45]: Lee, A., Doucet, A. and Łatuszyński, K., 2014. &quot;<a href="https://arxiv.org/abs/1407.5770v1"><strong>Perfect simulation using atomic regeneration with application to Sequential Monte Carlo</strong></a>&quot;, arXiv:1407.5770v1  [stat.CO].</p>

<p>[^46]: Morina, Giulio (2021) Extending the Bernoulli Factory to a dice enterprise. PhD thesis, University of Warwick.</p>

<p>[^47]: Huber, M., &quot;<a href="https://arxiv.org/abs/1907.06748v1"><strong>Designing perfect simulation algorithms using local correctness</strong></a>&quot;, arXiv:1907.06748v1 [cs.DS], 2019.</p>

<p>[^48]: The even-parity version from Flajolet et al. (2010) could be written as follows.  Do the following process repeatedly, until this algorithm returns a value: (1) Generate a uniform(0, 1) random variate <em>u</em>, if <em>u</em> wasn&#39;t generated yet; (2) <a href="#Implementation_Notes"><strong>Sample from the number <em>u</em></strong></a> twice, and flip the input coin twice.  If any of these calls or flips returns 0, return 1; (3) Sample from the number <em>u</em> twice, and flip the input coin twice.  If any of these calls or flips returns 0, return 0.</p>

<p>[^49]: The even-parity version from Flajolet et al. (2010) could be written as follows.  Do the following process repeatedly, until this algorithm returns a value: (1) Flip the input coin.  If it returns 0, flip the coin again and return the result; (2) Generate a uniform(0, 1) random variate <em>u</em>, if <em>u</em> wasn&#39;t generated yet; (3) <a href="#Implementation_Notes"><strong>Sample from the number <em>u</em></strong></a>. If the result is 0, flip the input coin and return the result; (4)  Flip the input coin.  If it returns 0, return 0; (5) Sample from the number <em>u</em>.  If the result is 0, return 0.</p>

<p>[^50]: One of the only implementations I could find of this, if not the only, was a <a href="https://github.com/derekelkins/buffon/blob/master/Data/Distribution/Buffon.hs"><strong>Haskell implementation</strong></a>.</p>

<p>[^51]: Another algorithm for this function uses the general martingale algorithm, but uses more bits on average as <em>&lambda;</em> approaches 1.  Here, the alternating series is <code>1 - x + x^2/2 - x^3/3 + ...</code>, whose coefficients are 1, 1, 1/2, 1/3, ...</p>

<p>[^52]: Canonne, C., Kamath, G., Steinke, T., &quot;<a href="https://arxiv.org/abs/2004.00010"><strong>The Discrete Gaussian for Differential Privacy</strong></a>&quot;, arXiv:2004.00010 [cs.DS], 2020.</p>

<p>[^53]: Forsythe, G.E., &quot;Von Neumann&#39;s Comparison Method for Random Sampling from the Normal and Other Distributions&quot;, <em>Mathematics of Computation</em> 26(120), October 1972.</p>

<p>[^54]: Sondow, Jonathan. “New Vacca-Type Rational Series for Euler&#39;s Constant and Its &#39;Alternating&#39; Analog ln 4/<em>&pi;</em>.”, 2005.</p>

<p>[^55]: von Neumann, J., &quot;Various techniques used in connection with random digits&quot;, 1951.</p>

<p>[^56]: Pae, S., &quot;Random number generation using a biased source&quot;, dissertation, University of Illinois at Urbana-Champaign, 2005.</p>

<p>[^57]: Peres, Y., &quot;Iterating von Neumann&#39;s procedure for extracting random bits&quot;, Annals of Statistics 1992,20,1, p. 590-597.</p>

<p>[^58]: Flajolet, P., Sedgewick, R., <em>Analytic Combinatorics</em>, Cambridge University Press, 2009.</p>

<p>[^59]: Monahan, J.. &quot;Extensions of von Neumann’s method for generating random variables.&quot; Mathematics of Computation 33 (1979): 1065-1069.</p>

<p>[^60]: Tsai, Yi-Feng, Farouki, R.T., &quot;Algorithm 812: BPOLY: An Object-Oriented Library of Numerical Algorithms for Polynomials in Bernstein Form&quot;, <em>ACM Trans. Math. Softw.</em> 27(2), 2001.</p>

<p>[^61]: There is another algorithm for tanh(<em>&lambda;</em>), based on Lambert&#39;s continued fraction for tanh(.), but it works only for <em>&lambda;</em> in [0, 1].  The algorithm begins with <em>k</em> equal to 1.  Then: (1) If <em>k</em> is 1, generate an unbiased random bit, then if that bit is 1, flip the input coin and return the result; (2) If <em>k</em> is greater than 1, then with probability <em>k</em>/(1+<em>k</em>), flip the input coin twice, and if either or both flips returned 0, return 0, and if both flips returned 1, return a number that is 1 with probability 1/<em>k</em> and 0 otherwise; (3) Do a separate run of the currently running algorithm, but with <em>k</em> = <em>k</em> + 2.  If the separate run returns 1, return 0; (4) Go to step 2.</p>

<p><a id=Appendix></a></p>

<h2>Appendix</h2>

<p>&nbsp;</p>

<p><a id=Using_the_Biased_Coin_Alone_for_Randomness></a></p>

<h3>Using the Biased Coin Alone for Randomness</h3>

<p>A function <em>f</em>(<em>&lambda;</em>) is <em>strongly simulable</em> (Keane and O&#39;Brien 1994)[^23] if there is a Bernoulli factory algorithm for that function that uses <em>only</em> the input coin (&quot;biased coin&quot;) as its source of randomness.</p>

<p>If a Bernoulli factory algorithm uses a fair coin, it can often generate flips of the fair coin using the input coin instead, with the help of <a href="https://peteroupc.github.io/randextract.html"><strong><em>randomness extraction</em></strong></a> techniques.</p>

<blockquote>
<p><strong>Example:</strong> If a Bernoulli factory algorithm would generate an unbiased random bit, instead it could flip the input coin twice until the flip returns 0 then 1 or 1 then 0 this way, then take the result as 0 or 1, respectively (von Neumann 1951)[^55].  But this trick works only if the input coin&#39;s probability of heads is neither 0 nor 1.</p>
</blockquote>

<p>When Keane and O&#39;Brien (1994)[^23] introduced Bernoulli factories, they showed already that <em>f</em>(<em>&lambda;</em>) is strongly simulable whenever it admits a Bernoulli factory and its domain includes neither 0 nor 1 (so the input coin doesn&#39;t show heads every time or tails every time) &mdash; just use the von Neumann trick as in the example above.  But does <em>f</em> remain strongly simulable if its domain includes 0 and/or 1?  That&#39;s a complexer question; see the <a href="https://peteroupc.github.io/bernsupp.html#Which_functions_don_t_require_outside_randomness_to_simulate"><strong>supplemental notes</strong></a>.</p>

<p><a id=The_Entropy_Bound></a></p>

<h3>The Entropy Bound</h3>

<p>There is a lower bound on the average number of coin flips needed to turn a coin with one probability of heads (<em>&lambda;</em>) into a coin with another (<em>&tau;</em> = <em>f</em>(<em>&lambda;</em>)).  It&#39;s called the <em>entropy bound</em> (see, e.g., (Pae 2005)[^56], (Peres 1992)[^57]) and is calculated as&mdash;</p>

<ul>
<li>((<em>&tau;</em> &minus; 1) * ln(1 &minus; <em>&tau;</em>) &minus; <em>&tau;</em> * ln(<em>&tau;</em>)) / ((<em>&lambda;</em> &minus; 1) * ln(1 &minus; <em>&lambda;</em>) &minus; <em>&lambda;</em> * ln(<em>&lambda;</em>)).</li>
</ul>

<p>For example, if <em>f</em>(<em>&lambda;</em>) is a constant, an algorithm whose only randomness comes from the input coin will require more coin flips to simulate that constant, the more strongly that coin leans towards heads or tails.  But this formula works only for such algorithms, even if <em>f</em> isn&#39;t a constant.</p>

<p>For certain values of <em>&lambda;</em>, Kozen (2014)[^34] showed a tighter lower bound of this kind, but in general, this bound is not so easy to describe and assumes <em>&lambda;</em> is known.  However, if <em>&lambda;</em> is 1/2 (the input coin is unbiased), this bound is simple: at least 2 flips of the input coin are needed on average to simulate a known constant <em>&tau;</em>, except when <em>&tau;</em> is a multiple of 1/(2<sup><em>n</em></sup>) for any integer <em>n</em>.</p>

<p><a id=Bernoulli_Factories_and_Unbiased_Estimation></a></p>

<h3>Bernoulli Factories and Unbiased Estimation</h3>

<p>If an algorithm&mdash;</p>

<ul>
<li>takes flips of a coin with an unknown probability of heads (<em>&lambda;</em>), and</li>
<li>produces heads with a probability that depends on <em>&lambda;</em> (<em>f</em>(<em>&lambda;</em>)) and tails otherwise,</li>
</ul>

<p>the algorithm acts as an <em>unbiased estimator</em> of <em>f</em>(<em>&lambda;</em>) that produces estimates in [0, 1] with probability 1 (Łatuszyński et al. 2009/2011)[^24]. (And an estimator like this is possible only if <em>f</em> is a factory function; see Łatuszyński.) Because the algorithm is <em>unbiased</em>, its expected value (or mean) is <em>f</em>(<em>&lambda;</em>).  Here&#39;s one result of unbiasedness: Take a sample of <em>n</em> independent outputs of the algorithm, sum them, then divide by <em>n</em>.  Then with probability 1, this <em>average</em> approaches <em>f</em>(<em>&lambda;</em>) as <em>n</em> gets <em>large</em>.  This is the <em>law of large numbers</em> in action.</p>

<p>On the other hand&mdash;</p>

<ul>
<li>estimating <em>&lambda;</em> as <em>&lambda;&prime;</em> (e.g., by averaging multiple flips of a <em>&lambda;</em>-coin), then</li>
<li>calculating <em>f</em>(<em>&lambda;&prime;</em>),</li>
</ul>

<p>is not necessarily an unbiased estimator of <em>f</em>(<em>&lambda;</em>), even if <em>&lambda;&prime;</em> is an unbiased estimator.</p>

<p>This page focuses on <em>unbiased</em> estimators because &quot;exact sampling&quot; depends on it. See also (Mossel and Peres 2005, section 4)[^15].</p>

<blockquote>
<p><strong>Note:</strong> Bias and variance are the two sources of error in a randomized estimation algorithm.  An unbiased estimator has no bias, but is not without error.  In the case at hand here, the variance of a Bernoulli factory for <em>f</em>(<em>&lambda;</em>) equals <em>f</em>(<em>&lambda;</em>) * (1&minus;<em>f</em>(<em>&lambda;</em>)) and can go as high as 1/4.  There are ways to reduce this variance, which are outside the scope of this document.  An estimation algorithm&#39;s <em>mean squared error</em> equals variance plus square of bias.</p>
</blockquote>

<p><a id=Correctness_Proof_for_the_Continued_Logarithm_Simulation_Algorithm></a></p>

<h3>Correctness Proof for the Continued Logarithm Simulation Algorithm</h3>

<p><strong>Theorem.</strong> <em>If the algorithm given in &quot;Continued Logarithms&quot; terminates with probability 1, it returns 1 with probability exactly equal to the number represented by the continued logarithm c, and 0 otherwise.</em></p>

<p><em>Proof.</em> This proof of correctness takes advantage of Huber&#39;s &quot;fundamental theorem of perfect simulation&quot; (Huber 2019)[^47].  Using Huber&#39;s theorem requires proving two things:</p>

<ul>
<li>The algorithm finishes with probability 1 by assumption.</li>
<li>Second, we show the algorithm is locally correct when the recursive call in the loop is replaced with a &quot;black box&quot; that simulates the correct &quot;continued sub-logarithm&quot;.  If step 1 reaches the last coefficient, the algorithm obviously passes with the correct probability.  Otherwise, we will be simulating the probability (1 / 2<sup><em>c</em>[<em>i</em>]</sup>) / (1 + <em>x</em>), where <em>x</em> is the &quot;continued sub-logarithm&quot; and will be at most 1 by construction.  Step 2 defines a loop that divides the probability space into three pieces: the first piece takes up one half, the second piece (in the second substep) takes up a portion of the other half (which here is equal to <em>x</em>/2), and the last piece is the &quot;rejection piece&quot; that reruns the loop.  Since this loop changes no variables that affect later iterations, each iteration acts like an acceptance/rejection algorithm already proved to be a perfect simulator by Huber.  The algorithm will pass at the first substep with probability <em>p</em> = (1 / 2<sup><em>c</em>[<em>i</em>]</sup>) / 2 and fail either at the first substep of the loop with probability <em>f1</em> = (1 &minus; 1 / 2<sup><em>c</em>[<em>i</em>]</sup>) / 2, or at the second substep with probability <em>f2</em> = <em>x</em>/2 (all these probabilities are relative to the whole iteration).  Finally, dividing the passes by the sum of passes and fails (<em>p</em> / (<em>p</em> + <em>f1</em> + <em>f2</em>)) leads to (1 / 2<sup><em>c</em>[<em>i</em>]</sup>) / (1 + <em>x</em>), which is the probability we wanted.</li>
</ul>

<p>Since both conditions of Huber&#39;s theorem are satisfied, this completes the proof. &#x25a1;</p>

<p><a id=Correctness_Proof_for_Continued_Fraction_Simulation_Algorithm_3></a></p>

<h3>Correctness Proof for Continued Fraction Simulation Algorithm 3</h3>

<p><strong>Theorem.</strong> <em>Suppose a generalized continued fraction&#39;s partial numerators are b[i] and all greater than 0, and its partial denominators are a[i] and all 1 or greater, and suppose further that each b[i]/a[i] is 1 or less. Then the algorithm given as Algorithm 3 in &quot;Continued Fractions&quot; returns 1 with probability exactly equal to the number represented by that continued fraction, and 0 otherwise.</em></p>

<p><em>Proof.</em> We use Huber&#39;s &quot;fundamental theorem of perfect simulation&quot; again in the proof of correctness.</p>

<ul>
<li>The algorithm finishes with probability 1 because with each recursion, the method is never more likely to do a recursive run than not to do so; observe that <em>a</em>[<em>i</em>] can never be more than 1, so that <em>a</em>[<em>i</em>]/(1+<em>a</em>[<em>i</em>]), that is, the probability of finishing the run in each iteration, is always 1/2 or greater.</li>
<li>If the recursive call in the loop is replaced with a &quot;black box&quot; that simulates the correct &quot;sub-fraction&quot;, the algorithm is locally correct.  If step 1 reaches the last element of the continued fraction, the algorithm obviously passes with the correct probability. Otherwise, we will be simulating the probability <em>b</em>[<em>i</em>] / (<em>a</em>[<em>i</em>] + <em>x</em>), where <em>x</em> is the &quot;continued sub-fraction&quot; and will be at most 1 by assumption.  Step 2 defines a loop that divides the probability space into three pieces: the first piece takes up a part equal to <em>h</em> = <em>a</em>[<em>i</em>]/(<em>a</em>[<em>i</em>] + 1), the second piece (in the second substep) takes up a portion of the remainder (which here is equal to <em>x</em> * (1 &minus; <em>h</em>)), and the last piece is the &quot;rejection piece&quot;.  The algorithm will pass at the first substep with probability <em>p</em> = (<em>b</em>[<em>i</em>] / <em>a</em>[<em>pos</em>]) * <em>h</em> and fail either at the first substep of the loop with probability <em>f1</em> = (1 &minus; <em>b</em>[<em>i</em>] / <em>a</em>[<em>pos</em>]) * <em>h</em>, or at the second substep with probability <em>f2</em> = <em>x</em> * (1 &minus; <em>h</em>) (all these probabilities are relative to the whole iteration).  Finally, dividing the passes by the sum of passes and fails leads to <em>b</em>[<em>i</em>] / (<em>a</em>[<em>i</em>] + <em>x</em>), which is the probability we wanted, so that both of Huber&#39;s conditions are satisfied and we are done.  &#x25a1;</li>
</ul>

<p><a id=The_von_Neumann_Schema></a></p>

<h3>The von Neumann Schema</h3>

<p>(Flajolet et al., 2010)[^1] describes what it calls the <em>von Neumann schema</em> (sec. 2).   Although the von Neumann schema is used in several Bernoulli factories given here, it&#39;s not a Bernoulli factory itself since it could produce random variates other than 0 and 1, which is why this section appears in the appendix.</p>

<p>To describe the von Neumann schema, the following definition is needed:</p>

<ul>
<li>A <em>permutation class</em> is a rule that describes how a sequence of numbers must be ordered.  The ordering of the numbers is called a <em>permutation</em>.  Two examples of permutation classes cover permutations sorted in descending order, and permutations whose highest number appears first.  When checking whether a sequence follows a permutation class, only less-than and greater-than comparisons between two numbers are allowed.</li>
</ul>

<p>Now, given a permutation class and an input coin, the von Neumann schema generates a random integer <em>n</em>, 0 or greater, with probability equal to&mdash;</p>

<ul>
<li>(<em>&lambda;</em><sup><em>n</em></sup> * V(<em>n</em>) / <em>n</em>!) / EGF(<em>&lambda;</em>),</li>
</ul>

<p>where&mdash;</p>

<ul>
<li>EGF(<em>&lambda;</em>) = &sum;<sub><em>k</em> = 0, 1, ...</sub> (<em>&lambda;</em><sup><em>k</em></sup> * V(<em>k</em>) / <em>k</em>!) (the <em>exponential generating function</em> or EGF, which completely determines a permutation class), and</li>
<li>V(<em>n</em>) is a number in the interval [0, <em>n</em>!] and is the number of permutations of size <em>n</em> that meet the requirements of the permutation class in question.</li>
</ul>

<p>Effectively, a random variate <em>G</em> is generated by flipping the coin until it returns 0 and counting the number of ones (the paper calls <em>G</em> a <em>geometric</em>(<em>&lambda;</em>) random variate, but this terminology is avoided in this article because it has several conflicting meanings in academic works), and then accepted with probability V(<em>G</em>)/(<em>G</em>!) and rejected otherwise.  The probability that <em>r</em> variates are rejected this way is <em>p</em>*(1 &minus; <em>p</em>)<sup><em>r</em></sup>, where <em>p</em> = (1 &minus; <em>&lambda;</em>) * EGF(<em>&lambda;</em>).</p>

<p>Examples of permutation classes include&mdash;</p>

<ul>
<li>single-cycle permutations (EGF(<em>&lambda;</em>) = Cyc(<em>&lambda;</em>) = ln(1/(1 &minus; <em>&lambda;</em>)); V(<em>n</em>) = (<em>n</em> &minus; 1)!)</li>
<li>sorted permutations, or permutations whose numbers are sorted in descending order (EGF(<em>&lambda;</em>) = Set(<em>&lambda;</em>) = exp(<em>&lambda;</em>); V(<em>n</em>) = 1),</li>
<li>all permutations (EGF(<em>&lambda;</em>) = Seq(<em>&lambda;</em>) = 1/(1 &minus; <em>&lambda;</em>); V(<em>n</em>) = <em>n</em>!),</li>
<li>alternating permutations of even size (EGF(<em>&lambda;</em>) = 1/cos(<em>&lambda;</em>); the V(<em>n</em>) starting at <em>n</em> = 0 is <a href="https://oeis.org/A000364"><strong>A000364</strong></a> in the <em>On-Line Encyclopedia of Integer Sequences</em>), and</li>
<li>alternating permutations of odd size (EGF(<em>&lambda;</em>) = tan(<em>&lambda;</em>); the V(<em>n</em>) starting at <em>n</em> = 0 is <a href="https://oeis.org/A000182"><strong>A000182</strong></a>),</li>
</ul>

<p>using the notation in &quot;Analytic Combinatorics&quot; (Flajolet and Sedgewick 2009)[^58].</p>

<p>The following algorithm generates a random variate that follows the von Neumann schema.</p>

<ol>
<li>Set <em>r</em> to 0. (This is the number of times the algorithm rejects a random variate.)</li>
<li>Flip the input coin until the flip returns 0.  Then set <em>G</em> to the number of times the flip returns 1 this way.</li>
<li>With probability V(<em>G</em>)/<em>G</em>!, return <em>G</em> (or <em>r</em> if desired).  (In practice, the probability check is done by generating <em>G</em> uniform(0, 1) random variates and determining whether those numbers satisfy the given permutation class, or generating as many of those numbers as necessary to make this determination.  This is especially because <em>G</em>!, the factorial of <em>G</em>, can easily become very large.)</li>
<li>Add 1 to <em>r</em> and go to step 2.</li>
</ol>

<p>A variety of Bernoulli factory probability functions can arise from the von Neumann schema, depending on the EGF and which values of <em>G</em> and/or <em>r</em> the Bernoulli factory algorithm treats as heads or tails.  The following Python functions use the SymPy computer algebra library to find probabilities and other useful information for applying the von Neumann schema, given a permutation class&#39;s EGF.</p>

<pre>def coeffext(f, x, power):
    # Extract a coefficient from a generating function
    # NOTE: Can also be done with just the following line:
    # return diff(f,(x,power)).subs(x,0)/factorial(power)
    px = 2
    for i in range(10):
      try:
        poly=Poly(series(f, x=x, n=power+px).removeO())
        return poly.as_expr().coeff(x, power)
      except:
        px+=2
    # Failed, assume 0
    return 0

def number_n_prob(f, x, n):
    # Probability that the number n is generated
    # for the von Neumann schema with the given
    # exponential generating function (e.g.f.)
    # Example: number_n_prob(exp(x),x,1) --&gt; x**exp(-x)
    return (x**n*coeffext(f, x, n))/f

def r_rejects_prob(f, x, r):
    # Probability that the von Neumann schema
    # with the given e.g.f. will reject r random variates
    # before accepting the next one
    p=(1-x)*f
    return p*(1-p)**r

def valid_perm(f, x, n):
    # Number of permutations of size n that meet
    # the requirements of the permutation class
    # determined by the given e.g.f. for the
    # von Neumann schema
    return coeffext(f, x, n)*factorial(n)
</pre>

<blockquote>
<p><strong>Note:</strong> The von Neumann schema can simulate any <em>power series distribution</em> (such as Poisson, negative binomial, geometric, and logarithmic series), given a suitable exponential generating function.  However, because of step 2, the number of input coin flips required by the schema grows without bound as <em>&lambda;</em> approaches 1.</p>

<p><strong>Example:</strong> Using the class of <em>sorted permutations</em>, we can generate a Poisson random variate with mean <em>&lambda;</em> via the von Neumann schema, where <em>&lambda;</em> is the probability of heads of the input coin.  This would lead to an algorithm for exp(&minus;<em>&lambda;</em>) &mdash; outputting 1 if a Poisson random variate with mean <em>&lambda;</em> is 0, or 0 otherwise &mdash; but for the reason given in the note, this algorithm gets slower as <em>&lambda;</em> approaches 1.  Also, if <em>c</em> &gt; 0 is a real number, adding a Poisson random variate with mean floor(<em>c</em>) to one with mean <em>c</em>&minus;floor(<em>c</em>) generates a Poisson random variate with mean <em>c</em>.</p>
</blockquote>

<p>A variation on the von Neumann schema occurs if <em>G</em> is generated differently than given in step 2, but is still generated by flipping the input coin.  In that case, the algorithm above will return <em>n</em> with probability&mdash;</p>

<ul>
<li>(<em>&kappa;</em>(<em>n</em>; <em>&lambda;</em>)*V(<em>n</em>)/(<em>n</em>!)) / <em>p</em>,</li>
</ul>

<p>where <em>p</em> = ( &sum;<sub><em>k</em>=0,1,...</sub> (<em>&kappa;</em>(<em>k</em>; <em>&lambda;</em>)*V(<em>k</em>)/(<em>k</em>!)) ), and where <em>&kappa;</em>(<em>n</em>; <em>&lambda;</em>) is the probability that <em>G</em> is <em>n</em>, with parameter <em>&lambda;</em> or the input coin&#39;s probability of heads.  Also, the probability that <em>r</em> random variates are rejected by the modified algorithm is <em>p</em>*(1 &minus; <em>p</em>)<sup><em>r</em></sup>.</p>

<blockquote>
<p><strong>Example:</strong>  If <em>G</em> is a Poisson random variate with mean <em>z</em><sup>2</sup>/4 and if the sorted permutation class is used, the algorithm will return 0 with probability 1/<em>I</em><sub>0</sub>(<em>z</em>), where <em>I</em><sub>0</sub>(.) is the modified Bessel function of the first kind.</p>
</blockquote>

<p><a id=Probabilities_Arising_from_Certain_Permutations></a></p>

<h3>Probabilities Arising from Certain Permutations</h3>

<p>Certain interesting probability functions can arise from permutations.</p>

<p>Inspired by the <a href="#The_von_Neumann_schema"><strong>von Neumann schema</strong></a> given earlier in this appendix, we can describe the following algorithm:</p>

<p>Let a <em>permutation class</em> (defined in the previous section) and two distributions <em>D</em> and <em>E</em>, which are both continuous with probability density functions, be given. Consider the following algorithm: Generate a sequence of independent random variates (where the first is distributed as <em>D</em> and the rest as <em>E</em>) until the sequence no longer follows the permutation class, then return <em>n</em>, which is how many numbers were generated this way minus 1.</p>

<p>Then the algorithm&#39;s behavior is given in the tables below.</p>

<table><thead>
<tr>
<th>Permutation Class</th>
<th>Distributions <em>D</em> and <em>E</em></th>
<th>The algorithm returns <em>n</em> with this probability:</th>
<th>The probability that <em>n</em> is ...</th>
</tr>
</thead><tbody>
<tr>
<td>Numbers sorted in descending order</td>
<td>Arbitrary; <em>D</em> = <em>E</em></td>
<td><em>n</em> / ((<em>n</em> + 1)!).</td>
<td>Odd is 1&minus;exp(&minus;1); even is exp(&minus;1). See note 3.</td>
</tr>
<tr>
<td>Numbers sorted in descending order</td>
<td>Each arbitrary</td>
<td>(&int;<sub>(&minus;&infin;,&infin;)</sub> DPDF(<em>z</em>) * ((ECDF(<em>z</em>))<sup><em>n</em>&minus;1</sup>/((<em>n</em>&minus;1)!) &minus; (ECDF(<em>z</em>))<sup><em>n</em></sup>/(<em>n</em>!)) <em>dz</em>), for every <em>n</em> &gt; 0 (see also proof of Theorem 2.1 of (Devroye 1986, Chapter IV)[^28]. DPDF and ECDF are defined later.</td>
<td>Odd is denominator of formula 1 below.</td>
</tr>
<tr>
<td>Alternating numbers</td>
<td>Arbitrary; <em>D</em> = <em>E</em></td>
<td>(<em>a</em><sub><em>n</em></sub> * (<em>n</em> + 1) &minus; <em>a</em><sub><em>n</em> + 1</sub>) / (<em>n</em> + 1)!, where <em>a</em><sub><em>i</em></sub> is the integer at position <em>i</em> (starting at 0) of the sequence <a href="https://oeis.org/A000111"><strong>A000111</strong></a> in the <em>On-Line Encyclopedia of Integer Sequences</em>.</td>
<td>Odd is 1&minus;cos(1)/(sin(1)+1); even is cos(1)/(sin(1)+1).  See note 3.</td>
</tr>
<tr>
<td>Any</td>
<td>Arbitrary; <em>D</em> = <em>E</em></td>
<td>(&int;<sub>[0, 1]</sub> 1 * (<em>z</em><sup><em>n</em>&minus;1</sup>*V(<em>n</em>)/((<em>n</em>&minus;1)!) &minus; <em>z</em><sup><em>n</em></sup>*V(<em>n</em>+1)/(<em>n</em>!)) <em>dz</em>), for every <em>n</em> &gt; 0.  <em>V</em>(<em>n</em>) is the number of permutations of size <em>n</em> that belong in the permutation class. For this algorithm, <em>V</em>(<em>n</em>) must be in the interval (0, <em>n</em>!]; this algorithm won&#39;t work, for example, if there are 0 permutations of odd size.</td>
<td>Odd is 1 &minus; 1 / EGF(1); even is 1/EGF(1).<br/>Less than <em>k</em> is (<em>V</em>(0) &minus; <em>V</em>(<em>k</em>)/(<em>k</em>!)) / <em>V</em>(0).  See note 3.</td>
</tr>
</tbody></table>

<table><thead>
<tr>
<th>Permutation Class</th>
<th>Distributions <em>D</em> and <em>E</em></th>
<th>The probability that the first number in the sequence is <em>x</em> or less given that <em>n</em> is ...</th>
</tr>
</thead><tbody>
<tr>
<td>Numbers sorted in descending order</td>
<td>Each arbitrary</td>
<td>Odd is <em>&psi;</em>(<em>x</em>) = (&int;<sub>(&minus;&infin;, <em>x</em>)</sub> exp(&minus;ECDF(<em>z</em>)) * DPDF(<em>z</em>) <em>dz</em>) / (&int;<sub>(&minus;&infin;, &infin;)</sub> exp(&minus;ECDF(<em>z</em>)) * DPDF(<em>z</em>) <em>dz</em>) (Formula 1; see Theorem 2.1(iii) of (Devroye 1986, Chapter IV)[^28]; see also Forsythe 1972[^53]).  Here, DPDF is the probability density function (PDF) of <em>D</em>, and ECDF is the cumulative distribution function for <em>E</em>.<br>If <em>x</em> is uniform(0, 1), this probability becomes &int;<sub>[0, 1]</sub> <em>&psi;</em>(<em>z</em>) <em>dz</em>.</td>
</tr>
<tr>
<td>Numbers sorted in descending order</td>
<td>Each arbitrary</td>
<td>Even is (&int;<sub>(&minus;&infin;, <em>x</em>)</sub> (1 &minus; exp(&minus;ECDF(<em>z</em>))) * DPDF(<em>z</em>) <em>dz</em>) / (&int;<sub>(&minus;&infin;, &infin;)</sub> (1 &minus; exp(&minus;ECDF(<em>z</em>))) * DPDF(<em>z</em>) <em>dz</em>) (Formula 2; see also Monahan 1979[^59]).  DPDF and ECDF are as above.</td>
</tr>
<tr>
<td>Numbers sorted in descending order</td>
<td>Both uniform in (0,1)</td>
<td>Odd is ((1&minus;exp(&minus;<em>x</em>))&minus;exp(1))/(1&minus;exp(1)).  Therefore, the first number in the sequence is distributed as exponential(1) and &quot;truncated&quot; to the interval [0, 1] (von Neumann 1951)[^55].</td>
</tr>
<tr>
<td>Numbers sorted in descending order</td>
<td><em>D</em> is uniform in (0,1); <em>E</em> is max. of two uniform variates in (0,1).</td>
<td>Odd is erf(<em>x</em>)/erf(1) (uses Formula 1, where DPDF(<em>z</em>) = 1 and ECDF(<em>z</em>) = <em>z</em><sup>2</sup> for <em>z</em> in [0, 1]; see also <a href="#erf__x__erf_1"><strong>erf(<em>x</em>)/erf(1)</strong></a>).</td>
</tr>
</tbody></table>

<blockquote>
<p><strong>Notes:</strong></p>

<ol>
<li>All the functions possible for formulas 1 and 2 are nondecreasing functions.  Both formulas express what are called <em>cumulative distribution functions</em>, namely <em>F</em><sub><em>D</em></sub>(<em>x</em> given that <em>n</em> is odd) or <em>F</em><sub><em>D</em></sub>(<em>x</em> given that <em>n</em> is even), respectively.</li>
<li>EGF(<em>z</em>) is the <em>exponential generating function</em> (EGF) for the kind of permutation involved in the algorithm.  For example, the class of <em>alternating permutations</em> (permutations whose numbers alternate between low and high, that is, <em>X1</em> &gt; <em>X2</em> &lt; <em>X3</em> &gt; ...) uses the EGF tan(<em>&lambda;</em>)+1/cos(<em>&lambda;</em>).  Other examples of EGFs were given in the section on the von Neumann schema.</li>
<li>The results that point to this note have the special case that both <em>D</em> and <em>E</em> are uniform in (0, 1).  Indeed, if each variate <em>x</em> in the sequence is transformed with <em>CDF</em>(<em>x</em>), where <em>CDF</em> is <em>D</em>&#39;s cumulative distribution function, then the variates become uniform in (0, 1), with the same numerical order as before (with probability 1).  See also <a href="https://stats.stackexchange.com/questions/550847/probability-of-winning-a-game-where-you-sample-an-increasing-sequence-from-a-uni/550854#550854"><strong>this Stack Exchange question</strong></a>.</li>
</ol>
</blockquote>

<p><a id=Sketch_of_Derivation_of_the_Algorithm_for_1___pi></a></p>

<h3>Sketch of Derivation of the Algorithm for 1 / <em>&pi;</em></h3>

<p>The Flajolet paper presented an algorithm to simulate 1 / <em>&pi;</em> but provided no derivation.  Here is a sketch of how this algorithm works.</p>

<p>The algorithm is an application of the <a href="#Convex_Combinations"><strong>convex combination</strong></a> technique.  Namely, 1 / <em>&pi;</em> can be seen as a convex combination of two components:</p>

<ul>
<li><p><em>g</em>(<em>n</em>): 2<sup>6 * <em>n</em></sup> * (6 * <em>n</em> + 1) / 2<sup>8 * <em>n</em> + 2</sup> = 2<sup>&minus;2 * <em>n</em></sup> * (6 * <em>n</em> + 1) / 4 = (6 * <em>n</em> + 1) / (2<sup>2 * <em>n</em> + 2</sup>), which is the probability that the sum of the following independent random variates equals <em>n</em>:</p>

<ul>
<li>Two random variates that each express the number of failures before the first success, where the chance of a success is 1&minus;1/4 (the paper calls these two numbers <em>geometric</em>(1/4) random variates, but this terminology is avoided in this article because it has several conflicting meanings in academic works).</li>
<li>One Bernoulli random variate with mean 5/9.</li>
</ul>

<p>This corresponds to step 1 of the convex combination algorithm and steps 2 through 4 of the 1 / <em>&pi;</em> algorithm.  (This also shows that there is an error in the identity for 1 / <em>&pi;</em> given in the Flajolet paper: the &quot;8 <em>n</em> + 4&quot; should read &quot;8 <em>n</em> + 2&quot;.)</p></li>
<li><em>h</em><sub><em>n</em></sub>(): (choose(<em>n</em> * 2, <em>n</em>) / 2<sup><em>n</em> * 2</sup>)<sup>3</sup>, which is the probability of heads of the &quot;coin&quot; numbered <em>n</em>.  This corresponds to step 2 of the convex combination algorithm and step 5 of the 1 / <em>&pi;</em> algorithm.</li>
</ul>

<blockquote>
<p><strong>Notes:</strong></p>

<ol>
<li>9 * (<em>n</em> + 1) / (2<sup>2 * <em>n</em> + 4</sup>) is the probability that the sum of two independent random variates equals <em>n</em>, where each of the two variates expresses the number of failures before the first success and the chance of a success is 1&minus;1/4.</li>
<li><em>p</em><sup><em>m</em></sup> * (1 &minus; <em>p</em>)<sup><em>n</em></sup> * choose(<em>n</em> + <em>m</em> &minus; 1, <em>m</em> &minus; 1) is the probability that the sum of <em>m</em> independent random variates equals <em>n</em> (a <em>negative binomial distribution</em>), where each of the <em>m</em> variates expresses the number of failures before the first success and the chance of a success is <em>p</em>.</li>
<li><em>p</em> * <em>f</em>(<em>z</em> &minus; 1) + (1 &minus; <em>p</em>) * <em>f</em>(<em>z</em>) is the probability that the sum of two independent random variates &mdash; a Bernoulli variate with mean <em>p</em> as well as an integer that equals <em>x</em> with probability <em>f</em>(<em>x</em>) &mdash; equals <em>z</em>.</li>
</ol>
</blockquote>

<p><a id=Preparing_Rational_Functions></a></p>

<h3>Preparing Rational Functions</h3>

<p>This section describes how to turn a single-variable rational function (ratio of polynomials) into an array of polynomials needed to apply the <strong>&quot;Dice Enterprise&quot; special case</strong> described in &quot;<a href="#Certain_Rational_Functions"><strong>Certain Rational Functions</strong></a>&quot;.  In short, the steps to do so can be described as <em>separating</em>, <em>homogenizing</em>, and <em>augmenting</em>.</p>

<p><strong>Separating.</strong> If a rational function&#39;s numerator (<em>D</em>) and denominator (<em>E</em>) are written&mdash;</p>

<ul>
<li> as a sum of terms of the form <em>z</em>*<em>&lambda;</em><sup><em>i</em></sup>*(1&minus;<em>&lambda;</em>)<sup><em>j</em></sup>, where <em>z</em> is a real number and <em>i</em>&ge;0 and <em>j</em>&ge;0 are integers (called <em>form 1</em> in this section),</li>
</ul>

<p>then the function can be separated into two polynomials that sum to the denominator.  (Here, <em>i</em>+<em>j</em> is the term&#39;s <em>degree</em>, and the polynomial&#39;s degree is the highest degree among its terms.)  To do this separation, subtract the numerator from the denominator to get a new polynomial (<em>G</em>) such that <em>G</em> = <em>E</em> &minus; <em>D</em> (or <em>D</em> + <em>G</em> = <em>E</em>).  (Then <em>D</em> and <em>G</em> are the two polynomials we will use.) Similarly, if we have multiple rational functions with a common denominator, namely (<em>D1</em>/<em>E</em>), ..., (<em>DN</em>/<em>E</em>), where <em>D1</em>, ..., <em>DN</em> and <em>E</em> are written in form 1, then they can be separated into <em>N</em> + 1 polynomials by subtracting the numerators from the denominator, so that <em>G</em> = <em>E</em> &minus; <em>D1</em> &minus; ... &minus; <em>DN</em>.  (Then <em>D1</em>, ..., <em>DN</em> and <em>G</em> are the polynomials we will use.) To use the polynomials in the algorithm, however, they need to be <em>homogenized</em>, then <em>augmented</em>, as described next.</p>

<blockquote>
<p><strong>Example:</strong> We have the rational function  (4*<em>&lambda;</em><sup>1</sup>*(1&minus;<em>&lambda;</em>)<sup>2</sup>) /  (7 &minus; 5*<em>&lambda;</em><sup>1</sup>*(1&minus;<em>&lambda;</em>)<sup>2</sup>).  Subtracting the numerator from the denominator leads to: 7 &minus; 1*<em>&lambda;</em><sup>1</sup>*(1&minus;<em>&lambda;</em>)<sup>2</sup>.</p>
</blockquote>

<p><strong>Homogenizing.</strong> The next step is to <em>homogenize</em> the polynomials so they have the same degree and a particular form.  For this step, choose <em>n</em> to be an integer no less than the highest degree among the polynomials.</p>

<p>Suppose a polynomial&mdash;</p>

<ul>
<li>is 0 or greater for every <em>&lambda;</em> in the interval [0, 1],</li>
<li>has degree <em>n</em> or less, and</li>
<li>is written in form 1 as given above.</li>
</ul>

<p>Then the polynomial can be turned into a <em>homogeneous polynomial</em> of degree <em>n</em> (all its terms have degree <em>n</em>) as follows.</p>

<ul>
<li>For each integer <em>m</em> in [0, <em>n</em>], the new homogeneous polynomial&#39;s coefficient at <em>m</em> is found as follows:

<ol>
<li>Set <em>r</em> to 0.</li>
<li>For each term (in the old polynomial) of the form <em>z</em>*<em>&lambda;</em><sup><em>i</em></sup>*(1&minus;<em>&lambda;</em>)<sup><em>j</em></sup>:

<ul>
<li>If <em>i</em> &le; <em>m</em>, and (<em>n</em>&minus;<em>m</em>) &ge; <em>j</em>, and <em>i</em> + <em>j</em> &le; <em>n</em>, add <em>z</em>*choose(<em>n</em>&minus;(<em>i</em>+<em>j</em>), (<em>n</em>&minus;<em>m</em>)&minus;<em>j</em>) to <em>r</em>.</li>
</ul></li>
<li>Now, <em>r</em> is the new coefficient (corresponding to the term <em>r</em>* <em>&lambda;</em><sup><em>m</em></sup>*(1&minus;<em>&lambda;</em>)<sup><em>n</em>&minus;<em>m</em></sup>).</li>
</ol></li>
</ul>

<p>If the polynomial is written in so-called &quot;power form&quot; as <em>c[0]</em> + <em>c[1]</em>*<em>&lambda;</em> + <em>c[2]</em>*<em>&lambda;</em><sup>2</sup> + ... + <em>c[n]</em>*<em>&lambda;</em><sup><em>n</em></sup>, then the method is instead as follows:</p>

<ul>
<li>For each integer <em>m</em> in [0, <em>n</em>], the new homogeneous polynomial&#39;s coefficient at <em>m</em> is found as follows:

<ol>
<li>Set <em>r</em> to 0.</li>
<li>For each integer <em>i</em> in [0, <em>m</em>], if there is a coefficient <em>c[i]</em>, add <em>c[i]</em>*choose(<em>n</em>&minus;<em>i</em>, <em>n</em>&minus;<em>m</em>) to <em>r</em>.</li>
<li>Now, <em>r</em> is the new coefficient (corresponding to the term <em>r</em>* <em>&lambda;</em><sup><em>m</em></sup>*(1&minus;<em>&lambda;</em>)<sup><em>n</em>&minus;<em>m</em></sup>).</li>
</ol></li>
</ul>

<blockquote>
<p><strong>Example:</strong> We have the following polynomial: 3*<em>&lambda;</em><sup>2</sup> + 10*<em>&lambda;</em><sup>1</sup>*(1&minus;<em>&lambda;</em>)<sup>2</sup>.  This is a degree-3 polynomial, and we seek to turn it into a degree-5 homogeneous polynomial.  The result becomes the sum of the terms&mdash;</p>

<ul>
<li>0 * <em>&lambda;</em><sup>0</sup>*(1&minus;<em>&lambda;</em>)<sup>5</sup>;</li>
<li>10*choose(2, 2) * <em>&lambda;</em><sup>1</sup>*(1&minus;<em>&lambda;</em>)<sup>4</sup> = 10* <em>&lambda;</em><sup>1</sup>*(1&minus;<em>&lambda;</em>)<sup>4</sup>;</li>
<li>(3*choose(3, 3) + 10*choose(2, 1)) * <em>&lambda;</em><sup>2</sup>*(1&minus;<em>&lambda;</em>)<sup>3</sup> = 23* <em>&lambda;</em><sup>2</sup>*(1&minus;<em>&lambda;</em>)<sup>3</sup>;</li>
<li>(3*choose(3, 2) + 10*choose(2, 0)) * <em>&lambda;</em><sup>3</sup>*(1&minus;<em>&lambda;</em>)<sup>2</sup> = 19* <em>&lambda;</em><sup>3</sup>*(1&minus;<em>&lambda;</em>)<sup>2</sup>;</li>
<li>3*choose(3, 1) * <em>&lambda;</em><sup>4</sup>*(1&minus;<em>&lambda;</em>)<sup>1</sup> = 9* <em>&lambda;</em><sup>4</sup>*(1&minus;<em>&lambda;</em>)<sup>1</sup>; and</li>
<li>3*choose(3, 0) * <em>&lambda;</em><sup>5</sup>*(1&minus;<em>&lambda;</em>)<sup>0</sup> = 3* <em>&lambda;</em><sup>5</sup>*(1&minus;<em>&lambda;</em>)<sup>0</sup>,</li>
</ul>

<p>resulting in the coefficients (0, 10, 23, 19, 9, 3) for the new homogeneous polynomial.</p>
</blockquote>

<p><strong>Augmenting.</strong> If we have an array of homogeneous single-variable polynomials of the same degree, they are ready for use in the <strong>Dice Enterprise special case</strong> if&mdash;</p>

<ul>
<li>the polynomials have the same degree, namely <em>n</em>,</li>
<li>their coefficients are all 0 or greater, and</li>
<li>the sum of <em>j</em><sup>th</sup> coefficients is greater than 0, for each <em>j</em> starting at 0 and ending at <em>n</em>, except that the list of sums may begin and/or end with zeros.</li>
</ul>

<p>If those conditions are not met, then each polynomial can be <em>augmented</em> as often as necessary to meet the conditions (Morina et al., 2019)[^17].  For polynomials of the kind relevant here, augmenting a polynomial amounts to degree elevation similar to that of polynomials in Bernstein form (see also Tsai and Farouki 2001[^60]).  It is implemented as follows:</p>

<ul>
<li>Let <em>n</em> be the polynomial&#39;s old degree.  For each <em>k</em> in [0, <em>n</em>+1], the new polynomial&#39;s coefficient at <em>k</em> is found as follows:

<ul>
<li>Let <em>c</em>[<em>j</em>] be the old polynomial&#39;s <em>j</em><sup>th</sup> coefficient (starting at 0).  Calculate <em>c</em>[<em>j</em>] * choose(1, <em>k</em>&minus;<em>j</em>) for each <em>j</em> in the interval [max(0, <em>k</em>&minus;1), min(<em>n</em>, <em>k</em>)], then add them together.  The sum is the new coefficient.</li>
</ul></li>
</ul>

<p>According to the Morina paper, it&#39;s enough to do <em>n</em> augmentations on each polynomial for the whole array to meet the conditions above (although fewer than <em>n</em> will often suffice).</p>

<blockquote>
<p><strong>Note</strong>: For best results, the input polynomials&#39; coefficients should be rational numbers.  If they are not, then special methods are needed to ensure exact results, such as interval arithmetic that calculates lower and upper bounds.</p>
</blockquote>

<p><a id=License></a></p>

<h2>License</h2>

<p>Any copyright to this page is released to the Public Domain.  In case this is not possible, this page is also licensed under <a href="https://creativecommons.org/publicdomain/zero/1.0/"><strong>Creative Commons Zero</strong></a>.</p>
</div><nav id="navigation"><ul>
<li><a href="/">Back to start site.</a>
<li><a href="https://github.com/peteroupc/peteroupc.github.io">This site's repository (source code)</a>
<li><a href="https://github.com/peteroupc/peteroupc.github.io/issues">Post an issue or comment</a></ul>

<div class="noprint">
<p>
<a href="//twitter.com/intent/tweet">Share via Twitter</a>, <a href="//www.facebook.com/sharer/sharer.php" id="sharer">Share via Facebook</a>
</p>
</div>
</nav><script>
if("share" in navigator){
 document.getElementById("sharer").href="javascript:void(null)";
 document.getElementById("sharer").innerHTML="Share This Page";
 navigator.share({title:document.title,url:document.location.href}).then(
   function(){});
} else {
 document.getElementById("sharer").href="//www.facebook.com/sharer/sharer.php?u="+
    encodeURIComponent(document.location.href)
}
</script>
</body></html>
