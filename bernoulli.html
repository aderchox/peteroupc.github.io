<!DOCTYPE html><html><head><meta http-equiv=Content-Type content="text/html; charset=utf-8"><title>Bernoulli Factory Algorithms</title><meta name="viewport" content="width=device-width"><link rel=stylesheet type="text/css" href="/style.css"></head><body>  <div class="header">
<p><a href="#navigation">Menu</a> - <a href="#top">Top</a> - <a href="/">Home</a> -
<a href="http://peteroupc.github.io/">Donate to Me</a></p></div>
<div class="mainarea" id="top">
<h1>Bernoulli Factory Algorithms</h1>

<p><a href="mailto:poccil14@gmail.com"><strong>Peter Occil</strong></a></p>

<p><a id=Introduction></a></p>

<h2>Introduction</h2>

<p>This page catalogs algorithms to turn coins biased one way into coins biased another way, also known as <em>Bernoulli factories</em>.  Many of them were suggested in (Flajolet et al., 2010)<sup><a href="#Note1"><strong>(1)</strong></a></sup>, but without step-by-step instructions in many cases.  This page provides these instructions to help programmers implement the Bernoulli factories they describe.  The <a href="https://peteroupc.github.io/randomgen.zip"><strong>Python sample code</strong></a> includes implementations of several Bernoulli factories.</p>

<p>This page also contains algorithms to exactly simulate probabilities that are irrational numbers, using only random bits, which is likewise related to the Bernoulli factory problem.  Again, many of these were suggested in (Flajolet et al., 2010)<sup><a href="#Note1"><strong>(1)</strong></a></sup>.</p>

<p><a id=About_This_Document></a></p>

<h3>About This Document</h3>

<p><strong>This is an open-source document; for an updated version, see the</strong> <a href="https://github.com/peteroupc/peteroupc.github.io/raw/master/bernoulli.md"><strong>source code</strong></a> <strong>or its</strong> <a href="https://github.com/peteroupc/peteroupc.github.io/blob/master/bernoulli.md"><strong>rendering on GitHub</strong></a><strong>.  You can send comments on this document on the</strong> <a href="https://github.com/peteroupc/peteroupc.github.io/issues"><strong>GitHub issues page</strong></a><strong>.  You are welcome to suggest additional Bernoulli factory algorithms, especially specific</strong> <a href="#Continued_Fractions"><strong>continued fraction expansions</strong></a> <strong>and series expansions for the</strong> <a href="#exp_minus_lambda"><strong>general martingale</strong></a> <strong>and</strong> <a href="#Certain_Power_Series"><strong>Mendo</strong></a> <strong>algorithms below.</strong></p>

<p><a id=Contents></a></p>

<h2>Contents</h2>

<ul>
<li><a href="#Introduction"><strong>Introduction</strong></a>

<ul>
<li><a href="#About_This_Document"><strong>About This Document</strong></a></li>
</ul></li>
<li><a href="#Contents"><strong>Contents</strong></a></li>
<li><a href="#About_Bernoulli_Factories"><strong>About Bernoulli Factories</strong></a></li>
<li><a href="#Algorithms"><strong>Algorithms</strong></a>

<ul>
<li><a href="#Algorithms_for_Functions_of_lambda"><strong>Algorithms for Functions of &lambda;</strong></a>

<ul>
<li><a href="#exp_minus_lambda"><strong>exp(&minus;&lambda;)</strong></a></li>
<li><a href="#exp_lambda_1_minus_lambda"><strong>exp(&lambda;)*(1&minus;&lambda;)</strong></a></li>
<li><a href="#exp_minus_lambda_minus__c"><strong>exp(&minus;&lambda; &minus; <em>c</em>)</strong></a></li>
<li><a href="#1_1_lambda"><strong>1/(1+&lambda;)</strong></a></li>
<li><a href="#log_1_lambda"><strong>log(1+&lambda;)</strong></a></li>
<li><a href="#1_minus_log_1_lambda"><strong>1 &minus; log(1+&lambda;)</strong></a></li>
<li><a href="#c__lambda_beta_beta__c__lambda__d__mu_minus_beta_minus_1__c___d"><strong><em>c</em> * &lambda; * &beta; / (&beta; * (<em>c</em> * &lambda; + <em>d</em> * &mu;) &minus; (&beta; &minus; 1) * (<em>c</em> + <em>d</em>))</strong></a></li>
<li><a href="#c__lambda__c__lambda__d__or__c___d__lambda_1__c___d__lambda"><strong><em>c</em> * &lambda; / (<em>c</em> * &lambda; + <em>d</em>) or (<em>c</em>/<em>d</em>) * &lambda; / (1 + (<em>c</em>/<em>d</em>) * &lambda;))</strong></a></li>
<li><a href="#lambda_mu"><strong>&lambda; + &mu;</strong></a></li>
<li><a href="#lambda_minus_mu"><strong>&lambda; &minus; &mu;</strong></a></li>
<li><a href="#1__c__lambda"><strong>1/(<em>c</em> + &lambda;)</strong></a></li>
<li><a href="#1_minus_lambda"><strong>1 &minus; &lambda;</strong></a></li>
<li><a href="#nu_lambda_1_minus_nu_mu"><strong>&nu; * &lambda; + (1 &minus; &nu;) * &mu;</strong></a></li>
<li><a href="#lambda_mu_minus_lambda_mu"><strong>&lambda; + &mu; &minus; (&lambda; * &mu;)</strong></a></li>
<li><a href="#lambda_mu_2"><strong>(&lambda; + &mu;) / 2</strong></a></li>
<li><a href="#arctan_lambda_lambda"><strong>arctan(&lambda;) /&lambda;</strong></a></li>
<li><a href="#arctan_lambda"><strong>arctan(&lambda;)</strong></a></li>
<li><a href="#lambda__x___y"><strong>&lambda;<sup><em>x</em>/<em>y</em></sup></strong></a></li>
<li><a href="#lambda_mu_3"><strong>&lambda;<sup>&mu;</sup></strong></a></li>
<li><a href="#sqrt_lambda"><strong>sqrt(&lambda;)</strong></a></li>
<li><a href="#arcsin_lambda_sqrt_1_minus_lambda_2_minus_1"><strong>arcsin(&lambda;) + sqrt(1 &minus; &lambda;<sup>2</sup>) &minus; 1</strong></a></li>
<li><a href="#arcsin_lambda_2"><strong>arcsin(&lambda;) / 2</strong></a></li>
<li><a href="#lambda_mu_4"><strong>&lambda; * &mu;</strong></a></li>
<li><a href="#lambda__x___y__linear_Bernoulli_factories"><strong>&lambda; * <em>x</em>/<em>y</em> (linear Bernoulli factories)</strong></a></li>
<li><a href="#lambda__x___y___i"><strong>(&lambda; * <em>x</em>/<em>y</em>)<sup><em>i</em></sup></strong></a></li>
<li><a href="#x03F5_lambda"><strong>&#x03F5; / &lambda;</strong></a></li>
<li><a href="#Certain_Power_Series"><strong>Certain Power Series</strong></a></li>
</ul></li>
<li><a href="#Algorithms_for_Irrational_Constants"><strong>Algorithms for Irrational Constants</strong></a>

<ul>
<li><a href="#Continued_Fractions"><strong>Continued Fractions</strong></a></li>
<li><a href="#1_phi"><strong>1 / &phi;</strong></a></li>
<li><a href="#sqrt_2_minus_1"><strong>sqrt(2) &minus; 1</strong></a></li>
<li><a href="#1_sqrt_2"><strong>1/sqrt(2)</strong></a></li>
<li><a href="#arctan__x___y___y___x"><strong>arctan(<em>x</em>/<em>y</em>) * <em>y</em>/<em>x</em></strong></a></li>
<li><a href="#pi_12"><strong>&pi; / 12</strong></a></li>
<li><a href="#pi_4"><strong>&pi; / 4</strong></a></li>
<li><a href="#1_pi"><strong>1 / &pi;</strong></a></li>
<li><a href="#a___b___x___y"><strong>(<em>a</em>/<em>b</em>)<sup><em>x</em>/<em>y</em></sup></strong></a></li>
<li><a href="#exp_minus__x___y"><strong>exp(&minus;<em>x</em>/<em>y</em>)</strong></a></li>
<li><a href="#exp_minus__z"><strong>exp(&minus;<em>z</em>)</strong></a></li>
<li><a href="#a___b___z"><strong>(<em>a</em>/<em>b</em>)<sup><em>z</em></sup></strong></a></li>
<li><a href="#1_1_exp__x___y__2_prec__LogisticExp"><strong>1 / 1 + exp(<em>x</em> / (<em>y</em> * 2<sup><em>prec</em></sup>)) (LogisticExp)</strong></a></li>
<li><a href="#1_1_exp__z__2_prec__LogisticExp"><strong>1 / 1 + exp(<em>z</em> / 2<sup><em>prec</em></sup>)) (LogisticExp)</strong></a></li>
</ul></li>
<li><a href="#General_Algorithms"><strong>General Algorithms</strong></a>

<ul>
<li><a href="#Simulating_the_Probability_Generating_Function"><strong>Simulating the Probability Generating Function</strong></a></li>
<li><a href="#URandLessThanFraction"><strong>URandLessThanFraction</strong></a></li>
</ul></li>
</ul></li>
<li><a href="#Correctness_and_Performance_Charts"><strong>Correctness and Performance Charts</strong></a>

<ul>
<li><a href="#The_Charts"><strong>The Charts</strong></a></li>
</ul></li>
<li><a href="#Notes"><strong>Notes</strong></a></li>
<li><a href="#Appendix"><strong>Appendix</strong></a>

<ul>
<li><a href="#Convergence_of_Bernoulli_Factories"><strong>Convergence of Bernoulli Factories</strong></a></li>
<li><a href="#Alternative_Implementation_of_Bernoulli_Factories"><strong>Alternative Implementation of Bernoulli Factories</strong></a></li>
</ul></li>
<li><a href="#License"><strong>License</strong></a></li>
</ul>

<p><a id=About_Bernoulli_Factories></a></p>

<h2>About Bernoulli Factories</h2>

<p>A <em>Bernoulli factory</em> (Keane and O&#39;Brien 1994)<sup><a href="#Note2"><strong>(2)</strong></a></sup> is an algorithm that takes an input coin (a method that returns 1, or heads, with an unknown probability, or 0, or tails, otherwise) and returns 0 or 1 with a probability that depends on the input coin&#39;s probability of heads.  For example, a Bernoulli factory algorithm can take a coin that returns heads with probability &lambda; and produce a coin that returns heads with probability exp(&minus;&lambda;).</p>

<p>A <em>factory function</em> is a function that relates the old probability to the new one.  Its domain is [0, 1] and returns a probability in [0, 1].  There are certain requirements for factory functions.  As shown by Keane and O&#39;Brien (1994)<sup><a href="#Note2"><strong>(2)</strong></a></sup>, a function <em>f</em> can serve as a factory function if and only if <em>f</em>, in the interval [0, 1]&mdash;</p>

<ul>
<li>is continuous everywhere, and</li>
<li>either returns a constant value in [0, 1] everywhere, or returns a value in [0, 1] at each of the points 0 and 1 and a value in (0, 1) at each other point.</li>
</ul>

<p>As one example, the function <em>f</em> = 2*p cannot serve as a factory function, since its graph touches 1 somewhere in the open interval (0, 1).</p>

<p>The next section will show algorithms for a number of factory functions, allowing different kinds of probabilities to be simulated from input coins.</p>

<p><a id=Algorithms></a></p>

<h2>Algorithms</h2>

<p>In the following algorithms:</p>

<ul>
<li>&lambda; is the unknown probability of heads of the input coin.</li>
<li>The <strong>SampleGeometricBag</strong> and <strong>URandLess</strong> algorithms are described in my article on <a href="https://peteroupc.github.io/exporand.html"><strong>partially-sampled random numbers (PSRNs)</strong></a>.</li>
<li>The <code>ZeroOrOne</code> method should be implemented as shown in my article on <a href="https://peteroupc.github.io/randomfunc.html#Boolean_True_False_Conditions"><strong>random sampling methods</strong></a>.</li>
<li>The instruction to &quot;generate a uniform random number&quot; can be implemented by creating an empty <a href="https://peteroupc.github.io/exporand.html"><strong>uniform PSRN</strong></a> (most accurate) or by generating <code>RNDEXCRANGE(0, 1)</code> or <code>RNDINT(1000)</code> (less accurate).</li>
<li>Where an algorithm says &quot;if <em>a</em> is less than <em>b</em>&quot;, where <em>a</em> and <em>b</em> are uniform random numbers, it means to run the <strong>URandLess</strong> algorithm on the two PSRNs, or do a less-than operation on <em>a</em> and <em>b</em>, as appropriate.</li>
<li>For best results, the algorithms should be implemented using exact rational arithmetic (such as <code>Fraction</code> in Python or <code>Rational</code> in Ruby).</li>
</ul>

<blockquote>
<p><strong>Performance notes:</strong></p>

<p>The algorithms as described here do not always lead to the best performance.  An implementation may change these algorithms as long as they produce the same results as the algorithms as described here.  Some algorithms are described as &quot;uniformly fast&quot;.  This means that their average running time is bounded from above for all choices of &lambda; and other parameters (Devroye 1986, esp. p. 717)<sup><a href="#Note3"><strong>(3)</strong></a></sup>.</p>

<p>An algorithm can be uniformly fast for all &lambda; parameters in a closed interval in (0, 1) only if its factory function meets the Lipschitz condition on that closed interval, that is, it is continuous and has no slope that tends to a vertical slope anywhere in that interval (Nacu and Peres 2005, proposition 23)<sup><a href="#Note4"><strong>(4)</strong></a></sup>.</p>

<p><strong>Note on &quot;non-randomized&quot; algorithms:</strong></p>

<p>A <em>non-randomized algorithm</em> is a simulation algorithm that uses nothing but the input coin as a source of randomness (in contrast to <em>randomized algorithms</em>, which do use other sources of randomness) (Mendo 2019)<sup><a href="#Note5"><strong>(5)</strong></a></sup>.  Instead of generating outside randomness, a randomized algorithm can implement a <em>randomness extraction</em> procedure (such as the von Neumann algorithm) to generate that randomness using the input coins themselves.  In this way, the algorithm becomes a <em>non-randomized algorithm</em>.  For example, if an algorithm implements the <strong>two-coin special case</strong> (below) by generating a random bit in step 1, it could replace generating that bit with flipping the input coin twice until the coin returns 0 then 1 or 1 then 0 this way, then taking the result as 0 or 1, respectively (von Neumann 1951)<sup><a href="#Note6"><strong>(6)</strong></a></sup>.</p>
</blockquote>

<p><a id=Algorithms_for_Functions_of_lambda></a></p>

<h3>Algorithms for Functions of &lambda;</h3>

<p>&nbsp;</p>

<p><a id=exp_minus_lambda></a></p>

<h4>exp(&minus;&lambda;)</h4>

<p>The algorithm in (Flajolet et al., 2010)<sup><a href="#Note1"><strong>(1)</strong></a></sup> calls for generating a Poisson(&lambda;) random number and returning 1 if that number is 0, or 0 otherwise.  The Poisson generator in turn involves generating a geometric(&lambda;) random number <em>G</em><sup><a href="#Note7"><strong>(7)</strong></a></sup>, then <em>G</em> uniform random numbers, then returning <em>G</em> only if all <em>G</em> uniform numbers are sorted.<sup><a href="#Note8"><strong>(8)</strong></a></sup>  The algorithm follows.</p>

<ol>
<li>Flip the input coin until the coin returns 0.  Then set <em>G</em> to the number of times the coin returns 1 this way.</li>
<li>If <em>G</em> is 0, return 1.</li>
<li>Generate a uniform random number <em>w</em>, and set <em>i</em> to 1.</li>
<li>While <em>i</em> is less than <em>G</em>:

<ol>
<li>Generate a uniform random number <em>U</em>.</li>
<li>If <em>w</em> is less than <em>U</em>, break out of this loop and go to step 1.</li>
<li>Add 1 to <em>i</em>, and set <em>w</em> to <em>U</em>.</li>
</ol></li>
<li>Return 0.  (<em>G</em> is now a Poisson(&lambda;) random number, but is other than 0.)</li>
</ol>

<p>This algorithm, however, runs very slowly as &lambda; approaches 1.</p>

<p>Here is an alternative version of the algorithm above, which doesn&#39;t generate a geometric random number at the outset.</p>

<ol>
<li>Set <em>k</em> and <em>w</em> each to 0.</li>
<li>Flip the input coin.  If the coin returns 0 and <em>k</em> is 0, return 1.  Otherwise, if the coin returns 0, return 0.</li>
<li>Generate a uniform random number <em>U</em>.</li>
<li>If <em>k</em> &gt; 0 and <em>w</em> is less than <em>U</em>, go to step 1.</li>
<li>Set <em>w</em> to <em>U</em>, add 1 to <em>k</em>, and go to step 2.</li>
</ol>

<p>In turn, this algorithm likewise converges very slowly as &lambda; approaches 1.</p>

<p>A third algorithm is uniformly fast everywhere in (0, 1).   It uses the reverse-time martingale approach for alternating series in (Łatuszyński et al. 2009/2011)<sup><a href="#Note9"><strong>(9)</strong></a></sup> and makes use of the fact that exp(&minus;&lambda;) can be rewritten as 1 &minus; &lambda; + &lambda;<sup>2</sup>/2 &minus; &lambda;<sup>3</sup>/6 + &lambda;<sup>4</sup>/24 &minus; ..., which is an alternating series whose coefficients are 1, 1, 1/(2!), 1/(3!), 1/(4!), ..., which satisfy the requirements for this approach because the coefficients are nonincreasing and all 1 or less.  However, the algorithm requires a bit more arithmetic, notably rational division.</p>

<p>First, the general algorithm for the reverse-time martingale approach (called the <strong>general martingale algorithm</strong>) follows.  It takes a list of coefficients and an input coin, and returns 1 with probability <em>c[0]</em> &minus; <em>c[1]</em> * &lambda; + <em>c[2]</em> * &lambda;<sup>2</sup> &minus; ..., and 0 otherwise.</p>

<ol>
<li>Let <em>c[0]</em>, <em>c[1]</em>, etc. be the first, second, etc. coefficients of the alternating series.  Set <em>u</em> to <em>c[0]</em>, set <em>w</em> to 1, set <em>l</em> to 0, and set <em>n</em> to 1.</li>
<li>Create an empty uniform PSRN.</li>
<li>If <em>w</em> is not 0, flip the input coin and multiply <em>w</em> by the result of the flip.</li>
<li>If <em>n</em> is even, set <em>u</em> to <em>l</em> + <em>w</em> * <em>c[n]</em>.  Otherwise, set <em>l</em> to <em>u</em> + <em>w</em> * <em>c[n]</em>.</li>
<li>Run the <strong>URandLessThanFraction algorithm</strong> on the PSRN and <em>l</em>.  If the algorithm returns 1, return 1.</li>
<li>Run the <strong>URandLessThanFraction algorithm</strong> on the PSRN and <em>u</em>.  If the algorithm returns 0, return 0.</li>
<li>Add 1 to <em>n</em> and go to step 3.</li>
</ol>

<p>For <strong>exp(&minus;&lambda;)</strong>, modify that algorithm as follows for more efficiency:</p>

<ul>
<li>Rather than multiplying by <em>c[n]</em> in step 4, divide <em>w</em> by <em>n</em> in step 3 (after multiplying by the result of the flip).  This is a more efficient way to take account of the factorial in the second and later coefficients.</li>
</ul>

<p><a id=exp_lambda_1_minus_lambda></a></p>

<h4>exp(&lambda;)*(1&minus;&lambda;)</h4>

<p>(Flajolet et al., 2010)<sup><a href="#Note1"><strong>(1)</strong></a></sup>:</p>

<ol>
<li>Set <em>k</em> and <em>w</em> each to 0.</li>
<li>Flip the input coin.  If it returns 0, return 1.</li>
<li>Generate a uniform random number <em>U</em>.</li>
<li>If <em>k</em> &gt; 0 and <em>w</em> is less than <em>U</em>, return 0.</li>
<li>Set <em>w</em> to <em>U</em>, add 1 to <em>k</em>, and go to step 2.</li>
</ol>

<p><a id=exp_minus_lambda_minus__c></a></p>

<h4>exp(&minus;&lambda; &minus; <em>c</em>)</h4>

<p>To the best of my knowledge, I am not aware of any article or paper by others that presents this particular Bernoulli factory. In this algorithm, <em>c</em> is an integer that is 0 or greater.</p>

<ol>
<li>Run the <strong>algorithm for exp(&minus;<em>c</em>/1)</strong> described later in this document.  Return 0 if the algorithm returns 0.</li>
<li>Return the result of the <strong>algorithm for exp(&minus;&lambda;)</strong>.</li>
</ol>

<p><a id=1_1_lambda></a></p>

<h4>1/(1+&lambda;)</h4>

<p>One algorithm is the general martingale algorithm, since when &lambda; is in [0, 1], this function is an alternating series of the form <code>1 - x + x^2 - x^3 + ...</code>, whose coefficients are 1, 1, 1, 1, ....  However, this algorithm converges slowly when &lambda; is very close to 1.</p>

<p>A second algorithm is the so-called &quot;even-parity&quot; construction of (Flajolet et al., 2010)<sup><a href="#Note1"><strong>(1)</strong></a></sup>.  However, this algorithm too converges slowly when &lambda; is very close to 1.</p>

<ol>
<li>Flip the input coin.  If it returns 0, return 1.</li>
<li>Flip the input coin.  If it returns 0, return 0.  Otherwise, go to step 1.</li>
</ol>

<p>A third algorithm is a special case of the two-coin Bernoulli factory of (Gonçalves et al., 2017)<sup><a href="#Note10"><strong>(10)</strong></a></sup> and is uniformly fast, unlike the previous two algorithms.  It will be called the <strong>two-coin special case</strong> in this document.</p>

<ol>
<li>With probability 1/2, return 1. (For example, generate an unbiased random bit and return 1 if that bit is 1.)</li>
<li>Flip the input coin.  If it returns 1, return 0.  Otherwise, go to step 1.</li>
</ol>

<p><a id=log_1_lambda></a></p>

<h4>log(1+&lambda;)</h4>

<p>(Flajolet et al., 2010)<sup><a href="#Note1"><strong>(1)</strong></a></sup>:</p>

<ol>
<li>Create an empty uniform PSRN.</li>
<li>Flip the input coin.  If it returns 0, flip the coin again and return the result.</li>
<li>Call the <strong>SampleGeometricBag</strong> algorithm with the PSRN.  If it returns 0, flip the input coin and return the result.</li>
<li>Flip the input coin.  If it returns 0, return 0.</li>
<li>Call the <strong>SampleGeometricBag</strong> algorithm with the PSRN.  If it returns 0, return 0.  Otherwise, go to step 2.</li>
</ol>

<p>Observing that the even-parity construction used in the Flajolet paper is equivalent to the two-coin special case, which is uniformly fast for all &lambda; parameters, the algorithm above can be made uniformly fast as follows:</p>

<ol>
<li>Create an empty uniform PSRN.</li>
<li>With probability 1/2, flip the input coin and return the result.</li>
<li>Call <strong>SampleGeometricBag</strong> on the PSRN, then flip the input coin.  If the call and the flip both return 1, return 0.  Otherwise, go to step 2.</li>
</ol>

<p><a id=1_minus_log_1_lambda></a></p>

<h4>1 &minus; log(1+&lambda;)</h4>

<p>Invert the result of the algorithm for log(1+&lambda;) (make it 1 if it&#39;s 0 and vice versa).<sup><a href="#Note11"><strong>(11)</strong></a></sup></p>

<p><a id=c__lambda_beta_beta__c__lambda__d__mu_minus_beta_minus_1__c___d></a></p>

<h4><em>c</em> * &lambda; * &beta; / (&beta; * (<em>c</em> * &lambda; + <em>d</em> * &mu;) &minus; (&beta; &minus; 1) * (<em>c</em> + <em>d</em>))</h4>

<p>This is the general two-coin algorithm of (Gonçalves et al., 2017)<sup><a href="#Note10"><strong>(10)</strong></a></sup> and (Vats et al. 2020)<sup><a href="#Note12"><strong>(12)</strong></a></sup>.  It takes two input coins that each output heads (1) with probability &lambda; or &mu;, respectively.  It also takes a parameter &beta; in the interval [0, 1], which is a so-called &quot;portkey&quot; or early rejection parameter (when &beta; = 1, the formula simplifies to <em>c</em> * &lambda; / (<em>c</em> * &lambda; + <em>d</em> * &mu;)).</p>

<ol>
<li>With probability &beta;, go to step 2.  Otherwise, return 0. (For example, call <code>ZeroOrOne</code> with &beta;&#39;s numerator and denominator, and return 0 if that call returns 0, or go to step 2 otherwise.)</li>
<li>With probability <em>c</em> / (<em>c</em> + <em>d</em>), flip the &lambda; input coin.  Otherwise, flip the &mu; input coin.  If the &lambda; input coin returns 1, return 1.  If the &mu; input coin returns 1, return 0.  If the corresponding coin returns 0, go to step 1.</li>
</ol>

<p><a id=c__lambda__c__lambda__d__or__c___d__lambda_1__c___d__lambda></a></p>

<h4><em>c</em> * &lambda; / (<em>c</em> * &lambda; + <em>d</em>) or (<em>c</em>/<em>d</em>) * &lambda; / (1 + (<em>c</em>/<em>d</em>) * &lambda;))</h4>

<p>This algorithm, also known as the <strong>logistic Bernoulli factory</strong> (Huber 2016)<sup><a href="#Note13"><strong>(13)</strong></a></sup>, (Morina et al., 2019)<sup><a href="#Note14"><strong>(14)</strong></a></sup>, is a special case of the two-coin algorithm above, but this time uses only one input coin.</p>

<ol>
<li>With probability <em>d</em> / (<em>c</em> + <em>d</em>), return 0.</li>
<li>Flip the input coin.  If the coin returns 1, return 1.  Otherwise, go to step 1.</li>
</ol>

<p>(Note that Huber [2016] specifies this Bernoulli factory in terms of a Poisson point process, which seems to require much more randomness on average.)</p>

<p><a id=lambda_mu></a></p>

<h4>&lambda; + &mu;</h4>

<p>(Nacu and Peres 2005, proposition 14(iii))<sup><a href="#Note4"><strong>(4)</strong></a></sup>.  This algorithm takes two input coins that simulate &lambda; or &mu;, respectively, and a parameter &#x03F5;, which must be greater than 0 and chosen such that &lambda; + &mu; &lt; 1 &minus; &#x03F5;.</p>

<ol>
<li>Create a &nu; input coin that does the following: &quot;With probability 1/2, flip the &lambda; input coin and return the result.  Otherwise, flip the &mu; input coin and return the result.&quot;</li>
<li>Call the <strong>2014 algorithm</strong>, the <strong>2016 algorithm</strong>, or the <strong>2019 algorithm</strong>, described later, using the &nu; input coin, <em>x</em>/<em>y</em> = 2/1, <em>i</em> = 1 (for the 2019 algorithm), and &#x03F5; = &#x03F5;, and return the result.</li>
</ol>

<p><a id=lambda_minus_mu></a></p>

<h4>&lambda; &minus; &mu;</h4>

<p>(Nacu and Peres 2005, proposition 14(iii-iv))<sup><a href="#Note4"><strong>(4)</strong></a></sup>.  This algorithm takes two input coins that simulate &lambda; or &mu;, respectively, and a parameter &#x03F5;, which must be greater than 0 and chosen such that &lambda; &minus; &mu; &gt; &#x03F5; (and should be chosen such that &#x03F5; is slightly less than &lambda; &minus; &mu;).</p>

<ol>
<li>Create a &nu; input coin that does the following: &quot;With probability 1/2, flip the &lambda; input coin and return <strong>1 minus the result</strong>.  Otherwise, flip the &mu; input coin and return the result.&quot;</li>
<li>Call the <strong>2014 algorithm</strong>, the <strong>2016 algorithm</strong>, or the <strong>2019 algorithm</strong>, described later, using the &nu; input coin, <em>x</em>/<em>y</em> = 2/1, <em>i</em> = 1 (for the 2019 algorithm), and &#x03F5; = &#x03F5;, and return 1 minus the result.</li>
</ol>

<p><a id=1__c__lambda></a></p>

<h4>1/(<em>c</em> + &lambda;)</h4>

<p>Works only if <em>c</em> &gt; 0.</p>

<ol>
<li>With probability <em>c</em>/(1 + <em>c</em>), return a number that is 1 with probability 1/<em>c</em> and 0 otherwise.</li>
<li>Flip the input coin.  If the coin returns 1, return 0.  Otherwise, go to step 1.</li>
</ol>

<p><a id=1_minus_lambda></a></p>

<h4>1 &minus; &lambda;</h4>

<p>(Flajolet et al., 2010)<sup><a href="#Note1"><strong>(1)</strong></a></sup>: Flip the &lambda; input coin and return 0 if the result is 1, or 1 otherwise.</p>

<p><a id=nu_lambda_1_minus_nu_mu></a></p>

<h4>&nu; * &lambda; + (1 &minus; &nu;) * &mu;</h4>

<p>(Flajolet et al., 2010)<sup><a href="#Note1"><strong>(1)</strong></a></sup>: Flip the &nu; input coin.  If the result is 0, flip the &lambda; input coin and return the result.  Otherwise, flip the &mu; input coin and return the result.</p>

<p><a id=lambda_mu_minus_lambda_mu></a></p>

<h4>&lambda; + &mu; &minus; (&lambda; * &mu;)</h4>

<p>(Flajolet et al., 2010)<sup><a href="#Note1"><strong>(1)</strong></a></sup>: Flip the &lambda; input coin and the &mu; input coin.  Return 1 if either flip returns 1, and 0 otherwise.</p>

<p><a id=lambda_mu_2></a></p>

<h4>(&lambda; + &mu;) / 2</h4>

<p>(Nacu and Peres 2005, proposition 14(iii))<sup><a href="#Note4"><strong>(4)</strong></a></sup>; (Flajolet et al., 2010)<sup><a href="#Note1"><strong>(1)</strong></a></sup>: With probability 1/2, flip the &lambda; input coin and return the result.  Otherwise, flip the &mu; input coin and return the result.</p>

<p><a id=arctan_lambda_lambda></a></p>

<h4>arctan(&lambda;) /&lambda;</h4>

<p>(Flajolet et al., 2010)<sup><a href="#Note1"><strong>(1)</strong></a></sup>:</p>

<ol>
<li>Generate an empty uniform PSRN.</li>
<li>Call <strong>SampleGeometricBag</strong> twice on the PSRN, and flip the input coin twice.  If any of these calls or flips returns 0, return 1.</li>
<li>Call <strong>SampleGeometricBag</strong> twice on the PSRN, and flip the input coin twice.  If any of these calls or flips returns 0, return 0.  Otherwise, go to step 2.</li>
</ol>

<p>Observing that the even-parity construction used in the Flajolet paper is equivalent to the two-coin special case, which is uniformly fast for all &lambda; parameters, the algorithm above can be made uniformly fast as follows:</p>

<ol>
<li>Create an empty uniform PSRN.</li>
<li>With probability 1/2, return 1.</li>
<li>Call <strong>SampleGeometricBag</strong> twice on the PSRN, and flip the input coin twice.  If all of these calls and flips return 1, return 0.  Otherwise, go to step 2.</li>
</ol>

<p><a id=arctan_lambda></a></p>

<h4>arctan(&lambda;)</h4>

<p>(Flajolet et al., 2010)<sup><a href="#Note1"><strong>(1)</strong></a></sup>: Call the <strong>algorithm for arctan(&lambda;) /&lambda;</strong> and flip the input coin.  Return 1 if the call and flip both return 1, or 0 otherwise.</p>

<p><a id=lambda__x___y></a></p>

<h4>&lambda;<sup><em>x</em>/<em>y</em></sup></h4>

<p>In the algorithm below, the case where <em>x</em>/<em>y</em> is in (0, 1) is due to recent work by Mendo (2019)<sup><a href="#Note5"><strong>(5)</strong></a></sup>.  The algorithm works only when <em>x</em>/<em>y</em> is 0 or greater.</p>

<ol>
<li>If <em>x</em>/<em>y</em> is 0, return 1.</li>
<li>If <em>x</em>/<em>y</em> is equal to 1, flip the input coin and return the result.</li>
<li>If <em>x</em>/<em>y</em> is greater than 1:

<ol>
<li>Set <em>ipart</em> to floor(<em>x</em>/<em>y</em>) and <em>fpart</em> to <code>rem(x, y)</code>.</li>
<li>If <em>fpart</em> is greater than 0, subtract 1 from <em>ipart</em>, then call this algorithm recursively with <em>x</em> = floor(<em>fpart</em>/2) and <em>y</em> = <em>y</em>, then call this algorithm, again recursively, with <em>x</em> = <em>fpart</em> &minus; floor(<em>fpart</em>/2) and <em>y</em> = <em>y</em>. Return 0 if either call returns 0.  (This is done rather than the more obvious approach in order to avoid calling this algorithm with fractional parts very close to 0, because the algorithm runs much more slowly than for fractional parts closer to 1.)</li>
<li>If <em>ipart</em> is 1 or greater, flip the input coin <em>ipart</em> many times.  Return 0 if any of these flips returns 1.</li>
<li>Return 1.</li>
</ol></li>
<li><em>x</em>/<em>y</em> is less than 1, so set <em>i</em> to 1.</li>
<li>Flip the input coin; if it returns 1, return 1.</li>
<li>Return 0 with probability <em>x</em>/(<em>y</em>*<em>i</em>).</li>
<li>Add 1 to <em>i</em> and go to step 5.</li>
</ol>

<blockquote>
<p><strong>Note:</strong> When <em>x</em>/<em>y</em> is less than 1, the minimum number of coin flips needed, on average, by this algorithm will grow without bound as &lambda; approaches 0.  In fact, no fast Bernoulli factory algorithm can avoid this unbounded growth without additional information on &lambda; (Mendo 2019)<sup><a href="#Note5"><strong>(5)</strong></a></sup>.  See also the appendix, which also shows an alternative way to implement this and other Bernoulli factory algorithms using PSRNs, which exploits knowledge of &lambda; but is not the focus of this article since it involves arithmetic.</p>
</blockquote>

<p><a id=lambda_mu_3></a></p>

<h4>&lambda;<sup>&mu;</sup></h4>

<p>This algorithm is based on the previous one, but changed to accept a second input coin (which outputs heads with probability &mu;) rather than a fixed value for the exponent. To the best of my knowledge, I am not aware of any other article or paper that presents this particular Bernoulli factory.</p>

<ol>
<li>Set <em>i</em> to 1.</li>
<li>Flip the input coin that simulates the base, &lambda;; if it returns 1, return 1.</li>
<li>Flip the input coin that simulates the exponent, &mu;; if it returns 1, return 0 with probability 1/<em>i</em>.</li>
<li>Add 1 to <em>i</em> and go to step 1.</li>
</ol>

<p><a id=sqrt_lambda></a></p>

<h4>sqrt(&lambda;)</h4>

<p>Use the algorithm for &lambda;<sup>1/2</sup>.</p>

<p><a id=arcsin_lambda_sqrt_1_minus_lambda_2_minus_1></a></p>

<h4>arcsin(&lambda;) + sqrt(1 &minus; &lambda;<sup>2</sup>) &minus; 1</h4>

<p>(Flajolet et al., 2010)<sup><a href="#Note1"><strong>(1)</strong></a></sup>.  The algorithm given here uses the special two-coin case rather than the even-parity construction.</p>

<ol>
<li>Create an empty uniform PSRN.</li>
<li>Create a secondary coin &mu; that does the following: &quot;Call <strong>SampleGeometricBag</strong> twice on the PSRN, and flip the input coin twice.  If all of these calls and flips return 1, return 0.  Otherwise, return 1.&quot;</li>
<li>Call the <strong>algorithm for &mu;<sup>1/2</sup></strong> using the secondary coin &mu;.  If it returns 0, return 0.</li>
<li>With probability 1/2, flip the input coin and return the result.</li>
<li>Call <strong>SampleGeometricBag</strong> once on the PSRN, and flip the input coin once.  If both the call and flip return 1, return 0.  Otherwise, go to step 4.</li>
</ol>

<p><a id=arcsin_lambda_2></a></p>

<h4>arcsin(&lambda;) / 2</h4>

<p>The Flajolet paper doesn&#39;t explain in detail how arcsin(&lambda;)/2 arises out of arcsin(&lambda;) + sqrt(1 &minus; &lambda;<sup>2</sup>) &minus; 1 via Bernoulli factory constructions, but here is an algorithm.<sup><a href="#Note15"><strong>(15)</strong></a></sup> Note, however, that the number of input coin flips is expected to grow without bound as &lambda; approaches 1.</p>

<ol>
<li>With probability 1/2, run the <strong>algorithm for arcsin(&lambda;) + sqrt(1 &minus; &lambda;<sup>2</sup>) &minus; 1</strong> and return the result.</li>
<li>Create a secondary coin &mu; that does the following: &quot;Flip the input coin twice.  If both flips return 1, return 0.  Otherwise, return 1.&quot;</li>
<li>Call the <strong>algorithm for &mu;<sup>1/2</sup></strong> using the secondary coin &mu;.  If it returns 0, return 1; otherwise, return 0.</li>
</ol>

<p><a id=lambda_mu_4></a></p>

<h4>&lambda; * &mu;</h4>

<p>(Flajolet et al., 2010)<sup><a href="#Note1"><strong>(1)</strong></a></sup>: Flip the &lambda; input coin and the &mu; input coin.  Return 1 if both flips return 1, and 0 otherwise.</p>

<p><a id=lambda__x___y__linear_Bernoulli_factories></a></p>

<h4>&lambda; * <em>x</em>/<em>y</em> (linear Bernoulli factories)</h4>

<p>Huber has suggested several algorithms for this function over the years.</p>

<p>The first algorithm is called the <strong>2014 algorithm</strong> in this document (Huber 2014)<sup><a href="#Note16"><strong>(16)</strong></a></sup>.  It uses three parameters: <em>x</em>, <em>y</em>, and &#x03F5;, such that <em>x</em>/<em>y</em> &gt; 0 and &#x03F5; is greater than 0.  When <em>x</em>/<em>y</em> is greater than 1, the &#x03F5; parameter has to be chosen such that &lambda; * <em>x</em>/<em>y</em> &lt; 1 &minus; &#x03F5;, which implies that some knowledge of &lambda; has to be available to the algorithm.  (In fact, as simulation results show, the choice of &#x03F5; is crucial to this algorithm&#39;s performance; for best results, &#x03F5; should be chosen such that &lambda; * <em>x</em>/<em>y</em> is slightly less than 1 &minus; &#x03F5;.) The algorithm as described below also includes certain special cases, not mentioned in Huber, to make it more general.</p>

<ol>
<li>Special cases: If <em>x</em> is 0, return 0.  Otherwise, if <em>x</em> equals <em>y</em>, flip the input coin and return the result.  Otherwise, if <em>x</em> is less than <em>y</em>, then: (a) With probability <em>x</em>/<em>y</em>, flip the input coin and return the result; otherwise (b) return 0.</li>
<li>Set <em>c</em> to <em>x</em>/<em>y</em>, and set <em>k</em> to 23 / (5 * &#x03F5;).</li>
<li>If &#x03F5; is greater than 644/1000, set &#x03F5; to 644/1000.</li>
<li>Set <em>i</em> to 1.</li>
<li>Flip the input coin.  If it returns 0, then generate numbers that are each 1 with probability (<em>c</em> &minus; 1) / <em>c</em> and 0 otherwise, until 0 is generated this way, then add 1 to <em>i</em> for each number generated this way (including the last).</li>
<li>Subtract 1 from <em>i</em>, then if <em>i</em> is 0, return 1.</li>
<li>If <em>i</em> is less than <em>k</em>, go to step 5.</li>
<li>If <em>i</em> is <em>k</em> or greater:

<ol>
<li>Generate <em>i</em> numbers that are each 1 with probability 2 / (&#x03F5; + 2) or 0 otherwise.  If any of those numbers is 0, return 0.</li>
<li>Multiply <em>c</em> by 2 / (&#x03F5; + 2), divide &#x03F5; by 2, and multiply <em>k</em> by 2.</li>
</ol></li>
<li>If <em>i</em> is 0, return 1.  Otherwise, go to step 5.</li>
</ol>

<p>The second algorithm is called the <strong>2016 algorithm</strong> (Huber 2016)<sup><a href="#Note17"><strong>(17)</strong></a></sup> and uses the same parameters <em>x</em>, <em>y</em>, and &#x03F5;, and its description uses the same special cases.  The difference here is that it involves a so-called &quot;logistic Bernoulli factory&quot;, which is replaced in this document with a different one that simulates the same function.  When <em>x</em>/<em>y</em> is greater than 1, the &#x03F5; parameter has to be chosen such that &lambda; * <em>x</em>/<em>y</em> &lt;= 1 &minus; &#x03F5;.</p>

<ol>
<li>The same special cases as for the 2014 algorithm apply.</li>
<li>Set <em>m</em> to ceil(1 + 9 / (2 * &#x03F5;)).</li>
<li>Set &beta; to 1 + 1 / (<em>m</em> &minus; 1).</li>
<li><strong>Algorithm A</strong> is what Huber calls this step.  Set <em>s</em> to 1, then while <em>s</em> is greater than 0 and less than <em>m</em>:

<ol>
<li>Run the <strong>logistic Bernoulli factory</strong> algorithm with <em>c</em>/<em>d</em> = &beta; * <em>x</em>/<em>y</em>.</li>
<li>Set <em>s</em> to <em>s</em> &minus; <em>z</em> * 2 + 1, where <em>z</em> is the result of the logistic Bernoulli factory.</li>
</ol></li>
<li>If <em>s</em> is other than 0, return 0.</li>
<li>With probability 1/&beta;, return 1.</li>
<li>Run this algorithm recursively, with <em>x</em>/<em>y</em> = &beta; * <em>x</em>/<em>y</em> and &#x03F5; = 1 &minus; &beta; * (1 &minus; &#x03F5;).  If it returns 0, return 0.</li>
<li>The <strong>high-power logistic Bernoulli factory</strong> is what Huber calls this step.  Set <em>s</em> to 1, then while <em>s</em> is greater than 0 and less than or equal to <em>m</em> minus 2:

<ol>
<li>Run the <strong>logistic Bernoulli factory</strong> algorithm with <em>c</em>/<em>d</em> = &beta; * <em>x</em>/<em>y</em>.</li>
<li>Set <em>s</em> to <em>s</em> + <em>z</em> * 2 &minus; 1, where <em>z</em> is the result of the logistic Bernoulli factory.</li>
</ol></li>
<li>If <em>s</em> is equal to <em>m</em> minus 1, return 1.</li>
<li>Subtract 1 from <em>m</em> and go to step 7.</li>
</ol>

<p>The paper that presented the 2016 algorithm also included a third algorithm, described below, that works only if &lambda; * <em>x</em> / <em>y</em> is known to be less than 1/2.  This third algorithm takes three parameters: <em>x</em>, <em>y</em>, and <em>m</em>, and <em>m</em> has to be chosen such that &lambda; * <em>x</em> / <em>y</em> &lt;= <em>m</em> &lt; 1/2.</p>

<ol>
<li>The same special cases as for the 2014 algorithm apply.</li>
<li>Run the <strong>logistic Bernoulli factory</strong> algorithm with <em>c</em>/<em>d</em> = (<em>x</em>/<em>y</em>) / (1 &minus; 2 * <em>m</em>).  If it returns 0, return 0.</li>
<li>With probability 1 &minus; 2 * <em>m</em>, return 1.</li>
<li>Run the 2014 algorithm or 2016 algorithm with <em>x</em>/<em>y</em> = (<em>x</em>/<em>y</em>) / (2 * <em>m</em>) and &#x03F5; = 1 &minus; <em>m</em>.</li>
</ol>

<p><a id=lambda__x___y___i></a></p>

<h4>(&lambda; * <em>x</em>/<em>y</em>)<sup><em>i</em></sup></h4>

<p>(Huber 2019)<sup><a href="#Note18"><strong>(18)</strong></a></sup>.  This algorithm, called the <strong>2019 algorithm</strong> in this document, uses four parameters: <em>x</em>, <em>y</em>, <em>i</em>, and &#x03F5;, such that <em>x</em>/<em>y</em> &gt; 0, <em>i</em> &gt;= 0 is an integer, and &#x03F5; is greater than 0.  When <em>x</em>/<em>y</em> is greater than 1, the &#x03F5; parameter has to be chosen such that &lambda; * <em>x</em>/<em>y</em> &lt; 1 &minus; &#x03F5;.  It also has special cases not mentioned in Huber 2019.</p>

<ol>
<li> Special cases: If <em>i</em> is 0, return 1.  If <em>x</em> is 0, return 0.  Otherwise, if <em>x</em> equals <em>y</em> and <em>i</em> equals 1, flip the input coin and return the result.</li>
<li>Special case: If <em>x</em> is less than <em>y</em> and <em>i</em> = 1, then: (a) With probability <em>x</em>/<em>y</em>, flip the input coin and return the result; otherwise (b) return 0.</li>
<li>Special case: If <em>x</em> is less than <em>y</em>, then create a secondary coin &mu; that does the following: &quot;(a) With probability <em>x</em>/<em>y</em>, flip the input coin and return the result; otherwise (b) return 0&quot;, then run the <strong>algorithm for (&mu;<sup><em>i</em>/1</sup>)</strong> (described earlier) using this secondary coin.</li>
<li>Set <em>t</em> to 355/100 and <em>c</em> to <em>x</em>/<em>y</em>.</li>
<li>If <em>i</em> is 0, return 1.</li>
<li>While <em>i</em> = <em>t</em> / &#x03F5;:

<ol>
<li>Set &beta; to (1 &minus; &#x03F5; / 2) / (1 &minus; &#x03F5;).</li>
<li>Run the <strong>algorithm for (1/&beta;)<sup><em>i</em></sup></strong> (described later).  If it returns 0, return 0.</li>
<li>Multiply <em>c</em> by &beta;, then divide &#x03F5; by 2.</li>
</ol></li>
<li>Run the <strong>logistic Bernoulli factory</strong> with <em>c</em>/<em>d</em> = <em>c</em>, then set <em>z</em> to the result.  Set <em>i</em> to <em>i</em> + 1 &minus; <em>z</em> * 2, then go to step 5.</li>
</ol>

<p><a id=x03F5_lambda></a></p>

<h4>&#x03F5; / &lambda;</h4>

<p>(Lee et al. 2014)<sup><a href="#Note19"><strong>(19)</strong></a></sup>  This algorithm, in addition to the input coin, takes a parameter &#x03F5;, which must be greater than 0 and be chosen such that &#x03F5; is less than &lambda;.</p>

<ol>
<li>If &beta; to max(&#x03F5;, 1/2) and set &gamma; to 1 &minus; (1 &minus; &beta;) / (1 &minus; (&beta; / 2)).</li>
<li>Create a &mu; input coin that flips the input coin and returns 1 minus the result.</li>
<li>With probability &#x03F5;, return 1.</li>
<li>Run the <strong>2014 algorithm</strong>, <strong>2016 algorithm</strong>, or <strong>2019 algorithm</strong>, with the &mu; input coin, <em>x</em>/<em>y</em> = 1 / (1 &minus; &#x03F5;),  <em>i</em> = 1 (for the 2019 algorithm), and &#x03F5; = &gamma;. If the result is 0, return 0.  Otherwise, go to step 3.  (Note that running the algorithm this way simulates the probability (&lambda; &minus; &#x03F5;)/(1 &minus; &#x03F5;) or 1 &minus; (1 &minus; &lambda;)/(1 &minus; &#x03F5;)).</li>
</ol>

<p><a id=Certain_Power_Series></a></p>

<h4>Certain Power Series</h4>

<p>Mendo (2019)<sup><a href="#Note5"><strong>(5)</strong></a></sup> gave a Bernoulli factory algorithm for certain functions that can be rewritten as a series of the form&mdash;</p>

<p>&nbsp;&nbsp;&nbsp;&nbsp;1 &minus; (<em>c</em>[0] * (1 &minus; &lambda;) + ... + <em>c</em>[<em>i</em>] * (1 &minus; &lambda;)<sup><em>i</em> + 1</sup> + ...),</p>

<p>where <em>c</em>[<em>i</em>] &gt;= 0 are the coefficients of the series.  The algorithm follows:</p>

<ol>
<li>Let <em>csum</em> be the sum of the coefficients.</li>
<li>Set <em>dsum</em> to 0 and <em>i</em> to 0.</li>
<li>Flip the input coin.  If it returns 1, return 1.</li>
<li>If <em>i</em> is equal to or greater than the number of coefficients, set <em>ci</em> to 0.  Otherwise, set <em>ci</em> to <em>c</em>[<em>i</em>]/<em>csum</em>.</li>
<li>With probability <em>ci</em>/(1 &minus; <em>dsum</em>), return 0.</li>
<li>Add <em>ci</em> to <em>dsum</em>, add 1 to <em>i</em>, and go to step 3.</li>
</ol>

<p><a id=Algorithms_for_Irrational_Constants></a></p>

<h3>Algorithms for Irrational Constants</h3>

<p>The following algorithms generate heads with a probability equal to an irrational number.  (On the other hand, probabilities that are <em>rational</em> constants are trivial to simulate.  If fair coins are available, the <code>ZeroOrOne</code> method should be used.  If coins with unknown bias are available, then a <em>randomness extraction</em> method such as the von Neumann algorithm should be used to turn them into fair coins.  Randomness extraction is outside the scope of this document, however.)</p>

<p><a id=Continued_Fractions></a></p>

<h4>Continued Fractions</h4>

<p>The following algorithm simulates a probability expressed as a regular continued fraction of the following form: 0 + 1 / (<em>a</em>[1] + 1 / (<em>a</em>[2] + 1 / (<em>a</em>[3] + ... ))).  The <em>a</em>[<em>i</em>] are the <em>partial denominators</em>, none of which may have an absolute value less than 1.  Inspired by (Flajolet et al., 2010, &quot;Finite graphs (Markov chains) and rational functions&quot;)<sup><a href="#Note1"><strong>(1)</strong></a></sup>, I developed the following algorithm. Note that the algorithm will work even if some or all of the partial denominators are not integers or are negative (unless the first is negative), and the algorithm is designed to allow the partial denominators to be calculated &quot;on the fly&quot;.</p>

<p>The algorithm begins with <em>pos</em> equal to 1.  Then the following steps are taken.</p>

<ol>
<li>Set <em>k</em> to <em>a</em>[<em>pos</em>].</li>
<li>If the partial denominator at <em>pos</em> is the last, return a number that is 1 with probability 1/<em>k</em> and 0 otherwise.</li>
<li>If <em>a</em>[<em>pos</em>] is less than 0, set <em>kp</em> to <em>k</em> &minus; 1 and <em>s</em> to 0.  Otherwise, set <em>kp</em> to <em>k</em> and <em>s</em> to 1. (This step accounts for negative partial denominators.)</li>
<li>With probability <em>kp</em>/(1+<em>kp</em>), return a number that is 1 with probability 1/<em>kp</em> and 0 otherwise.</li>
<li>Run this algorithm recursively, but with <em>pos</em> = <em>pos</em> + 1.  If the result is <em>s</em>, return 0.  Otherwise, go to step 3.</li>
</ol>

<p>A <em>generalized continued fraction</em> has the form 0 + <em>b</em>[1] / (<em>a</em>[1] + <em>b</em>[2] / (<em>a</em>[2] + <em>b</em>[3] / (<em>a</em>[3] + ... ))).  The <em>a</em>[<em>i</em>] are the same as before, but the <em>b</em>[<em>i</em>] are the <em>partial numerators</em>. The following is an algorithm to simulate a probability in the form of a generalized continued fraction; this algorithm employs an equivalence transform from generalized to regular continued fractions. Note that the algorithm will work even if some or all of the partial numerators and denominators are not integers or are negative (unless <em>b</em>[1] &lt; 0, <em>a</em>[1] &lt; 0, or abs(<em>b</em>[<em>i</em>]/<em>a</em>[<em>i</em>]) &gt; 1 for some <em>i</em>), and the algorithm is designed to allow <em>a</em> and <em>b</em> to be calculated &quot;on the fly&quot;.</p>

<p>The algorithm begins with <em>pos</em> and <em>r</em> both equal to 1.  Then the following steps are taken.</p>

<ol>
<li>Set <em>r</em> to 1 / (<em>r</em> * <em>b</em>[<em>pos</em>]), then set <em>k</em> to <em>a</em>[<em>pos</em>] * <em>r</em>. (<em>k</em> is the partial denominator for the equivalent regular continued fraction.)</li>
<li>If the partial numerator/denominator pair at <em>pos</em> is the last, return a number that is 1 with probability 1/abs(<em>k</em>) and 0 otherwise.</li>
<li>Set <em>kp</em> to abs(<em>k</em>) and <em>s</em> to 1.</li>
<li>Set <em>r2</em> to 1 / (<em>r</em> * <em>b</em>[<em>pos</em> + 1]).  If <em>a</em>[<em>pos</em> + 1] * <em>r2</em> is less than 0, set <em>kp</em> to <em>kp</em> &minus; 1 and <em>s</em> to 0. (This step accounts for negative partial numerators and denominators.)</li>
<li>With probability <em>kp</em>/(1+<em>kp</em>), return a number that is 1 with probability 1/<em>kp</em> and 0 otherwise.</li>
<li>Run this algorithm recursively, but with <em>pos</em> = <em>pos</em> + 1 and <em>r</em> = <em>r</em>.  If the result is <em>s</em>, return 0.  Otherwise, go to step 5.</li>
</ol>

<blockquote>
<p><strong>Note:</strong> If any of these algorithms encounters a probability outside the interval [0, 1], the entire algorithm will fail for that continued fraction.</p>

<p><strong>Note:</strong>  The following is an alternative way to write the first algorithm, which better shows the inspiration because it shows how the &quot;even parity construction&quot; (or the two-coin special case) as well as the &quot;1 &minus; <em>x</em>&quot; construction can be used to develop rational number simulators that are as big as their continued fraction expansions, as suggested in the cited part of the Flajolet paper.  However, it only works if the size of the continued fraction expansion (here, <em>size</em>) is known in advance.</p>

<ol>
<li>Set <em>i</em> to <em>size</em>.</li>
<li>Create an input coin that does the following: &quot;Return a number that is 1 with probability 1/<em>a</em>[<em>size</em>] or 0 otherwise&quot;.</li>
<li>While <em>i</em> is 1 or greater:

<ol>
<li>Set <em>k</em> to <em>a</em>[<em>i</em>].</li>
<li>Create an input coin that takes the previous input coin and <em>k</em> and does the following: &quot;(a) With probability <em>k</em>/(1+<em>k</em>), return a number that is 1 with probability 1/<em>k</em> and 0 otherwise; (b) Flip the previous input coin.  If the result is 1, return 0.  Otherwise, go to step (a)&quot;.  (The probability <em>k</em>/(1+<em>k</em>) is related to &lambda;/(1+&lambda;) = 1 &minus; 1/(1+&lambda;), which involves the even-parity construction&mdash;or the two-coin special case&mdash;for 1/(1+&lambda;) as well as complementation for &quot;1 &minus; <em>x</em>&quot;.)</li>
<li>Subtract 1 from <em>i</em>.</li>
</ol></li>
<li>Flip the last input coin created by this algorithm, and return the result.</li>
</ol>
</blockquote>

<p><a id=1_phi></a></p>

<h4>1 / &phi;</h4>

<p>This algorithm uses the algorithm described in the previous section to simulate 1 divided by the golden ratio, whose continued fraction&#39;s partial denominators are 1, 1, 1, 1, ....</p>

<ol>
<li>With probability 1/2, return 1.</li>
<li>Run this algorithm recursively.  If the result is 1, return 0.  Otherwise, go to step 1.</li>
</ol>

<p><a id=sqrt_2_minus_1></a></p>

<h4>sqrt(2) &minus; 1</h4>

<p>Another example of a continued fraction is that of the fractional part of the square root of 2, where the partial denominators are 2, 2, 2, 2, .... The algorithm to simulate this number is as follows:</p>

<ol>
<li>With probability 2/3, generate an unbiased random bit and return that bit.</li>
<li>Run this algorithm recursively.  If the result is 1, return 0.  Otherwise, go to step 1.</li>
</ol>

<p><a id=1_sqrt_2></a></p>

<h4>1/sqrt(2)</h4>

<p>This third example of a continued fraction shows how to simulate a probability 1/<em>z</em>, where <em>z</em> &gt; 1 has a known regular continued fraction expansion.  In this case, the partial denominators are as follows: floor(<em>z</em>), <em>a</em>[1], <em>a</em>[2], ..., where the <em>a</em>[<em>i</em>] are <em>z</em>&#39;s partial denominators (not including <em>z</em>&#39;s integer part).  In the example of 1/sqrt(2), the partial denominators are 1, 2, 2, 2, ..., where 1 comes first since floor(sqrt(2)) = 1.  The algorithm to simulate 1/sqrt(2) is as follows:</p>

<p>The algorithm begins with <em>pos</em> equal to 1.  Then the following steps are taken.</p>

<ol>
<li>If <em>pos</em> is 1, return 1 with probability 1/2.  If <em>pos</em> is greater than 1, then with probability 2/3, generate an unbiased random bit and return that bit.</li>
<li>Run this algorithm recursively, but with <em>pos</em> = <em>pos</em> + 1.  If the result is 1, return 0.  Otherwise, go to step 1.</li>
</ol>

<p><a id=arctan__x___y___y___x></a></p>

<h4>arctan(<em>x</em>/<em>y</em>) * <em>y</em>/<em>x</em></h4>

<p>(Flajolet et al., 2010)<sup><a href="#Note1"><strong>(1)</strong></a></sup>:</p>

<ol>
<li>Create an empty uniform PSRN.</li>
<li>Generate a number that is 1 with probability <em>x</em> * <em>x</em>/(<em>y</em> * <em>y</em>), or 0 otherwise.  If the number is 0, return 1.</li>
<li>Call <strong>SampleGeometricBag</strong> twice on the PSRN.  If either of these calls returns 0, return 1.</li>
<li>Generate a number that is 1 with probability <em>x</em> * <em>x</em>/(<em>y</em> * <em>y</em>), or 0 otherwise.  If the number is 0, return 0.</li>
<li>Call <strong>SampleGeometricBag</strong> twice on the PSRN.  If either of these calls returns 0, return 0.  Otherwise, go to step 2.</li>
</ol>

<p>Observing that the even-parity construction used in the Flajolet paper is equivalent to the two-coin special case, which is uniformly fast, the algorithm above can be made uniformly fast as follows:</p>

<ol>
<li>Create an empty uniform PSRN.</li>
<li>With probability 1/2, return 1.</li>
<li>With probability <em>x</em> * <em>x</em>/(<em>y</em> * <em>y</em>), call <strong>SampleGeometricBag</strong> twice on the PSRN.  If both of these calls return 1, return 0.</li>
<li>Go to step 2.</li>
</ol>

<p><a id=pi_12></a></p>

<h4>&pi; / 12</h4>

<p>Two algorithms:</p>

<ul>
<li>First algorithm: Use the algorithm for <strong>arcsin(1/2) / 2</strong>.  Where the algorithm says to &quot;flip the input coin&quot;, instead generate an unbiased random bit.</li>
<li>Second algorithm: With probability 2/3, return 0.  Otherwise, run the algorithm for <strong>&pi; / 4</strong> and return the result.</li>
</ul>

<p><a id=pi_4></a></p>

<h4>&pi; / 4</h4>

<p>(Flajolet et al., 2010)<sup><a href="#Note1"><strong>(1)</strong></a></sup>:</p>

<ol>
<li>Generate a random integer in the interval [0, 6), call it <em>n</em>.</li>
<li>If <em>n</em> is less than 3, return the result of the <strong>algorithm for arctan(1/2) * 2</strong>.  Otherwise, if <em>n</em> is 3, return 0.  Otherwise, return the result of the <strong>algorithm for arctan(1/3) * 3</strong>.</li>
</ol>

<p><a id=1_pi></a></p>

<h4>1 / &pi;</h4>

<p>(Flajolet et al., 2010)<sup><a href="#Note1"><strong>(1)</strong></a></sup>:</p>

<ol>
<li>Generate two geometric(1/4) random numbers, and call <em>t</em> their sum.  (As used here, a geometric(1/4) random number is the number of successes before the first failure, with success probability 1/4.)</li>
<li>With probability 5/9, add 1 to <em>t</em>.</li>
<li>Generate 2*<em>t</em> unbiased random bits, and return 0 if there are more zeros than ones generated this way or more ones than zeros.  (Note that this condition can be checked even before all the bits are generated this way.)  Repeat this step two more times.</li>
<li>Return 1.</li>
</ol>

<p><a id=a___b___x___y></a></p>

<h4>(<em>a</em>/<em>b</em>)<sup><em>x</em>/<em>y</em></sup></h4>

<p>In the algorithm below, <em>a</em>, <em>b</em>, <em>x</em>, and <em>y</em> are integers, and the case where <em>x</em>/<em>y</em> is in (0, 1) is due to recent work by Mendo (2019)<sup><a href="#Note5"><strong>(5)</strong></a></sup>.  This algorithm works only if&mdash;</p>

<ul>
<li> <em>x</em>/<em>y</em> is 0 or greater and <em>a</em>/<em>b</em> is in the interval [0, 1], or</li>
<li> <em>x</em>/<em>y</em> is less than 0 and <em>a</em>/<em>b</em> is 1 or greater.</li>
</ul>

<p>The algorithm follows.</p>

<ol>
<li>If <em>x</em>/<em>y</em> is less than 0, swap <em>a</em> and <em>b</em>, and remove the sign from <em>x</em>/<em>y</em>.  If <em>a</em>/<em>b</em> is now no longer in the interval [0, 1], return an error.</li>
<li>If <em>x</em>/<em>y</em> is equal to 1, return 1 with probability <em>a</em>/<em>b</em> and 0 otherwise.</li>
<li>If <em>x</em> is 0, return 1.  Otherwise, if <em>a</em> is 0, return 0.  Otherwise, if <em>a</em> equals <em>b</em>, return 1.</li>
<li>If <em>x</em>/<em>y</em> is greater than 1:

<ol>
<li>Set <em>ipart</em> to floor(<em>x</em>/<em>y</em>) and <em>fpart</em> to <code>rem(x, y)</code>.</li>
<li>If <em>fpart</em> is greater than 0, subtract 1 from <em>ipart</em>, then call this algorithm recursively with <em>x</em> = floor(<em>fpart</em>/2) and <em>y</em> = <em>y</em>, then call this algorithm, again recursively, with <em>x</em> = <em>fpart</em> &minus; floor(<em>fpart</em>/2) and <em>y</em> = <em>y</em>. Return 0 if either call returns 0.  (This is done rather than the more obvious approach in order to avoid calling this algorithm with fractional parts very close to 0, because the algorithm runs much more slowly than for fractional parts closer to 1.)</li>
<li>If <em>ipart</em> is 1 or greater, generate a random number that is 1 with probability <em>a</em><sup><em>ipart</em></sup>/<em>b</em><sup><em>ipart</em></sup> or 0 otherwise. (Or generate <em>ipart</em> many random numbers that are each 1 with probability <em>a</em>/<em>b</em> or 0 otherwise, then multiply them all into one number.)  If that number is 0, return 0.</li>
<li>Return 1.</li>
</ol></li>
<li>Set <em>i</em> to 1.</li>
<li>With probability <em>a</em>/<em>b</em>, return 1.</li>
<li>Otherwise, with probability <em>x</em>/(<em>y</em>*<em>i</em>), return 0.</li>
<li>Add 1 to <em>i</em> and go to step 6.</li>
</ol>

<p><a id=exp_minus__x___y></a></p>

<h4>exp(&minus;<em>x</em>/<em>y</em>)</h4>

<p>This algorithm takes integers <em>x</em> &gt;= 0 and <em>y</em> &gt; 0 and outputs 1 with probability <code>exp(-x/y)</code> or 0 otherwise. It originates from (Canonne et al. 2020)<sup><a href="#Note20"><strong>(20)</strong></a></sup>.</p>

<ol>
<li>Special case: If <em>x</em> is 0, return 1. (This is because the probability becomes <code>exp(0) = 1</code>.)</li>
<li>If <code>x &gt; y</code> (so <em>x</em>/<em>y</em> is greater than 1), call this algorithm (recursively) <code>floor(x/y)</code> times with <em>x</em> = <em>y</em> = 1 and once with <em>x</em> = <em>x</em> &minus; floor(<em>x</em>/<em>y</em>) * <em>y</em> and <em>y</em> = <em>y</em>.  Return 1 if all these calls return 1; otherwise, return 0.</li>
<li>Set <em>r</em> to 1 and <em>i</em> to 1.</li>
<li>Return <em>r</em> with probability (<em>y</em> * <em>i</em> &minus; <em>x</em>) / (<em>y</em> * <em>i</em>).</li>
<li>Set <em>r</em> to 1 &minus; <em>r</em>, add 1 to <em>i</em>, and go to step 4.</li>
</ol>

<p><a id=exp_minus__z></a></p>

<h4>exp(&minus;<em>z</em>)</h4>

<p>This algorithm is similar to the previous algorithm, except that the exponent, <em>z</em>, can be any real number 0 or greater, as long as <em>z</em> can be rewritten as the sum of one or more components whose fractional parts can each be simulated by a Bernoulli factory algorithm that outputs heads with probability equal to that fractional part. (This makes use of the identity exp(&minus;a) = exp(&minus;b) * exp(&minus;c).)</p>

<p>More specifically:</p>

<ol>
<li>Decompose <em>z</em> into <em>n</em> &gt; 0 positive components that sum to <em>z</em>.  For example, if <em>z</em> = 3.5, it can be decomposed into only one component, 3.5 (whose fractional part is trivial to simulate), and if <em>z</em> = &pi;, it can be decomposed into four components that are all (&pi; / 4), which has a not-so-trivial simulation described earlier on this page.</li>
<li>For each component <em>LC</em>[<em>i</em>] found this way, let <em>LI</em>[<em>i</em>] be floor(<em>LC</em>[<em>i</em>]) and let <em>LF</em>[<em>i</em>] be <em>LC</em>[<em>i</em>] &minus; floor(<em>LC</em>[<em>i</em>]) (<em>LC</em>[<em>i</em>]&#39;s fractional part).</li>
</ol>

<p>The algorithm is then as follows:</p>

<ul>
<li>For each component <em>LC</em>[<em>i</em>], call the <strong>algorithm for exp(&minus; <em>LI</em>[<em>i</em>]/1)</strong>, and call the <strong>general martingale algorithm</strong> adapted for <strong>exp(&minus;&lambda;)</strong> using the input coin that simulates  <em>LF</em>[<em>i</em>].  If any of these calls returns 0, return 0; otherwise, return 1. (See also (Canonne et al. 2020)<sup><a href="#Note20"><strong>(20)</strong></a></sup>.)</li>
</ul>

<p><a id=a___b___z></a></p>

<h4>(<em>a</em>/<em>b</em>)<sup><em>z</em></sup></h4>

<p>This algorithm is similar to the previous algorithm for powering, except that the exponent, <em>z</em>,  can be any real number 0 or greater, as long as <em>z</em> can be rewritten as the sum of one or more components whose fractional parts can each be simulated by a Bernoulli factory algorithm that outputs heads with probability equal to that fractional part. This algorithm makes use of a similar identity as for <code>exp</code> and works only if <em>z</em> is 0 or greater and <em>a</em>/<em>b</em> is in the interval [0, 1].</p>

<p>Decompose <em>z</em> into <em>LC</em>[<em>i</em>], <em>LI</em>[<em>i</em>], and <em>LF</em>[<em>i</em>] just as for the <strong>exp(&minus; <em>z</em>)</strong> algorithm.  The algorithm is then as follows.</p>

<ul>
<li>If <em>z</em> is 0, return 1.  Otherwise, if <em>a</em> is 0, return 0.  Otherwise, for each component <em>LC</em>[<em>i</em>] (until the algorithm returns a number):

<ol>
<li>Call the <strong>algorithm for  (<em>a</em>/<em>b</em>)<sup><em>LI</em>[<em>i</em>]/1</sup></strong>.  If it returns 0, return 0.</li>
<li>Set <em>j</em> to 1.</li>
<li>Generate a random number that is 1 with probability <em>a</em>/<em>b</em> and 0 otherwise.  If that number is 1, abort these steps and move on to the next component or, if there are no more components, return 1.</li>
<li>Flip the input coin that simulates  <em>LF</em>[<em>i</em>] (which is the exponent); if it returns 1, return 0 with probability 1/<em>j</em>.</li>
<li>Add 1 to <em>j</em> and go to substep 2.</li>
</ol></li>
</ul>

<p><a id=1_1_exp__x___y__2_prec__LogisticExp></a></p>

<h4>1 / 1 + exp(<em>x</em> / (<em>y</em> * 2<sup><em>prec</em></sup>)) (LogisticExp)</h4>

<p>This is the probability that the bit at <em>prec</em> (the <em>prec</em><sup>th</sup> bit after the point) is set for an exponential random number with rate <em>x</em>/<em>y</em>.  This algorithm is a special case of the <strong>logistic Bernoulli factory</strong>.</p>

<ol>
<li>With probability 1/2, return 1.</li>
<li>Call the <strong>algorithm for exp(&minus; <em>x</em>/(<em>y</em> * 2<sup><em>prec</em></sup>))</strong>.  If the call returns 1, return 1.  Otherwise, go to step 1.</li>
</ol>

<p><a id=1_1_exp__z__2_prec__LogisticExp></a></p>

<h4>1 / 1 + exp(<em>z</em> / 2<sup><em>prec</em></sup>)) (LogisticExp)</h4>

<p>This is similar to the previous algorithm, except that <em>z</em> can be any real number described in the <strong>algorithm for exp(&minus;<em>z</em>)</strong>.</p>

<p>Decompose <em>z</em> into <em>LC</em>[<em>i</em>], <em>LI</em>[<em>i</em>], and <em>LF</em>[<em>i</em>] just as for the <strong>exp(&minus;<em>z</em>)</strong> algorithm.  The algorithm is then as follows.</p>

<ol>
<li>For each component <em>LC</em>[<em>i</em>], create an input coin that does the following: &quot;(a) With probability 1/(2<sup><em>prec</em></sup>), return 1 if the input coin that simulates <em>LF</em>[<em>i</em>] returns 1; (b) Return 0&quot;.</li>
<li>Return 0 with probability 1/2.</li>
<li>Call the <strong>algorithm for exp(&minus; <em>x</em>/<em>y</em>)</strong> with <em>x</em> = &Sigma;<sub><em>i</em></sub> <em>LI</em>[<em>i</em>] and <em>y</em> = 2<sup><em>prec</em></sup>.  If this call returns 0, go to step 2.</li>
<li>For each component <em>LC</em>[<em>i</em>], call the <strong>algorithm for exp(&minus;&lambda;)</strong>, using the corresponding input coin for  <em>LC</em>[<em>i</em>] created in step 1. If any of these calls returns 0, go to step 2.  Otherwise, return 1.</li>
</ol>

<p><a id=General_Algorithms></a></p>

<h3>General Algorithms</h3>

<p><a id=Simulating_the_Probability_Generating_Function></a></p>

<h4>Simulating the Probability Generating Function</h4>

<p>Let <em>X</em> be a random number that follows a discrete distribution (one that takes on a countable number of values).  The following algorithm generates heads with probability <strong>E</strong>[&lambda;<sup><em>X</em></sup>], that is, the expected (average) value of &lambda;<sup><em>X</em></sup>.  <strong>E</strong>[&lambda;<sup><em>X</em></sup>] is the distribution&#39;s <em>probability generating function</em>, also known as <em>factorial moment generating function</em> (Dughmi et al. 2017)<sup><a href="#Note21"><strong>(21)</strong></a></sup>.</p>

<ol>
<li>Generate a random number <em>N</em> of the given distribution.</li>
<li>Flip the input coin until the coin returns 0 or the coin is flipped <em>N</em> times.  Return 1 if all the coin flips, including the last, returned 1 (or if <em>N</em> is 0); or return 0 otherwise.</li>
</ol>

<p><a id=URandLessThanFraction></a></p>

<h4>URandLessThanFraction</h4>

<p>The following helper algorithm is used by some of the algorithms on this page.  It returns 1 if a PSRN turns out to be less than a fraction, <em>frac</em>, which is a number in the interval [0, 1].</p>

<ol>
<li>If <em>frac</em> is 0 or 1, return 0 or 1, respectively. (The case of 1 is a degenerate case since the PSRN could, at least in theory, represent an infinite sequence of ones, making it equal to 1.)</li>
<li>Set <em>pt</em> to 1/<em>base</em>, and set <em>i</em> to 0. (<em>base</em> is the base, or radix, of the PSRN&#39;s digits, such as 2 for binary or 10 for decimal.)</li>
<li>Set <em>d1</em> to the digit at the <em>i</em><sup>th</sup> position (starting from 0) of the uniform PSRN.  If there is no digit there, put a digit chosen uniformly at random at that position and set <em>d1</em> to that digit.</li>
<li>Set <em>d2</em> to floor(<em>frac</em> / <em>pt</em>).  (For example, in base 2, set <em>d2</em> to 0 if <em>frac</em> is less than <em>pt</em>, or 1 otherwise.)</li>
<li>If <em>d1</em> is less than <em>d2</em>, return 1.  If <em>d1</em> is greater than <em>d2</em>, return 0.</li>
<li>If <em>frac</em> &gt;= <em>pt</em>, subtract <em>pt</em> from <em>frac</em>.</li>
<li>Divide <em>pt</em> by <em>base</em>, add 1 to <em>i</em>, and go to step 3.</li>
</ol>

<p><a id=Correctness_and_Performance_Charts></a></p>

<h2>Correctness and Performance Charts</h2>

<p>The following charts show the correctness of many of the algorithms on this page and show their performance in terms of the number of bits they use on average.  For each algorithm, and for each of 100 &lambda; values evenly spaced from 0.0001 to 0.9999:</p>

<ul>
<li>500 runs of the algorithm were done.  Then...</li>
<li>The number of bits used by the runs were averaged, as were the return values of the runs (since the return value is either 0 or 1, the mean return value will be in the interval [0, 1]).  The number of bits used included the number of bits used to produce each coin flip, assuming the coin flip procedure for &lambda; was generated using the <code>Bernoulli#coin()</code> method in <em>bernoulli.py</em>, which produces that probability in an optimal or near-optimal way.</li>
</ul>

<p>For each algorithm, if a single run was detected to use more than 5000 bits for a given &lambda;, the entire data point for that &lambda; was suppressed in the charts below.</p>

<p>In addition, for each algorithm, a chart appears showing the minimum number of input coin flips that any fast Bernoulli factory algorithm will need on average to simulate the given function, based on work by Mendo (2019)<sup><a href="#Note5"><strong>(5)</strong></a></sup>.  Note that some functions require a growing number of coin flips as &lambda; approaches 0 or 1.  Note that for the 2014, 2016, and 2019 algorithms&mdash;</p>

<ul>
<li>an &#x03F5; of 1 &minus; (<em>x</em> + <em>c</em>) * 1.001 was used (or 0.0001 if &#x03F5; would be greater than 1), and</li>
<li>an &#x03F5; of (<em>x</em> &minus; <em>c</em>) * 0.9995 for the subtraction variants.</li>
</ul>

<p>Points with invalid &#x03F5; values were suppressed.  For the low-mean algorithm, an <em>m</em> of max(0.49999, <em>x</em><em><em>c</em></em>1.02) was used unless noted otherwise.</p>

<p><a id=The_Charts></a></p>

<h3>The Charts</h3>

<table><thead>
<tr>
<th>Algorithm</th>
<th>Simulated Mean</th>
<th>Average Bits Consumed</th>
<th>Coin Flips</th>
</tr>
</thead><tbody>
<tr>
<td>(1/3)*x/(1+(1/3)*x)</td>
<td><img src="bernoullicharts/1_3_x_1_1_3_x__mean.svg" alt="**Simulated Mean for (1/3)\*x/(1+(1/3)\*x)**"></td>
<td><img src="bernoullicharts/1_3_x_1_1_3_x__bits.svg" alt="**Expected Bits Consumed by (1/3)\*x/(1+(1/3)\*x)**"></td>
<td><img src="bernoullicharts/1_3_x_1_1_3_x__bound.svg" alt="**Coin Flips for the Function**"></td>
</tr>
<tr>
<td>0.5*x/(1+0.5*x)</td>
<td><img src="bernoullicharts/0_5_x_1_0_5_x__mean.svg" alt="**Simulated Mean for 0.5\*x/(1+0.5\*x)**"></td>
<td><img src="bernoullicharts/0_5_x_1_0_5_x__bits.svg" alt="**Expected Bits Consumed by 0.5\*x/(1+0.5\*x)**"></td>
<td><img src="bernoullicharts/0_5_x_1_0_5_x__bound.svg" alt="**Coin Flips for the Function**"></td>
</tr>
<tr>
<td>1 - log(1+x) (Alt. Series)</td>
<td><img src="bernoullicharts/1_-_log_1_x_alt_series__mean.svg" alt="**Simulated Mean for 1 - log(1+x) (Alt. Series)**"></td>
<td><img src="bernoullicharts/1_-_log_1_x_alt_series__bits.svg" alt="**Expected Bits Consumed by 1 - log(1+x) (Alt. Series)**"></td>
<td><img src="bernoullicharts/1_-_log_1_x_alt_series__bound.svg" alt="**Coin Flips for the Function**"></td>
</tr>
<tr>
<td>1/(1+x) (Alt. Series)</td>
<td><img src="bernoullicharts/1_1_x_alt_series__mean.svg" alt="**Simulated Mean for 1/(1+x) (Alt. Series)**"></td>
<td><img src="bernoullicharts/1_1_x_alt_series__bits.svg" alt="**Expected Bits Consumed by 1/(1+x) (Alt. Series)**"></td>
<td><img src="bernoullicharts/1_1_x_alt_series__bound.svg" alt="**Coin Flips for the Function**"></td>
</tr>
<tr>
<td>1/(1+x) (Even Parity)</td>
<td><img src="bernoullicharts/1_1_x_even_parity__mean.svg" alt="**Simulated Mean for 1/(1+x) (Even Parity)**"></td>
<td><img src="bernoullicharts/1_1_x_even_parity__bits.svg" alt="**Expected Bits Consumed by 1/(1+x) (Even Parity)**"></td>
<td><img src="bernoullicharts/1_1_x_even_parity__bound.svg" alt="**Coin Flips for the Function**"></td>
</tr>
<tr>
<td>1/(1+x) (Two-Coin Special Case)</td>
<td><img src="bernoullicharts/1_1_x_two-coin_special_case__mean.svg" alt="**Simulated Mean for 1/(1+x) (Two-Coin Special Case)**"></td>
<td><img src="bernoullicharts/1_1_x_two-coin_special_case__bits.svg" alt="**Expected Bits Consumed by 1/(1+x) (Two-Coin Special Case)**"></td>
<td><img src="bernoullicharts/1_1_x_two-coin_special_case__bound.svg" alt="**Coin Flips for the Function**"></td>
</tr>
<tr>
<td>1/(3+x)</td>
<td><img src="bernoullicharts/1_3_x__mean.svg" alt="**Simulated Mean for 1/(3+x)**"></td>
<td><img src="bernoullicharts/1_3_x__bits.svg" alt="**Expected Bits Consumed by 1/(3+x)**"></td>
<td><img src="bernoullicharts/1_3_x__bound.svg" alt="**Coin Flips for the Function**"></td>
</tr>
<tr>
<td>1/(5+x)</td>
<td><img src="bernoullicharts/1_5_x__mean.svg" alt="**Simulated Mean for 1/(5+x)**"></td>
<td><img src="bernoullicharts/1_5_x__bits.svg" alt="**Expected Bits Consumed by 1/(5+x)**"></td>
<td><img src="bernoullicharts/1_5_x__bound.svg" alt="**Coin Flips for the Function**"></td>
</tr>
<tr>
<td>2014 Add. x+0.1</td>
<td><img src="bernoullicharts/2014_add_x_0_1_mean.svg" alt="**Simulated Mean for 2014 Add. x+0.1**"></td>
<td><img src="bernoullicharts/2014_add_x_0_1_bits.svg" alt="**Expected Bits Consumed by 2014 Add. x+0.1**"></td>
<td><img src="bernoullicharts/2014_add_x_0_1_bound.svg" alt="**Coin Flips for the Function**"></td>
</tr>
<tr>
<td>2014 Add. x+0.2</td>
<td><img src="bernoullicharts/2014_add_x_0_2_mean.svg" alt="**Simulated Mean for 2014 Add. x+0.2**"></td>
<td><img src="bernoullicharts/2014_add_x_0_2_bits.svg" alt="**Expected Bits Consumed by 2014 Add. x+0.2**"></td>
<td><img src="bernoullicharts/2014_add_x_0_2_bound.svg" alt="**Coin Flips for the Function**"></td>
</tr>
<tr>
<td>2014 Add. x+0.3</td>
<td><img src="bernoullicharts/2014_add_x_0_3_mean.svg" alt="**Simulated Mean for 2014 Add. x+0.3**"></td>
<td><img src="bernoullicharts/2014_add_x_0_3_bits.svg" alt="**Expected Bits Consumed by 2014 Add. x+0.3**"></td>
<td><img src="bernoullicharts/2014_add_x_0_3_bound.svg" alt="**Coin Flips for the Function**"></td>
</tr>
<tr>
<td>2014 Add. x+0.5</td>
<td><img src="bernoullicharts/2014_add_x_0_5_mean.svg" alt="**Simulated Mean for 2014 Add. x+0.5**"></td>
<td><img src="bernoullicharts/2014_add_x_0_5_bits.svg" alt="**Expected Bits Consumed by 2014 Add. x+0.5**"></td>
<td><img src="bernoullicharts/2014_add_x_0_5_bound.svg" alt="**Coin Flips for the Function**"></td>
</tr>
<tr>
<td>2014 Lin. x*1.3</td>
<td><img src="bernoullicharts/2014_lin_x_1_3_mean.svg" alt="**Simulated Mean for 2014 Lin. x\*1.3**"></td>
<td><img src="bernoullicharts/2014_lin_x_1_3_bits.svg" alt="**Expected Bits Consumed by 2014 Lin. x\*1.3**"></td>
<td><img src="bernoullicharts/2014_lin_x_1_3_bound.svg" alt="**Coin Flips for the Function**"></td>
</tr>
<tr>
<td>2014 Lin. x*1.5</td>
<td><img src="bernoullicharts/2014_lin_x_1_5_mean.svg" alt="**Simulated Mean for 2014 Lin. x\*1.5**"></td>
<td><img src="bernoullicharts/2014_lin_x_1_5_bits.svg" alt="**Expected Bits Consumed by 2014 Lin. x\*1.5**"></td>
<td><img src="bernoullicharts/2014_lin_x_1_5_bound.svg" alt="**Coin Flips for the Function**"></td>
</tr>
<tr>
<td>2014 Lin. x*2.0</td>
<td><img src="bernoullicharts/2014_lin_x_2_0_mean.svg" alt="**Simulated Mean for 2014 Lin. x\*2.0**"></td>
<td><img src="bernoullicharts/2014_lin_x_2_0_bits.svg" alt="**Expected Bits Consumed by 2014 Lin. x\*2.0**"></td>
<td><img src="bernoullicharts/2014_lin_x_2_0_bound.svg" alt="**Coin Flips for the Function**"></td>
</tr>
<tr>
<td>2014 Lin. x*4.0</td>
<td><img src="bernoullicharts/2014_lin_x_4_0_mean.svg" alt="**Simulated Mean for 2014 Lin. x\*4.0**"></td>
<td><img src="bernoullicharts/2014_lin_x_4_0_bits.svg" alt="**Expected Bits Consumed by 2014 Lin. x\*4.0**"></td>
<td><img src="bernoullicharts/2014_lin_x_4_0_bound.svg" alt="**Coin Flips for the Function**"></td>
</tr>
<tr>
<td>2014 Lin. x*6.0</td>
<td><img src="bernoullicharts/2014_lin_x_6_0_mean.svg" alt="**Simulated Mean for 2014 Lin. x\*6.0**"></td>
<td><img src="bernoullicharts/2014_lin_x_6_0_bits.svg" alt="**Expected Bits Consumed by 2014 Lin. x\*6.0**"></td>
<td><img src="bernoullicharts/2014_lin_x_6_0_bound.svg" alt="**Coin Flips for the Function**"></td>
</tr>
<tr>
<td>2014 Lin. x*8.0</td>
<td><img src="bernoullicharts/2014_lin_x_8_0_mean.svg" alt="**Simulated Mean for 2014 Lin. x\*8.0**"></td>
<td><img src="bernoullicharts/2014_lin_x_8_0_bits.svg" alt="**Expected Bits Consumed by 2014 Lin. x\*8.0**"></td>
<td><img src="bernoullicharts/2014_lin_x_8_0_bound.svg" alt="**Coin Flips for the Function**"></td>
</tr>
<tr>
<td>2014 Sub. x-0.1</td>
<td><img src="bernoullicharts/2014_sub_x-0_1_mean.svg" alt="**Simulated Mean for 2014 Sub. x-0.1**"></td>
<td><img src="bernoullicharts/2014_sub_x-0_1_bits.svg" alt="**Expected Bits Consumed by 2014 Sub. x-0.1**"></td>
<td><img src="bernoullicharts/2014_sub_x-0_1_bound.svg" alt="**Coin Flips for the Function**"></td>
</tr>
<tr>
<td>2014 Sub. x-0.2</td>
<td><img src="bernoullicharts/2014_sub_x-0_2_mean.svg" alt="**Simulated Mean for 2014 Sub. x-0.2**"></td>
<td><img src="bernoullicharts/2014_sub_x-0_2_bits.svg" alt="**Expected Bits Consumed by 2014 Sub. x-0.2**"></td>
<td><img src="bernoullicharts/2014_sub_x-0_2_bound.svg" alt="**Coin Flips for the Function**"></td>
</tr>
<tr>
<td>2014 Sub. x-0.3</td>
<td><img src="bernoullicharts/2014_sub_x-0_3_mean.svg" alt="**Simulated Mean for 2014 Sub. x-0.3**"></td>
<td><img src="bernoullicharts/2014_sub_x-0_3_bits.svg" alt="**Expected Bits Consumed by 2014 Sub. x-0.3**"></td>
<td><img src="bernoullicharts/2014_sub_x-0_3_bound.svg" alt="**Coin Flips for the Function**"></td>
</tr>
<tr>
<td>2014 Sub. x-0.5</td>
<td><img src="bernoullicharts/2014_sub_x-0_5_mean.svg" alt="**Simulated Mean for 2014 Sub. x-0.5**"></td>
<td><img src="bernoullicharts/2014_sub_x-0_5_bits.svg" alt="**Expected Bits Consumed by 2014 Sub. x-0.5**"></td>
<td><img src="bernoullicharts/2014_sub_x-0_5_bound.svg" alt="**Coin Flips for the Function**"></td>
</tr>
<tr>
<td>arcsin(x)+sqrt(1-x*x)-1</td>
<td><img src="bernoullicharts/arcsin_x_sqrt_1-x_x_-1_mean.svg" alt="**Simulated Mean for arcsin(x)+sqrt(1-x\*x)-1**"></td>
<td><img src="bernoullicharts/arcsin_x_sqrt_1-x_x_-1_bits.svg" alt="**Expected Bits Consumed by arcsin(x)+sqrt(1-x\*x)-1**"></td>
<td><img src="bernoullicharts/arcsin_x_sqrt_1-x_x_-1_bound.svg" alt="**Coin Flips for the Function**"></td>
</tr>
<tr>
<td>arcsin(x)/2</td>
<td><img src="bernoullicharts/arcsin_x_2_mean.svg" alt="**Simulated Mean for arcsin(x)/2**"></td>
<td><img src="bernoullicharts/arcsin_x_2_bits.svg" alt="**Expected Bits Consumed by arcsin(x)/2**"></td>
<td><img src="bernoullicharts/arcsin_x_2_bound.svg" alt="**Coin Flips for the Function**"></td>
</tr>
<tr>
<td>arctan(x) (Flajolet)</td>
<td><img src="bernoullicharts/arctan_x_flajolet__mean.svg" alt="**Simulated Mean for arctan(x) (Flajolet)**"></td>
<td><img src="bernoullicharts/arctan_x_flajolet__bits.svg" alt="**Expected Bits Consumed by arctan(x) (Flajolet)**"></td>
<td><img src="bernoullicharts/arctan_x_flajolet__bound.svg" alt="**Coin Flips for the Function**"></td>
</tr>
<tr>
<td>arctan(x) (Two-Coin Special Case)</td>
<td><img src="bernoullicharts/arctan_x_two-coin_special_case__mean.svg" alt="**Simulated Mean for arctan(x) (Two-Coin Special Case)**"></td>
<td><img src="bernoullicharts/arctan_x_two-coin_special_case__bits.svg" alt="**Expected Bits Consumed by arctan(x) (Two-Coin Special Case)**"></td>
<td><img src="bernoullicharts/arctan_x_two-coin_special_case__bound.svg" alt="**Coin Flips for the Function**"></td>
</tr>
<tr>
<td>exp(-x) (Alg. 2)</td>
<td><img src="bernoullicharts/exp_-x_alg_2__mean.svg" alt="**Simulated Mean for exp(-x) (Alg. 2)**"></td>
<td><img src="bernoullicharts/exp_-x_alg_2__bits.svg" alt="**Expected Bits Consumed by exp(-x) (Alg. 2)**"></td>
<td><img src="bernoullicharts/exp_-x_alg_2__bound.svg" alt="**Coin Flips for the Function**"></td>
</tr>
<tr>
<td>exp(-x) (Alt. Series)</td>
<td><img src="bernoullicharts/exp_-x_alt_series__mean.svg" alt="**Simulated Mean for exp(-x) (Alt. Series)**"></td>
<td><img src="bernoullicharts/exp_-x_alt_series__bits.svg" alt="**Expected Bits Consumed by exp(-x) (Alt. Series)**"></td>
<td><img src="bernoullicharts/exp_-x_alt_series__bound.svg" alt="**Coin Flips for the Function**"></td>
</tr>
<tr>
<td>exp(-x) (Flajolet)</td>
<td><img src="bernoullicharts/exp_-x_flajolet__mean.svg" alt="**Simulated Mean for exp(-x) (Flajolet)**"></td>
<td><img src="bernoullicharts/exp_-x_flajolet__bits.svg" alt="**Expected Bits Consumed by exp(-x) (Flajolet)**"></td>
<td><img src="bernoullicharts/exp_-x_flajolet__bound.svg" alt="**Coin Flips for the Function**"></td>
</tr>
<tr>
<td>exp(x)*(1-x)</td>
<td><img src="bernoullicharts/exp_x_1-x__mean.svg" alt="**Simulated Mean for exp(x)\*(1-x)**"></td>
<td><img src="bernoullicharts/exp_x_1-x__bits.svg" alt="**Expected Bits Consumed by exp(x)\*(1-x)**"></td>
<td><img src="bernoullicharts/exp_x_1-x__bound.svg" alt="**Coin Flips for the Function**"></td>
</tr>
<tr>
<td>log(1+x) (Flajolet)</td>
<td><img src="bernoullicharts/log_1_x_flajolet__mean.svg" alt="**Simulated Mean for log(1+x) (Flajolet)**"></td>
<td><img src="bernoullicharts/log_1_x_flajolet__bits.svg" alt="**Expected Bits Consumed by log(1+x) (Flajolet)**"></td>
<td><img src="bernoullicharts/log_1_x_flajolet__bound.svg" alt="**Coin Flips for the Function**"></td>
</tr>
<tr>
<td>log(1+x) (Two-Coin Special Case)</td>
<td><img src="bernoullicharts/log_1_x_two-coin_special_case__mean.svg" alt="**Simulated Mean for log(1+x) (Two-Coin Special Case)**"></td>
<td><img src="bernoullicharts/log_1_x_two-coin_special_case__bits.svg" alt="**Expected Bits Consumed by log(1+x) (Two-Coin Special Case)**"></td>
<td><img src="bernoullicharts/log_1_x_two-coin_special_case__bound.svg" alt="**Coin Flips for the Function**"></td>
</tr>
<tr>
<td>pow(x,1/3)</td>
<td><img src="bernoullicharts/pow_x_1_3__mean.svg" alt="**Simulated Mean for pow(x,1/3)**"></td>
<td><img src="bernoullicharts/pow_x_1_3__bits.svg" alt="**Expected Bits Consumed by pow(x,1/3)**"></td>
<td><img src="bernoullicharts/pow_x_1_3__bound.svg" alt="**Coin Flips for the Function**"></td>
</tr>
<tr>
<td>pow(x,2/1)</td>
<td><img src="bernoullicharts/pow_x_2_1__mean.svg" alt="**Simulated Mean for pow(x,2/1)**"></td>
<td><img src="bernoullicharts/pow_x_2_1__bits.svg" alt="**Expected Bits Consumed by pow(x,2/1)**"></td>
<td><img src="bernoullicharts/pow_x_2_1__bound.svg" alt="**Coin Flips for the Function**"></td>
</tr>
<tr>
<td>pow(x,2/4)</td>
<td><img src="bernoullicharts/pow_x_2_4__mean.svg" alt="**Simulated Mean for pow(x,2/4)**"></td>
<td><img src="bernoullicharts/pow_x_2_4__bits.svg" alt="**Expected Bits Consumed by pow(x,2/4)**"></td>
<td><img src="bernoullicharts/pow_x_2_4__bound.svg" alt="**Coin Flips for the Function**"></td>
</tr>
<tr>
<td>pow(x,3/4)</td>
<td><img src="bernoullicharts/pow_x_3_4__mean.svg" alt="**Simulated Mean for pow(x,3/4)**"></td>
<td><img src="bernoullicharts/pow_x_3_4__bits.svg" alt="**Expected Bits Consumed by pow(x,3/4)**"></td>
<td><img src="bernoullicharts/pow_x_3_4__bound.svg" alt="**Coin Flips for the Function**"></td>
</tr>
<tr>
<td>pow(x,4/5)</td>
<td><img src="bernoullicharts/pow_x_4_5__mean.svg" alt="**Simulated Mean for pow(x,4/5)**"></td>
<td><img src="bernoullicharts/pow_x_4_5__bits.svg" alt="**Expected Bits Consumed by pow(x,4/5)**"></td>
<td><img src="bernoullicharts/pow_x_4_5__bound.svg" alt="**Coin Flips for the Function**"></td>
</tr>
<tr>
<td>pow(x,5/1)</td>
<td><img src="bernoullicharts/pow_x_5_1__mean.svg" alt="**Simulated Mean for pow(x,5/1)**"></td>
<td><img src="bernoullicharts/pow_x_5_1__bits.svg" alt="**Expected Bits Consumed by pow(x,5/1)**"></td>
<td><img src="bernoullicharts/pow_x_5_1__bound.svg" alt="**Coin Flips for the Function**"></td>
</tr>
<tr>
<td>pow(x,5/4)</td>
<td><img src="bernoullicharts/pow_x_5_4__mean.svg" alt="**Simulated Mean for pow(x,5/4)**"></td>
<td><img src="bernoullicharts/pow_x_5_4__bits.svg" alt="**Expected Bits Consumed by pow(x,5/4)**"></td>
<td><img src="bernoullicharts/pow_x_5_4__bound.svg" alt="**Coin Flips for the Function**"></td>
</tr>
<tr>
<td>sqrt(x)</td>
<td><img src="bernoullicharts/sqrt_x__mean.svg" alt="**Simulated Mean for sqrt(x)**"></td>
<td><img src="bernoullicharts/sqrt_x__bits.svg" alt="**Expected Bits Consumed by sqrt(x)**"></td>
<td><img src="bernoullicharts/sqrt_x__bound.svg" alt="**Coin Flips for the Function**"></td>
</tr>
</tbody></table>

<p><a id=Notes></a></p>

<h2>Notes</h2>

<p><small><sup id=Note1>(1)</sup> Flajolet, P., Pelletier, M., Soria, M., &quot;<a href="https://arxiv.org/abs/0906.5560v2"><strong>On Buffon machines and numbers</strong></a>&quot;, arXiv:0906.5560v2  [math.PR], 2010.</small></p>

<p><small><sup id=Note2>(2)</sup> Keane,  M.  S.,  and  O&#39;Brien,  G.  L., &quot;A Bernoulli factory&quot;, <em>ACM Transactions on Modeling and Computer Simulation</em> 4(2), 1994.</small></p>

<p><small><sup id=Note3>(3)</sup> Devroye, L., <a href="http://luc.devroye.org/rnbookindex.html"><strong><em>Non-Uniform Random Variate Generation</em></strong></a>, 1986.</small></p>

<p><small><sup id=Note4>(4)</sup> Nacu, Şerban, and Yuval Peres. &quot;Fast simulation of new coins from old&quot;, The Annals of Applied Probability 15, no. 1A (2005): 93-115.</small></p>

<p><small><sup id=Note5>(5)</sup> Mendo, Luis. &quot;An asymptotically optimal Bernoulli factory for certain functions that can be expressed as power series.&quot; Stochastic Processes and their Applications 129, no. 11 (2019): 4366-4384.</small></p>

<p><small><sup id=Note6>(6)</sup> von Neumann, J., &quot;Various techniques used in connection with random digits&quot;, 1951.</small></p>

<p><small><sup id=Note7>(7)</sup> As used here and in the Flajolet paper, a geometric random number is the number of successes before the first failure, where the success probability is &lambda;.</small></p>

<p><small><sup id=Note8>(8)</sup> The Flajolet paper describes what it calls the <em>von Neumann schema</em>, which, given a permutation class and an input coin, generates a random non-negative integer <em>n</em> with probability equal to (&lambda;<sup><em>n</em></sup> * V(<em>n</em>) / <em>n</em>!) / EGF(&lambda;), where EGF(&lambda;) = &Sigma;<sub><em>k</em> = 0, 1, ...</sub> (&lambda;<sup><em>k</em></sup> * V(<em>k</em>) / <em>k</em>!), and V(<em>n</em>) is the number of <em>valid</em> permutations of size <em>n</em>.  Here, EGF(&lambda;) is the <em>exponential generating function</em>.  Effectively, a geometric(&lambda;) random number <em>G</em> is accepted with probability V(<em>G</em>)/<em>G</em>! (where <em>G</em>! is the number of <em>possible</em> permutations of size <em>G</em>, or 1 if <em>G</em> is 0), and rejected otherwise.  The probability that <em>r</em> geometric random numbers are rejected this way is <em>p</em>*(1 &minus; <em>p</em>)<sup><em>r</em></sup>, where <em>p</em> = (1 &minus; &lambda;) * EGF(&lambda;).</small></p>

<p><small><sup id=Note9>(9)</sup> Łatuszyński, K., Kosmidis, I.,  Papaspiliopoulos, O., Roberts, G.O., &quot;<a href="https://arxiv.org/abs/0907.4018v2"><strong>Simulating events of unknown probabilities via reverse time martingales</strong></a>&quot;, arXiv:0907.4018v2 [stat.CO], 2009/2011.</small></p>

<p><small><sup id=Note10>(10)</sup> Gonçalves, F. B., Łatuszyński, K. G., Roberts, G. O. (2017).  Exact Monte Carlo likelihood-based inference for jump-diffusion processes.</small></p>

<p><small><sup id=Note11>(11)</sup> Another algorithm for this function uses the general martingale algorithm, but uses more bits on average as &lambda; approaches 1.  Here, the alternating series is <code>1 - x + x^2/2 - x^3/3 + ...</code>, whose coefficients are 1, 1, 1/2, 1/3, ...</small></p>

<p><small><sup id=Note12>(12)</sup> Vats, D., Gonçalves, F. B., Łatuszyński, K. G., Roberts, G. O. Efficient Bernoulli factory MCMC for intractable likelihoods, arXiv:2004.07471v1 [stat.CO], 2020.</small></p>

<p><small><sup id=Note13>(13)</sup> Huber, M., &quot;<a href="https://arxiv.org/abs/1507.00843v2"><strong>Optimal linear Bernoulli factories for small mean problems</strong></a>&quot;, arXiv:1507.00843v2 [math.PR], 2016</small></p>

<p><small><sup id=Note14>(14)</sup> Morina, G., Łatuszyński, K., et al., &quot;<a href="https://arxiv.org/abs/1912.09229v1"><strong>From the Bernoulli Factory to a Dice Enterprise via Perfect Sampling of Markov Chains</strong></a>&quot;, arXiv:1912.09229v1 [math.PR], 2019.</small></p>

<p><small><sup id=Note15>(15)</sup> One of the only implementations I could find of this, if not the only, was a <a href="https://github.com/derekelkins/buffon/blob/master/Data/Distribution/Buffon.hs"><strong>Haskell implementation</strong></a>.</small></p>

<p><small><sup id=Note16>(16)</sup> Huber, M., &quot;<a href="https://arxiv.org/abs/1308.1562v2"><strong>Nearly optimal Bernoulli factories for linear functions</strong></a>&quot;, arXiv:1308.1562v2  [math.PR], 2014.</small></p>

<p><small><sup id=Note17>(17)</sup> Huber, M., &quot;<a href="https://arxiv.org/abs/1507.00843v2"><strong>Optimal linear Bernoulli factories for small mean problems</strong></a>&quot;, arXiv:1507.00843v2 [math.PR], 2016.</small></p>

<p><small><sup id=Note18>(18)</sup> Huber, M., &quot;<a href="https://arxiv.org/abs/1907.06748v1"><strong>Designing perfect simulation algorithms using local correctness</strong></a>&quot;, arXiv:1907.06748v1 [cs.DS], 2019.</small></p>

<p><small><sup id=Note19>(19)</sup> Lee, A., Doucet, A. and Łatuszyński, K., 2014. Perfect simulation using atomic regeneration with application to Sequential Monte Carlo, arXiv:1407.5770v1  [stat.CO].</small></p>

<p><small><sup id=Note20>(20)</sup> Canonne, C., Kamath, G., Steinke, T., &quot;<a href="https://arxiv.org/abs/2004.00010v2"><strong>The Discrete Gaussian for Differential Privacy</strong></a>&quot;, arXiv:2004.00010v2 [cs.DS], 2020.</small></p>

<p><small><sup id=Note21>(21)</sup> Shaddin Dughmi, Jason D. Hartline, Robert Kleinberg, and Rad Niazadeh. 2017. Bernoulli Factories and Black-Box Reductions in Mechanism Design. In <em>Proceedings of 49th Annual ACM SIGACT Symposium on the Theory of Computing</em>, Montreal, Canada, June 2017 (STOC’17).</small></p>

<p><small><sup id=Note22>(22)</sup> Brassard, G., Devroye, L., Gravel, C., &quot;Remote Sampling with Applications to General Entanglement Simulation&quot;, Entropy 2019(21)(92), doi:10.3390/e21010092.</small></p>

<p><small><sup id=Note23>(23)</sup> Devroye, L., Gravel, C., &quot;<a href="https://arxiv.org/abs/1502.02539v5"><strong>Sampling with arbitrary precision</strong></a>&quot;, arXiv:1502.02539v5 [cs.IT], 2015.</small></p>

<p><a id=Appendix></a></p>

<h2>Appendix</h2>

<p>&nbsp;</p>

<p><a id=Convergence_of_Bernoulli_Factories></a></p>

<h3>Convergence of Bernoulli Factories</h3>

<p>The following Python code illustrates how to test a Bernoulli factory algorithm for convergence to the correct probability, as well as the speed of this convergence.  In this case, we are testing the Bernoulli factory algorithm of <em>x</em><sup><em>y</em>/<em>z</em></sup>, where <em>x</em> is in the interval (0, 1) and <em>y</em>/<em>z</em> is greater than 0.  Depending on the parameters <em>x</em>, <em>y</em>, and <em>z</em>, this Bernoulli factory converges faster or slower.</p>

<pre># Parameters for the Bernoulli factory x**(y/z)
x=0.005 # x is the input coin&#39;s probability of heads
y=2
z=3
# Print the desired probability
print(x**(y/z))
passp = 0
failp = 0
# Set cumulative probability to 1
cumu = 1
iters=4000
for i in range(iters):
  # With probability x, the algorithm returns 1 (heads)
  prob=(x);prob*=cumu; passp+=prob; cumu-=prob
  # With probability (y/(z*(i+1))), the algorithm returns 0 (tails)
  prob=(y/(z*(i+1)));prob*=cumu; failp+=prob; cumu-=prob
  # Output the current probability in this iteration,
  # but only for the first 30 and last 30 iterations
  if i&lt;30 or i&gt;=iters-30: print(passp)
</pre>

<p>As this code shows, as <em>x</em> (the probability of heads of the input coin) approaches 0, the convergence rate gets slower and slower, even though the probability will eventually converge to the correct one. In fact, when <em>y</em>/<em>z</em> is less than 1:</p>

<ul>
<li>The average number of coin flips needed by this algorithm will grow without bound as <em>x</em> approaches 0, and Mendo (2019)<sup><a href="#Note5"><strong>(5)</strong></a></sup> showed that this is a lower bound; that is, no Bernoulli factory algorithm can do much better without knowing more information on <em>x</em>.</li>
<li><em>x</em><sup><em>y</em>/<em>z</em></sup> has a slope that tends to a vertical slope near 0, so that the so-called <a href="https://en.wikipedia.org/wiki/Lipschitz_continuity"><strong><em>Lipschitz condition</em></strong></a> is not met at 0.  And (Nacu and Peres 2005, propositions 10 and 23)<sup><a href="#Note4"><strong>(4)</strong></a></sup> showed that the Lipschitz condition is necessary for a Bernoulli factory to have an upper bound on the average running time.</li>
</ul>

<p>Thus, a practical implementation of this algorithm may have to switch to an alternative implementation (such as the one described in the next section) when it detects that the geometric bag&#39;s first few digits are zeros.</p>

<p><a id=Alternative_Implementation_of_Bernoulli_Factories></a></p>

<h3>Alternative Implementation of Bernoulli Factories</h3>

<p>Say we have a Bernoulli factory algorithm that takes a coin with probability of heads of <em>p</em> and outputs 1 with probability <em>f</em>(<em>p</em>).  If this algorithm takes a geometric bag (a partially-sampled uniform random number or PSRN) as the input coin and flips that coin using <strong>SampleGeometricBag</strong>, the algorithm could instead be implemented as follows in order to return 1 with probability <em>f</em>(<em>U</em>), where <em>U</em> is the number represented by the geometric bag (see also (Brassard et al., 2019)<sup><a href="#Note22"><strong>(22)</strong></a></sup>, (Devroye 1986, p. 431)<sup><a href="#Note3"><strong>(3)</strong></a></sup>, (Devroye and Gravel 2015)<sup><a href="#Note23"><strong>(23)</strong></a></sup>:</p>

<ol>
<li>Set <em>v</em> to 0 and <em>k</em> to 1.</li>
<li>Set <em>v</em> to <em>b</em> * <em>v</em> + <em>d</em>, where <em>b</em> is the base (or radix) of the geometric bag&#39;s digits, and <em>d</em> is a digit chosen uniformly at random.</li>
<li>Calculate an approximation of <em>f</em>(<em>U</em>) as follows:

<ol>
<li>Set <em>n</em> to the number of items (sampled and unsampled digits) in the geometric bag.</li>
<li>Of the first <em>n</em> items in the geometric bag, sample each of the unsampled digits uniformly at random.  Then let <em>uk</em> be the geometric bag&#39;s digit expansion up to the first <em>n</em> digits after the point.</li>
<li>Calculate the lowest and highest values of <em>f</em> in the interval [<em>uk</em>, <em>uk</em> + <em>b</em><sup>&minus;<em>n</em></sup>], call them <em>fmin</em> and <em>fmax</em>. If abs(<em>fmin</em> - <em>fmax</em>) &lt;= 2 * <em>b</em><sup>&minus;<em>k</em></sup>, calculate (<em>fmax</em> + <em>fmin</em>) / 2 as the approximation.  Otherwise, add 1 to <em>n</em> and go to the previous substep.</li>
</ol></li>
<li>Let <em>pk</em> be the approximation&#39;s digit expansion up to the <em>k</em> digits after the point.  For example, if <em>f</em>(<em>U</em>) is &pi; and <em>k</em> is 2, <em>pk</em> is 314.</li>
<li>If <em>pk</em> + 1 &lt;= <em>v</em>, return 0. If <em>pk</em> &minus; 2 &gt;= <em>v</em>, return 1.  If neither is the case, add 1 to <em>k</em> and go to step 2.</li>
</ol>

<p>However, the focus of this article is on algorithms that don&#39;t rely on calculations of irrational numbers, which is why this section is in the appendix.</p>

<p><a id=License></a></p>

<h2>License</h2>

<p>Any copyright to this page is released to the Public Domain.  In case this is not possible, this page is also licensed under <a href="https://creativecommons.org/publicdomain/zero/1.0/"><strong>Creative Commons Zero</strong></a>.</p>
</div><nav id="navigation"><ul>
<li><a href="/">Back to start site.</a>
<li><a href="https://github.com/peteroupc/peteroupc.github.io">This site's repository (source code)</a>
<li><a href="https://github.com/peteroupc/peteroupc.github.io/issues">Post an issue or comment</a></ul>
<p>
If you like this software, you should consider donating to me, Peter O., at the link below:</p>
<p class="printonly"><b>peteroupc.github.io</b></p>
<div class="noprint">
<a href="https://www.paypal.com/cgi-bin/webscr?cmd=_s-xclick&hosted_button_id=56E5T4FH7KD2S">
<img src="https://www.paypalobjects.com/en_US/i/btn/btn_donateCC_LG.gif"
name="submit" border="2" alt="PayPal - The safer, easier way to pay online!"></a>
<p>
<a href="//twitter.com/share">Share via Twitter</a>, <a href="//www.facebook.com/sharer/sharer.php" id="sharer">Share via Facebook</a>
</p>
</div>
</nav><script>
if("share" in navigator){
 document.getElementById("sharer").href="javascript:void(null)";
 document.getElementById("sharer").innerHTML="Share This Page";
 navigator.share({title:document.title,url:document.location.href}).then(
   function(){});
} else {
 document.getElementById("sharer").href="//www.facebook.com/sharer/sharer.php?u="+
    encodeURIComponent(document.location.href)
}
</script>
</body></html>
