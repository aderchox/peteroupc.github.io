<!DOCTYPE html><html xmlns:dc="http://purl.org/dc/terms/" itemscope itemtype="http://schema.org/Article"><head><meta http-equiv=Content-Type content="text/html; charset=utf-8"><title>Partially-Sampled Random Numbers for Accurate Sampling of the Beta, Exponential, and Other Continuous Distributions</title><meta name="citation_title" content="Partially-Sampled Random Numbers for Accurate Sampling of the Beta, Exponential, and Other Continuous Distributions"><meta name="og:title" content="Partially-Sampled Random Numbers for Accurate Sampling of the Beta, Exponential, and Other Continuous Distributions"><meta name="og:type" content="article"><meta name="og:site_name" content="peteroupc.github.io"><meta name="twitter:title" content="Partially-Sampled Random Numbers for Accurate Sampling of the Beta, Exponential, and Other Continuous Distributions"><meta name="author" content="Peter Occil"/><meta name="viewport" content="width=device-width"><link rel=stylesheet type="text/css" href="/style.css"></head><body>  <div class="header">
<nav><p><a href="#navigation">Menu</a> - <a href="#top">Top</a> - <a href="/">Home</a></nav></div>
<div class="mainarea" id="top">
<h1>Partially-Sampled Random Numbers for Accurate Sampling of the Beta, Exponential, and Other Continuous Distributions</h1>

<p><a href="mailto:poccil14@gmail.com"><strong>Peter Occil</strong></a></p>

<p><em>Note: Formerly &quot;Partially Sampled Exponential Random Numbers&quot;, due to a merger with &quot;An Exact Beta Generator&quot;.</em></p>

<p><a id=Introduction></a></p>

<h2>Introduction</h2>

<p>This page introduces a Python implementation of <em>partially-sampled random numbers</em> (PSRNs).  Although structures for PSRNs were largely described before this work, this document unifies the concepts for these kinds of numbers from prior works and shows how they can be used to sample the beta distribution (for most sets of parameters), the exponential distribution (with an arbitrary rate parameter), and other continuous distributions&mdash;</p>

<ul>
<li>while avoiding floating-point arithmetic, and</li>
<li>to an arbitrary precision and with user-specified error bounds (and thus in an &quot;exact&quot; manner in the sense defined in (Karney 2014)<sup><a href="#Note1"><strong>(1)</strong></a></sup>).</li>
</ul>

<p>For instance, these two points distinguish the beta sampler in this document from any other specially-designed beta sampler I am aware of.  As for the exponential distribution, there are papers that discuss generating exponential random numbers using random bits (Flajolet and Saheb 1982)<sup><a href="#Note2"><strong>(2)</strong></a></sup>, (Karney 2014)<sup><a href="#Note1"><strong>(1)</strong></a></sup>, (Devroye and Gravel 2015)<sup><a href="#Note3"><strong>(3)</strong></a></sup>, (Thomas and Luk 2008)<sup><a href="#Note4"><strong>(4)</strong></a></sup>, but almost all of them that I am aware of don&#39;t deal with generating exponential PSRNs using an arbitrary rate, not just 1.  (Habibizad Navin et al., 2010)<sup><a href="#Note5"><strong>(5)</strong></a></sup>, which came to my attention on the afternoon of July 20, after I wrote much of this article, is perhaps an exception; however the approach appears to involve pregenerated tables of digit probabilities.</p>

<p>The samplers discussed here also draw on work dealing with a construct called the <em>Bernoulli factory</em> (Keane and O&#39;Brien 1994)<sup><a href="#Note6"><strong>(6)</strong></a></sup> (Flajolet et al., 2010)<sup><a href="#Note7"><strong>(7)</strong></a></sup>, which can simulate an arbitrary probability by transforming biased coins to biased coins.  One important feature of Bernoulli factories is that they can simulate a given probability <em>exactly</em>, without having to calculate that probability manually, which is important if the probability can be an irrational number that no computer can compute exactly (such as <code>pow(p, 1/2)</code> or <code>exp(-2)</code>).</p>

<p>This page shows <a href="#Sampler_Code"><strong>Python code</strong></a> for these samplers.</p>

<p><a id=About_This_Document></a></p>

<h3>About This Document</h3>

<p><strong>This is an open-source document; for an updated version, see the</strong> <a href="https://github.com/peteroupc/peteroupc.github.io/raw/master/exporand.md"><strong>source code</strong></a> <strong>or its</strong> <a href="https://github.com/peteroupc/peteroupc.github.io/blob/master/exporand.md"><strong>rendering on GitHub</strong></a><strong>.  You can send comments on this document either on</strong> <a href="https://www.codeproject.com/Articles/5272482/Partially-Sampled-Random-Numbers-for-Accurate-Samp"><strong>CodeProject</strong></a> <strong>or on the</strong> <a href="https://github.com/peteroupc/peteroupc.github.io/issues"><strong>GitHub issues page</strong></a><strong>.</strong></p>

<p><a id=Contents></a></p>

<h2>Contents</h2>

<ul>
<li><a href="#Introduction"><strong>Introduction</strong></a>

<ul>
<li><a href="#About_This_Document"><strong>About This Document</strong></a></li>
</ul></li>
<li><a href="#Contents"><strong>Contents</strong></a></li>
<li><a href="#Notation"><strong>Notation</strong></a></li>
<li><a href="#About_the_Beta_Distribution"><strong>About the Beta Distribution</strong></a></li>
<li><a href="#About_the_Exponential_Distribution"><strong>About the Exponential Distribution</strong></a></li>
<li><a href="#About_Partially_Sampled_Random_Numbers"><strong>About Partially-Sampled Random Numbers</strong></a>

<ul>
<li><a href="#Uniform_Partially_Sampled_Random_Numbers"><strong>Uniform Partially-Sampled Random Numbers</strong></a></li>
<li><a href="#Exponential_Partially_Sampled_Random_Numbers"><strong>Exponential Partially-Sampled Random Numbers</strong></a></li>
<li><a href="#Other_Distributions"><strong>Other Distributions</strong></a></li>
<li><a href="#Properties"><strong>Properties</strong></a></li>
<li><a href="#Comparisons"><strong>Comparisons</strong></a></li>
</ul></li>
<li><a href="#Sampling_Uniform_and_Exponential_PSRNs"><strong>Sampling Uniform and Exponential PSRNs</strong></a>

<ul>
<li><a href="#Sampling_Uniform_PSRNs"><strong>Sampling Uniform PSRNs</strong></a></li>
<li><a href="#Sampling_E_rands"><strong>Sampling E-rands</strong></a></li>
</ul></li>
<li><a href="#Arithmetic_with_PSRNs"><strong>Arithmetic with PSRNs</strong></a>

<ul>
<li><a href="#In_General"><strong>In General</strong></a></li>
<li><a href="#Addition_and_Subtraction"><strong>Addition and Subtraction</strong></a></li>
<li><a href="#Multiplication"><strong>Multiplication</strong></a></li>
</ul></li>
<li><a href="#Building_Blocks"><strong>Building Blocks</strong></a>

<ul>
<li><a href="#SampleGeometricBag"><strong>SampleGeometricBag</strong></a></li>
<li><a href="#FillGeometricBag"><strong>FillGeometricBag</strong></a></li>
<li><a href="#kthsmallest"><strong>kthsmallest</strong></a></li>
<li><a href="#Power_of_Uniform_Sub_Algorithm"><strong>Power-of-Uniform Sub-Algorithm</strong></a></li>
</ul></li>
<li><a href="#Algorithms_for_the_Beta_and_Exponential_Distributions"><strong>Algorithms for the Beta and Exponential Distributions</strong></a>

<ul>
<li><a href="#Beta_Distribution"><strong>Beta Distribution</strong></a></li>
<li><a href="#Exponential_Distribution"><strong>Exponential Distribution</strong></a></li>
</ul></li>
<li><a href="#Sampler_Code"><strong>Sampler Code</strong></a>

<ul>
<li><a href="#Exponential_Sampler_Extension"><strong>Exponential Sampler: Extension</strong></a></li>
</ul></li>
<li><a href="#Correctness_Testing"><strong>Correctness Testing</strong></a>

<ul>
<li><a href="#Beta_Sampler"><strong>Beta Sampler</strong></a></li>
<li><a href="#ExpRandFill"><strong>ExpRandFill</strong></a></li>
<li><a href="#ExpRandLess"><strong>ExpRandLess</strong></a></li>
</ul></li>
<li><a href="#Accurate_Simulation_of_Continuous_Distributions_Supported_on_0_to_1"><strong>Accurate Simulation of Continuous Distributions Supported on 0 to 1</strong></a>

<ul>
<li><a href="#An_Example_The_Continuous_Bernoulli_Distribution"><strong>An Example: The Continuous Bernoulli Distribution</strong></a></li>
</ul></li>
<li><a href="#Complexity"><strong>Complexity</strong></a>

<ul>
<li><a href="#General_Principles"><strong>General Principles</strong></a></li>
<li><a href="#Complexity_of_Specific_Algorithms"><strong>Complexity of Specific Algorithms</strong></a></li>
</ul></li>
<li><a href="#Application_to_Weighted_Reservoir_Sampling"><strong>Application to Weighted Reservoir Sampling</strong></a></li>
<li><a href="#Open_Questions"><strong>Open Questions</strong></a></li>
<li><a href="#Acknowledgments"><strong>Acknowledgments</strong></a></li>
<li><a href="#Other_Documents"><strong>Other Documents</strong></a></li>
<li><a href="#Notes"><strong>Notes</strong></a></li>
<li><a href="#Appendix"><strong>Appendix</strong></a>

<ul>
<li><a href="#SymPy_Formula_for_the_algorithm_for_exp_minus__x___y"><strong>SymPy Formula for the algorithm for exp(&minus;<em>x</em>/<em>y</em>)</strong></a></li>
<li><a href="#Additional_Examples_of_Arbitrary_Precision_Samplers"><strong>Additional Examples of Arbitrary-Precision Samplers</strong></a></li>
<li><a href="#Equivalence_of_SampleGeometricBag_Algorithms"><strong>Equivalence of SampleGeometricBag Algorithms</strong></a></li>
<li><a href="#Oberhoff_s_Exact_Rejection_Sampling_Method"><strong>Oberhoff&#39;s &quot;Exact Rejection Sampling&quot; Method</strong></a></li>
<li><a href="#Setting_Digits_by_Digit_Probabilities"><strong>Setting Digits by Digit Probabilities</strong></a></li>
</ul></li>
<li><a href="#License"><strong>License</strong></a></li>
</ul>

<p><a id=Notation></a></p>

<h2>Notation</h2>

<p>In this document, <code>RNDINT(x)</code> is a uniformly-distributed random integer in the interval [0, x], <code>RNDINTEXC(x)</code> is a uniformly-distributed random integer in the interval [0, x), and <code>RNDU01OneExc()</code> is a uniformly-distributed random real number in the interval [0, 1).</p>

<p><a id=About_the_Beta_Distribution></a></p>

<h2>About the Beta Distribution</h2>

<p>The <a href="https://en.wikipedia.org/wiki/Beta_distribution"><strong>beta distribution</strong></a> is a bounded-domain probability distribution; its two parameters, <code>alpha</code> and <code>beta</code>, are both greater than 0 and describe the distribution&#39;s shape.  Depending on <code>alpha</code> and <code>beta</code>, the shape can be a smooth peak or a smooth valley.  The beta distribution can take on values in the interval [0, 1].  Any value in this interval (<code>x</code>) can occur with a probability proportional to&mdash;</p>

<pre>pow(x, alpha - 1) * pow(1 - x, beta - 1).               (1)
</pre>

<p>Although <code>alpha</code> and <code>beta</code> can each be greater than 0, the sampler presented in this document only works if&mdash;</p>

<ul>
<li>both parameters are 1 or greater, or</li>
<li>in the case of base-2 numbers, one parameter equals 1 and the other is greater than 0.</li>
</ul>

<p><a id=About_the_Exponential_Distribution></a></p>

<h2>About the Exponential Distribution</h2>

<p>The <em>exponential distribution</em> takes a parameter &lambda;.  Informally speaking, a random number that follows an exponential distribution is the number of units of time between one event and the next, and &lambda; is the expected average number of events per unit of time.  Usually, &lambda; is equal to 1.</p>

<p>An exponential random number is commonly generated as follows: <code>-ln(1 - RNDU01OneExc()) / lamda</code>.  (This particular formula is not robust, though, for reasons that are outside the scope of this document, but see (Pedersen 2018)<sup><a href="#Note8"><strong>(8)</strong></a></sup>.)  This page presents an alternative way to sample exponential random numbers.</p>

<p><a id=About_Partially_Sampled_Random_Numbers></a></p>

<h2>About Partially-Sampled Random Numbers</h2>

<p>In this document, a <em>partially-sampled random number</em> (PSRN) is a data structure that stores a real number of unlimited precision, but whose contents are sampled only when necessary. PSRNs open the door to algorithms that sample a random number that &quot;exactly&quot; follows a continuous distribution, <em>with arbitrary precision</em>, and <em>without floating-point arithmetic</em> (see &quot;Properties&quot; later in this section).</p>

<p>PSRNs specified here consist of the following three things:</p>

<ul>
<li><p>A <em>fractional part</em> with an arbitrary number of digits.  This can be implemented as an array of digits or as a packed integer containing all the digits.  Some algorithms care whether those digits were <em>sampled</em> or <em>unsampled</em>; in that case, if a digit is unsampled, its unsampled status can be noted in a way that distinguishes it from sampled digits (e.g., by using the <code>None</code> keyword in Python, or the number &minus;1, or by storing a separate bit array indicating which bits are sampled and unsampled).  The base in which all the digits are stored (such as base 10 for decimal or base 2 for binary) is arbitrary.  The fractional part&#39;s digits form a so-called <em>digit expansion</em> (e.g., <em>binary expansion</em> in the case of binary or base-2 digits).  Digits beyond those stored in the fractional part are unsampled.</p>

<p>For example, if the fractional part stores the base-10 digits [1, 3, 5], in that order, then it represents a random number in the interval [0.135, 0.136], reflecting the fact that the digits between 0.135 and 0.136 are unknown.</p></li>
<li>An optional <em>integer part</em> (more specifically, the integer part of the number&#39;s absolute value, that is, <code>floor(abs(x))</code>).</li>
<li>An optional <em>sign</em> (positive or negative).</li>
</ul>

<p>If an implementation cares only about PSRNs in the interval [0, 1], it can store only a fractional part; in this case, the unstored integer part and sign are assumed to be 0 and positive, respectively.</p>

<p>PSRNs ultimately represent a random number between two others; one of the number&#39;s two bounds has the following form: sign * (integer part + fractional part), which is a lower bound if the PSRN is positive, or an upper bound if it&#39;s negative. For example, if the PSRN stores a positive sign, the integer 3, and the fractional part [3, 5, 6] (in base 10), then the PSRN represents a random number in the interval [3.356, 3.357].  Here, one of the bounds is built using the PSRN&#39;s sign, integer part, and fractional part, and because the PSRN is positive, this is a lower bound.</p>

<p>This section specifies two kinds of PSRNs: uniform and exponential.</p>

<p><a id=Uniform_Partially_Sampled_Random_Numbers></a></p>

<h3>Uniform Partially-Sampled Random Numbers</h3>

<p>The most trivial example of a PSRN is that of the uniform distribution.</p>

<ul>
<li>Flajolet et al. (2010)<sup><a href="#Note7"><strong>(7)</strong></a></sup> use the term <em>geometric bag</em> to refer to a uniform PSRN in the interval [0, 1] that stores binary (base-2) digits, some of which may be unsampled.  In this case, the PSRN can consist of just a fractional part, which can be implemented as described earlier.</li>
<li>(Karney 2014)<sup><a href="#Note1"><strong>(1)</strong></a></sup> uses the term <em>u-rand</em> to refer to uniform PSRNs that can store a sign, integer part, and a fractional part, where the base of the fractional part&#39;s digits is arbitrary, but Karney&#39;s concept only contemplates sampling digits from left to right without any gaps.</li>
</ul>

<p>Each additional digit of a uniform PSRN&#39;s fractional part is sampled simply by setting it to an independent uniform random digit, an observation that dates from von Neumann (1951)<sup><a href="#Note9"><strong>(9)</strong></a></sup> in the binary case.  A PSRN with this property is called a <strong>uniform PSRN</strong> in this document, even if was generated using a non-uniform random sampling algorithm (such as Karney&#39;s algorithm for the normal distribution). (This is notably because, in general, this kind of PSRN represents a uniformly-distributed random number in a given interval.  For example, if the PSRN is 3.356..., then it represents a random number that is uniformly distributed in the interval [3.356, 3.357].)</p>

<p><a id=Exponential_Partially_Sampled_Random_Numbers></a></p>

<h3>Exponential Partially-Sampled Random Numbers</h3>

<p>In this document, an <strong>exponential PSRN</strong> (or <strong><em>e-rand</em></strong>, named similarly to Karney&#39;s &quot;u-rands&quot; for partially-sampled uniform random numbers (Karney 2014)<sup><a href="#Note1"><strong>(1)</strong></a></sup>) samples each bit that, when combined with the existing bits, results in an exponentially-distributed random number of the given rate.  Also, because <code>-ln(1 - RNDU01())</code> is exponentially distributed, e-rands can also represent the natural logarithm of a partially-sampled uniform random number in (0, 1].  The difference here is that additional bits are sampled not as unbiased random bits, but rather as bits with a vanishing bias.   (More specifically, an exponential PSRN generally represents an exponentially-distributed random number in a given interval.)</p>

<p>Algorithms for sampling e-rands are given in the section &quot;Algorithms for the Beta and Exponential Distributions&quot;.</p>

<p><a id=Other_Distributions></a></p>

<h3>Other Distributions</h3>

<p>PSRNs of other distributions can be implemented via rejection from the uniform distribution. Examples include the following:</p>

<ul>
<li>The beta and continuous Bernoulli distributions, as discussed later in this document.</li>
<li>The standard normal distribution, as shown in (Karney 2014)<sup><a href="#Note1"><strong>(1)</strong></a></sup> by running Karney&#39;s Algorithm N and filling unsampled digits uniformly at random, or as shown in an improved version of that algorithm by Du et al. (2020)<sup><a href="#Note10"><strong>(10)</strong></a></sup>.</li>
<li>Sampling uniform distributions in [0, <em>n</em>) (not just [0, 1]), is described later in &quot;<a href="#Sampling_Uniform_PSRNs"><strong>Sampling Uniform PSRNs</strong></a>&quot;.)</li>
</ul>

<p>For these distributions (and others that are continuous almost everywhere and bounded from above), Oberhoff (2018)<sup><a href="#Note11"><strong>(11)</strong></a></sup> proved that unsampled trailing bits of the PSRN converge to the uniform distribution (see also (Kakutani 1948)<sup><a href="#Note12"><strong>(12)</strong></a></sup>).</p>

<p>PSRNs could also be implemented via rejection from the exponential distribution, although no concrete examples are presented here.</p>

<p><a id=Properties></a></p>

<h3>Properties</h3>

<p>An algorithm that samples from a continuous distribution using PSRNs has the following properties:</p>

<ol>
<li>The algorithm relies only on a source of random bits for randomness.</li>
<li>The algorithm does not rely on floating-point arithmetic or calculations of irrational or transcendental numbers (other than digit extractions), including when the algorithm samples each digit of a PSRN.</li>
<li>The algorithm may use rational arithmetic (such as <code>Fraction</code> in Python or <code>Rational</code> in Ruby), as long as the arithmetic is exact.</li>
<li>If the algorithm outputs a PSRN, the number represented by the sampled digits must follow a distribution that is close to the ideal distribution by a distance of not more than <em>b</em><sup>&minus;<em>m</em></sup>, where <em>b</em> is the PSRN&#39;s base, or radix (such as 2 for binary), and <em>m</em> is the position, starting from 1, of the rightmost sampled digit of the PSRN&#39;s fractional part.  ((Devroye and Gravel 2015)<sup><a href="#Note3"><strong>(3)</strong></a></sup> suggests Wasserstein distance, or &quot;earth-mover distance&quot;, as the distance to use for this purpose.) The number has to be close this way even if the algorithm&#39;s caller later samples unsampled digits of that PSRN at random (e.g., uniformly at random in the case of a uniform PSRN).</li>
<li>If the algorithm fills a PSRN&#39;s unsampled fractional digits at random (e.g., uniformly at random in the case of a uniform PSRN), so that the number&#39;s fractional part has <em>m</em> digits, the number&#39;s distribution must remain close to the ideal distribution by a distance of not more than <em>b</em><sup>&minus;<em>m</em></sup>.</li>
</ol>

<blockquote>
<p><strong>Note:</strong> The <em>exact rejection sampling</em> algorithm described by Oberhoff (2018)<sup><a href="#Note11"><strong>(11)</strong></a></sup> produces samples that act like PSRNs; however, the algorithm doesn&#39;t have the properties described in this section.  This is because the method requires calculating minimums of probabilities and, in practice, requires the use of floating-point arithmetic in most cases (see property 2 above).  Moreover, the algorithm&#39;s progression depends on the value of previously sampled bits, not just on the position of those bits as with the uniform and exponential distributions (see also (Thomas and Luk 2008)<sup><a href="#Note4"><strong>(4)</strong></a></sup>).  For completeness, Oberhoff&#39;s method appears in the appendix.</p>
</blockquote>

<p><a id=Comparisons></a></p>

<h3>Comparisons</h3>

<p>Two PSRNs, each of a different distribution but storing digits of the same base (radix), can be exactly compared to each other using algorithms similar to those in this section.</p>

<p>The <strong>RandLess</strong> algorithm compares two PSRNs, <strong>a</strong> and <strong>b</strong> (and samples additional bits from them as necessary) and returns 1 if <strong>a</strong> turns out to be less than <strong>b</strong> almost surely, or 0 otherwise (see also (Karney 2014)<sup><a href="#Note1"><strong>(1)</strong></a></sup>)).</p>

<ol>
<li>If <strong>a</strong>&#39;s integer part wasn&#39;t sampled yet, sample <strong>a</strong>&#39;s integer part according to the kind of PSRN <strong>a</strong> is.  Do the same for <strong>b</strong>.</li>
<li>If <strong>a</strong>&#39;s sign is different from <strong>b</strong>&#39;s sign, return 1 if <strong>a</strong> is negative and 0 if non-negative.  If <strong>a</strong> is non-negative, return 1 if <strong>a</strong>&#39;s integer part is less than <strong>b</strong>&#39;s, or 0 if greater.  If <strong>a</strong> is negative, return 0 if <strong>a</strong>&#39;s integer part is less than <strong>b</strong>&#39;s, or 1 if greater.</li>
<li>Set <em>i</em> to 0.</li>
<li>If the digit at position <em>i</em> of <strong>a</strong>&#39;s fractional part is unsampled, set the digit at that position according to the kind of PSRN <strong>a</strong> is. (Positions start at 0 where 0 is the most significant digit after the point, 1 is the next, etc.)  Do the same for <strong>b</strong>.</li>
<li>Let <em>da</em> be the digit at position <em>i</em> of <strong>a</strong>&#39;s fractional part, and let <em>db</em> be <strong>b</strong>&#39;s corresponding digit.</li>
<li>If <strong>a</strong> is non-negative, return 1 if <em>da</em> is less than <em>db</em>, or 0 if <em>da</em> is greater than <em>db</em>.</li>
<li>If <strong>a</strong> is negative, return 0 if <em>da</em> is less than <em>db</em>, or 1 if <em>da</em> is greater than <em>db</em>.</li>
<li>Add 1 to <em>i</em> and go to step 4.</li>
</ol>

<p><strong>URandLess</strong> is a version of <strong>RandLess</strong> that involves two uniform PSRNs.  The algorithm for <strong>URandLess</strong> samples digit <em>i</em> in step 4 by setting the digit at position <em>i</em> to a digit chosen uniformly at random. (For example, if <strong>a</strong> is a uniform PSRN that stores base-2 or binary digits, this can be done by setting the digit at that position to <code>RNDINTEXC(2)</code>.)</p>

<p>The <strong>RandLessThanReal</strong> algorithm compares a PSRN <strong>a</strong> with a real number <strong>b</strong> and returns 1 if <strong>a</strong> turns out to be less than <strong>b</strong> almost surely, or 0 otherwise.  This algorithm samples digits of <strong>a</strong>&#39;s fractional part as necessary.  This algorithm works whether <strong>b</strong> is known to be a rational number or not (for example, <strong>b</strong> can be the result of an expression such as <code>exp(-2)</code> or <code>log(20)</code>), but the algorithm notes how it can be more efficiently implemented if <strong>b</strong> is known to be a rational number.</p>

<ol>
<li>If <strong>a</strong>&#39;s integer part or sign is unsampled, return an error.</li>
<li>Set <em>bs</em> to &minus;1 if <strong>b</strong> is less than 0, or 1 otherwise. Calculate floor(abs(<strong>b</strong>)), and set <em>bi</em> to the result. (<em>If <strong>b</strong> is known rational:</em> Then set <em>bf</em> to abs(<strong>b</strong>) minus <em>bi</em>.)</li>
<li>If <strong>a</strong>&#39;s sign is different from <em>bs</em>&#39;s sign, return 1 if <strong>a</strong> is negative and 0 if non-negative.  If <strong>a</strong> is non-negative, return 1 if <strong>a</strong>&#39;s integer part is less than <em>bi</em>, or 0 if greater.  If <strong>a</strong> is negative, return 0 if <strong>a</strong>&#39;s integer part is less than <em>bi</em>, or 1 if greater.</li>
<li>Set <em>i</em> to 0.</li>
<li>If the digit at position <em>i</em> of <strong>a</strong>&#39;s fractional part is unsampled, set the digit at that position according to the kind of PSRN <strong>a</strong> is. (Positions start at 0 where 0 is the most significant digit after the point, 1 is the next, etc.)</li>
<li>Calculate the base-&beta; digit at position <em>i</em> of <strong>b</strong>&#39;s fractional part, and set <em>d</em> to that digit. (<em>If <strong>b</strong> is known rational:</em> Do this step by multiplying <em>bf</em> by &beta;, then setting <em>d</em> to floor(<em>bf</em>), then subtracting <em>d</em> from <em>bf</em>.)</li>
<li>Let <em>ad</em> be the digit at position <em>i</em> of <strong>a</strong>&#39;s fractional part.</li>
<li>Return 1 if&mdash;

<ul>
<li><em>ad</em> is less than <em>d</em> and <strong>a</strong> is non-negative,</li>
<li><em>ad</em> is greater than <em>d</em> and <strong>a</strong> is negative, or</li>
<li><em>ad</em> is equal to <em>d</em>, <strong>a</strong> is negative, and&mdash;

<ul>
<li><em><strong>b</strong> is not known to be rational</em> and all the digits after the digit at position <em>i</em> of <strong>b</strong>&#39;s fractional part are zeros (indicating <strong>a</strong> is less than <strong>b</strong> almost surely), or</li>
<li><em><strong>b</strong> is known to be rational</em> and <em>bf</em> is 0 (indicating <strong>a</strong> is less than <strong>b</strong> almost surely).</li>
</ul></li>
</ul></li>
<li>Return 0 if&mdash;

<ul>
<li><em>ad</em> is less than <em>d</em> and <strong>a</strong> is negative,</li>
<li><em>ad</em> is greater than <em>d</em> and <strong>a</strong> is non-negative, or</li>
<li><em>ad</em> is equal to <em>d</em>, <strong>a</strong> is non-negative, and&mdash;

<ul>
<li><em><strong>b</strong> is not known to be rational</em> and all the digits after the digit at position <em>i</em> of <strong>b</strong>&#39;s fractional part are zeros (indicating <strong>a</strong> is greater than <strong>b</strong> almost surely), or</li>
<li><em><strong>b</strong> is known to be rational</em> and <em>bf</em> is 0 (indicating <strong>a</strong> is greater than <strong>b</strong> almost surely).</li>
</ul></li>
</ul></li>
<li>Add 1 to <em>i</em> and go to step 5.</li>
</ol>

<p>An alternative version of steps 6 through 9 in the algorithm above are as follows (see also (Brassard et al. 2019)<sup><a href="#Note13"><strong>(13)</strong></a></sup>):</p>

<ul>
<li>(6.) Calculate <em>bp</em>, which is an approximation to <strong>b</strong> such that abs(<strong>b</strong> &minus; <em>bp</em>) &lt;= &beta;<sup>&minus;<em>i</em> &minus; 1</sup>.  Let <em>bk</em> be <em>bp</em>&#39;s digit expansion up to the <em>i</em> + 1 digits after the point.  For example, if <strong>b</strong> is &pi;, &beta; is 10, and <em>i</em> is 4, one possibility is <em>bp</em> = 3.14159 and <em>bk</em> = 314159.</li>
<li>(7.) Let <em>ak</em> be <strong>a</strong>&#39;s digit expansion up to the <em>i</em> + 1 digits after the point.</li>
<li>(8.) Return 1 if <em>ak</em> &lt;= <em>bk</em> &minus; 2.</li>
<li>(9.) Return 0 if <em>ak</em> &gt;= <em>bk</em> + 1.</li>
</ul>

<p><strong>URandLessThanReal</strong> is a version of <strong>RandLessThanReal</strong> in which <strong>a</strong> is a uniform PSRN.  The algorithm for <strong>URandLessThanReal</strong> samples digit <em>i</em> in step 4 by setting the digit at position <em>i</em> to a digit chosen uniformly at random.</p>

<p>The following is a simpler way to implement <strong>URandLessThanReal</strong> when <strong>a</strong> is non-negative and its integer part is 0, and when <strong>b</strong> is known to be a rational number.</p>

<ol>
<li>If <strong>a</strong>&#39;s integer part or sign is unsampled, or if <strong>a</strong> is negative or its integer part is other than 0, return an error.  If <strong>b</strong> is 0 or less, return 0.  If <strong>b</strong> is 1 or greater, return 1. (The case of 1 is a degenerate case since <strong>a</strong> could, at least in theory, represent an infinite sequence of ones, making it equal to 1.)</li>
<li>Set <em>pt</em> to 1/<em>base</em>, and set <em>i</em> to 0. (<em>base</em> is the base, or radix, of <strong>a</strong>&#39;s digits, such as 2 for binary or 10 for decimal.)</li>
<li>Set <em>d1</em> to the digit at the <em>i</em><sup>th</sup> position (starting from 0) of <strong>a</strong>&#39;s fractional part.  If the digit at that position is unsampled, put a digit chosen uniformly at random at that position and set <em>d1</em> to that digit.</li>
<li>Set <em>d2</em> to floor(<strong>b</strong> / <em>pt</em>).  (For example, in base 2, set <em>d2</em> to 0 if <strong>b</strong> is less than <em>pt</em>, or 1 otherwise.)</li>
<li>If <em>d1</em> is less than <em>d2</em>, return 1.  If <em>d1</em> is greater than <em>d2</em>, return 0.</li>
<li>If <strong>b</strong> &gt;= <em>pt</em>, subtract <em>pt</em> from <strong>b</strong>.</li>
<li>If <strong>b</strong> is 0, return 0 (indicating that <strong>a</strong> is greater than the original fraction almost surely).</li>
<li>Divide <em>pt</em> by <em>base</em>, add 1 to <em>i</em>, and go to step 3.</li>
</ol>

<p>The following is a simpler way to implement <strong>URandLessThanReal</strong> when <strong>a</strong> is non-negative and its integer part is 0, and when <strong>b</strong> is a fraction known by its numerator and denominator, <em>num</em>/<em>den</em>.</p>

<ol>
<li>If <strong>a</strong>&#39;s integer part or sign is unsampled, or if <em>den</em> is 0, return an error.  If <em>num</em> and <em>den</em> are both less than 0, set them to their absolute values.  If <strong>a</strong> is negative or its integer part is other than 0, return an error. If <em>num</em> is 0, or if <em>num</em> &lt; 0 or <em>den</em> &lt; 0, return 0.  If <em>num</em> &gt;= <em>den</em>, return 1.</li>
<li>Set <em>pt</em> to <em>base</em>, and set <em>i</em> to 0. (<em>base</em> is the base, or radix, of <strong>a</strong>&#39;s digits, such as 2 for binary or 10 for decimal.)</li>
<li>Set <em>d1</em> to the digit at the <em>i</em><sup>th</sup> position (starting from 0) of <strong>a</strong>&#39;s fractional part.  If the digit at that position is unsampled, put a digit chosen uniformly at random at that position and set <em>d1</em> to that digit.</li>
<li>Set <em>c</em> to 1 if <em>num</em> * <em>pt</em> &gt;= <em>den</em>, and 0 otherwise.</li>
<li>Set <em>d2</em> to floor(<em>num</em> * <em>pt</em> / <em>den</em>).  (In base 2, this is equivalent to setting <em>d2</em> to <em>c</em>.)</li>
<li>If <em>d1</em> is less than <em>d2</em>, return 1.  If <em>d1</em> is greater than <em>d2</em>, return 0.</li>
<li>If <em>c</em> is 1, set <em>num</em> to <em>num</em> * <em>pt</em> &minus; <em>den</em>, then multiply <em>den</em> by <em>pt</em>.</li>
<li>If <em>num</em> is 0, return 0.</li>
<li>Multiply <em>pt</em> by <em>base</em>, add 1 to <em>i</em>, and go to step 3.</li>
</ol>

<p><a id=Sampling_Uniform_and_Exponential_PSRNs></a></p>

<h2>Sampling Uniform and Exponential PSRNs</h2>

<p>&nbsp;</p>

<p><a id=Sampling_Uniform_PSRNs></a></p>

<h3>Sampling Uniform PSRNs</h3>

<p>There are two algorithms for sampling uniform partially-sampled random numbers given another number.</p>

<p>The <strong>RandUniform</strong> algorithm generates a uniformly distributed PSRN (<strong>a</strong>) that is greater than 0 and less than another PSRN (<strong>b</strong>) almost surely.  This algorithm samples digits of <strong>b</strong>&#39;s fractional part as necessary.  This algorithm should not be used if <strong>b</strong> is known to be a real number rather than a partially-sampled random number, since this algorithm could overshoot the value <strong>b</strong> had (or appeared to have) at the beginning of the algorithm; instead, the <strong>RandUniformFromReal</strong> algorithm, given later, should be used.  (For example, if <strong>b</strong> is 3.425..., one possible result of this algorithm is <strong>a</strong> = 3.42574... and <strong>b</strong> = 3.42575... Note that in this example, 3.425... is not considered an exact number.)</p>

<ol>
<li>Create an empty uniform PSRN <strong>a</strong>.  Let &beta; be the base (or radix) of digits stored in <strong>b</strong>&#39;s fractional part (e.g., 2 for binary or 10 for decimal).  If <strong>b</strong>&#39;s integer part or sign is unsampled, or if <strong>b</strong>&#39;s sign is negative, return an error.</li>
<li>Set <strong>a</strong>&#39;s sign to positive and <strong>a</strong>&#39;s integer part to an integer chosen uniformly at random in [0, <em>bi</em>], where <em>bi</em> is <strong>b</strong>&#39;s integer part (e.g., <code>RNDINT(0, bi)</code>).  If <strong>a</strong>&#39;s integer part is less than <em>bi</em>, return <strong>a</strong>.</li>
<li>(We now sample <strong>a</strong>&#39;s fractional part.)  Set <em>i</em> to 0.</li>
<li>If <strong>b</strong>&#39;s integer part is 0 and <strong>b</strong>&#39;s fractional part begins with a sampled 0-digit, set <em>i</em> to the number of sampled zeros at the beginning of <strong>b</strong>&#39;s fractional part.  A nonzero digit or an unsampled digit ends this sequence.  Then append <em>i</em> zeros to <strong>a</strong>&#39;s fractional part.  (For example, if <strong>b</strong> is 5.000302 or 4.000 or 0.0008, there are three sampled zeros that begin <strong>b</strong>&#39;s fractional part, so <em>i</em> is set to 3 and three zeros are appended to <strong>a</strong>&#39;s fractional part.)</li>
<li>If the digit at position <em>i</em> of <strong>a</strong>&#39;s fractional part is unsampled, set the digit at that position to a base-&beta; digit chosen uniformly at random. (Positions start at 0 where 0 is the most significant digit after the point, 1 is the next, etc.  An example if &beta; is 2, or binary, is <code>RNDINTEXC(2)</code>.)</li>
<li>If the digit at position <em>i</em> of <strong>b</strong>&#39;s fractional part is unsampled, sample the digit at that position according to the kind of PSRN <strong>b</strong> is. (For example, if <strong>b</strong> is a uniform PSRN and &beta; is 2, this can be done by setting the digit at that position to <code>RNDINTEXC(2)</code>.)</li>
<li>If the digit at position <em>i</em> of <strong>a</strong>&#39;s fractional part is less than the corresponding digit for <strong>b</strong>, return <strong>a</strong>.</li>
<li>If that digit is greater, then discard <strong>a</strong>, then create a new empty uniform PSRN <strong>a</strong>, then go to step 2.</li>
<li>Add 1 to <em>i</em> and go to step 5.</li>
</ol>

<blockquote>
<p><strong>Notes:</strong></p>

<ol>
<li>Karney (2014, end of sec. 4)<sup><a href="#Note1"><strong>(1)</strong></a></sup> discusses how even the integer part can be partially sampled rather than generating the whole integer as in step 2 of the algorithm.  However, incorporating this suggestion will add a non-trivial amount of complexity to the algorithm given above.</li>
<li>The <strong>RandUniform</strong> algorithm is equivalent to generating the product of a random number (<strong>b</strong>) and a uniform(0, 1) random number.</li>
<li>If <strong>b</strong> is a uniform PSRN with a positive sign, an integer part of 0, and an empty fractional part, the <strong>RandUniform</strong> algorithm is equivalent to generating the product of two uniform(0, 1) random numbers.</li>
</ol>
</blockquote>

<p>The <strong>RandUniformFromReal</strong> algorithm generates a uniformly distributed PSRN (<strong>a</strong>) that is greater than 0 and less than a real number <strong>b</strong> almost surely.  This algorithm works whether <strong>b</strong> is known to be a rational number or not (for example, <strong>b</strong> can be the result of an expression such as <code>exp(-2)</code> or <code>log(20)</code>), but the algorithm notes how it can be more efficiently implemented if <strong>b</strong> is known to be a rational number.</p>

<ol>
<li>If <strong>b</strong> is 0 or less, return an error.</li>
<li>Create an empty uniform PSRN <strong>a</strong>.</li>
<li>Calculate floor(<strong>b</strong>), and set <em>bi</em> to the result. (<em>If <strong>b</strong> is known rational:</em> Then set <em>bf</em> to <strong>b</strong> minus <em>bi</em>.)</li>
<li>If <em>bi</em> is equal to <strong>b</strong>, set <strong>a</strong>&#39;s sign to positive and <strong>a</strong>&#39;s integer part to an integer chosen uniformly at random in [0, <em>bi</em>) (e.g., <code>RNDINTEXC(0, bi)</code>), then return <strong>a</strong>.  (It should be noted that determining whether a real number is equal to another is undecidable in general.)</li>
<li>Set <strong>a</strong>&#39;s sign to positive and <strong>a</strong>&#39;s integer part to an integer chosen uniformly at random in [0, <em>bi</em>] (e.g., <code>RNDINT(0, bi)</code>), then if <strong>a</strong>&#39;s integer part is less than <em>bi</em>, return <strong>a</strong>.</li>
<li>(We now sample <strong>a</strong>&#39;s fractional part.)  Set <em>i</em> to 0.</li>
<li>If <em>bi</em> is 0 and not equal to <strong>b</strong>, then do the following in a loop:

<ol>
<li>Calculate the base-&beta; digit at position <em>i</em> of <strong>b</strong>&#39;s fractional part, and set <em>d</em> to that digit. (&beta; is the desired digit base, or radix, of the uniform PSRN, such as 10 for decimal or 2 for binary). (<em>If <strong>b</strong> is known rational:</em> Do this step by multiplying <em>bf</em> by &beta;, then setting <em>d</em> to floor(<em>bf</em>), then subtracting <em>d</em> from <em>bf</em>.)</li>
<li>If <em>d</em> is 0, append a 0-digit to <strong>a</strong>&#39;s fractional part, then add 1 to <em>i</em>.  Otherwise, break from this loop.</li>
</ol></li>
<li>If the digit at position <em>i</em> of <strong>a</strong>&#39;s fractional part is unsampled, set the digit at that position to a base-&beta; digit chosen uniformly at random. (Positions start at 0 where 0 is the most significant digit after the point, 1 is the next, etc.  An example if &beta; is 2, or binary, is <code>RNDINTEXC(2)</code>.)</li>
<li>Calculate the base-&beta; digit at position <em>i</em> of <strong>b</strong>&#39;s fractional part, and set <em>d</em> to that digit. (<em>If <strong>b</strong> is known rational:</em> Do this step by multiplying <em>bf</em> by &beta;, then setting <em>d</em> to floor(<em>bf</em>), then subtracting <em>d</em> from <em>bf</em>.)</li>
<li>Let <em>ad</em> be the digit at position <em>i</em> of <strong>a</strong>&#39;s fractional part.  If <em>ad</em> is less than <em>d</em>, return <strong>a</strong>.</li>
<li><em>If <strong>b</strong> is not known to be rational:</em> If <em>ad</em> is greater than <em>d</em>, or if all the digits after the digit at position <em>i</em> of <strong>b</strong>&#39;s fractional part are zeros, then discard <strong>a</strong>, then create a new empty uniform PSRN <strong>a</strong>, then go to step 5.</li>
<li><em>If <strong>b</strong> is known rational:</em> If <em>ad</em> is greater than <em>d</em>, or if <em>bf</em> is 0, then discard <strong>a</strong>, then create a new empty uniform PSRN <strong>a</strong>, then set <em>bf</em> to <strong>b</strong> minus <em>bi</em>, then go to step 5.</li>
<li>Add 1 to <em>i</em> and go to step 8.</li>
</ol>

<p><a id=Sampling_E_rands></a></p>

<h3>Sampling E-rands</h3>

<p><strong>Sampling an e-rand</strong> (a exponential PSRN) makes use of two observations (based on the parameter &lambda; of the exponential distribution):</p>

<ul>
<li>While a coin flip with probability of heads of exp(-&lambda;) is heads, the exponential random number is increased by 1.</li>
<li>If a coin flip with probability of heads of 1/(1+exp(&lambda;/2<sup><em>k</em></sup>)) is heads, the exponential random number is increased by 2<sup>-<em>k</em></sup>, where <em>k</em> &gt; 0 is an integer.</li>
</ul>

<p>(Devroye and Gravel 2015)<sup><a href="#Note3"><strong>(3)</strong></a></sup> already made these observations in their Appendix, but only for &lambda; = 1.</p>

<p>To implement these probabilities using just random bits, the sampler uses two algorithms, which both enable e-rands with rational valued &lambda; parameters:</p>

<ol>
<li>One to simulate a probability of the form <code>exp(-x/y)</code> (here, the <strong>algorithm for exp(&minus;<em>x</em>/<em>y</em>)</strong> described in &quot;<a href="https://peteroupc.github.io/bernoulli.html"><strong>Bernoulli Factory Algorithms</strong></a>&quot;).</li>
<li>One to simulate a probability of the form <code>1/(1+exp(x/(y*pow(2, prec))))</code> (here, the <strong>LogisticExp</strong> algorithm described in &quot;<a href="https://peteroupc.github.io/bernoulli.html"><strong>Bernoulli Factory Algorithms</strong></a>&quot;).</li>
</ol>

<p><a id=Arithmetic_with_PSRNs></a></p>

<h2>Arithmetic with PSRNs</h2>

<p>&nbsp;</p>

<p><a id=In_General></a></p>

<h3>In General</h3>

<p>Arithmetic between two PSRNs is not always trivial.</p>

<ul>
<li><p>Adding, multiplying, or dividing two PSRNs <em>A</em> and <em>B</em> (see also (Brassard et al., 2019)<sup><a href="#Note13"><strong>(13)</strong></a></sup>) is not as simple as adding their integer and fractional parts.</p>

<p>An example illustrates this. Say we have two uniform PSRNs: <em>A</em> = 0.12345... and <em>B</em> = 0.38901....  They represent random numbers in the intervals <em>AI</em> = [0.12345, 0.12346] and <em>BI</em> = [0.38901, 0.38902], respectively.  Adding two uniform PSRNs is akin to adding their intervals (using interval arithmetic), so that in this example, the result <em>C</em> lies in <em>CI</em> = [0.12345 + 0.38901, 0.12346 + 0.38902] = [0.51246, 0.51248].  However, the resulting random number is <em>not</em> uniformly distributed in [0.51246, 0.51248], so that simply choosing a uniform random number in the interval won&#39;t work.  This can be demonstrated by generating many pairs of uniform random numbers in the intervals <em>AI</em> and <em>BI</em>, summing the numbers in each pair, and building a histogram using the sums (which will all lie in the interval <em>CI</em>).  In this case, the histogram will show a triangular distribution that peaks at 0.51247.</p>

<p>This example can also apply to other arithmetic operations besides addition: do the interval operation (multiplication, division, etc.) on the intervals <em>AI</em> and <em>BI</em>, and build a histogram of random results (products, quotients, etc.) that lie in the resulting interval to find out what distribution forms this way.</p>

<p>Another reason most operations are nontrivial is that the result of the operation may be an irrational number (as in <code>log</code>, <code>sin</code>, etc.), or can even have a non-terminating digit expansion (as in most cases of division).  For these operations, although interval arithmetic can tightly bound the possible result to a finite number of digits, the resulting interval can include numbers with a probability density of zero.</p></li>
<li>On the other hand, some other arithmetic operations are trivial to carry out in PSRNs.  They include:

<ul>
<li>Adding 1/2 to a uniform PSRN provided <em>b</em> (the base, or radix, of the PSRN&#39;s digits) is even, as mentioned in (Karney 2014)<sup><a href="#Note1"><strong>(1)</strong></a></sup>.</li>
<li>Negation, likewise mentioned in Karney.</li>
<li>Adding a constant with a terminating base-<em>b</em> expansion to a uniform PSRN (but first making sure to sample digits as needed so that the PSRN&#39;s fractional part is at least as long as that constant&#39;s fractional part; otherwise, a bias can be introduced).</li>
<li>Operations affecting the PSRN&#39;s integer part only.</li>
</ul></li>
<li>Partially-sampled-number arithmetic may also be possible by relating the relative probabilities of each digit, in the result&#39;s digit expansion, to some kind of formula.

<ul>
<li>There is previous work that relates continuous distributions to digit probabilities in a similar manner (but only in base 10) (Habibizad Navin et al., 2007)<sup><a href="#Note14"><strong>(14)</strong></a></sup>, (Nezhad et al., 2013)<sup><a href="#Note15"><strong>(15)</strong></a></sup>.  This previous work points to building a probability tree, where the probability of the next digit depends on the value of the previous digits.  However, calculating each probability requires knowing the distribution&#39;s cumulative distribution function (CDF), and the calculations can incur rounding errors especially when the digit probabilities are not rational numbers or they have no simple mathematical form, as is often the case.</li>
<li>For some distributions (including the uniform and exponential distributions), the digit probabilities don&#39;t depend on previous digits, only on the position of the digit.  In this case, however, there appear to be limits on how practical this approach is; see the <a href="#Setting_Digits_by_Digit_Probabilities"><strong>appendix</strong></a> for details.</li>
</ul></li>
<li>Finally, arithmetic with PSRNs may be possible if the result of the arithmetic is distributed with a known probability density function (PDF) (e.g., one found via Rohatgi&#39;s formula (Rohatgi 1976)<sup><a href="#Note16"><strong>(16)</strong></a></sup>), allowing for an algorithm that implements rejection from the uniform or exponential distribution.  An example of this is found in my article on <a href="https://peteroupc.github.io/uniformsum.html"><strong>arbitrary-precision samplers for the sum of uniform random numbers</strong></a>.  However, that PDF may have an unbounded peak, thus ruling out rejection sampling in practice.  For example, if <em>X</em> is a uniform PSRN, then <em>X</em><sup>3</sup> is distributed as <code>(1/3) / pow(X, 2/3)</code>, which has an unbounded peak at 0.  While this rules out plain rejection samplers for <em>X</em><sup>3</sup> in practice, it&#39;s still possible to sample powers of uniforms using PSRNs, which will be described later in this article.</li>
</ul>

<p><a id=Addition_and_Subtraction></a></p>

<h3>Addition and Subtraction</h3>

<p>The following algorithm shows how to add or subtract two uniform PSRNs (<strong>a</strong> and <strong>b</strong>) that store digits of the same base (radix) in their fractional parts, and get a uniform PSRN as a result.  The input PSRNs may be negative or non-negative, and it is assumed that their integer parts and signs were sampled.  <em>Python code implementing this algorithm is given later in this document.</em></p>

<ol>
<li>If <strong>a</strong> has unsampled digits before the last sampled digit in its fractional part, set each of those unsampled digits to a digit chosen uniformly at random.  Do the same for <strong>b</strong>.</li>
<li>If <strong>a</strong> has fewer digits in its fractional part than <strong>b</strong> (or vice versa), sample enough digits (by setting them to uniform random digits, such as unbiased random bits if <strong>a</strong> and <strong>b</strong> store binary, or base-2, digits) so that both PSRNs&#39; fractional parts have the same number of digits.  Now, let <em>digitcount</em> be the number of digits in <strong>a</strong>&#39;s fractional part.</li>
<li>To simplify matters: If <strong>a</strong> has no digits in its fractional part, append a digit chosen uniformly at random to that fractional part.  Do the same for <strong>b</strong>.</li>
<li>Let <em>asign</em> be &minus;1 if <strong>a</strong> is negative, or 1 otherwise.  Let <em>bsign</em> be &minus;1 if <strong>b</strong> is negative, or 1 otherwise.  Let <em>afp</em> be the digits of <strong>a</strong>&#39;s <em>fractional part</em>, and let <em>bfp</em> be the digits of <strong>b</strong>&#39;s <em>fractional part</em>.  (For example, if <strong>a</strong> represents the number 83.12344..., <em>afp</em> is 12344.)</li>
<li>Calculate the following four numbers:

<ul>
<li><em>afp</em>*<em>asign</em> + <em>bfp</em>*<em>bsign</em>.</li>
<li><em>afp</em>*<em>asign</em> + (<em>bfp</em>+1)*<em>bsign</em>.</li>
<li>(<em>afp</em>+1)*<em>asign</em> + <em>bfp</em>*<em>bsign</em>.</li>
<li>(<em>afp</em>+1)*<em>asign</em> + (<em>bfp</em>+1)*<em>bsign</em>.</li>
</ul></li>
<li>Set <em>minv</em> to the minimum and <em>maxv</em> to the maximum of the four numbers just calculated.  These are lower and upper bounds to the result of applying interval addition to the PSRNs <strong>a</strong> and <strong>b</strong>. (For example, if <strong>a</strong> is 0.12344... and <strong>b</strong> is 0.38925..., their fractional parts are added to form <strong>c</strong> = 0.51269...., or the interval [0.51269, 0.51271].)  However, the resulting PSRN is not uniformly distributed in its interval, and this is what the rest of this algorithm will solve, since in fact, the distribution of numbers in the interval resembles the distribution of the sum of two uniform random numbers.</li>
<li>Set <em>dir</em> to an unbiased random bit (that is, either 0 or 1, chosen with equal probability), then set <em>x</em> and <em>y</em> each to a digit chosen uniformly at random, then set <em>newdigits</em> to 0, then set <em>b</em> to <em>base</em>, where <em>base</em> is the base of digits stored by <strong>a</strong> and <strong>b</strong> (such as 2 for binary or 10 for decimal).</li>
<li>If <em>dir</em> is 1, set <em>lower</em> to (<em>b</em> &minus; 1 &minus; <em>x</em>).  Otherwise, set <em>lower</em> to <em>x</em>.</li>
<li>If <em>y</em> is less than <em>lower</em>, the algorithm is almost finished, so do the following:

<ol>
<li>If <em>minv</em> is less than 0 and <em>dir</em> is 1, set <em>s</em> to (<em>maxv</em> &minus; 1)*<em>base</em><sup><em>newdigits</em></sup> &minus; <em>x</em>.</li>
<li>Otherwise, if <em>minv</em> is less than 0 and <em>dir</em> is 0, set <em>s</em> to (<em>maxv</em> &minus; 1)*<em>base</em><sup><em>newdigits</em></sup> + <em>x</em>.</li>
<li>Otherwise, if <em>dir</em> is 1, set <em>s</em> to (<em>minv</em> + 1)*<em>base</em><sup><em>newdigits</em></sup> + <em>x</em>.</li>
<li>Otherwise, set <em>s</em> to (<em>minv</em>)*<em>base</em><sup><em>newdigits</em></sup> + <em>x</em>.</li>
<li>Create a new uniform PSRN, <em>ret</em>.  Set <em>ret</em>&#39;s sign to negative if <em>s</em> is less than 0, or non-negative otherwise.  Set <em>s</em> to abs(<em>s</em>).</li>
<li>Transfer the (<em>n</em> + <em>newdigits</em>) least significant digits of <em>s</em> to <em>ret</em>&#39;s fractional part, where <em>n</em> is the number of digits in <strong>a</strong>&#39;s fractional part.  (Note that <em>ret</em>&#39;s fractional part stores digits from most to least significant.)  Then set <em>ret</em>&#39;s integer part to floor(<em>s</em>/<em>base</em><sup><em>n</em> + <em>newdigits</em></sup>).  (For example, if <em>base</em> is 10, (<em>n</em> + <em>newdigits</em>) is 3, and <em>s</em> is 34297, then <em>ret</em>&#39;s fractional part is set to [2, 9, 7], and <em>ret</em>&#39;s integer part is set to 34.)</li>
<li>Return <em>ret</em>.</li>
</ol></li>
<li>If <em>y</em> is greater than <em>lower</em> + 1, go to step 7.</li>
<li>Multiply <em>x</em>, <em>y</em>, and <em>b</em> each by <em>base</em>, then add a digit chosen uniformly at random to <em>x</em>, then add a digit chosen uniformly at random to <em>y</em>, then add 1 to <em>newdigits</em>, then go to step 8.</li>
</ol>

<p><a id=Multiplication></a></p>

<h3>Multiplication</h3>

<p>The following algorithm shows how to multiply two uniform PSRNs (<strong>a</strong> and <strong>b</strong>) that store digits of the same base (radix) in their fractional parts, and get a uniform PSRN as a result.  The input PSRNs may be negative or non-negative, and it is assumed that their integer parts and signs were sampled. <em>Python code implementing this algorithm is given later in this document.</em></p>

<ol>
<li>If <strong>a</strong> has unsampled digits before the last sampled digit in its fractional part, set each of those unsampled digits to a digit chosen uniformly at random.  Do the same for <strong>b</strong>.</li>
<li>If <strong>a</strong> has fewer digits in its fractional part than <strong>b</strong> (or vice versa), sample enough digits (by setting them to uniform random digits, such as unbiased random bits if <strong>a</strong> and <strong>b</strong> store binary, or base-2, digits) so that both PSRNs&#39; fractional parts have the same number of digits.  Now, let <em>digitcount</em> be the number of digits in <strong>a</strong>&#39;s fractional part.</li>
<li>To simplify matters: If <strong>a</strong> has no digits in its fractional part, append a digit chosen uniformly at random to that fractional part.  Do the same for <strong>b</strong>.</li>
<li>Let <em>afp</em> be the digits of <strong>a</strong>&#39;s <em>fractional part</em>, and let <em>bfp</em> be the digits of <strong>b</strong>&#39;s <em>fractional part</em>.  (For example, if <strong>a</strong> represents the number 83.12344..., <em>afp</em> is 12344.)</li>
<li>Calculate <em>n1</em> = <em>afp</em>*<em>bfp</em>, <em>n2</em> = <em>afp</em>*(<em>bfp</em>+1), <em>n3</em> = (<em>afp</em>+1)*<em>bfp</em>, and <em>n4</em> = (<em>afp</em>+1)*(<em>bfp</em>+1).</li>
<li>Set <em>minv</em> to the minimum and <em>maxv</em> to the maximum of the four numbers just calculated.  Set <em>midmin</em> to min(<em>n2</em>, <em>n3</em>) and <em>midmax</em> to max(<em>n2</em>, <em>n3</em>).  The numbers <em>minv</em> and <em>maxv</em> are lower and upper bounds to the result of applying interval multiplication to the PSRNs <strong>a</strong> and <strong>b</strong>. (For example, if <strong>a</strong> is 0.12344... and <strong>b</strong> is 0.38925..., their fractional parts are added to form <strong>c</strong> = 0.51269...., or the interval [0.51269, 0.51271].)  However, the resulting PSRN is not uniformly distributed in its interval; in the case of multiplication the distribution resembles a trapezoid whose domain is the interval [<em>minv</em>, <em>maxv</em>] and whose top is delimited by <em>midmin</em> and <em>midmax</em>.</li>
<li>Create a new uniform PSRN, <em>ret</em>.  If <strong>a</strong> is negative and <strong>b</strong> is negative, or vice versa, set <em>ret</em>&#39;s sign to negative.  Otherwise, set <em>ret</em>&#39;s sign to non-negative.</li>
<li>Set <em>z</em> to a uniform random integer in the interval [0, <em>maxv</em>&minus;<em>minv</em>).</li>
<li>If <em>z</em> is less than <em>midmin</em>&minus;<em>minv</em>, we will sample from the left side of the trapezoid.  In this case, do the following:

<ol>
<li>Set <em>x</em> to <em>z</em>, then set <em>newdigits</em> to 0, then set <em>b</em> to <em>midmin</em>&minus;<em>minv</em>, then set <em>y</em> to a uniform random integer in the interval [0, <em>b</em>).</li>
<li>If <em>y</em> is less than <em>x</em>, the algorithm succeeds, so do the following:

<ol>
<li>Set <em>s</em> to <em>minv</em>*<em>base</em><sup><em>newdigits</em></sup> + <em>x</em> (where <em>base</em> is the base of digits stored by <strong>a</strong> and <strong>b</strong>, such as 2 for binary or 10 for decimal).</li>
<li>Transfer the (<em>n</em>*2 + <em>newdigits</em>) least significant digits of <em>s</em> to <em>ret</em>&#39;s fractional part, where <em>n</em> is the number of digits in <strong>a</strong>&#39;s fractional part.  (Note that <em>ret</em>&#39;s fractional part stores digits from most to least significant.)  Then set <em>ret</em>&#39;s integer part to floor(<em>s</em>/<em>base</em><sup><em>n</em>*2 + <em>newdigits</em></sup>).  (For example, if <em>base</em> is 10, (<em>n</em>*2 + <em>newdigits</em>) is 4, and <em>s</em> is 342978, then <em>ret</em>&#39;s fractional part is set to [2, 9, 7, 8], and <em>ret</em>&#39;s integer part is set to 34.)  Finally, return <em>ret</em>.</li>
</ol></li>
<li>If <em>y</em> is greater than <em>x</em> + 1, abort these substeps and go to step 8. (This is a rejection event.)</li>
<li>Multiply <em>x</em>, <em>y</em>, and <em>b</em> each by <em>base</em>, then add a digit chosen uniformly at random to <em>x</em>, then add a digit chosen uniformly at random to <em>y</em>, then add 1 to <em>newdigits</em>, then go to the second substep.</li>
</ol></li>
<li>If <em>z</em> is greater than or equal to <em>midmax</em>&minus;<em>minv</em>, we will sample from the right side of the trapezoid.  In this case, do the following:

<ol>
<li>Set <em>x</em> to <em>z</em>&minus;(<em>midmax</em>&minus;<em>minv</em>), then set <em>newdigits</em> to 0, then set <em>b</em> to <em>maxv</em>&minus;<em>midmax</em>, then set <em>y</em> to a uniform random integer in the interval [0, <em>b</em>).</li>
<li>If <em>y</em> is less than <em>b</em>&minus;1&minus;<em>x</em>, the algorithm succeeds, so do the following: Set <em>s</em> to <em>midmax</em>*<em>base</em><sup><em>newdigits</em></sup> + <em>x</em>, then transfer the (<em>n</em>*2+ <em>newdigits</em>) least significant digits of <em>s</em> to <em>ret</em>&#39;s fractional part, then set <em>ret</em>&#39;s integer part to floor(<em>s</em>/<em>base</em><sup><em>n</em>*2 + <em>newdigits</em></sup>), then return <em>ret</em>.</li>
<li>If <em>y</em> is greater than (<em>b</em>&minus;1&minus;<em>x</em>) + 1, abort these substeps and go to step 8. (This is a rejection event.)</li>
<li>Multiply <em>x</em>, <em>y</em>, and <em>b</em> each by <em>base</em>, then add a digit chosen uniformly at random to <em>x</em>, then add a digit chosen uniformly at random to <em>y</em>, then add 1 to <em>newdigits</em>, then go to the second substep.</li>
</ol></li>
<li>If we reach here, we have reached the middle part of the trapezoid, which is flat and uniform, so no rejection is necessary. Set <em>s</em> to <em>minv</em> + <em>z</em>, then transfer the (<em>n</em>*2) least significant digits of <em>s</em> to <em>ret</em>&#39;s fractional part, then set <em>ret</em>&#39;s integer part to floor(<em>s</em>/<em>base</em><sup><em>n</em>*2</sup>), then return <em>ret</em>.</li>
</ol>

<p>The following algorithm shows how to multiply a uniform PSRN (<strong>a</strong>) by a rational number <strong>b</strong>.  The input PSRN may be negative or non-negative, and it is assumed that its integer part and sign were sampled. <em>Python code implementing this algorithm is given later in this document.</em></p>

<ol>
<li>If <strong>a</strong> has unsampled digits before the last sampled digit in its fractional part, set each of those unsampled digits to a digit chosen uniformly at random.   Now, let <em>digitcount</em> be the number of digits in <strong>a</strong>&#39;s fractional part.</li>
<li>To simplify matters: If <strong>a</strong> has no digits in its fractional part, append a digit chosen uniformly at random to that fractional part.</li>
<li>Create a uniform PSRN, call it <em>ret</em>.  Set <em>ret</em>&#39;s sign to be &minus;1 if <strong>a</strong> is non-negative and <strong>b</strong> is less than 0 or if <strong>a</strong> is negative and <strong>b</strong> is 0 or greater, or 1 otherwise, then set <em>ret</em>&#39;s integer part to 0.  Let <em>base</em> be the base of digits stored in <strong>a</strong>&#39;s fractional part (such as 2 for binary or 10 for decimal).  Set <em>absfrac</em> to abs(<strong>b</strong>), then set <em>fraction</em> to <em>absfrac</em> &minus; floor(_absfrac).</li>
<li>Let <em>afp</em> be the digits of <strong>a</strong>&#39;s <em>fractional part</em>.  (For example, if <strong>a</strong> represents the number 83.12344..., <em>afp</em> is 12344.)</li>
<li>If <em>fraction</em> is not 0, then it was detected to be &quot;inexact&quot; and a different approach is needed.  Set <em>dcount</em> to <em>digitcount</em>, then set <em>ddc</em> to <em>base</em><sup><em>dcount</em></sup>, then set <em>lower</em> to (<em>afp</em>/<em>ddc</em>)*<em>absfrac</em> (using rational arithmetic), then set <em>upper</em> to (<em>afp</em>/<em>ddc</em>)*<em>absfrac</em> (again using rational arithmetic).</li>
<li>Set <em>rv</em> to a uniform random integer in the interval [floor(<em>lower</em>*<em>ddc</em>), floor(<em>lower</em>*<em>ddc</em>)).</li>
<li>Set <em>rvlower</em> to <em>rv</em>/<em>ddc</em> (as a rational number), then set <em>rvupper</em> to (<em>rv</em>+1)/<em>ddc</em> (as a rational number).</li>
<li>If <em>rvlower</em> is greater than or equal to <em>lower</em> and <em>rvupper</em> is less than <em>upper</em>, then the algorithm is almost done, so do the following: Transfer the <em>dcount</em> least significant digits of <em>rv</em> to <em>ret</em>&#39;s fractional part (note that <em>ret</em>&#39;s fractional part stores digits from most to least significant),  then set <em>ret</em>&#39;s integer part to floor(<em>rv</em>/<em>base</em><sup><em>dcount</em></sup>), then return <em>ret</em>. (For example, if <em>base</em> is 10, (<em>dcount</em>) is 4, and <em>rv</em> is 342978, then <em>ret</em>&#39;s fractional part is set to [2, 9, 7, 8], and <em>ret</em>&#39;s integer part is set to 34.)</li>
<li>If <em>rvlower</em> is greater than <em>upper</em> or if <em>rvupper</em> is less than <em>lower</em>, go to step 5.</li>
<li>Multiply <em>rv</em> and <em>ddc</em> each by <em>base</em>, then add 1 to <em>dcount</em>, then add a digit chosen uniformly at random to <em>rv</em>, then go to step 8.</li>
</ol>

<p><a id=Building_Blocks></a></p>

<h2>Building Blocks</h2>

<p>This document relies on several building blocks described in this section.</p>

<p>One of them is the &quot;geometric bag&quot; technique by Flajolet and others (2010)<sup><a href="#Note7"><strong>(7)</strong></a></sup>, which generates heads or tails with a probability that is built up digit by digit.</p>

<p><a id=SampleGeometricBag></a></p>

<h3>SampleGeometricBag</h3>

<p>The algorithm <strong>SampleGeometricBag</strong> returns 1 with a probability built up by a uniform PSRN.  (Flajolet et al., 2010)<sup><a href="#Note7"><strong>(7)</strong></a></sup> described an algorithm for the base-2 (binary) case, but that algorithm is difficult to apply to other digit bases.  Thus the following is a general version of the algorithm for any digit base.</p>

<ol>
<li>Set <em>i</em> to 0, and set <strong>b</strong> to a uniform PSRN with a positive sign and an integer part of 0.</li>
<li>If the item at position <em>i</em> of the input PSRN&#39;s fractional part is unsampled (that is, not set to a digit), set the item at that position to a digit chosen uniformly at random, increasing the fractional part&#39;s capacity as necessary (positions start at 0 where 0 is the most significant digit after the point, 1 is the next, etc.), and append the result to that fractional part&#39;s digit expansion.  Do the same for <strong>b</strong>.</li>
<li>Let <em>da</em> be the digit at position <em>i</em> of the input PSRN&#39;s fractional part, and let <em>db</em> be the corresponding digit for <strong>b</strong>.  Return 0 if <em>da</em> is less than <em>db</em>, or 1 if <em>da</em> is greater than <em>db</em>.</li>
<li>Add 1 to <em>i</em> and go to step 2.</li>
</ol>

<p>For base 2, the following <strong>SampleGeometricBag</strong> algorithm can be used, which is closer to the one given in the Flajolet paper:</p>

<ol>
<li> Set <em>N</em> to 0.</li>
<li> With probability 1/2, go to the next step.  Otherwise, add 1 to <em>N</em> and repeat this step. (When the algorithm moves to the next step, <em>N</em> is a geometric(1/2) random number.)</li>
<li> If the item at position <em>N</em> in the uniform PSRN&#39;s fractional part (positions start at 0) is not set to a digit (e.g., 0 or 1 for base 2), set the item at that position to a digit chosen uniformly at random (e.g., either 0 or 1 for base 2), increasing the fractional part&#39;s capacity as necessary.  (As a result of this step, there may be &quot;gaps&quot; in the uniform PSRN where no digit was sampled yet.)</li>
<li> Return the item at position <em>N</em>.</li>
</ol>

<p>For more on why these two algorithms are equivalent, see the appendix.</p>

<p><strong>SampleGeometricBagComplement</strong> is the same as the <strong>SampleGeometricBag</strong> algorithm, except the return value is 1 minus the original return value.  The result is that if <strong>SampleGeometricBag</strong> outputs 1 with probability <em>U</em>, <strong>SampleGeometricBagComplement</strong> outputs 1 with probability 1 &minus; <em>U</em>.</p>

<p><a id=FillGeometricBag></a></p>

<h3>FillGeometricBag</h3>

<p><strong>FillGeometricBag</strong> takes a uniform PSRN and generates a number whose fractional part has <code>p</code> digits as follows:</p>

<ol>
<li>For each position in [0, <code>p</code>), if the item at that position in the uniform PSRN&#39;s fractional part is unsampled, set the item there to to a digit chosen uniformly at random (e.g., either 0 or 1 for binary), increasing the fractional part&#39;s capacity as necessary. (Positions start at 0 where 0 is the most significant digit after the point, 1 is the next, etc.  See also (Oberhoff 2018, sec. 8)<sup><a href="#Note11"><strong>(11)</strong></a></sup>.)</li>
<li>Let <code>sign</code> be -1 if the PSRN is negative, or 1 otherwise; let <code>ipart</code> be the PSRN&#39;s integer part; and let <code>bag</code> be the PSRN&#39;s fractional part.  Take the first <code>p</code> digits of <code>bag</code> and return <code>sign</code> * (<code>ipart</code> + &Sigma;<sub><em>i</em>=0, ..., <code>p</code>&minus;1</sub> bag[<em>i</em>] * <em>b</em><sup>&minus;<em>i</em>&minus;1</sup>), where <em>b</em> is the base, or radix.  (If it somehow happens that digits beyond <code>p</code> in the PSRN&#39;s fractional part were already sampled [that is, set to a digit], then the implementation could choose instead to fill all unsampled digits between the first and the last set digit and return the full number, optionally rounding it to a number whose fractional part has <code>p</code> digits, with a rounding mode of choice.)</li>
</ol>

<p><a id=kthsmallest></a></p>

<h3>kthsmallest</h3>

<p>The <strong>kthsmallest</strong> method generates the &#39;k&#39;th smallest &#39;bitcount&#39;-digit uniform random number out of &#39;n&#39; of them (also known as the &#39;n&#39;th <em>order statistic</em>), is also relied on by this beta sampler.  It is used when both <code>a</code> and <code>b</code> are integers, based on the known property that a beta random variable in this case is the <code>a</code>th smallest uniform (0, 1) random number out of <code>a + b - 1</code> of them (Devroye 1986, p. 431)<sup><a href="#Note17"><strong>(17)</strong></a></sup>.</p>

<p><strong>kthsmallest</strong>, however, doesn&#39;t simply generate &#39;n&#39; &#39;bitcount&#39;-digit numbers and then sort them.  Rather, it builds up their digit expansions digit by digit, via PSRNs.    It uses the observation that (in the binary case) each uniform (0, 1) random number is equally likely to be less than half or greater than half; thus, the number of uniform numbers that are less than half vs. greater than half follows a binomial(n, 1/2) distribution (and of the numbers less than half, say, the less-than-one-quarter vs. greater-than-one-quarter numbers follows the same distribution, and so on).    Thanks to this observation, the algorithm can generate a sorted sample &quot;on the fly&quot;.  A similar observation applies to other bases than base 2 if we use the multinomial distribution instead of the binomial distribution.  I am not aware of any other article or paper (besides one by me) that describes the <strong>kthsmallest</strong> algorithm given here.</p>

<p>The algorithm is as follows:</p>

<ol>
<li>Create <code>n</code> uniform PSRNs with positive sign and an integer part of 0.</li>
<li>Set <code>index</code> to 1.</li>
<li>If <code>index &lt;= k</code> and <code>index + n &gt;= k</code>:

<ol>
<li>Generate <strong>v</strong>, a multinomial random vector with <em>b</em> probabilities equal to 1/<em>b</em>, where <em>b</em> is the base, or radix (for the binary case, <em>b</em> = 2, so this is equivalent to generating <code>LC</code> = binomial(<code>n</code>, 0.5) and setting <strong>v</strong> to {<code>LC</code>, <code>n - LC</code>}).</li>
<li>Starting at <code>index</code>, append the digit 0 to the first <strong>v</strong>[0] PSRNs, a 1 digit to the next <strong>v</strong>[1] PSRNs, and so on to appending a <em>b</em> &minus; 1 digit to the last <strong>v</strong>[<em>b</em> &minus; 1] PSRNs (for the binary case, this means appending a 0 bit to the first <code>LC</code> PSRNs and a 1 bit to the next <code>n - LC</code> PSRNs).</li>
<li>For each integer <em>i</em> in [0, <em>b</em>): If <strong>v</strong>[<em>i</em>] &gt; 1, repeat step 3 and these substeps with <code>index</code> = <code>index</code> + &Sigma;<sub><em>j</em>=0, ..., <em>i</em>&minus;1</sub> <strong>v</strong>[<em>j</em>] and <code>n</code> = <strong>v</strong>[<em>i</em>]. (For the binary case, this means: If <code>LC &gt; 1</code>, repeat step 3 and these substeps with the same <code>index</code> and <code>n = LC</code>; then, if <code>n - LC &gt; 1</code>, repeat step 3 and these substeps with <code>index = index + LC</code>, and <code>n = n - LC</code>).</li>
</ol></li>
<li>Take the <code>k</code>th PSRN (starting at 1) and fill it with uniform random digits as necessary to give its fractional part <code>bitcount</code> many digits (similarly to <strong>FillGeometricBag</strong> above). Return that number.  (An implementation may instead just return the PSRN without filling it this way first, but the beta sampler described later doesn&#39;t use this alternative.)</li>
</ol>

<p><a id=Power_of_Uniform_Sub_Algorithm></a></p>

<h3>Power-of-Uniform Sub-Algorithm</h3>

<p>The power-of-uniform sub-algorithm is used for certain cases of the beta sampler below.  It returns <em>U</em><sup><em>px</em>/<em>py</em></sup>, where <em>U</em> is a uniform random number in the interval [0, 1] and <em>px</em>/<em>py</em> is greater than 1, but unlike the naïve algorithm it supports an arbitrary precision, uses only random bits, and avoids floating-point arithmetic.  It also uses a <em>complement</em> flag to determine whether to return 1 minus the result.</p>

<p>It makes use of a number of algorithms as follows:</p>

<ul>
<li>It uses an algorithm for <a href="https://peteroupc.github.io/unbounded.html"><strong>sampling unbounded monotone PDFs</strong></a>, which in turn is similar to the inversion-rejection algorithm in (Devroye 1986, ch. 7, sec. 4.4)<sup><a href="#Note17"><strong>(17)</strong></a></sup>.  This is needed because when <em>px</em>/<em>py</em> is greater than 1, <em>U</em><sup><em>px</em>/<em>py</em></sup> is distributed as <code>(py/px) / pow(U, 1-py/px)</code>, which has an unbounded peak at 0.</li>
<li>It uses a number of Bernoulli factory algorithms, including <strong>SampleGeometricBag</strong> and some algorithms described in &quot;<a href="https://peteroupc.github.io/bernoulli.html"><strong>Bernoulli Factory Algorithms</strong></a>&quot;.</li>
</ul>

<p>However, this algorithm supports only base 2.</p>

<p>The power-of-uniform algorithm is as follows:</p>

<ol>
<li>Set <em>i</em> to 1.</li>
<li>Call the <strong>algorithm for (<em>a</em>/<em>b</em>)<sup><em>x</em>/<em>y</em></sup></strong> described in &quot;<a href="https://peteroupc.github.io/bernoulli.html"><strong>Bernoulli Factory Algorithms</strong></a>&quot;, with parameters <code>a = 1, b = 2, x = py, y = px</code>.  If the call returns 1 and <em>i</em> is less than <em>n</em>, add 1 to <em>i</em> and repeat this step.  If the call returns 1 and <em>i</em> is <em>n</em> or greater, return 1 if the <em>complement</em> flag is 1 or 0 otherwise (or return a uniform PSRN with a positive sign, an integer part of 0, and a fractional part filled with exactly <em>n</em> ones or zeros, respectively).</li>
<li>As a result, we will now sample a number in the interval [2<sup>&minus;<em>i</em></sup>, 2<sup>&minus;(<em>i</em> &minus; 1)</sup>).  We now have to generate a uniform random number <em>X</em> in this interval, then accept it with probability (<em>py</em> / (<em>px</em> * 2<sup><em>i</em></sup>)) / <em>X</em><sup>1 &minus; <em>py</em> / <em>px</em></sup>; the 2<sup><em>i</em></sup> in this formula is to help avoid very low probabilities for sampling purposes.  The following steps will achieve this without having to use floating-point arithmetic.</li>
<li>Create a positive-sign zero-integer-part uniform PSRN, then create a <em>geobag</em> input coin that returns the result of <strong>SampleGeometricBag</strong> on that PSRN.</li>
<li>Create a <em>powerbag</em> input coin that does the following: &quot;Call the  <strong>algorithm for &lambda;<sup><em>x</em>/<em>y</em></sup></strong>, described in &#39;<a href="https://peteroupc.github.io/bernoulli.html#lambda__x___y"><strong>Bernoulli Factory Algorithms</strong></a>&#39;, using the <em>geobag</em> input coin and with <em>x</em>/<em>y</em> = 1 &minus; <em>py</em> / <em>px</em>, and return the result.&quot;</li>
<li>Append <em>i</em> &minus; 1 zero-digits followed by a single one-digit to the PSRN&#39;s fractional part.  This will allow us to sample a uniform random number limited to the interval mentioned earlier.</li>
<li>Call the <strong>algorithm for ϵ / λ</strong>, described in &quot;<a href="https://peteroupc.github.io/bernoulli.html#x03F5_lambda"><strong>Bernoulli Factory Algorithms</strong></a>&quot;, using the <em>powerbag</em> input coin (which represents <em>b</em>) and with ϵ = <em>py</em>/(<em>px</em> * 2<sup><em>i</em></sup>) (which represents <em>a</em>), thus returning 1 with probability <em>a</em>/<em>b</em>.  If the call returns 1, the PSRN was accepted, so do the following:

<ol>
<li>If the <em>complement</em> flag is 1, make each zero-digit in the PSRN&#39;s fractional part a one-digit and vice versa.</li>
<li>Either return the PSRN as is or fill the unsampled digits of the PSRN&#39;s fractional part with uniform random digits as necessary to give the number an <em>n</em>-digit fractional part (similarly to <strong>FillGeometricBag</strong> above), where <em>n</em> is a precision parameter, then return the resulting number.</li>
</ol></li>
<li>If the call to the algorithm for ϵ / λ returns 0, remove all but the first <em>i</em> digits from the PSRN&#39;s fractional part, then go to step 7.</li>
</ol>

<p><a id=Algorithms_for_the_Beta_and_Exponential_Distributions></a></p>

<h2>Algorithms for the Beta and Exponential Distributions</h2>

<p>&nbsp;</p>

<p><a id=Beta_Distribution></a></p>

<h3>Beta Distribution</h3>

<p>All the building blocks are now in place to describe a <em>new</em> algorithm to sample the beta distribution, described as follows.  It takes three parameters: <em>a</em> &gt;= 1 and <em>b</em> &gt;= 1 (or one parameter is 1 and the other is greater than 0 in the binary case) are the parameters to the beta distribution, and <em>p</em> &gt; 0 is a precision parameter.</p>

<ol>
<li>Special cases:

<ul>
<li>If <em>a</em> = 1 and <em>b</em> = 1, return a positive-sign zero-integer-part uniform PSRN.</li>
<li>If <em>a</em> and <em>b</em> are both integers, return the result of <strong>kthsmallest</strong> with <code>n = a - b + 1</code> and <code>k = a</code></li>
<li>In the binary case, if <em>a</em> is 1 and <em>b</em> is less than 1, call the <strong>power-of-uniform sub-algorithm</strong> described below, with <em>px</em>/<em>py</em> = 1/<em>b</em>, and the <em>complement</em> flag set to 1, and return the result of that algorithm as is (without filling it as described in substep 7.2 of that algorithm).</li>
<li>In the binary case, if <em>b</em> is 1 and <em>a</em> is less than 1, call the <strong>power-of-uniform sub-algorithm</strong> described below, with <em>px</em>/<em>py</em> = 1/<em>a</em>, and the <em>complement</em> flag set to 0, and return the result of that algorithm as is (without filling it as described in substep 7.2 of that algorithm).</li>
</ul></li>
<li>If <em>a</em> &gt; 2 and <em>b</em> &gt; 2, do the following steps, which split <em>a</em> and <em>b</em> into two parts that are faster to simulate (and implement the generalized rejection strategy in (Devroye 1986, top of page 47)<sup><a href="#Note17"><strong>(17)</strong></a></sup>):

<ol>
<li>Set <em>aintpart</em> to floor(<em>a</em>) &minus; 1, set <em>bintpart</em> to floor(<em>b</em>) &minus; 1, set <em>arest</em> to <em>a</em> &minus; <em>aintpart</em>, and set <em>brest</em> to <em>b</em> &minus; <em>bintpart</em>.</li>
<li>Run this algorithm recursively, but with <em>a</em> = <em>aintpart</em> and <em>b</em> = <em>bintpart</em>. Set <em>bag</em> to the PSRN created by the run.</li>
<li>Create an input coin <em>geobag</em> that returns the result of <strong>SampleGeometricBag</strong> using the given PSRN.  Create another input coin <em>geobagcomp</em> that returns the result of <strong>SampleGeometricBagComplement</strong> using the given PSRN.</li>
<li>Call the <strong>algorithm for &lambda;<sup><em>x</em>/<em>y</em></sup></strong>, described in &quot;<a href="https://peteroupc.github.io/bernoulli.html"><strong>Bernoulli Factory Algorithms</strong></a>&quot;, using the <em>geobag</em> input coin and <em>x</em>/<em>y</em> = <em>arest</em>/1, then call the same algorithm using the <em>geobagcomp</em> input coin and <em>x</em>/<em>y</em> = <em>brest</em>/1. If both calls return 1, return <em>bag</em>. Otherwise, go to substep 2.</li>
</ol></li>
<li>Create an positive-sign zero-integer-part uniform PSRN.  Create an input coin <em>geobag</em> that returns the result of <strong>SampleGeometricBag</strong> using the given PSRN.  Create another input coin <em>geobagcomp</em> that returns the result of <strong>SampleGeometricBagComplement</strong> using the given PSRN.</li>
<li>Remove all digits from the PSRN&#39;s fractional part.  This will result in an &quot;empty&quot; uniform(0, 1) random number, <em>U</em>, for the following steps, which will accept <em>U</em> with probability <em>U</em><sup>a&minus;1</sup>*(1&minus;<em>U</em>)<sup>b&minus;1</sup>) (the proportional probability for the beta distribution), as <em>U</em> is built up.</li>
<li>Call the <strong>algorithm for &lambda;<sup><em>x</em>/<em>y</em></sup></strong>, described in &quot;<a href="https://peteroupc.github.io/bernoulli.html"><strong>Bernoulli Factory Algorithms</strong></a>&quot;, using the <em>geobag</em> input coin and <em>x</em>/<em>y</em> = <em>a</em> &minus; 1)/1 (thus returning with probability <em>U</em><sup>a&minus;1</sup>).  If the result is 0, go to step 4.</li>
<li>Call the same algorithm using the <em>geobagcomp</em> input coin and <em>x</em>/<em>y</em> = (<em>b</em> &minus; 1)/1 (thus returning 1 with probability (1&minus;<em>U</em>)<sup>b&minus;1</sup>).  If the result is 0, go to step 4. (Note that this step and the previous step don&#39;t depend on each other and can be done in either order without affecting correctness, and this is taken advantage of in the Python code below.)</li>
<li><em>U</em> was accepted, so return the result of <strong>FillGeometricBag</strong>.</li>
</ol>

<p>Once a PSRN is accepted by the steps above, either return the PSRN as is or fill the unsampled digits of the PSRN&#39;s fractional part with uniform random digits as necessary to give the number a <em>p</em>-digit fractional part (similarly to <strong>FillGeometricBag</strong>), then return the resulting number.</p>

<blockquote>
<p><strong>Notes:</strong></p>

<ul>
<li>A beta(1/<em>x</em>, 1) random number is the same as a uniform random number raised to the power of <em>x</em>.</li>
<li>For the beta distribution bigger <code>alpha</code> or <code>beta</code> is, the smaller the area of acceptance becomes (and the more likely random numbers get rejected by steps 5 and 6, raising its run-time).  This is because <code>max(u^(alpha-1)*(1-u)^(beta-1))</code>, the peak of the PDF, approaches 0 as the parameters get bigger.  To deal with this, step 2 was included, which under certain circumstances breaks the PDF into two parts that are relatively trivial to sample (in terms of bit complexity).</li>
</ul>
</blockquote>

<p><a id=Exponential_Distribution></a></p>

<h3>Exponential Distribution</h3>

<p>We also have the necessary building blocks to describe how to sample e-rands.  As implemented in the Python code, an e-rand consists of five numbers: the first is a multiple of 1/(2<sup><em>x</em></sup>), the second is <em>x</em>, the third is the integer part (initially &minus;1 to indicate the integer part wasn&#39;t sampled yet), and the fourth and fifth are the &lambda; parameter&#39;s numerator and denominator, respectively.  (Because exponential random numbers are always non-negative, the e-rand&#39;s sign is implicitly positive).</p>

<p>To sample bit <em>k</em> after the binary point of an exponential random number with rate &lambda; (where <em>k</em> = 1 means the first digit after the point, <em>k</em> = 2 means the second, etc.), call the <strong>LogisticExp</strong> algorithm with <em>x</em> = &lambda;&#39;s numerator, <em>y</em> = &lambda;&#39;s denominator, and <em>prec</em> = <em>k</em>.</p>

<p>The <strong>ExpRandLess</strong> algorithm is a special case of the general <strong>RandLess</strong> algorithm given earlier.  It compares two e-rands <strong>a</strong> and <strong>b</strong> (and samples additional bits from them as necessary) and returns 1 if <strong>a</strong> turns out to be less than <strong>b</strong>, or 0 otherwise. (Note that <strong>a</strong> and <strong>b</strong> are allowed to have different &lambda; parameters.)</p>

<ol>
<li>If <strong>a</strong>&#39;s integer part wasn&#39;t sampled yet, call the <strong>algorithm for exp(&minus;<em>x</em>/<em>y</em>)</strong> with <em>x</em> = &lambda;&#39;s numerator and <em>y</em> = &lambda;&#39;s denominator, until the call returns 0, then set the integer part to the number of times 1 was returned this way.  Do the same for <strong>b</strong>.</li>
<li>Return 1 if <strong>a</strong>&#39;s integer part is less than <strong>b</strong>&#39;s, or 0 if <strong>a</strong>&#39;s integer part is greater than <strong>b</strong>&#39;s.</li>
<li>Set <em>i</em> to 0.</li>
<li>If <strong>a</strong>&#39;s fractional part has <em>i</em> or fewer bits, call the <strong>LogisticExp</strong> algorithm with <em>x</em> = &lambda;&#39;s numerator, <em>y</em> = &lambda;&#39;s denominator, and <em>prec</em> = <em>i</em> + 1, and append the result to that fractional part&#39;s binary expansion.  (For example, if the implementation stores the binary expansion as a packed integer and a size, the implementation can shift the packed integer by 1, add the result of the algorithm to that integer, then add 1 to the size.) Do the same for <strong>b</strong>.</li>
<li>Return 1 if <strong>a</strong>&#39;s fractional part is less than <strong>b</strong>&#39;s, or 0 if <strong>a</strong>&#39;s fractional part is greater than <strong>b</strong>&#39;s.</li>
<li>Add 1 to <em>i</em> and go to step 4.</li>
</ol>

<p>The <strong>ExpRandFill</strong> algorithm takes an e-rand <strong>a</strong> and generates a number whose fractional part has <code>p</code> bits as follows:</p>

<ol>
<li>If <strong>a</strong>&#39;s integer part wasn&#39;t sampled yet, sample it as given in step 1 of <strong>ExpRandLess</strong>.</li>
<li>If <strong>a</strong>&#39;s fractional part has greater than <code>p</code> bits, round <strong>a</strong> to a number whose fractional part has <code>p</code> bits, and return that number.  The rounding can be done, for example, by discarding all bits beyond <code>p</code> bits after the place to be rounded, or by rounding to the nearest 2<sup>-p</sup>, ties-to-up, as done in the sample Python code.</li>
<li>While <strong>a</strong>&#39;s fractional part has fewer than <code>p</code> bits, call the <strong>LogisticExp</strong> algorithm with <em>x</em> = &lambda;&#39;s numerator, <em>y</em> = &lambda;&#39;s denominator, and <em>prec</em> = <em>i</em>, where <em>i</em> is 1 plus the number of bits in <strong>a</strong>&#39;s fractional part, and append the result to that fractional part&#39;s binary expansion.</li>
<li>Return the number represented by <strong>a</strong>.</li>
</ol>

<p><a id=Sampler_Code></a></p>

<h2>Sampler Code</h2>

<p>The following Python code implements the beta sampler just described.  It relies on two Python modules I wrote:</p>

<ul>
<li>&quot;<a href="https://github.com/peteroupc/peteroupc.github.io/blob/master/bernoulli.py"><strong>bernoulli.py</strong></a>&quot;, which collects a number of Bernoulli factories, some of which are relied on by the code below.</li>
<li>&quot;<a href="https://github.com/peteroupc/peteroupc.github.io/blob/master/randomgen.py"><strong>randomgen.py</strong></a>&quot;, which collects a number of random number generation methods, including <code>kthsmallest</code>, as well as the <code>RandomGen</code> class.</li>
</ul>

<p>Note that the code uses floating-point arithmetic only to convert the result of the sampler to a convenient form, namely a floating-point number.</p>

<p>This code is far from fast, though, at least in Python.</p>

<pre>import math
import random
import bernoulli
from randomgen import RandomGen
from fractions import Fraction

def _toreal(ret, precision):
        # NOTE: Although we convert to a floating-point
        # number here, this is not strictly necessary and
        # is merely for convenience.
        return ret*1.0/(1&lt;&lt;precision)

def _urand_to_geobag(bag):
  return [(bag[0]&gt;&gt;(bag[1]-1-i))&amp;1 for i in range(bag[1])]

def _power_of_uniform_greaterthan1(bern, power, complement=False, precision=53):
    return bern.fill_geometric_bag(
        _power_of_uniform_greaterthan1_geobag(bern, power, complement), precision
    )

def _power_of_uniform_greaterthan1_geobag(bern, power, complement=False, precision=53):
   if power&lt;1:
     raise ValueError(&quot;Not supported&quot;)
   if power==1:
        return []  # Empty uniform random number
   i=1
   powerfrac=Fraction(power)
   powerrest=Fraction(1) - Fraction(1)/powerfrac
   # Choose an interval
   while bern.zero_or_one_power_ratio(1,2,
         powerfrac.denominator,powerfrac.numerator) == 1:
      i+=1
   epsdividend = Fraction(1)/(powerfrac * 2**i)
   # -- A choice for epsdividend which makes eps_div
   # -- much faster, but this will require floating-point arithmetic
   # -- to calculate &quot;**powerrest&quot;, which is not the focus
   # -- of this article.
   # probx=((2.0**(-i-1))**powerrest)
   # epsdividend=Fraction(probx)*255/256
   bag=[]
   gb=lambda: bern.geometric_bag(bag)
   bf =lambda: bern.power(gb, powerrest.numerator, powerrest.denominator)
   while True:
      # Limit sampling to the chosen interval
      bag.clear()
      for k in range(i-1):
         bag.append(0)
      bag.append(1)
      # Simulate epsdividend / x**(1-1/power)
      if bern.eps_div(bf, epsdividend) == 1:
          # Flip all bits if complement is true
          bag=[x if x==None else 1-x for x in bag] if complement else bag
          return bag

def powerOfUniform(b, px, py, precision=53):
        # Special case of beta, returning power of px/py
        # of a uniform random number, provided px/py
        # is in (0, 1].
        return betadist(b, py, px, 1, 1, precision)

    return b.fill_geometric_bag(
        betadist_geobag(b, ax, ay, bx, by), precision
    )

def betadist_geobag(b, ax=1, ay=1, bx=1, by=1):
    &quot;&quot;&quot; Generates a beta-distributed random number with arbitrary
          (user-defined) precision.  Currently, this sampler only works if (ax/ay) and
          (bx/by) are both 1 or greater, or if one of these parameters is
         1 and the other is less than 1.
         - b: Bernoulli object (from the &quot;bernoulli&quot; module).
         - ax, ay: Numerator and denominator of first shape parameter.
         - bx, by: Numerator and denominator of second shape parameter.
         - precision: Number of bits after the point that the result will contain.
        &quot;&quot;&quot;
    # Beta distribution for alpha&gt;=1 and beta&gt;=1
    bag = []
    afrac=(Fraction(ax) if ay==1 else Fraction(ax, ay))
    bfrac=(Fraction(bx) if by==1 else Fraction(bx, by))
    bpower = bfrac - 1
    apower = afrac - 1
    # Special case for a=b=1
    if bpower == 0 and apower == 0:
        return bag
    # Special case if a=1
    if apower == 0 and bpower &lt; 0:
        return _power_of_uniform_greaterthan1_geobag(b, Fraction(by, bx), True)
    # Special case if b=1
    if bpower == 0 and apower &lt; 0:
        return _power_of_uniform_greaterthan1_geobag(b, Fraction(ay, ax), False)
    if apower &lt;= -1 or bpower &lt;= -1:
        raise ValueError
    # Special case if a and b are integers
    if int(bpower) == bpower and int(apower) == apower:
        a = int(afrac)
        b = int(bfrac)
        return _urand_to_geobag(randomgen.RandomGen().kthsmallest_urand(a + b - 1, a))
    # Split a and b into two parts which are relatively trivial to simulate
    if bfrac &gt; 2 and afrac &gt; 2:
        bintpart = int(bfrac) - 1
        aintpart = int(afrac) - 1
        brest = bfrac - bintpart
        arest = afrac - aintpart
        # Generalized rejection method, p. 47
        while True:
           bag = betadist_geobag(b, aintpart, 1, bintpart, 1)
           gb = lambda: b.geometric_bag(bag)
           gbcomp = lambda: b.geometric_bag(bag) ^ 1
           if (b.power(gbcomp, brest)==1 and \
              b.power(gb, arest)==1):
              return bag
    # Create a &quot;geometric bag&quot; to hold a uniform random
    # number (U), described by Flajolet et al. 2010
    gb = lambda: b.geometric_bag(bag)
    # Complement of &quot;geometric bag&quot;
    gbcomp = lambda: b.geometric_bag(bag) ^ 1
    bp1=lambda: (1 if b.power(gbcomp, bpower)==1 and \
            b.power(gb, apower)==1 else 0)
    while True:
        # Create a uniform random number (U) bit-by-bit, and
        # accept it with probability U^(a-1)*(1-U)^(b-1), which
        # is the unnormalized PDF of the beta distribution
        bag.clear()
        if bp1() == 1:
            # Accepted
            return ret

def _fill_geometric_bag(b, bag, precision):
        ret=0
        lb=min(len(bag), precision)
        for i in range(lb):
           if i&gt;=len(bag) or bag[i]==None:
              ret=(ret&lt;&lt;1)|b.randbit()
           else:
              ret=(ret&lt;&lt;1)|bag[i]
        if len(bag) &lt; precision:
           diff=precision-len(bag)
           ret=(ret &lt;&lt; diff)|random.randint(0,(1 &lt;&lt; diff)-1)
        # Now we have a number that is a multiple of
        # 2^-precision.
        return _toreal(ret, precision)
</pre>

<p>The following Python code implements the exponential sampler described earlier.  In the Python code below, note that <code>zero_or_one</code> uses <code>random.randint</code> which does not necessarily use only random bits, even though it&#39;s called only to return either zero or one.</p>

<pre>import random

def logisticexp(ln, ld, prec):
        &quot;&quot;&quot; Returns 1 with probability 1/(1+exp(ln/(ld*2^prec))). &quot;&quot;&quot;
        denom=ld*2**prec
        while True:
           if zero_or_one(1, 2)==0: return 0
           if zero_or_one_exp_minus(ln, denom) == 1: return 1

def exprandnew(lamdanum=1, lamdaden=1):
     &quot;&quot;&quot; Returns an object to serve as a partially-sampled
          exponential random number with the given
          rate &#39;lamdanum&#39;/&#39;lamdaden&#39;.  The object is a list of five numbers
          as given in the prose.  Default for &#39;lamdanum&#39;
          and &#39;lamdaden&#39; is 1.
          The number created by this method will be &quot;empty&quot;
          (no bits sampled yet).
          &quot;&quot;&quot;
     return [0, 0, -1, lamdanum, lamdaden]

def exprandfill(a, bits):
    &quot;&quot;&quot; Fills the unsampled bits of the given exponential random number
           &#39;a&#39; as necessary to make a number whose fractional part
           has &#39;bits&#39; many bits.  If the number&#39;s fractional part already has
           that many bits or more, the number is rounded using the round-to-nearest,
           ties to even rounding rule.  Returns the resulting number as a
           multiple of 2^&#39;bits&#39;. &quot;&quot;&quot;
    # Fill the integer if necessary.
    if a[2]==-1:
        a[2]=0
        while zero_or_one_exp_minus(a[3], a[4]) == 1:
            a[2]+=1
    if a[1] &gt; bits:
        # Shifting bits beyond the first excess bit.
        aa = a[0] &gt;&gt; (a[1] - bits - 1)
        # Check the excess bit; if odd, round up.
        ret=aa &gt;&gt; 1 if (aa &amp; 1) == 0 else (aa &gt;&gt; 1) + 1
        return ret|(a[2]&lt;&lt;bits)
    # Fill the fractional part if necessary.
    while a[1] &lt; bits:
       index = a[1]
       a[1]+=1
       a[0]=(a[0]&lt;&lt;1)|logisticexp(a[3], a[4], index+1)
    return a[0]|(a[2]&lt;&lt;bits)

def exprandless(a, b):
        &quot;&quot;&quot; Determines whether one partially-sampled exponential number
           is less than another; returns
           true if so and false otherwise.  During
           the comparison, additional bits will be sampled in both numbers
           if necessary for the comparison. &quot;&quot;&quot;
        # Check integer part of exponentials
        if a[2] == -1:
            a[2] = 0
            while zero_or_one_exp_minus(a[3], a[4]) == 1:
                a[2] += 1
        if b[2] == -1:
            b[2] = 0
            while zero_or_one_exp_minus(b[3], b[4]) == 1:
                b[2] += 1
        if a[2] &lt; b[2]:
            return True
        if a[2] &gt; b[2]:
            return False
        index = 0
        while True:
            # Fill with next bit in a&#39;s exponential number
            if a[1] &lt; index:
                raise ValueError
            if b[1] &lt; index:
                raise ValueError
            if a[1] &lt;= index:
                a[1] += 1
                a[0] = logisticexp(a[3], a[4], index + 1) | (a[0] &lt;&lt; 1)
            # Fill with next bit in b&#39;s exponential number
            if b[1] &lt;= index:
                b[1] += 1
                b[0] = logisticexp(b[3], b[4], index + 1) | (b[0] &lt;&lt; 1)
            aa = (a[0] &gt;&gt; (a[1] - 1 - index)) &amp; 1
            bb = (b[0] &gt;&gt; (b[1] - 1 - index)) &amp; 1
            if aa &lt; bb:
                return True
            if aa &gt; bb:
                return False
            index += 1

def zero_or_one(px, py):
        &quot;&quot;&quot; Returns 1 at probability px/py, 0 otherwise.
            Uses Bernoulli algorithm from Lumbroso appendix B,
            with one exception noted in this code. &quot;&quot;&quot;
        if py &lt;= 0:
            raise ValueError
        if px == py:
            return 1
        z = px
        while True:
            z = z * 2
            if z &gt;= py:
                if random.randint(0,1) == 0:
                    return 1
                z = z - py
            # Exception: Condition added to help save bits
            elif z == 0: return 0
            else:
                if random.randint(0,1) == 0:
                   return 0

def zero_or_one_exp_minus(x, y):
        &quot;&quot;&quot; Generates 1 with probability exp(-px/py); 0 otherwise.
               Reference: Canonne et al. 2020. &quot;&quot;&quot;
        if y &lt;= 0 or x &lt; 0:
            raise ValueError
        if x==0: return 1
        if x &gt; y:
            xf = int(x / y)  # Get integer part
            x = x % y  # Reduce to fraction
            if x &gt; 0 and zero_or_one_exp_minus(x, y) == 0:
                return 0
            for i in range(xf):
                if zero_or_one_exp_minus(1, 1) == 0:
                    return 0
            return 1
        r = 1
        ii = 1
        while True:
            if zero_or_one(x, y*ii) == 0:
                return r
            r=1-r
            ii += 1

# Example of use
def exprand(lam):
   return exprandfill(exprandnew(lam),53)*1.0/(1&lt;&lt;53)

</pre>

<p>In the following Python code, <code>multiply_psrns</code> and <code>add_psrns</code> are methods to generate the result of multiplying or adding two uniform PSRNs, respectively.</p>

<pre>def multiply_psrns(psrn1, psrn2, digits=2):
    &quot;&quot;&quot; Multiplies two uniform partially-sampled random numbers.
        psrn1: List containing the sign, integer part, and fractional part
            of the first PSRN.  Fractional part is a list of digits
            after the point, starting with the first.
        psrn2: List containing the sign, integer part, and fractional part
            of the second PSRN.
        digits: Digit base of PSRNs&#39; digits.  Default is 2, or binary. &quot;&quot;&quot;
    if psrn1[0] == None or psrn1[1] == None or psrn2[0] == None or psrn2[1] == None:
        raise ValueError
    for i in range(len(psrn1[2])):
        psrn1[2][i] = (
            random.randint(0, digits - 1) if psrn1[2][i] == None else psrn1[2][i]
        )
    for i in range(len(psrn2[2])):
        psrn2[2][i] = (
            random.randint(0, digits - 1) if psrn2[2][i] == None else psrn2[2][i]
        )
    while len(psrn1[2]) &lt; len(psrn2[2]):
        psrn1[2].append(random.randint(0, digits - 1))
    while len(psrn1[2]) &gt; len(psrn2[2]):
        psrn2[2].append(random.randint(0, digits - 1))
    digitcount = len(psrn1[2])
    if digitcount == 0:
        # Make sure fractional part has at least one digit, to simplify matters
        psrn1[2].append(random.randint(0, digits - 1))
        psrn2[2].append(random.randint(0, digits - 1))
        digitcount += 1
    if len(psrn2[2]) != digitcount:
        raise ValueError
    # Perform multiplication
    frac1 = psrn1[1]
    frac2 = psrn2[1]
    for i in range(digitcount):
        frac1 = frac1 * digits + psrn1[2][i]
    for i in range(digitcount):
        frac2 = frac2 * digits + psrn2[2][i]
    small = frac1 * frac2
    mid1 = frac1 * (frac2 + 1)
    mid2 = (frac1 + 1) * frac2
    large = (frac1 + 1) * (frac2 + 1)
    midmin = min(mid1, mid2)
    midmax = max(mid1, mid2)
    cpsrn = [1, 0, [0 for i in range(digitcount * 2)]]
    cpsrn[0] = psrn1[0] * psrn2[0]
    while True:
        rv = random.randint(0, large - small - 1)
        if rv &lt; midmin - small:
            # Left side of product density; rising triangular
            pw = rv
            newdigits = 0
            b = midmin - small
            y = random.randint(0, b - 1)
            while True:
                if y &lt; pw:
                    # Success
                    sret = small * (digits ** newdigits) + pw
                    for i in range(digitcount * 2 + newdigits):
                        idx = (digitcount * 2 + newdigits) - 1 - i
                        while idx &gt;= len(cpsrn[2]):
                            cpsrn[2].append(None)
                        cpsrn[2][idx] = sret % digits
                        sret //= digits
                    cpsrn[1] = sret
                    return cpsrn
                elif y &gt; pw + 1:  # Greater than upper bound
                    # Rejected
                    break
                pw = pw * digits + random.randint(0, digits - 1)
                y = y * digits + random.randint(0, digits - 1)
                b *= digits
                newdigits += 1
        elif rv &gt;= midmax - small:
            # Right side of product density; falling triangular
            pw = rv - (midmax - small)
            newdigits = 0
            b = large - midmax
            y = random.randint(0, b - 1)
            while True:
                lowerbound = b - 1 - pw
                if y &lt; lowerbound:
                    # Success
                    sret = midmax * (digits ** newdigits) + pw
                    for i in range(digitcount * 2 + newdigits):
                        idx = (digitcount * 2 + newdigits) - 1 - i
                        while idx &gt;= len(cpsrn[2]):
                            cpsrn[2].append(None)
                        cpsrn[2][idx] = sret % digits
                        sret //= digits
                    cpsrn[1] = sret
                    return cpsrn
                elif y &gt; lowerbound + 1:  # Greater than upper bound
                    # Rejected
                    break
                pw = pw * digits + random.randint(0, digits - 1)
                y = y * digits + random.randint(0, digits - 1)
                b *= digits
                newdigits += 1
        else:
            # Middle, or uniform, part of product density
            sret = small + rv
            for i in range(digitcount * 2):
                cpsrn[2][digitcount * 2 - 1 - i] = sret % digits
                sret //= digits
            cpsrn[1] = sret
            return cpsrn

def multiply_psrn_by_fraction(psrn1, fraction, digits=2):
    &quot;&quot;&quot; Multiplies a partially-sampled random number by a fraction.
        psrn1: List containing the sign, integer part, and fractional part
            of the first PSRN.  Fractional part is a list of digits
            after the point, starting with the first.
        fraction: Fraction to multiply by.
        digits: Digit base of PSRNs&#39; digits.  Default is 2, or binary. &quot;&quot;&quot;
    if psrn1[0] == None or psrn1[1] == None:
        raise ValueError
    fraction = Fraction(fraction)
    for i in range(len(psrn1[2])):
        psrn1[2][i] = (
            random.randint(0, digits - 1) if psrn1[2][i] == None else psrn1[2][i]
        )
    digitcount = len(psrn1[2])
    if digitcount == 0:
        # Make sure fractional part has at least one digit, to simplify matters
        psrn1[2].append(random.randint(0, digits - 1))
        digitcount += 1
    # Perform multiplication
    frac1 = psrn1[1]
    fracsign = -1 if fraction &lt; 0 else 1
    absfrac = abs(fraction)
    for i in range(digitcount):
        frac1 = frac1 * digits + psrn1[2][i]
    # Result is &quot;inexact&quot;, and &quot;small&quot; expresses a lower bound
    while True:
        dcount = digitcount
        ddc = digits ** dcount
        small1 = Fraction(frac1, ddc) * absfrac
        large1 = Fraction(frac1 + 1, ddc) * absfrac
        #print([&quot;small1&quot;,float(small1),&quot;large1&quot;,float(large1)])
        dc = int(small1 * ddc)
        dc2 = int(large1 * ddc) + 1
        rv = random.randint(dc, dc2 - 1)
        while True:
            rvsmall = Fraction(rv, ddc)
            rvlarge = Fraction(rv + 1, ddc)
            if rvsmall &gt;= small1 and rvlarge &lt; large1:
                cpsrn = [1, 0, [0 for i in range(dcount)]]
                cpsrn[0] = psrn1[0] * fracsign
                sret = rv
                for i in range(dcount):
                    cpsrn[2][dcount - 1 - i] = sret % digits
                    sret //= digits
                cpsrn[1] = sret
                return cpsrn
            elif rvsmall &gt; large1 or rvlarge &lt; small1:
                break
            else:
                rv = rv * digits + random.randint(0, digits - 1)
                dcount += 1
                ddc *= digits

def add_psrns(psrn1, psrn2, digits=2):
    &quot;&quot;&quot; Adds two uniform partially-sampled random numbers.
        psrn1: List containing the sign, integer part, and fractional part
            of the first PSRN.  Fractional part is a list of digits
            after the point, starting with the first.
        psrn2: List containing the sign, integer part, and fractional part
            of the second PSRN.
        digits: Digit base of PSRNs&#39; digits.  Default is 2, or binary. &quot;&quot;&quot;
    if psrn1[0] == None or psrn1[1] == None or psrn2[0] == None or psrn2[1] == None:
        raise ValueError
    for i in range(len(psrn1[2])):
        psrn1[2][i] = (
            random.randint(0, digits - 1) if psrn1[2][i] == None else psrn1[2][i]
        )
    for i in range(len(psrn2[2])):
        psrn2[2][i] = (
            random.randint(0, digits - 1) if psrn2[2][i] == None else psrn2[2][i]
        )
    while len(psrn1[2]) &lt; len(psrn2[2]):
        psrn1[2].append(random.randint(0, digits - 1))
    while len(psrn1[2]) &gt; len(psrn2[2]):
        psrn2[2].append(random.randint(0, digits - 1))
    digitcount = len(psrn1[2])
    if len(psrn2[2]) != digitcount:
        raise ValueError
    # Perform addition
    if digitcount == 0:
        # Make sure fractional part has at least one digit, to simplify matters
        psrn1[2].append(random.randint(0, digits - 1))
        psrn2[2].append(random.randint(0, digits - 1))
        digitcount += 1
    frac1 = psrn1[1]
    frac2 = psrn2[1]
    for i in range(digitcount):
        frac1 = frac1 * digits + psrn1[2][i]
    for i in range(digitcount):
        frac2 = frac2 * digits + psrn2[2][i]
    small = frac1 * psrn1[0] + frac2 * psrn2[0]
    mid1 = frac1 * psrn1[0] + (frac2 + 1) * psrn2[0]
    mid2 = (frac1 + 1) * psrn1[0] + frac2 * psrn2[0]
    large = (frac1 + 1) * psrn1[0] + (frac2 + 1) * psrn2[0]
    minv = min(small, mid1, mid2, large)
    maxv = max(small, mid1, mid2, large)
    while True:
        rv = random.randint(0, 1)
        pw = random.randint(0, digits - 1)
        newdigits = 1
        b = digits
        y = random.randint(0, digits - 1)
        while True:
            if rv == 1:
                lowerbound = b - 1 - pw
            else:
                lowerbound = pw
            if y &lt; lowerbound:
                # Success
                if rv == 1:
                    if minv &gt;= 0:
                        sret = (minv + 1) * (digits ** newdigits) + pw
                    else:
                        sret = (maxv - 1) * (digits ** newdigits) - pw
                else:
                    if minv &gt;= 0:
                        sret = minv * (digits ** newdigits) + pw
                    else:
                        sret = (maxv - 1) * (digits ** newdigits) + pw
                cpsrn = [1, 0, [0 for i in range(digitcount + newdigits)]]
                cpsrn[0] = -1 if sret &lt; 0 else 1
                sret = abs(sret)
                for i in range(digitcount + newdigits):
                    idx = (digitcount + newdigits) - 1 - i
                    cpsrn[2][idx] = abs(sret) % digits
                    sret //= digits
                cpsrn[1] = abs(sret)
                return cpsrn
            elif y &gt; lowerbound + 1:
                # Rejected
                break
            pw = pw * digits + random.randint(0, digits - 1)
            y = y * digits + random.randint(0, digits - 1)
            b *= digits
            newdigits += 1
</pre>

<p><a id=Exponential_Sampler_Extension></a></p>

<h3>Exponential Sampler: Extension</h3>

<p>The code above supports rational-valued &lambda; parameters.  It can be extended to support any real-valued &lambda; parameter greater than 0, as long as &lambda; can be rewritten as the sum of one or more components whose fractional parts can each be simulated by a Bernoulli factory algorithm that outputs heads with probability equal to that fractional part.<sup><a href="#Note18"><strong>(18)</strong></a></sup>.</p>

<p>More specifically:</p>

<ol>
<li>Decompose &lambda; into <em>n</em> &gt; 0 positive components that sum to &lambda;.  For example, if &lambda; = 3.5, it can be decomposed into only one component, 3.5 (whose fractional part is trivial to simulate), and if &lambda; = &pi;, it can be decomposed into four components that are all (&pi; / 4), which has a not-so-trivial simulation described in &quot;<a href="https://peteroupc.github.io/bernoulli.html"><strong>Bernoulli Factory Algorithms</strong></a>&quot;.</li>
<li>For each component <em>LC</em>[<em>i</em>] found this way, let <em>LI</em>[<em>i</em>] be floor(<em>LC</em>[<em>i</em>]) and let <em>LF</em>[<em>i</em>] be <em>LC</em>[<em>i</em>] &minus; floor(<em>LC</em>[<em>i</em>]) (<em>LC</em>[<em>i</em>]&#39;s fractional part).</li>
</ol>

<p>The code above can then be modified as follows:</p>

<ul>
<li><p><code>exprandnew</code> is modified so that instead of taking <code>lamdanum</code> and <code>lamdaden</code>, it takes a list of the components described above.  Each component is stored as <em>LI</em>[<em>i</em>] and an algorithm that simulates <em>LF</em>[<em>i</em>].</p></li>
<li><p><code>zero_or_one_exp_minus(a, b)</code> is replaced with the <strong>algorithm for exp(&minus; <em>z</em>)</strong> described in &quot;<a href="https://peteroupc.github.io/bernoulli.html"><strong>Bernoulli Factory Algorithms</strong></a>&quot;, where <em>z</em> is the real-valued &lambda; parameter.</p></li>
<li><p><code>logisticexp(a, b, index+1)</code> is replaced with the <strong>algorithm for 1 / 1 + exp(<em>z</em> / 2<sup><em>index</em> + 1</sup>)) (LogisticExp)</strong> described in &quot;<a href="https://peteroupc.github.io/bernoulli.html"><strong>Bernoulli Factory Algorithms</strong></a>&quot;, where <em>z</em> is the real-valued &lambda; parameter.</p></li>
</ul>

<p><a id=Correctness_Testing></a></p>

<h2>Correctness Testing</h2>

<p>&nbsp;</p>

<p><a id=Beta_Sampler></a></p>

<h3>Beta Sampler</h3>

<p>To test the correctness of the beta sampler presented in this document, the Kolmogorov&ndash;Smirnov test was applied with various values of <code>alpha</code> and <code>beta</code> and the default precision of 53, using SciPy&#39;s <code>kstest</code> method.  The code for the test is very simple: <code>kst = scipy.stats.kstest(ksample, lambda x: scipy.stats.beta.cdf(x, alpha, beta))</code>, where <code>ksample</code> is a sample of random numbers generated using the sampler above.  Note that SciPy uses a two-sided Kolmogorov&ndash;Smirnov test by default.</p>

<p>See the results of the <a href="https://peteroupc.github.io/betadistresults.html"><strong>correctness testing</strong></a>.   For each pair of parameters, five samples with 50,000 numbers per sample were taken, and results show the lowest and highest Kolmogorov&ndash;Smirnov statistics and p-values achieved for the five samples.  Note that a p-value extremely close to 0 or 1 strongly indicates that the samples do not come from the corresponding beta distribution.</p>

<p><a id=ExpRandFill></a></p>

<h3>ExpRandFill</h3>

<p>To test the correctness of the <code>exprandfill</code> method (which implements the <strong>ExpRandFill</strong> algorithm), the Kolmogorov&ndash;Smirnov test was applied with various values of &lambda; and the default precision of 53, using SciPy&#39;s <code>kstest</code> method.  The code for the test is very simple: <code>kst = scipy.stats.kstest(ksample, lambda x: scipy.stats.expon.cdf(x, scale=1/lamda))</code>, where <code>ksample</code> is a sample of random numbers generated using the <code>exprand</code> method above.  Note that SciPy uses a two-sided Kolmogorov&ndash;Smirnov test by default.</p>

<p>The table below shows the results of the correctness testing. For each parameter, five samples with 50,000 numbers per sample were taken, and results show the lowest and highest Kolmogorov&ndash;Smirnov statistics and p-values achieved for the five samples.  Note that a p-value extremely close to 0 or 1 strongly indicates that the samples do not come from the corresponding exponential distribution.</p>

<table><thead>
<tr>
<th>&lambda;</th>
<th>Statistic</th>
<th><em>p</em>-value</th>
</tr>
</thead><tbody>
<tr>
<td>1/10</td>
<td>0.00233-0.00435</td>
<td>0.29954-0.94867</td>
</tr>
<tr>
<td>1/4</td>
<td>0.00254-0.00738</td>
<td>0.00864-0.90282</td>
</tr>
<tr>
<td>1/2</td>
<td>0.00195-0.00521</td>
<td>0.13238-0.99139</td>
</tr>
<tr>
<td>2/3</td>
<td>0.00295-0.00457</td>
<td>0.24659-0.77715</td>
</tr>
<tr>
<td>3/4</td>
<td>0.00190-0.00636</td>
<td>0.03514-0.99381</td>
</tr>
<tr>
<td>9/10</td>
<td>0.00226-0.00474</td>
<td>0.21032-0.96029</td>
</tr>
<tr>
<td>1</td>
<td>0.00267-0.00601</td>
<td>0.05389-0.86676</td>
</tr>
<tr>
<td>2</td>
<td>0.00293-0.00684</td>
<td>0.01870-0.78310</td>
</tr>
<tr>
<td>3</td>
<td>0.00284-0.00675</td>
<td>0.02091-0.81589</td>
</tr>
<tr>
<td>5</td>
<td>0.00256-0.00546</td>
<td>0.10130-0.89935</td>
</tr>
<tr>
<td>10</td>
<td>0.00279-0.00528</td>
<td>0.12358-0.82974</td>
</tr>
</tbody></table>

<p><a id=ExpRandLess></a></p>

<h3>ExpRandLess</h3>

<p>To test the correctness of <code>exprandless</code>, a two-independent-sample T-test was applied to scores involving e-rands and scores involving the Python <code>random.expovariate</code> method.  Specifically, the score is calculated as the number of times one exponential number compares as less than another; for the same &lambda; this event should ideally be as likely as the event that it compares as greater.  The Python code that follows the table calculates this score for e-rands and <code>expovariate</code>.   Even here, the code for the test is very simple: <code>kst = scipy.stats.ttest_ind(exppyscores, exprandscores)</code>, where <code>exppyscores</code> and <code>exprandscores</code> are each lists of 20 results from <code>exppyscore</code> or <code>exprandscore</code>, respectively, and the results contained in <code>exppyscores</code> and <code>exprandscores</code> were generated independently of each other.</p>

<p>The table below shows the results of the correctness testing. For each pair of parameters, results show the lowest and highest T-test statistics and p-values achieved for the 20 results.  Note that a p-value extremely close to 0 or 1 strongly indicates that exponential random numbers are not compared as less or greater with the expected probability.</p>

<table><thead>
<tr>
<th>Left &lambda;</th>
<th>Right &lambda;</th>
<th>Statistic</th>
<th><em>p</em>-value</th>
</tr>
</thead><tbody>
<tr>
<td>1/10</td>
<td>1/10</td>
<td>-1.21015 &ndash; 0.93682</td>
<td>0.23369 &ndash; 0.75610</td>
</tr>
<tr>
<td>1/10</td>
<td>1/2</td>
<td>-1.25248 &ndash; 3.56291</td>
<td>0.00101 &ndash; 0.39963</td>
</tr>
<tr>
<td>1/10</td>
<td>1</td>
<td>-0.76586 &ndash; 1.07628</td>
<td>0.28859 &ndash; 0.94709</td>
</tr>
<tr>
<td>1/10</td>
<td>2</td>
<td>-1.80624 &ndash; 1.58347</td>
<td>0.07881 &ndash; 0.90802</td>
</tr>
<tr>
<td>1/10</td>
<td>5</td>
<td>-0.16197 &ndash; 1.78700</td>
<td>0.08192 &ndash; 0.87219</td>
</tr>
<tr>
<td>1/2</td>
<td>1/10</td>
<td>-1.46973 &ndash; 1.40308</td>
<td>0.14987 &ndash; 0.74549</td>
</tr>
<tr>
<td>1/2</td>
<td>1/2</td>
<td>-0.79555 &ndash; 1.21538</td>
<td>0.23172 &ndash; 0.93613</td>
</tr>
<tr>
<td>1/2</td>
<td>1</td>
<td>-0.90496 &ndash; 0.11113</td>
<td>0.37119 &ndash; 0.91210</td>
</tr>
<tr>
<td>1/2</td>
<td>2</td>
<td>-1.32157 &ndash; -0.07066</td>
<td>0.19421 &ndash; 0.94404</td>
</tr>
<tr>
<td>1/2</td>
<td>5</td>
<td>-0.55135 &ndash; 1.85604</td>
<td>0.07122 &ndash; 0.76994</td>
</tr>
<tr>
<td>1</td>
<td>1/10</td>
<td>-1.27023 &ndash; 0.73501</td>
<td>0.21173 &ndash; 0.87314</td>
</tr>
<tr>
<td>1</td>
<td>1/2</td>
<td>-2.33246 &ndash; 0.66827</td>
<td>0.02507 &ndash; 0.58741</td>
</tr>
<tr>
<td>1</td>
<td>1</td>
<td>-1.24446 &ndash; 0.84555</td>
<td>0.22095 &ndash; 0.90587</td>
</tr>
<tr>
<td>1</td>
<td>2</td>
<td>-1.13643 &ndash; 0.84148</td>
<td>0.26289 &ndash; 0.95717</td>
</tr>
<tr>
<td>1</td>
<td>5</td>
<td>-0.70037 &ndash; 1.46778</td>
<td>0.15039 &ndash; 0.86996</td>
</tr>
<tr>
<td>2</td>
<td>1/10</td>
<td>-0.77675 &ndash; 1.15350</td>
<td>0.25591 &ndash; 0.97870</td>
</tr>
<tr>
<td>2</td>
<td>1/2</td>
<td>-0.23122 &ndash; 1.20764</td>
<td>0.23465 &ndash; 0.91855</td>
</tr>
<tr>
<td>2</td>
<td>1</td>
<td>-0.92273 &ndash; -0.05904</td>
<td>0.36197 &ndash; 0.95323</td>
</tr>
<tr>
<td>2</td>
<td>2</td>
<td>-1.88150 &ndash; 0.64096</td>
<td>0.06758 &ndash; 0.73056</td>
</tr>
<tr>
<td>2</td>
<td>5</td>
<td>-0.08315 &ndash; 1.01951</td>
<td>0.31441 &ndash; 0.93417</td>
</tr>
<tr>
<td>5</td>
<td>1/10</td>
<td>-0.60921 &ndash; 1.54606</td>
<td>0.13038 &ndash; 0.91563</td>
</tr>
<tr>
<td>5</td>
<td>1/2</td>
<td>-1.30038 &ndash; 1.43602</td>
<td>0.15918 &ndash; 0.86349</td>
</tr>
<tr>
<td>5</td>
<td>1</td>
<td>-1.22803 &ndash; 1.35380</td>
<td>0.18380 &ndash; 0.64158</td>
</tr>
<tr>
<td>5</td>
<td>2</td>
<td>-1.83124 &ndash; 1.40222</td>
<td>0.07491 &ndash; 0.66075</td>
</tr>
<tr>
<td>5</td>
<td>5</td>
<td>-0.97110 &ndash; 2.00904</td>
<td>0.05168 &ndash; 0.74398</td>
</tr>
</tbody></table>

<pre>def exppyscore(ln,ld,ln2,ld2):
        return sum(1 if random.expovariate(ln*1.0/ld)&lt;random.expovariate(ln2*1.0/ld2) \
              else 0 for i in range(1000))

def exprandscore(ln,ld,ln2,ld2):
        return sum(1 if exprandless(exprandnew(ln,ld), exprandnew(ln2,ld2)) \
              else 0 for i in range(1000))
</pre>

<p><a id=Accurate_Simulation_of_Continuous_Distributions_Supported_on_0_to_1></a></p>

<h2>Accurate Simulation of Continuous Distributions Supported on 0 to 1</h2>

<p>The beta sampler in this document shows one case of a general approach to simulating a wide class of continuous distributions supported on [0, 1], thanks to Bernoulli factories.  This general approach can sample a number that follows one of these distributions, using the algorithm below.  The algorithm allows any arbitrary base (or radix) <em>b</em> (such as 2 for binary).</p>

<ol>
<li>Create an uniform PSRN with a positive sign, an integer part of 0, and an empty fractional part.  Create a <strong>SampleGeometricBag</strong> Bernoulli factory that uses that PSRN.</li>
<li><p>As the PSRN builds up a uniform random number, accept the PSRN with a probability that can be represented by a Bernoulli factory algorithm (that takes the <strong>SampleGeometricBag</strong> factory from step 1 as part of its input), or reject it otherwise. (A number of these algorithms can be found in &quot;<a href="https://peteroupc.github.io/bernoulli.html"><strong>Bernoulli Factory Algorithms</strong></a>&quot;.)  Let <em>f</em>(<em>U</em>) be the probability function modeled by this Bernoulli factory, where <em>U</em> is the uniform random number built up by the PSRN. <em>f</em> is a multiple of the PDF for the underlying continuous distribution (as a result, this algorithm can be used even if the distribution&#39;s PDF is only known up to a normalization constant).  As shown by Keane and O&#39;Brien <sup><a href="#Note6"><strong>(6)</strong></a></sup>, however, this step works if and only if <em>f</em>(&lambda;), in a given interval in [0, 1]&mdash;</p>

<ul>
<li>is continuous everywhere,</li>
<li>does not go to 0 or 1 exponentially fast, and</li>
<li>either returns a constant value in [0, 1] everywhere, or returns a value in [0, 1] at each of the points 0 and 1 and a value in (0, 1) at each other point,</li>
</ul>

<p>and they give the example of 2 * &lambda; as a probability function that cannot be represented by a Bernoulli factory.  Notice that the probability can be a constant, including an irrational number; see &quot;<a href="https://peteroupc.github.io/bernoulli.html#Algorithms_for_Irrational_Constants"><strong>Algorithms for Irrational Constants</strong></a>&quot; for ways to simulate constant probabilities.</p></li>
<li>If the PSRN is accepted, either return the PSRN as is or fill the unsampled digits of the PSRN&#39;s fractional part with uniform random digits as necessary to give the number an <em>n</em>-digit fractional part (similarly to <strong>FillGeometricBag</strong> above), where <em>n</em> is a precision parameter, then return the resulting number.</li>
</ol>

<p>However, the speed of this algorithm depends crucially on the mode (highest point) of <em>f</em> in [0, 1].  As that mode approaches 0, the average rejection rate increases.  Effectively, this step generates a point uniformly at random in a 1&times;1 area in space.  If that mode is close to 0, <em>f</em> will cover only a tiny portion of this area, so that the chance is high that the generated point will fall outside the area of <em>f</em> and have to be rejected.</p>

<p>The beta distribution&#39;s probability function at (1) fits the requirements of Keane and O&#39;Brien (for <code>alpha</code> and <code>beta</code> both greater than 1), thus it can be simulated by Bernoulli factories and is covered by this general algorithm.</p>

<p>This algorithm can be modified to produce random numbers in the interval [<em>m</em>, <em>m</em> + <em>b</em><sup><em>i</em></sup>] (where <em>b</em> is the base, or radix, and <em>i</em> and <em>m</em> are integers), rather than [0, 1], as follows:</p>

<ol>
<li>Apply the algorithm above, except a modified probability function <em>f&prime;</em>(<em>x</em>) = <em>f</em>(<em>x</em> * <em>b</em><sup><em>i</em></sup> + <em>m</em>) is used rather than <em>f</em>, where <em>x</em> is the number in [0, 1] that is built up by the PSRN.</li>
<li>Multiply the resulting random number or PSRN by <em>b</em><sup><em>i</em></sup>, then add <em>m</em> (this step is relatively trivial given that the PSRN&#39;s fractional part stores base-b digits).</li>
<li>If the random number (rather than the PSRN that holds it) will be returned, and the number&#39;s fractional part now has fewer than <em>n</em> digits due to step 2, re-fill the number as necessary to give the fractional part <em>n</em> digits.</li>
</ol>

<p>Note that here, the probability function <em>f&prime;</em> must meet the requirements of Keane and O&#39;Brien.  (For example, take the probability function <code>sqrt((x - 4) / 2)</code>, which isn&#39;t a Bernoulli factory function.  If we now seek to sample from the interval [4, 4+2<sup>1</sup>] = [4, 6], the <em>f</em> used in step 2 is now <code>sqrt(x)</code>, which <em>is</em> a Bernoulli factory function so that we can apply this algorithm.)</p>

<p>On the other hand, modifying this algorithm to produce random numbers in any other interval is non-trivial, since it often requires relating digit probabilities to some kind of formula (see &quot;About Partially-Sampled Random Numbers&quot;, above).</p>

<p><a id=An_Example_The_Continuous_Bernoulli_Distribution></a></p>

<h3>An Example: The Continuous Bernoulli Distribution</h3>

<p>The continuous Bernoulli distribution (Loaiza-Ganem and Cunningham 2019)<sup><a href="#Note19"><strong>(19)</strong></a></sup> was designed to considerably improve performance of variational autoencoders (a machine learning model) in modeling continuous data that takes values in the interval [0, 1], including &quot;almost-binary&quot; image data.</p>

<p>The continous Bernoulli distribution takes one parameter <code>lamda</code> (a number in [0, 1]), and takes on values in the interval [0, 1] with a probability proportional to&mdash;</p>

<pre>pow(lamda, x) * pow(1 - lamda, 1 - x).
</pre>

<p>Again, this function meets the requirements stated by Keane and O&#39;Brien, so it can be simulated via Bernoulli factories.  Thus, this distribution can be simulated in Python as described below.</p>

<p>The algorithm for sampling the continuous Bernoulli distribution follows.  It uses an input coin that returns 1 with probability <code>lamda</code>.</p>

<ol>
<li>Create a positive-sign zero-integer-part uniform PSRN.</li>
<li>Create a <strong>complementary lambda Bernoulli factory</strong> that returns 1 minus the result of the input coin.</li>
<li>Remove all digits from the uniform PSRN&#39;s fractional part.  This will result in an &quot;empty&quot; uniform(0,1) random number, <em>U</em>, for the following steps, which will accept <em>U</em> with probability <code>lamda</code><sup><em>U</em></sup>*(1&minus;<code>lamda</code>)<sup>1&minus;<em>U</em></sup>) (the proportional probability for the beta distribution), as <em>U</em> is built up.</li>
<li>Call the <strong>algorithm for &lambda;<sup>&mu;</sup></strong> described in &quot;<a href="https://peteroupc.github.io/bernoulli.html"><strong>Bernoulli Factory Algorithms</strong></a>&quot;, using the input coin as the &lambda;-coin, and <strong>SampleGeometricBag</strong> as the &mu;-coin (which will return 1 with probability <code>lamda</code><sup><em>U</em></sup>).  If the result is 0, go to step 3.</li>
<li>Call the <strong>algorithm for &lambda;<sup>&mu;</sup></strong> using the <strong>complementary lambda Bernoulli factory</strong> as the &lambda;-coin and <strong>SampleGeometricBagComplement</strong> algorithm as the &mu;-coin (which will return 1 with probability (1-<code>lamda</code>)<sup>1&minus;<em>U</em></sup>).  If the result is 0, go to step 3. (Note that steps 4 and 5 don&#39;t depend on each other and can be done in either order without affecting correctness.)</li>
<li><em>U</em> was accepted, so return the result of <strong>FillGeometricBag</strong>.</li>
</ol>

<p>The Python code that samples the continuous Bernoulli distribution follows.</p>

<pre>def _twofacpower(b, fbase, fexponent):
    &quot;&quot;&quot; Bernoulli factory B(p, q) =&gt; B(p^q).
           - fbase, fexponent: Functions that return 1 if heads and 0 if tails.
             The first is the base, the second is the exponent.
             &quot;&quot;&quot;
    i = 1
    while True:
        if fbase() == 1:
            return 1
        if fexponent() == 1 and \
            b.zero_or_one(1, i) == 1:
            return 0
        i = i + 1

def contbernoullidist(b, lamda, precision=53):
    # Continuous Bernoulli distribution
    bag=[]
    lamda=Fraction(lamda)
    gb=lambda: b.geometric_bag(bag)
    # Complement of &quot;geometric bag&quot;
    gbcomp=lambda: b.geometric_bag(bag)^1
    fcoin=b.coin(lamda)
    lamdab=lambda: fcoin()
    # Complement of &quot;lambda coin&quot;
    lamdabcomp=lambda: fcoin()^1
    acc=0
    while True:
       # Create a uniform random number (U) bit-by-bit, and
       # accept it with probability lamda^U*(1-lamda)^(1-U), which
       # is the unnormalized PDF of the beta distribution
       bag.clear()
       # Produce 1 with probability lamda^U
       r=_twofacpower(b, lamdab, gb)
       # Produce 1 with probability (1-lamda)^(1-U)
       if r==1: r=_twofacpower(b, lamdabcomp, gbcomp)
       if r == 1:
             # Accepted, so fill up the &quot;bag&quot; and return the
             # uniform number
             ret=_fill_geometric_bag(b, bag, precision)
             return ret
       acc+=1
</pre>

<p><a id=Complexity></a></p>

<h2>Complexity</h2>

<p>The <em>bit complexity</em> of an algorithm that generates random numbers is measured as the number of random bits that algorithm uses on average.</p>

<p><a id=General_Principles></a></p>

<h3>General Principles</h3>

<p>Existing work shows how to calculate the bit complexity for any distribution of random numbers:</p>

<ul>
<li>For a 1-dimensional continuous distribution, the bit complexity is bounded from below by <code>DE + prec - 1</code> random bits, where <code>DE</code> is the differential entropy for the distribution and <em>prec</em> is the number of bits in the random number&#39;s fractional part (Devroye and Gravel 2015)<sup><a href="#Note3"><strong>(3)</strong></a></sup>.</li>
<li>For a discrete distribution (a distribution of random integers with separate probabilities of occurring), the bit complexity is bounded from below by the binary entropies of all the probabilities involved, summed together (Knuth and Yao 1976)<sup><a href="#Note20"><strong>(20)</strong></a></sup>.  (For a given probability <em>p</em>, the binary entropy is <code>p*log2(1/p)</code>.)  An optimal algorithm will come within 2 bits of this lower bound on average.</li>
</ul>

<p>For example, in the case of the exponential distribution, <code>DE</code> is log2(exp(1)/&lambda;), so the minimum bit complexity for this distribution is log2(exp(1)/&lambda;) + <em>prec</em> &minus; 1, so that if <em>prec</em> = 20, this minimum is about 20.443 bits when &lambda; = 1, decreases when &lambda; goes up, and increases when &lambda; goes down.  In the case of any other continuous distribution, <code>DE</code> is the integral of <code>f(x) * log2(1/f(x))</code> over all valid values <code>x</code>, where <code>f</code> is the distribution&#39;s PDF.</p>

<p>Although existing work shows lower bounds on the number of random bits an algorithm will need on average, most algorithms will generally not achieve these lower bounds in practice.</p>

<p>In general, if an algorithm calls other algorithms that generate random numbers, the total expected bit complexity is&mdash;</p>

<ul>
<li>the expected number of calls to each of those other algorithms, times</li>
<li>the bit complexity for each such call.</li>
</ul>

<p><a id=Complexity_of_Specific_Algorithms></a></p>

<h3>Complexity of Specific Algorithms</h3>

<p>The beta and exponential samplers given here will generally use many more bits on average than the lower bounds on bit complexity, especially since they generate a PSRN one digit at a time.</p>

<p>The <code>zero_or_one</code> method generally uses 2 random bits on average, due to its nature as a Bernoulli trial involving random bits, see also (Lumbroso 2013, Appendix B)<sup><a href="#Note21"><strong>(21)</strong></a></sup>.  However, it uses no random bits if both its parameters are the same.</p>

<p>For <strong>SampleGeometricBag</strong> with base 2, the bit complexity has two components.</p>

<ul>
<li>One component comes from sampling a geometric (1/2) random number, as follows:

<ul>
<li>Optimal lower bound: Since the binary entropy of the random number is 2, the optimal lower bound is 2 bits.</li>
<li>Optimal upper bound: 4 bits.</li>
</ul></li>
<li>The other component comes from filling the partially-sampled random number&#39;s fractional part with random bits.  The complexity here depends on the number of times <strong>SampleGeometricBag</strong> is called for the same PSRN, call it <code>n</code>.  Then the expected number of bits is the expected number of bit positions filled this way after <code>n</code> calls.</li>
</ul>

<p><strong>SampleGeometricBagComplement</strong> has the same bit complexity as <strong>SampleGeometricBag</strong>.</p>

<p><strong>FillGeometricBag</strong>&#39;s bit complexity is rather easy to find.  For base 2, it uses only one bit to sample each unfilled digit at positions less than <code>p</code>. (For bases other than 2, sampling <em>each</em> digit this way might not be optimal, since the digits are generated one at a time and random bits are not recycled over several digits.)  As a result, for an algorithm that uses both <strong>SampleGeometricBag</strong> and <strong>FillGeometricBag</strong> with <code>p</code> bits, these two contribute, on average, anywhere from <code>p + g * 2</code> to <code>p + g * 4</code> bits to the complexity, where <code>g</code> is the number of calls to <strong>SampleGeometricBag</strong>. (This complexity could be increased by 1 bit if <strong>FillGeometricBag</strong> is implemented with a rounding mechanism other than simple truncation.)</p>

<p>The complexity of the <strong>algorithm for exp(&minus;<em>x</em>/<em>y</em>)</strong> (which outputs 1 with probability exp(&minus;<em>x</em>/<em>y</em>)) was discussed in some detail by (Canonne et al. 2020)<sup><a href="#Note22"><strong>(22)</strong></a></sup>, but not in terms of its bit complexity.  The special case of &gamma; =<em>x</em>/<em>y</em> = 0 requires no bits.  If &gamma; is an integer greater than 1, then the bit complexity is the same as that of sampling a random number <em>G</em>, where <em>G</em> is &gamma; or the number of successes before the first failure, whichever is less, and where a success has probility exp(&minus;1).</p>

<ul>
<li>Optimal lower bound: Has a complicated formula for general &gamma;, but approaches <code>log2(exp(1)-(exp(1)+1)*ln(exp(1)-1))</code> = 2.579730853... bits with increasing &gamma;.</li>
<li>Optimal upper bound: Optimal lower bound plus 2.</li>
<li>The actual implementation&#39;s average bit complexity is generally&mdash;

<ul>
<li>the expected number of calls to the <strong>algorithm for exp(&minus;<em>x</em>/<em>y</em>)</strong> (with &gamma; = 1), which is the expected value of <em>G</em> as described above, times</li>
<li>the bit complexity for each such call.</li>
</ul></li>
</ul>

<p>If &gamma; is 1 or less, the optimal bit complexity is determined as the complexity of sampling a random integer <em>k</em> with probability function&mdash;</p>

<ul>
<li>P(<em>k</em>) = &gamma;<sup><em>k</em></sup>/<em>k</em>! &minus; &gamma;<sup><em>k</em> + 1</sup>/(<em>k</em> + 1)!,</li>
</ul>

<p>and the optimal lower bound is found by taking the binary entropy of each probability (<code>P(k)/log2(1/P(k))</code>) and summing them all.</p>

<ul>
<li>Optimal lower bound: Again, this has a complicated formula (see the appendix for SymPy code), but it appears to be highest at about 1.85 bits, which is reached when &gamma; is about 0.848.</li>
<li>Optimal upper bound: Optimal lower bound plus 2.</li>
<li>The actual implementation&#39;s average bit complexity is generally&mdash;

<ul>
<li>the expected number of calls to <code>zero_or_one</code>, which was determined to be exp(&gamma;) in (Canonne et al. 2020)<sup><a href="#Note22"><strong>(22)</strong></a></sup>, times</li>
<li>the bit complexity for each such call (which is generally 2, but is lower in the case of &gamma; = 1, which involves <code>zero_or_one(1, 1)</code> that uses no random bits).</li>
</ul></li>
</ul>

<p>If &gamma; is a non-integer greater than 1, the bit complexity is the sum of the bit complexities for its integer part and for its fractional part.</p>

<p><a id=Application_to_Weighted_Reservoir_Sampling></a></p>

<h2>Application to Weighted Reservoir Sampling</h2>

<p><a href="https://peteroupc.github.io/randomfunc.html#Weighted_Choice_Without_Replacement_List_of_Unknown_Size"><strong>Weighted reservoir sampling</strong></a> (choosing an item at random from a list of unknown size) is often implemented by&mdash;</p>

<ul>
<li>assigning each item a <em>weight</em> (an integer 0 or greater) as it&#39;s encountered, call it <em>w</em>,</li>
<li>giving each item an exponential random number with &lambda; = <em>w</em>, call it a key, and</li>
<li>choosing the item with the smallest key</li>
</ul>

<p>(see also (Efraimidis 2015)<sup><a href="#Note23"><strong>(23)</strong></a></sup>). However, using fully-sampled exponential random numbers as keys (such as the naïve idiom <code>-ln(1-RNDU01())/w</code> in common floating-point arithmetic) can lead to inexact sampling, since the keys have a limited precision, it&#39;s possible for multiple items to have the same random key (which can make sampling those items depend on their order rather than on randomness), and the maximum weight is unknown.  Partially-sampled e-rands, as given in this document, eliminate the problem of inexact sampling.  This is notably because the <code>exprandless</code> method returns one of only two answers&mdash;either &quot;less&quot; or &quot;greater&quot;&mdash;and samples from both e-rands as necessary so that they will differ from each other by the end of the operation.  (This is not a problem because randomly generated real numbers are expected to differ from each other almost surely.) Another reason is that partially-sampled e-rands have potentially arbitrary precision.</p>

<p><a id=Open_Questions></a></p>

<h2>Open Questions</h2>

<p>There are some open questions on PSRNs:</p>

<ol>
<li>Are there constructions for partially-sampled normal random numbers with a standard deviation other than 1?</li>
<li>Are there constructions for PSRNs other than for cases given earlier in this document?</li>
<li>Doing an arithmetic operation between two PSRNs is akin to doing an interval operation between those PSRNs, since a PSRN is ultimately a random number that lies in an interval.  However, as explained in &quot;<a href="#Arithmetic_with_PSRNs"><strong>Arithmetic with PSRNs</strong></a>&quot;, the result of the operation is an interval that bounds a random number that is <em>not</em> always uniformly distributed in that interval.  For example, in the case of addition this distribution is triangular with a peak in the middle, and in the case of multiplication this distribution resembles a trapezoid.  What are the exact distributions of this kind for other interval arithmetic operations, such as division?</li>
</ol>

<p><a id=Acknowledgments></a></p>

<h2>Acknowledgments</h2>

<p>I acknowledge Claude Gravel who reviewed a previous version of this article.</p>

<p><a id=Other_Documents></a></p>

<h2>Other Documents</h2>

<p>The following are some additional articles I have written on the topic of random and pseudorandom number generation.  All of them are open-source.</p>

<ul>
<li><a href="https://peteroupc.github.io/random.html"><strong>Random Number Generator Recommendations for Applications</strong></a></li>
<li><a href="https://peteroupc.github.io/randomfunc.html"><strong>Randomization and Sampling Methods</strong></a></li>
<li><a href="https://peteroupc.github.io/randomnotes.html"><strong>More Random Number Sampling Methods</strong></a></li>
<li><a href="https://peteroupc.github.io/autodist.html"><strong>Code Generator for Discrete Distributions</strong></a></li>
<li><a href="https://peteroupc.github.io/randomcommon.html"><strong>The Most Common Topics Involving Randomization</strong></a></li>
<li><a href="https://peteroupc.github.io/bernoulli.html"><strong>Bernoulli Factory Algorithms</strong></a></li>
<li><a href="https://peteroupc.github.io/morealg.html"><strong>More Algorithms for Arbitrary-Precision Sampling</strong></a></li>
<li><a href="https://peteroupc.github.io/randomtest.html"><strong>Testing PRNGs for High-Quality Randomness</strong></a></li>
<li><a href="https://peteroupc.github.io/hqprng.html"><strong>Examples of High-Quality PRNGs</strong></a></li>
</ul>

<p><a id=Notes></a></p>

<h2>Notes</h2>

<ul>
<li><small><sup id=Note1>(1)</sup> Karney, C.F.F., &quot;<a href="https://arxiv.org/abs/1303.6257v2"><strong>Sampling exactly from the normal distribution</strong></a>&quot;, arXiv:1303.6257v2  [physics.comp-ph], 2014.</small></li>
<li><small><sup id=Note2>(2)</sup> Philippe Flajolet, Nasser Saheb. The complexity of generating an exponentially distributed variate. [Research Report] RR-0159, INRIA. 1982. inria-00076400.</small></li>
<li><small><sup id=Note3>(3)</sup> Devroye, L., Gravel, C., &quot;<a href="https://arxiv.org/abs/1502.02539v5"><strong>Sampling with arbitrary precision</strong></a>&quot;, arXiv:1502.02539v5 [cs.IT], 2015.</small></li>
<li><small><sup id=Note4>(4)</sup> Thomas, D.B. and Luk, W., 2008, September. Sampling from the exponential distribution using independent bernoulli variates. In 2008 International Conference on Field Programmable Logic and Applications (pp. 239-244). IEEE.</small></li>
<li><small><sup id=Note5>(5)</sup> A. Habibizad Navin, R. Olfatkhah and M. K. Mirnia, &quot;A data-oriented model of exponential random variable,&quot; 2010 2nd International Conference on Advanced Computer Control, Shenyang, 2010, pp. 603-607, doi: 10.1109/ICACC.2010.5487128.</small></li>
<li><small><sup id=Note6>(6)</sup> Keane,  M.  S.,  and  O&#39;Brien,  G.  L., &quot;A Bernoulli factory&quot;, <em>ACM Transactions on Modeling and Computer Simulation</em> 4(2), 1994.</small></li>
<li><small><sup id=Note7>(7)</sup> Flajolet, P., Pelletier, M., Soria, M., &quot;<a href="https://arxiv.org/abs/0906.5560v2"><strong>On Buffon machines and numbers</strong></a>&quot;, arXiv:0906.5560v2  [math.PR], 2010.</small></li>
<li><small><sup id=Note8>(8)</sup> Pedersen, K., &quot;<a href="https://arxiv.org/abs/1704.07949v3"><strong>Reconditioning your quantile function</strong></a>&quot;, arXiv:1704.07949v3 [stat.CO], 2018.</small></li>
<li><small><sup id=Note9>(9)</sup> von Neumann, J., &quot;Various techniques used in connection with random digits&quot;, 1951.</small></li>
<li><small><sup id=Note10>(10)</sup> Yusong Du, Baoying Fan, and Baodian Wei, &quot;<a href="https://arxiv.org/abs/2008.03855"><strong>An Improved Exact Sampling Algorithm for the Standard Normal Distribution</strong></a>&quot;, arXiv:2008.03855 [cs.DS], 2020.</small></li>
<li><small><sup id=Note11>(11)</sup> Oberhoff, Sebastian, &quot;<a href="https://dc.uwm.edu/etd/1888"><strong>Exact Sampling and Prefix Distributions</strong></a>&quot;, <em>Theses and Dissertations</em>, University of Wisconsin Milwaukee, 2018.</small></li>
<li><small><sup id=Note12>(12)</sup> S. Kakutani, &quot;On equivalence of infinite product measures&quot;, <em>Annals of Mathematics</em> 1948.</small></li>
<li><small><sup id=Note13>(13)</sup> Brassard, G., Devroye, L., Gravel, C., &quot;Remote Sampling with Applications to General Entanglement Simulation&quot;, <em>Entropy</em> 2019(21)(92), doi:10.3390/e21010092.</small></li>
<li><small><sup id=Note14>(14)</sup> A. Habibizad Navin, Fesharaki, M.N., Teshnelab, M. and Mirnia, M., 2007. &quot;Data oriented modeling of uniform random variable: Applied approach&quot;. <em>World Academy Science Engineering Technology</em>, 21, pp.382-385.</small></li>
<li><small><sup id=Note15>(15)</sup> Nezhad, R.F., Effatparvar, M., Rahimzadeh, M., 2013. &quot;Designing a Universal Data-Oriented Random Number Generator&quot;, <em>International Journal of Modern Education and Computer Science</em> 2013(2), pp. 19-24.</small></li>
<li><small><sup id=Note16>(16)</sup> Rohatgi, V.K., 1976. An Introduction to Probability Theory Mathematical Statistics.</small></li>
<li><small><sup id=Note17>(17)</sup> Devroye, L., <a href="http://luc.devroye.org/rnbookindex.html"><strong><em>Non-Uniform Random Variate Generation</em></strong></a>, 1986.</small></li>
<li><small><sup id=Note18>(18)</sup> In fact, thanks to the &quot;geometric bag&quot; technique of Flajolet et al. (2010), that fractional part can even be a uniform random number in [0, 1] whose contents are built up digit by digit.</small></li>
<li><small><sup id=Note19>(19)</sup> Loaiza-Ganem, G., Cunningham, J.P., &quot;<a href="https://arxiv.org/abs/1907.06845v5"><strong>The continuous Bernoulli: fixing a pervasive error in variational autoencoders</strong></a>&quot;, arXiv:1907.06845v5  [stat.ML], 2019.</small></li>
<li><small><sup id=Note20>(20)</sup> Knuth, Donald E. and Andrew Chi-Chih Yao. &quot;The complexity of nonuniform random number generation&quot;, in <em>Algorithms and Complexity: New Directions and Recent Results</em>, 1976.</small></li>
<li><small><sup id=Note21>(21)</sup> Lumbroso, J., &quot;<a href="https://arxiv.org/abs/1304.1916"><strong>Optimal Discrete Uniform Generation from Coin Flips, and Applications</strong></a>&quot;, arXiv:1304.1916 [cs.DS].</small></li>
<li><small><sup id=Note22>(22)</sup> Canonne, C., Kamath, G., Steinke, T., &quot;<a href="https://arxiv.org/abs/2004.00010v2"><strong>The Discrete Gaussian for Differential Privacy</strong></a>&quot;, arXiv:2004.00010v2 [cs.DS], 2020.</small></li>
<li><small><sup id=Note23>(23)</sup> Efraimidis, P. &quot;<a href="https://arxiv.org/abs/1012.0256v2"><strong>Weighted Random Sampling over Data Streams</strong></a>&quot;, arXiv:1012.0256v2 [cs.DS], 2015.</small></li>
<li><small><sup id=Note24>(24)</sup> Devroye, L., Gravel, C., &quot;<a href="https://arxiv.org/abs/1511.02273"><strong>The expected bit complexity of the von Neumann rejection algorithm</strong></a>&quot;, arXiv:1511.02273 [cs.IT], 2016.</small></li>
<li><small><sup id=Note25>(25)</sup> This means that every zero-volume (measure-zero) subset of the distribution&#39;s domain (such as a set of points) has zero probability.</small></li>
</ul>

<p><a id=Appendix></a></p>

<h2>Appendix</h2>

<p><a id=SymPy_Formula_for_the_algorithm_for_exp_minus__x___y></a></p>

<h3>SymPy Formula for the algorithm for exp(&minus;<em>x</em>/<em>y</em>)</h3>

<p>The following Python code uses SymPy to plot the bit complexity lower bound for the <strong>algorithm for exp(&minus;<em>x</em>/<em>y</em>)</strong> when &gamma; is 1 or less:</p>

<pre>def ent(p):
   return p*log(1/p,2)

def expminusformula():
   i=symbols(&#39;i&#39;,integer=True)
   x=symbols(&#39;x&#39;,real=True)
   # Approximation for k = [0, 6]; the result is little different
   # for k = [0, infinity]
   return summation(ent(x**i/factorial(i) - \
      x**(i+1)/factorial(i+1)), (i,0,6))

plot(expminusformula(), xlim=(0,1), ylim=(0,2))
</pre>

<p><a id=Additional_Examples_of_Arbitrary_Precision_Samplers></a></p>

<h3>Additional Examples of Arbitrary-Precision Samplers</h3>

<p>As an additional example of how PSRNs can be useful, here we reimplement an example from Devroye&#39;s book <em>Non-Uniform Random Variate Generation</em> (Devroye 1986, pp. 128&ndash;129)<sup><a href="#Note17"><strong>(17)</strong></a></sup></sup>.  The following algorithm generates a random number from a distribution with the following cumulative distribution function (CDF): <code>1 - cos(pi*x/2).</code>  The random number will be in the interval [0, 1].  What is notable about this algorithm is that it&#39;s an arbitrary-precision algorithm that avoids floating-point arithmetic.  Note that the result is the same as applying acos(<em>U</em>)*2/&pi;, where <em>U</em> is a uniform [0, 1] random number, as pointed out by Devroye.  The algorithm follows.</p>

<ol>
<li>Call the <strong>kthsmallest</strong> algorithm with <code>n = 2</code> and <code>k = 2</code>, but without filling it with digits at the last step.  Let <em>ret</em> be the result.</li>
<li>Set <em>m</em> to 1.</li>
<li>Call the <strong>kthsmallest</strong> algorithm with <code>n = 2</code> and <code>k = 2</code>, but without filling it with digits at the last step.  Let <em>u</em> be the result.</li>
<li>With probability 4/(4*<em>m</em>*<em>m</em> + 2*<em>m</em>), call the <strong>URandLess</strong> algorithm with parameters <em>u</em> and <em>ret</em> in that order, and if that call returns 1, call the <strong>algorithm for &pi; / 4</strong>, described in &quot;<a href="https://peteroupc.github.io/bernoulli.html"><strong>Bernoulli Factory Algorithms</strong></a>&quot;, twice, and if both of these calls return 1, add 1 to <em>m</em> and go to step 3.  (Here, we incorporate an erratum in the algorithm on page 129 of the book.)</li>
<li>If <em>m</em> is odd, fill <em>ret</em> with uniform random digits as necessary to give its fractional part the desired number of digits  (similarly to <strong>FillGeometricBag</strong>), and return <em>ret</em>.</li>
<li>If <em>m</em> is even, go to step 1.</li>
</ol>

<p>And here is Python code that implements this algorithm.  Note again that it uses floating-point arithmetic only at the end, to convert the result to a convenient form, and that it relies on methods from <em>randomgen.py</em> and <em>bernoulli.py</em>.</p>

<pre>def example_4_2_1(rg, bern, precision=53):
    while True:
       ret=rg.kthsmallest_urand(2,2)
       k=1
       while True:
          u=rg.kthsmallest_urand(2,2)
          kden=4*k*k+2*k # erratum incorporated
          if randomgen.urandless(rg,u, ret) and \
             rg.zero_or_one(4, kden)==1 and \
             bern.zero_or_one_pi_div_4()==1 and \
             bern.zero_or_one_pi_div_4()==1:
             k+=1
          elif (k&amp;1)==1:
             return randomgen.urandfill(rg,ret,precision)/(1&lt;&lt;precision)
          else: break
</pre>

<p>Another example is the following new algorithm that generates a random number that follows the logistic distribution.</p>

<ol>
<li>Set <em>k</em> to 0.</li>
<li>(Choose a 1-unit-wide piece of the logistic density.) Run the <strong>algorithm for (1+exp(<em>k</em>))/(1+exp(<em>k</em>+1))</strong> described in &quot;<a href="https://peteroupc.github.io/bernoulli.html"><strong>Bernoulli Factory Algorithms</strong></a>&quot;).  If the call returns 0, add 1 to <em>k</em> and repeat this step.  Otherwise, go to step 3.</li>
<li>(The rest of the algorithm samples from the chosen piece.) Generate a uniform(0, 1) random number, call it <em>f</em>.</li>
<li>(Steps 4 through 7 succeed with probability exp(&minus;(<em>f</em>+<em>k</em>))/(1+exp(&minus;(<em>f</em>+<em>k</em>)))<sup>2</sup>.) With probability 1/2, go to step 3.</li>
<li>Run the <strong>algorithm for exp(&minus;<em>k</em>/1)</strong> (described in &quot;Bernoulli Factory Algorithms&quot;), then <strong>sample from the number <em>f</em></strong> (e.g., call <strong>SampleGeometricBag</strong> on <em>f</em> if <em>f</em> is implemented as a uniform PSRN).  If any of these calls returns 0, go to step 4.</li>
<li>With probability 1/2, accept <em>f</em>.  If <em>f</em> is accepted this way,  fill <em>f</em> with uniform random digits as necessary to give its fractional part the desired number of digits (similarly to <strong>FillGeometricBag</strong>), and return (<em>f</em> + <em>k</em>) with probability 1/2, and &minus;(<em>f</em> + <em>k</em>) otherwise.</li>
<li>Run the <strong>algorithm for exp(&minus;<em>k</em>/1)</strong> and <strong>sample from the number <em>f</em></strong> (e.g., call <strong>SampleGeometricBag</strong> on <em>f</em> if <em>f</em> is implemented as a uniform PSRN).  If both calls return 1, go to step 3.  Otherwise, go to step 6.</li>
</ol>

<p><a id=Equivalence_of_SampleGeometricBag_Algorithms></a></p>

<h3>Equivalence of SampleGeometricBag Algorithms</h3>

<p>For the <strong>SampleGeometricBag</strong>, there are two versions: one for binary (base 2) and one for other bases.  Here is why these two versions are equivalent in the binary case.  Step 2 of the first algorithm samples a temporary random number <em>N</em>.  This can be implemented by generating unbiased random bits (that is, each bit is either 0 or 1, chosen with equal probability) until a zero is generated this way.  There are three cases relevant here.</p>

<ul>
<li>The generated bit is one, which will occur at a 50% chance. This means the bit position is skipped and the algorithm moves on to the next position.  In algorithm 3, this corresponds to moving to step 3 because <strong>a</strong>&#39;s fractional part is equal to <strong>b</strong>&#39;s, which likewise occurs at a 50% chance compared to the fractional parts being unequal (since <strong>a</strong> is fully built up in the course of the algorithm).</li>
<li>The generated bit is zero, and the algorithm samples (or retrieves) a zero bit at position <em>N</em>, which will occur at a 25% chance. In algorithm 3, this corresponds to returning 0 because <strong>a</strong>&#39;s fractional part is less than <strong>b</strong>&#39;s, which will occur with the same probability.</li>
<li>The generated bit is zero, and the algorithm samples (or retrieves) a one bit at position <em>N</em>, which will occur at a 25% chance. In algorithm 3, this corresponds to returning 1 because <strong>a</strong>&#39;s fractional part is greater than <strong>b</strong>&#39;s, which will occur with the same probability.</li>
</ul>

<p><a id=Oberhoff_s_Exact_Rejection_Sampling_Method></a></p>

<h3>Oberhoff&#39;s &quot;Exact Rejection Sampling&quot; Method</h3>

<p>The following describes an algorithm described by Oberhoff for sampling a continuous distribution supported on the interval [0, 1], as long as its probability function is continuous almost everywhere and bounded from above (Oberhoff 2018, section 3)<sup><a href="#Note11"><strong>(11)</strong></a></sup>, see also (Devroye and Gravel 2016)<sup><a href="#Note24"><strong>(24)</strong></a></sup>. (Note that if the probability function&#39;s domain is wider than [0, 1], then the function needs to be divided into one-unit-long pieces, one piece chosen at random with probability proportional to its area, and that piece shifted so that it lies in [0, 1] rather than its usual place; see Oberhoff pp. 11-12.)</p>

<ol>
<li>Set <em>pdfmax</em> to an upper bound of the probability function on the domain at [0, 1].  Let <em>base</em> be the base, or radix, of the digits in the return value (such as 2 for binary or 10 for decimal).</li>
<li>Set <em>prefix</em> to 0 and <em>prefixLength</em> to 0.</li>
<li>Set <em>y</em> to a uniform random number in the interval [0, <em>pdfmax</em>].</li>
<li>Let <em>pw</em> be <em>base</em><sup>&minus;<em>prefixLength</em></sup>.  Set <em>lower</em> and <em>upper</em> to a lower or upper bound, respectively, of the probability function&#39;s value on the domain at [<em>prefix</em> * <em>pw</em>, <em>prefix</em> * <em>pw</em> + <em>pw</em>].</li>
<li>If <em>y</em> turns out to be greater than <em>upper</em>, the prefix was rejected, so go to step 2.</li>
<li>If <em>y</em> turns out to be less than <em>lower</em>, the prefix was accepted.  Now do the following:

<ol>
<li>While <em>prefixLength</em> is less than the desired precision, set <em>prefix</em> to <em>prefix</em> * <em>base</em> + <em>r</em>, where <em>r</em> is a uniform random digit, then add 1 to <em>prefixLength</em>.</li>
<li>Return <em>prefix</em> * <em>base</em><sup>&minus;<em>prefixLength</em></sup>.  (If <em>prefixLength</em> is somehow greater than the desired precision, then the algorithm could choose to round the return value to a number whose fractional part has the desired number of digits, with a rounding mode of choice.)</li>
</ol></li>
<li>Set <em>prefix</em> to <em>prefix</em> * <em>base</em> + <em>r</em>, where <em>r</em> is a uniform random digit, then add 1 to <em>prefixLength</em>, then go to step 4.</li>
</ol>

<p>Because this algorithm requires evaluating the probability function and finding its maximum and minimum values at an interval (which often requires floating-point arithmetic and is often not trivial), this algorithm appears here in the appendix rather than in the main text.  Moreover, there is additional approximation error from generating <em>y</em> with a fixed number of digits, unless <em>y</em> is a uniform PSRN (see also &quot;<a href="#Application_to_Weighted_Reservoir_Sampling"><strong>Application to Weighted Reservoir Sampling</strong></a>&quot;).</p>

<p>Oberhoff also describes <em>prefix distributions</em> that sample a box that covers the probability function, with probability proportional to the box&#39;s area, but these distributions will have to support a fixed maximum prefix length and so will only approximate the underlying continuous distribution.</p>

<p><a id=Setting_Digits_by_Digit_Probabilities></a></p>

<h3>Setting Digits by Digit Probabilities</h3>

<p>In principle, a partially-sampled random number is possible by finding a sequence of digit probabilities and setting that number&#39;s digits according to those probabilities.  However, there seem to be limits on how practical this approach is.</p>

<p>The following is part of Kakutani&#39;s theorem (Kakutani 1948)<sup><a href="#Note12"><strong>(12)</strong></a></sup>: Let <em>a</em><sub><em>j</em></sub> be the <em>j</em><sup>th</sup> binary digit probability in a random number&#39;s binary expansion, where the random number is in [0, 1] and each digit is independently set.  Then the random number&#39;s distribution is <em>absolutely continuous</em><sup><a href="#Note25"><strong>(25)</strong></a></sup> if and only if the sum of squares of (<em>a</em><sub><em>j</em></sub> &minus; 1/2) converges.  In other words, the random number&#39;s bits become less and less biased as they move farther and farther from the binary point.</p>

<p>An absolutely continuous distribution can thus be built if we can find a sequence <em>a</em><sub><em>j</em></sub> that converges to 1/2.  Then a random number could be formed by setting each of its digits to 1 with probability equal to the corresponding <em>a</em><sub><em>j</em></sub>.  However, experiments show that the resulting distribution will have a discontinuous <em>PDF</em>, except if the sequence has the form&mdash;</p>

<ul>
<li><em>a</em><sub><em>j</em></sub> = <em>y</em><sup><em>w</em>/&beta;<sup><em>j</em></sup></sup>/(1 + <em>y</em><sup><em>w</em>/&beta;<sup><em>j</em></sup></sup>),</li>
</ul>

<p>where &beta; = 2, <em>y</em> &gt; 0, and <em>w</em> &gt; 0, and special cases include the uniform distribution (<em>y</em> = 1, <em>w</em> = 1), the truncated exponential(1) distribution (<em>y</em> = (1/exp(1)), <em>w</em> = 1; (Devroye and Gravel 2015)<sup><a href="#Note3"><strong>(3)</strong></a></sup>), and the more general exponential(&lambda;) distribution (<em>y</em> = (1/exp(1)), <em>w</em> = &lambda;).  Other sequences of the form <em>z</em>(<em>j</em>)/(1 + <em>z</em>(<em>j</em>)) will generally result in a discontinuous PDF even if <em>z</em>(<em>j</em>) converges to 1.</p>

<p>For reference, the following calculates the relative probability for <em>x</em> for a given sequence, where <em>x</em> is in [0, 1), and plotting this probability function (which is proportional to the PDF) will often show whether the function is discontinuous:</p>

<ul>
<li>Let <em>b</em><sub><em>j</em></sub> be the <em>j</em><sup>th</sup> base-&beta; digit after the point (e.g., <code>rem(floor(x*pow(beta, j)), beta)</code> where <code>beta</code> = &beta;).</li>
<li>Let <em>t</em>(<em>x</em>) = &Pi;<sub><em>j</em> = 1, 2, ...</sub> <em>b</em><sub><em>j</em></sub> * <em>a</em><sub><em>j</em></sub> + (1 &minus; <em>b</em><sub><em>j</em></sub>) * (1 &minus; <em>a</em><sub><em>j</em></sub>).</li>
<li>The relative probability for <em>x</em> is <em>t</em>(<em>x</em>) / (argmax<sub><em>z</em></sub> <em>t</em>(<em>z</em>)).</li>
</ul>

<p>It appears that the distribution&#39;s PDF will be continuous only if&mdash;</p>

<ul>
<li>the probabilities of the first half, interval (0, 1/2), are proportional to those of the second half, interval (1/2, 1), and</li>
<li>the probabilities of each quarter, eighth, etc. are proportional to those of every other quarter, eighth, etc.</li>
</ul>

<p>It may be that something similar applies for &beta; other than 2 (non-base-2 or non-binary cases) as it does to &beta; = 2 (the base-2 or binary case).</p>

<p><a id=License></a></p>

<h2>License</h2>

<p>Any copyright to this page is released to the Public Domain.  In case this is not possible, this page is also licensed under <a href="https://creativecommons.org/publicdomain/zero/1.0/"><strong>Creative Commons Zero</strong></a>.</p>
</div><nav id="navigation"><ul>
<li><a href="/">Back to start site.</a>
<li><a href="https://github.com/peteroupc/peteroupc.github.io">This site's repository (source code)</a>
<li><a href="https://github.com/peteroupc/peteroupc.github.io/issues">Post an issue or comment</a></ul>
<p>
If you like this software, you should consider donating to me, Peter O., at the link below:</p>
<p class="printonly"><b>peteroupc.github.io</b></p>
<div class="noprint">
<a href="https://www.paypal.com/cgi-bin/webscr?cmd=_s-xclick&hosted_button_id=56E5T4FH7KD2S">
<img src="https://www.paypalobjects.com/en_US/i/btn/btn_donateCC_LG.gif"
name="submit" border="2" alt="PayPal - The safer, easier way to pay online!"></a>
<p>
<a href="//twitter.com/share">Share via Twitter</a>, <a href="//www.facebook.com/sharer/sharer.php" id="sharer">Share via Facebook</a>
</p>
</div>
</nav><script>
if("share" in navigator){
 document.getElementById("sharer").href="javascript:void(null)";
 document.getElementById("sharer").innerHTML="Share This Page";
 navigator.share({title:document.title,url:document.location.href}).then(
   function(){});
} else {
 document.getElementById("sharer").href="//www.facebook.com/sharer/sharer.php?u="+
    encodeURIComponent(document.location.href)
}
</script>
</body></html>
