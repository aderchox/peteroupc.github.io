<!DOCTYPE html><html xmlns:dc="http://purl.org/dc/terms/" itemscope itemtype="http://schema.org/Article"><head><meta http-equiv=Content-Type content="text/html; charset=utf-8"><title>Supplemental Notes for Bernoulli Factory Algorithms</title><meta name="citation_title" content="Supplemental Notes for Bernoulli Factory Algorithms"><meta name="citation_pdf_url" content="https://peteroupc.github.io/bernsupp.pdf"><meta name="citation_url" content="https://peteroupc.github.io/bernsupp.html"><meta name="citation_date" content="2021/02/25"><meta name="citation_online_date" content="2021/02/25"><meta name="og:title" content="Supplemental Notes for Bernoulli Factory Algorithms"><meta name="og:type" content="article"><meta name="og:url" content="https://peteroupc.github.io/bernsupp.html"><meta name="og:site_name" content="peteroupc.github.io"><meta name="twitter:title" content="Supplemental Notes for Bernoulli Factory Algorithms"><meta name="author" content="Peter Occil"/><meta name="viewport" content="width=device-width"><link rel=stylesheet type="text/css" href="/style.css"></head><body>  <div class="header">
<nav><p><a href="#navigation">Menu</a> - <a href="#top">Top</a> - <a href="/">Home</a></nav></div>
<div class="mainarea" id="top">
<h1>Supplemental Notes for Bernoulli Factory Algorithms</h1>

<p><a href="mailto:poccil14@gmail.com"><strong>Peter Occil</strong></a></p>

<p><a id=General_Factory_Functions></a></p>

<h2>General Factory Functions</h2>

<p>As a reminder, the <em>Bernoulli factory problem</em> is: Given a coin with unknown probability of heads of <em>&lambda;</em>, sample the probability <em>f</em>(<em>&lambda;</em>).</p>

<p>The algorithms for <a href="https://peteroupc.github.io/bernoulli.html#General_Factory_Functions"><strong>general factory functions</strong></a>, described in my main article on Bernoulli factory algorithms, work by building randomized upper and lower bounds for a function <em>f</em>(<em>&lambda;</em>), based on flips of the input coin.  Roughly speaking, the algorithms work as follows:</p>

<ol>
<li>Generate a uniform(0, 1) random number, <em>U</em>.</li>
<li>Flip the input coin, then build an upper and lower bound for <em>f</em>(<em>&lambda;</em>), based on the outcomes of the flips so far.</li>
<li>If <em>U</em> is less than or equal to the lower bound, return 1. If <em>U</em> is greater than the upper bound, return 0.  Otherwise, go to step 2.</li>
</ol>

<p>These randomized upper and lower bounds come from two sequences of polynomials: one approaches the function <em>f</em>(<em>&lambda;</em>) from above, the other from below, where <em>f</em> is a continuous function that maps the interval (0, 1) to (0, 1).  (These two sequences form a so-called <em>approximation scheme</em> for <em>f</em>.) One requirement for these algorithms to work correctly is called the <em>consistency requirement</em>:</p>

<p><em>The difference&mdash;</em></p>

<ul>
<li><em>between the degree-(n&minus;1) upper polynomial and the degree-n upper polynomial, and</em></li>
<li><em>between the degree-n lower polynomial and the degree-(n&minus;1) lower polynomial,</em></li>
</ul>

<p><em>must have non-negative coefficients, once the polynomials are elevated to degree n and rewritten in Bernstein form.</em></p>

<p>The consistency requirement ensures that the upper polynomials &quot;decrease&quot; and the lower polynomials &quot;increase&quot;.  Unfortunately, the reverse is not true in general; even if the upper polynomials &quot;decrease&quot; and the lower polynomials &quot;increase&quot; to <em>f</em>, this does not mean that the scheme will ensure consistency.  Examples of this fact are shown in the section &quot;<a href="#Schemes_That_Don_t_Work"><strong>Schemes That Don&#39;t Work</strong></a>&quot; later in this document.</p>

<p>In this document, <strong>fbelow</strong>(<em>n</em>, <em>k</em>) and <strong>fabove</strong>(<em>n</em>, <em>k</em>) mean the <em>k</em><sup>th</sup> coefficient for the lower or upper degree-<em>n</em> polynomial in Bernstein form, respectively, where <em>k</em> is an integer in the interval [0, <em>n</em>].</p>

<p><a id=Approximation_Schemes></a></p>

<h3>Approximation Schemes</h3>

<p>A <em>factory function</em> <em>f</em>(<em>&lambda;</em>) is a function for which the Bernoulli factory problem can be solved (see &quot;<a href="https://peteroupc.github.io/bernoulli.html#About_Bernoulli_Factories"><strong>About Bernoulli Factories</strong></a>&quot;). The following are approximation schemes for <em>f</em> if it belongs to one of certain classes of factory functions.  It would be helpful to plot the desired function <em>f</em> using a computer algebra system to see if it belongs to any of the classes of functions described below.</p>

<p><strong>Concave functions.</strong> If <em>f</em> is known to be <em>concave</em> in the interval [0, 1] (which roughly means that its rate of growth there never goes up), then <strong>fbelow</strong>(<em>n</em>, <em>k</em>) can equal <em>f</em>(<em>k</em>/<em>n</em>), thanks to Jensen&#39;s inequality.</p>

<p><strong>Convex functions.</strong> If <em>f</em> is known to be <em>convex</em> in the interval [0, 1] (which roughly means that its rate of growth there never goes down), then <strong>fabove</strong>(<em>n</em>, <em>k</em>) can equal <em>f</em>(<em>k</em>/<em>n</em>), thanks to Jensen&#39;s inequality.  One example is <em>f</em>(<em>&lambda;</em>) = exp(&minus;<em>&lambda;</em>/4).</p>

<p><strong><em>C</em><sup>2</sup> continuous functions.</strong> The following method, proved in the appendix, implements <strong>fabove</strong> and <strong>fbelow</strong> if <em>f</em>(<em>&lambda;</em>)&mdash;</p>

<ul>
<li>has continuous &quot;slope&quot; and &quot;slope-of-slope&quot; functions in the interval [0, 1] (in other words, <em>f</em> is <em>C</em><sup>2</sup> continuous or <em>twice differentiable</em> there), and</li>
<li>in the interval [0, 1]&mdash;

<ul>
<li>has a minimum of greater than 0 and a maximum of less than 1, or</li>
<li>is convex and has a minimum of greater than 0, or</li>
<li>is concave and has a maximum of less than 1.</li>
</ul></li>
</ul>

<p>Let <em>m</em> be an upper bound of the highest value of abs(<em>f&prime;&prime;</em>(<em>x</em>)) for any <em>x</em> in [0, 1], where <em>f&prime;&prime;</em> is the &quot;slope-of-slope&quot; function of <em>f</em>.  Then for all <em>n</em> that are powers of 2:</p>

<ul>
<li><strong>fbelow</strong>(<em>n</em>, <em>k</em>) = <em>f</em>(<em>k</em>/<em>n</em>) if <em>f</em> is concave; otherwise, min(<strong>fbelow</strong>(4,0), <strong>fbelow</strong>(4,1), ..., <strong>fbelow</strong>(4,4)) if <em>n</em> &lt; 4; otherwise,  <em>f</em>(<em>k</em>/<em>n</em>) &minus; <em>m</em>/(7*<em>n</em>).</li>
<li><strong>fabove</strong>(<em>n</em>, <em>k</em>) = <em>f</em>(<em>k</em>/<em>n</em>) if <em>f</em> is convex; otherwise, max(<strong>fabove</strong>(4,0), <strong>fabove</strong>(4,1), ..., <strong>fabove</strong>(4,4)) if <em>n</em> &lt; 4; otherwise, <em>f</em>(<em>k</em>/<em>n</em>) + <em>m</em>/(7*<em>n</em>).</li>
</ul>

<p>My <a href="https://github.com/peteroupc/peteroupc.github.io/blob/master/approxscheme.py"><strong>GitHub repository</strong></a> includes SymPy code for a method, <code>c2params</code>, to calculate the necessary values for <em>m</em> and the bounds of these polynomials, given <em>f</em>.</p>

<p><strong>Hölder and Lipschitz continuous functions.</strong> I have found a way to extend the results of Nacu and Peres (2005)<sup><a href="#Note1"><strong>(1)</strong></a></sup> to certain functions with a slope that tends to a vertical slope.  The following scheme, proved in the appendix, implements <strong>fabove</strong> and <strong>fbelow</strong> if <em>f</em>(<em>&lambda;</em>)&mdash;</p>

<ul>
<li>is <em>&alpha;</em>-<em>Hölder continuous</em> in [0, 1], meaning its vertical slopes there, if any, are no &quot;steeper&quot; than <em>m</em>*<em>&lambda;</em><sup><em>&alpha;</em></sup>, for some number <em>m</em> greater than 0 (the Hölder constant) and for some <em>&alpha;</em> in the interval (0, 1], and</li>
<li>in the interval [0, 1]&mdash;

<ul>
<li>has a minimum of greater than 0 and a maximum of less than 1, or</li>
<li>is convex and has a minimum of greater than 0, or</li>
<li>is concave and has a maximum of less than 1.</li>
</ul></li>
</ul>

<p>If <em>f</em> in [0, 1] has a defined slope at all but a countable number of points, and does not tend to a vertical slope anywhere, then <em>f</em> is <a href="https://en.wikipedia.org/wiki/Lipschitz_continuity"><strong><em>Lipschitz continuous</em></strong></a>, <em>&alpha;</em> is 1, and <em>m</em> is the highest absolute value of the function&#39;s &quot;slope&quot;.  Otherwise, finding <em>m</em> for a given <em>&alpha;</em> is non-trivial and it requires knowing where <em>f</em>&#39;s vertical slopes are, among other things.<sup><a href="#Note2"><strong>(2)</strong></a></sup>  But assuming <em>m</em> and <em>&alpha;</em> are known, then for all <em>n</em> that are powers of 2:</p>

<ul>
<li><em>&delta;</em>(<em>n</em>) = <em>m</em>*(2/7)<sup><em>&alpha;</em>/2</sup>/((2<sup><em>&alpha;</em>/2</sup>&minus;1)*<em>n</em><sup><em>&alpha;</em>/2</sup>).</li>
<li><strong>fbelow</strong>(<em>n</em>, <em>k</em>) = <em>f</em>(<em>k</em>/<em>n</em>) if <em>f</em> is concave; otherwise, min(<strong>fbelow</strong>(4,0), <strong>fbelow</strong>(4,1), ..., <strong>fbelow</strong>(4,4)) if <em>n</em> &lt; 4; otherwise, <em>f</em>(<em>k</em>/<em>n</em>) &minus; <em>&delta;</em>(<em>n</em>).</li>
<li><strong>fabove</strong>(<em>n</em>, <em>k</em>) = <em>f</em>(<em>k</em>/<em>n</em>) if <em>f</em> is convex; otherwise, max(<strong>fabove</strong>(4,0), <strong>fabove</strong>(4,1), ..., <strong>fabove</strong>(4,4)) if <em>n</em> &lt; 4; otherwise, <em>f</em>(<em>k</em>/<em>n</em>) + <em>&delta;</em>(<em>n</em>).</li>
</ul>

<p><strong>Specific functions.</strong> My <a href="https://github.com/peteroupc/peteroupc.github.io/blob/master/approxscheme.py"><strong>GitHub repository</strong></a> includes SymPy code for a method, <code>approxscheme2</code>, to build a polynomial approximation scheme for certain factory functions.</p>

<p><a id=Schemes_That_Don_t_Work></a></p>

<h3>Schemes That Don&#39;t Work</h3>

<p>In the academic literature (papers and books), there are many approximation schemes that involve polynomials that converge from above and below to a function.  Unfortunately, most of them cannot be used as is to simulate a function <em>f</em> in the Bernoulli Factory setting, because they don&#39;t ensure the consistency requirement described earlier.</p>

<p>The following are approximation schemes with counterexamples to consistency.</p>

<p><strong>First scheme.</strong> In this scheme (Powell 1981)<sup><a href="#Note3"><strong>(3)</strong></a></sup>, let <em>f</em> be a twice differentiable function (that is, a C<sup>2</sup> continuous function, or a function with continuous &quot;slope&quot; and &quot;slope-of-slope&quot; functions).  Then for all <em>n</em>&ge;1:</p>

<ul>
<li><strong>fabove</strong>(<em>n</em>, <em>k</em>) = <em>f</em>(<em>k</em>/<em>n</em>) + <em>M</em> / (8*<em>n</em>).</li>
<li><strong>fbelow</strong>(<em>n</em>, <em>k</em>) = <em>f</em>(<em>k</em>/<em>n</em>) &minus; <em>M</em> / (8*<em>n</em>).</li>
</ul>

<p>Where <em>M</em> is an upper bound of the maximum absolute value of <em>f</em>&#39;s slope-of-slope function (second derivative), and where <em>k</em> is an integer in the interval [0, <em>n</em>].</p>

<p>The counterexample involves the twice differentiable function <em>g</em>(<em>&lambda;</em>) = sin(<em>&pi;</em>*<em>&lambda;</em>)/4 + 1/2.</p>

<p>For <em>g</em>, the coefficients for&mdash;</p>

<ul>
<li>the degree-2 upper polynomial in Bernstein form (<strong>fabove</strong>(5, <em>k</em>)) are [0.6542..., 0.9042..., 0.6542...], and</li>
<li>the degree-4 upper polynomial in Bernstein form (<strong>fabove</strong>(6, <em>k</em>)) are [0.5771..., 0.7538..., 0.8271..., 0.7538..., 0.5771...].</li>
</ul>

<p>The degree-2 polynomial lies above the degree-4 polynomial everywhere in [0, 1].  However, to ensure consistency, the degree-2 polynomial, once elevated to degree 4 and rewritten in Bernstein form, must have coefficients that are greater than or equal to those of the degree-4 polynomial.</p>

<ul>
<li>Once elevated to degree 4, the degree-2 polynomial&#39;s coefficients are [0.6542..., 0.7792..., 0.8208..., 0.7792..., 0.6542...].</li>
</ul>

<p>As we can see, the elevated polynomial&#39;s coefficient 0.8208... is less than the corresponding coefficient 0.8271... for the degree-4 polynomial.</p>

<p><em>The rest of this section will note counterexamples involving other functions and schemes, without demonstrating them in detail.</em></p>

<p><strong>Second scheme.</strong> In this scheme, let <em>f</em> be a Lipschitz continuous function in [0, 1] (that is, a continuous function in [0, 1] that has a defined slope at all but a countable number of points, and does not tend to a vertical slope anywhere).  Then for all <em>n</em>&ge;2:</p>

<ul>
<li><strong>fabove</strong>(<em>n</em>, <em>k</em>) = <em>f</em>(<em>k</em>/<em>n</em>) + <em>L</em>*(5/4) / sqrt(<em>n</em>).</li>
<li><strong>fbelow</strong>(<em>n</em>, <em>k</em>) = <em>f</em>(<em>k</em>/<em>n</em>) &minus;  <em>L</em>*(5/4) / sqrt(<em>n</em>).</li>
</ul>

<p>Where L is the maximum absolute &quot;slope&quot;, also known as the Lipschitz constant, and (5/4) is the so-called Popoviciu constant, and where <em>k</em> is an integer in the interval [0, <em>n</em>] (Lorentz 1986)<sup><a href="#Note4"><strong>(4)</strong></a></sup>, (Popoviciu 1935)<sup><a href="#Note5"><strong>(5)</strong></a></sup>.</p>

<p>There are two counterexamples here; together they show that this scheme can fail to ensure consistency, even if the set of functions is restricted to &quot;smooth&quot; functions (not just Lipschitz continuous functions):</p>

<ol>
<li>The function <em>f</em>(<em>&lambda;</em>) = min(<em>&lambda;</em>, 1&minus;<em>&lambda;</em>)/2 is Lipschitz continuous with Lipschitz constant 1/2.  (In addition, <em>f</em> has a kink at 1/2, so that it&#39;s not differentiable, but this is not essential for the counterexample.)  The counterexample involves the degree-5 and degree-6 upper polynomials (<strong>fabove</strong>(5, <em>k</em>) and <strong>fabove</strong>(6, <em>k</em>)).</li>
<li>The function <em>f</em> = sin(4*<em>&pi;</em>*<em>&lambda;</em>)/4 + 1/2, a &quot;smooth&quot; function with Lipschitz constant <em>&pi;</em>.  The counterexample involves the degree-3 and degree-4 lower polynomials (<strong>fbelow</strong>(3, <em>k</em>) and <strong>fbelow</strong>(4, <em>k</em>)).</li>
</ol>

<p>It is yet to be seen whether a counterexample exists for this scheme when <em>n</em> is restricted to powers of 2.</p>

<p><strong>Third scheme.</strong> Same as the second scheme, but replacing (5/4) with the Sikkema constant, <em>S</em> = (4306+837*sqrt(6))/5832 (Lorentz 1986)<sup><a href="#Note4"><strong>(4)</strong></a></sup>, (Sikkema 1961)<sup><a href="#Note6"><strong>(6)</strong></a></sup>, which equals about 1.09.   In fact, the same counterexamples for the second scheme apply to this one, since this scheme merely multiplies the offset to bring the approximating polynomials closer to <em>f</em>.</p>

<p><strong>Fourth scheme.</strong>  In this scheme, which relates to a result from Kopotun et al. (2017)<sup><a href="#Note7"><strong>(7)</strong></a></sup>, let <em>f</em> be a nondecreasing and Lipschitz continuous function in [0, 1].  Then for all <em>n</em>&ge;2:</p>

<ul>
<li><strong>fabove</strong>(<em>n</em>, <em>k</em>) = <em>f</em>(<em>k</em>/<em>n</em>) + sqrt(1&minus;(2*<em>k</em>/<em>n</em>&minus;1)<sup>2</sup>)*<em>L</em>/<em>n</em>.</li>
<li><strong>fbelow</strong>(<em>n</em>, <em>k</em>) = <em>f</em>(<em>k</em>/<em>n</em>) &minus; sqrt(1&minus;(2*<em>k</em>/<em>n</em>&minus;1)<sup>2</sup>)*<em>L</em>/<em>n</em>.</li>
</ul>

<p>Where <em>L</em> is the Lipschitz constant for <em>f</em>.</p>

<p>This counterexample has <em>f</em> be a degree-12 polynomial in Bernstein form with coefficients [0, 61/625, 1273/10000, 697/5000, 1573/10000, 2411/5000, 271/500, 5903/10000, 374/625, 6013/10000, 6017/10000, 1107/1250, 8983/10000]. This polynomial is nondecreasing and Lipschitz continuous with Lipschitz constant (<em>L</em>) slightly less than 1.37277.  And the counterexample involves the upper polynomials of degree 16 and 32 generated by <strong>fabove</strong>(16, <em>k</em>) and <strong>fabove</strong>(32, <em>k</em>), respectively.</p>

<p><strong>Note on &quot;clamping&quot;.</strong> For any approximation scheme, &quot;clamping&quot; the values of <strong>fbelow</strong> and <strong>fabove</strong> to fit the interval [0, 1] won&#39;t necessarily preserve the consistency requirement, even if the original scheme met that requirement.</p>

<p>Here is a counterexample that applies to any approximation scheme.</p>

<p>Let <em>g</em> and <em>h</em> be two polynomials in Bernstein form as follows:</p>

<ul>
<li><em>g</em> has degree 5 and coefficients [10179/10000, 2653/2500, 9387/10000, 5049/5000, 499/500, 9339/10000].</li>
<li><em>h</em> has degree 6 and coefficients [10083/10000, 593/625, 9633/10000, 4513/5000, 4947/5000, 9473/10000, 4519/5000].</li>
</ul>

<p>After elevating <em>g</em>&#39;s degree, <em>g</em>&#39;s coefficients are no less than <em>h</em>&#39;s, as required by the consistency property.</p>

<p>However, if we clamp coefficients above 1 to equal 1, so that <em>g</em> is now <em>g&prime;</em> with [1, 1, 9387/10000, 1, 499/500, 9339/10000] and <em>h</em> is now <em>h&prime;</em> with [1, 593/625, 9633/10000, 4513/5000, 4947/5000, 9473/10000, 4519/5000], and elevate <em>g&prime;</em> for coefficients [1, 1, 14387/15000, 19387/20000, 1499/1500, 59239/60000, 9339/10000], some of the coefficients of <em>g&prime;</em> are less than those of <em>h&prime;</em>.  Thus, for this pair of polynomials, clamping the coefficients will destroy the consistent approximation property.</p>

<p><a id=Achievable_Simulation_Rates></a></p>

<h2>Achievable Simulation Rates</h2>

<p>In general, the number of input coin flips needed by any Bernoulli factory algorithm for a factory function <em>f</em>(<em>&lambda;</em>) depends on how &quot;smooth&quot; the function <em>f</em> is.</p>

<p>The following table summarizes the rate of simulation (in terms of the number of input coin flips needed) that can be achieved <em>in theory</em> depending on <em>f</em>(<em>&lambda;</em>), assuming the unknown probability of heads, <em>&lambda;</em>, lies in the interval [<em>&epsilon;</em>, 1&minus;<em>&epsilon;</em>] for some <em>&epsilon;</em> &gt; 0.  In the table below, <em>&Delta;</em>(<em>n</em>, <em>r</em>, <em>&lambda;</em>) = <em>O</em>(max(sqrt(<em>&lambda;</em>*(1&minus;<em>&lambda;</em>)/<em>n</em>),1/<em>n</em>)<sup><em>r</em></sup>), that is, <em>O</em>((1/<em>n</em>)<sup>2*<em>r</em></sup>) near <em>&lambda;</em> = 0 or 1, and <em>O</em>((1/<em>n</em>)<sup><em>r</em></sup>) elsewhere.</p>

<table><thead>
<tr>
<th>Property of simulation</th>
<th>Property of <em>f</em></th>
</tr>
</thead><tbody>
<tr>
<td>Requires no more than <em>n</em> input coin flips.</td>
<td>If and only if <em>f</em> is a constant 0 or 1 or can be written as a polynomial in Bernstein form of degree <em>n</em> with coefficients in [0, 1] (Goyal and Sigman 2012)<sup><a href="#Note12"><strong>(12)</strong></a></sup>.</td>
</tr>
<tr>
<td>Requires a finite number of flips on average. Also known as &quot;realizable&quot; by Flajolet et al. (2011)<sup><a href="#Note13"><strong>(13)</strong></a></sup>.</td>
<td>Only if <em>f</em> is Lipschitz continuous (Nacu and Peres 2005)<sup><a href="#Note1"><strong>(1)</strong></a></sup>.</td>
</tr>
<tr>
<td>Number of flips required, raised to power of <em>r</em>, is finite on average and drops off uniformly for all <em>&lambda;</em>.</td>
<td>Only if <em>f</em> is <em>C</em><sup><em>r</em></sup> continuous (has <em>r</em> or more continuous derivatives, or &quot;slope&quot; functions) (Nacu and Peres 2005)<sup><a href="#Note1"><strong>(1)</strong></a></sup>.</td>
</tr>
<tr>
<td>Requires more than <em>n</em> flips with probability <em>&Delta;</em>(<em>n</em>, <em>r</em> + 1, <em>&lambda;</em>), for integer <em>r</em> &ge; 0. (The greater <em>r</em> is, the faster the simulation.)</td>
<td>Only if <em>f</em> is <em>C</em><sup><em>r</em></sup> continuous and the <em>r</em><sup>th</sup> derivative is in the Zygmund class (has no vertical slope) (Holtz et al. 2011)<sup><a href="#Note8"><strong>(8)</strong></a></sup>.</td>
</tr>
<tr>
<td>Requires more than <em>n</em> flips with probability <em>&Delta;</em>(<em>n</em>, <em>&alpha;</em>, <em>&lambda;</em>), for non-integer <em>&alpha;</em> &gt; 0. (The greater <em>&alpha;</em> is, the faster the simulation.)</td>
<td>If and only if <em>f</em> is <em>C</em><sup><em>r</em></sup> continuous and the <em>r</em><sup>th</sup> derivative is (<em>&alpha;</em> &minus; <em>r</em>)-Hölder continuous, where <em>r</em> = floor(<em>&alpha;</em>) (Holtz et al. 2011)<sup><a href="#Note8"><strong>(8)</strong></a></sup>.</td>
</tr>
<tr>
<td>&quot;Fast simulation&quot; (number of flips required drops off exponentially).  Also known as &quot;strongly realizable&quot; by Flajolet et al. (2011)<sup><a href="#Note14"><strong>(14)</strong></a></sup>.</td>
<td>If and only if <em>f</em> is real analytic (is <em>C</em><sup>&infin;</sup> continuous, or has continuous <em>k</em><sup>th</sup> derivative for every <em>k</em>, and agrees with its Taylor series &quot;near&quot; every point) (Nacu and Peres 2005)<sup><a href="#Note1"><strong>(1)</strong></a></sup>.</td>
</tr>
<tr>
<td>Average number of flips bounded from below by (<em>f&prime;</em>(<em>&lambda;</em>))<sup>2</sup>*<em>&lambda;</em>*(1&minus;<em>&lambda;</em>)/(<em>f</em>(<em>&lambda;</em>)*(1&minus;<em>f</em>(<em>&lambda;</em>))), where <em>f&prime;</em> is the first derivative of <em>f</em>.</td>
<td>Whenever <em>f</em> admits a fast simulation (Mendo 2019)<sup><a href="#Note9"><strong>(9)</strong></a></sup>.</td>
</tr>
</tbody></table>

<p><a id=Notes></a></p>

<h2>Notes</h2>

<ul>
<li><small><sup id=Note1>(1)</sup> Nacu, Şerban, and Yuval Peres. &quot;<a href="https://projecteuclid.org/euclid.aoap/1106922322"><strong>Fast simulation of new coins from old</strong></a>&quot;, The Annals of Applied Probability 15, no. 1A (2005): 93-115.</small></li>
<li><small><sup id=Note2>(2)</sup> Specifically, the constant <em>m</em> is an upper bound of abs(<em>f</em>(<em>x</em>)&minus;<em>f</em>(<em>y</em>))/(abs(<em>x</em>&minus;<em>y</em>)<sup><em>&alpha;</em></sup>) for all <em>x</em>, <em>y</em> pairs, where <em>x</em> and <em>y</em> are each in [0, 1] and <em>x</em> != <em>y</em>.  However, this bound can&#39;t directly be calculated as it would involve checking an infinite number of <em>x</em>, <em>y</em> pairs.</small></li>
<li><small><sup id=Note3>(3)</sup> Powell, M.J.D., <em>Approximation Theory and Methods</em>, 1981</small></li>
<li><small><sup id=Note4>(4)</sup> G. G. Lorentz. Bernstein polynomials. 1986.</small></li>
<li><small><sup id=Note5>(5)</sup> Popoviciu, T., &quot;Sur l&#39;approximation des fonctions convexes d&#39;ordre supérieur&quot;, Mathematica (Cluj), 1935.</small></li>
<li><small><sup id=Note6>(6)</sup> Sikkema, P.C., &quot;Der Wert einiger Konstanten in der Theorie der Approximation mit Bernstein-Polynomen&quot;, Numer. Math. 3 (1961).</small></li>
<li><small><sup id=Note7>(7)</sup> Kopotun, K.A., et al., &quot;<a href="https://arxiv.org/abs/1711.07083"><strong>Interpolatory pointwise estimates for monotone polynomial approximation</strong></a>&quot;, arXiv:1711.07083 [math.CA], 2017.</small></li>
<li><small><sup id=Note8>(8)</sup> Holtz, O., Nazarov, F., Peres, Y., &quot;New Coins from Old, Smoothly&quot;, <em>Constructive Approximation</em> 33 (2011).</small></li>
<li><small><sup id=Note9>(9)</sup> Mendo, Luis. &quot;An asymptotically optimal Bernoulli factory for certain functions that can be expressed as power series.&quot; Stochastic Processes and their Applications 129, no. 11 (2019): 4366-4384.</small></li>
<li><small><sup id=Note10>(10)</sup> Levy, H., <em>Stochastic dominance</em>, 1998.</small></li>
<li><small><sup id=Note11>(11)</sup> Henry (<a href="https://math.stackexchange.com/users/6460/henry">https://math.stackexchange.com/users/6460/henry</a>), Proving stochastic dominance for hypergeometric random variables, URL (version: 2021-02-20): <a href="https://math.stackexchange.com/q/4033573"><strong>https://math.stackexchange.com/q/4033573</strong></a> .</small></li>
<li><small><sup id=Note12>(12)</sup> Goyal, V. and Sigman, K., 2012. On simulating a class of Bernstein polynomials. ACM Transactions on Modeling and Computer Simulation (TOMACS), 22(2), pp.1-5.</small></li>
<li><small><sup id=Note13>(13)</sup> Flajolet, P., Pelletier, M., Soria, M., &quot;<a href="https://arxiv.org/abs/0906.5560">On Buffon machines and numbers</a>&quot;, arXiv:0906.5560 [math.PR], 2010.</small></li>
<li><small><sup id=Note14>(14)</sup> Flajolet, P., Pelletier, M., Soria, M., &quot;<a href="https://arxiv.org/abs/0906.5560">On Buffon machines and numbers</a>&quot;, arXiv:0906.5560 [math.PR], 2010.</small></li>
</ul>

<p><a id=Appendix></a></p>

<h2>Appendix</h2>

<p>&nbsp;</p>

<p><a id=Proofs_for_H_lder_Function_Approximation_Scheme></a></p>

<h3>Proofs for Hölder Function Approximation Scheme</h3>

<p>This section shows mathematical proofs for some of the approximation schemes of this page.</p>

<p>There is a straightforward extension to lemma 6(i) of Nacu and Peres (2005)<sup><a href="#Note1"><strong>(1)</strong></a></sup> to certain functions with a slope that tends to a vertical slope.  Specifically, it applies to any <em>Hölder continuous</em> function, which means a continuous function whose slope doesn&#39;t go exponentially fast to a vertical slope.</p>

<p><strong>Lemma 1.</strong> <em>Let f(&lambda;) be a continuous and nondecreasing function, and let X<sub>k</sub> be a hypergeometric(2*n, k, n) random variable, where n&ge;1 is a constant integer and k is an integer in [0, 2*n] .  Then <strong>E</strong>[f(X<sub>k</sub>/n)] is nondecreasing as k increases.</em></p>

<p><em>Proof.</em> This is equivalent to verifying whether <em>X</em><sub><em>m</em>+1</sub>/<em>n</em> &succeq; <em>X</em><sub><em>m</em></sub>/<em>n</em> (and, obviously by extension, <em>X</em><sub><em>m</em>+1</sub> &succeq; <em>X</em><sub><em>m</em></sub>) in terms of first-degree stochastic dominance (Levy 1998)<sup><a href="#Note10"><strong>(10)</strong></a></sup>.   This means that the probability that <em>X</em><sub><em>m</em>+1</sub> &le; <em>j</em>) is less than or equal to that for <em>X</em><sub><em>m</em></sub> for each <em>j</em> in the interval [0, <em>n</em>].  A proof of this was given by the user &quot;Henry&quot; of the <em>Mathematics Stack Exchange</em> community<sup><a href="#Note11"><strong>(11)</strong></a></sup>. &#x25a1;</p>

<p><strong>Lemma 2.</strong> <em>Let f(&lambda;) be a continuous function that maps [0, 1] to [&minus;1, 1], and let X be a hypergeometric(2*n, k, n) random variable.</em></p>

<ol>
<li><p><em>If f is &alpha;-Hölder continuous with Hölder constant M, then&mdash;</em></p>

<p>abs(<strong>E</strong>[<em>f</em>(<em>X</em>/<em>n</em>)] &minus; <em>f</em>(<em>k</em>/(2*<em>n</em>))),&nbsp;&nbsp;&nbsp;(1)</p>

<p><em>is bounded from above by M*(1/(2*n))<sup>&alpha;/2</sup>, for all n&ge;1 that are integer powers of 2.</em></p></li>
<li><em>If f is &alpha;-Hölder continuous with Hölder constant M, then the expression (1) is bounded from above by M*(1/(7*n))<sup>&alpha;/2</sup>, for all n&ge;4 that are integer powers of 2.</em></li>
<li><em>If f is C<sup>2</sup> continuous, and its second derivative&#39;s absolute value is bounded from above by M, then the expression (1) is bounded from above by (M/2)*(1/(7*n)), for all n&ge;4 that are integer powers of 2.</em></li>
<li><em>If f is convex, nondecreasing, and bounded from below by 0, then the expression (1) is bounded from above by E[f(Y/n)] for all n&ge;1 that are integer powers of 2, where Y is a hypergeometric(2*n, n, n) random variable.</em></li>
</ol>

<p><em>Proof.</em></p>

<ol>
<li>abs(<strong>E</strong>[<em>f</em>(<em>X</em>/<em>n</em>)] &minus; <em>f</em>(k/(2*<em>n</em>))) &le; <strong>E</strong>[abs(<em>f</em>(<em>X</em>/<em>n</em>) &minus; <em>f</em>(<em>k</em>/(2*<em>n</em>))] &le; <em>M</em>*<strong>E</strong>[abs(<em>X</em>/<em>n</em> &minus; <em>k</em>/(2*<em>n</em>))]<sup><em>&alpha;</em></sup> (by the definition of Hölder continuous functions) &le; <em>M</em>*(<strong>E</strong>[abs(<em>X</em>/<em>n</em> &minus; <em>k</em>/(2*<em>n</em>))]<sup>2</sup>)<sup><em>&alpha;</em>/2</sup> = <em>M</em>*<strong>Var</strong>[<em>X</em>/<em>n</em>]<sup><em>&alpha;</em>/2</sup> &le; <em>M</em>*(1/(2*<em>n</em>))<sup><em>&alpha;</em>/2</sup>.</li>
<li>For all integers <em>n</em>&ge;4, abs(<strong>E</strong>[<em>f</em>(<em>X</em>/<em>n</em>)] &minus; <em>f</em>(k/(2*<em>n</em>))) &le; <em>M</em>*<strong>Var</strong>[<em>X</em>/<em>n</em>]<sup><em>&alpha;</em>/2</sup> = <em>M</em>*(<em>k</em>*(2*<em>n</em>&minus;<em>k</em>)/(4*(2*<em>n</em>&minus;1)*<em>n</em><sup>2</sup>))<sup><em>&alpha;</em>/2</sup> &le; <em>M</em>*(<em>n</em><sup>2</sup>/(4*(2*<em>n</em>&minus;1)*<em>n</em><sup>2</sup>))<sup><em>&alpha;</em>/2</sup> = <em>M</em>*(1/(8*<em>n</em>&minus;4))<sup><em>&alpha;</em>/2</sup> &le;  <em>M</em>*(1/(7*<em>n</em>))<sup><em>&alpha;</em>/2</sup>.</li>
<li>For all integers <em>n</em>&ge;4, abs(<strong>E</strong>[<em>f</em>(<em>X</em>/<em>n</em>)] &minus; <em>f</em>(k/(2*<em>n</em>))) &le; (<em>M</em>/2)*<strong>Var</strong>[<em>X</em>/<em>n</em>]<sup><em>&alpha;</em>/2</sup> = (<em>M</em>/2)*(<em>k</em>*(2*<em>n</em>&minus;<em>k</em>)/(4*(2*<em>n</em>&minus;1)*<em>n</em><sup>2</sup>)) &le; (<em>M</em>/2)*(<em>n</em><sup>2</sup>/(4*(2*<em>n</em>&minus;1)*<em>n</em><sup>2</sup>)) = (<em>M</em>/2)*(1/(8*<em>n</em>&minus;4)) &le;  (<em>M</em>/2)*(1/(7*<em>n</em>)).</li>
<li>Let <em>X</em><sub><em>k</em></sub> be a hypergeometric(2*<em>n</em>, <em>k</em>, <em>n</em>) random variable.  By Lemma 1 and the assumption that <em>f</em> is nondecreasing, <strong>E</strong>[<em>f</em>(<em>X</em><sub><em>k</em></sub>/<em>n</em>)] is nondecreasing as <em>k</em> increases, so take <strong>E</strong>[<em>f</em>(<em>X</em><sub><em>n</em></sub>/<em>n</em>)] = <strong>E</strong>[<em>f</em>(<em>Y</em></sub>/<em>n</em>)] as the upper bound.  Then, abs(<strong>E</strong>[<em>f</em>(<em>X</em>/<em>n</em>)] &minus; <em>f</em>(<em>k</em>/(2*<em>n</em>))) = abs(<strong>E</strong>[<em>f</em>(<em>X</em>/<em>n</em>)] &minus; <em>f</em>(<strong>E</strong>[<em>X</em>/<em>n</em>])) = <strong>E</strong>[<em>f</em>(<em>X</em>/<em>n</em>)] &minus; <em>f</em>(<strong>E</strong>[<em>X</em>/<em>n</em>]) (by Jensen&#39;s inequality, because <em>f</em> is convex and bounded by 0) = <strong>E</strong>[<em>f</em>(<em>X</em>/<em>n</em>)] &minus; <em>f</em>(<em>k</em>/(2*<em>n</em>)) &le; <strong>E</strong>[<em>f</em>(<em>X</em>/<em>n</em>)] (because <em>f</em> is bounded by 0) &le; <strong>E</strong>[<em>f</em>(<em>Y</em>/<em>n</em>)]. &#x25a1;</li>
</ol>

<blockquote>
<p><strong>Notes:</strong></p>

<ol>
<li><strong>E</strong>[.] means expected or average value, and <strong>Var</strong>[.] means variance.  A hypergeometric(2*<em>n</em>, <em>k</em>, <em>n</em>) random variable is the number of &quot;good&quot; balls out of <em>n</em> balls taken uniformly at random, all at once, from a bag containing 2*<em>n</em> balls, <em>k</em> of which are &quot;good&quot;.</li>
<li><em>f</em> is <em>&alpha;</em>-Hölder continuous if its vertical slopes, if any, are no &quot;steeper&quot; than <em>M</em>*<em>&lambda;</em><sup><em>&alpha;</em></sup>, where <em>&alpha;</em> is in the interval (0, 1] and <em>M</em> is greater than 0.  An <em>&alpha;</em>-Hölder continuous function in [0, 1] is also <em>&beta;</em>-Hölder continuous for any <em>&beta;</em> less than <em>&alpha;</em>.</li>
<li>Parts 2 and 3 exploit a tighter bound on <strong>Var</strong>[<em>X</em>/<em>n</em>] than the bound given in Nacu and Peres (2005)<sup><a href="#Note1"><strong>(1)</strong></a></sup>.  However, for technical reasons, these bounds are proved only for all integers n&ge;4.</li>
</ol>
</blockquote>

<p><strong>Theorem 1.</strong> <em>Let f(&lambda;), &alpha;, and M be as described in part 1 of Lemma 2, except f maps [0, 1] to the interval [&epsilon;, 1&minus;&epsilon;] for &epsilon; in (0, 1/2). By forming two sequences of polynomials in Bernstein form with coefficients <strong>fabove</strong>(n, k) for the upper polynomials, and <strong>fbelow</strong>(n, k) for the lower polynomials, the result is an approximation scheme that meets conditions (i), (iii), and (iv) of Proposition 3 of Nacu and Peres (2005)<sup><a href="#Note1"><strong>(1)</strong></a></sup>, for all n&ge;1 that are integer powers of 2, and thus can be used to simulate f via the algorithms for general factory functions described at the top of this page:</em></p>

<ul>
<li><em><strong>fbelow</strong>(n, k) = f(k/n) &minus; &delta;(n).</em></li>
<li><em><strong>fabove</strong>(n, k) = f(k/n) + &delta;(n).</em></li>
</ul>

<p><em>Where &delta;(n) = M/((2<sup>&alpha;/2</sup>&minus;1)*n<sup>&alpha;/2</sup>).</em></p>

<p><em>Proof.</em> Follows from part 1 of Lemma 2 above as well as Remark B and the proof of Proposition 10 of Nacu and Peres (2005)<sup><a href="#Note1"><strong>(1)</strong></a></sup>.  The term <em>&delta;</em>(<em>n</em>) is found as a solution to the functional equation <em>&delta;</em>(<em>n</em>) = <em>&delta;</em>(2*<em>n</em>) + <em>M</em>*(1/(2*<em>n</em>))<sup><em>&alpha;</em>/2</sup>, and functional equations of this kind were suggested in the proof of Proposition 10, to find the offset by which to shift the approximating polynomials. &#x25a1;</p>

<blockquote>
<p><strong>Note:</strong> For specific values of <em>&alpha;</em>, the functional equation given in the proof can be solved via linear recurrences; an example for <em>&alpha;</em> = 1/2 is the following SymPy code: <code>rsolve(Eq(f(n),f(n+1)+z*(1/(2*2**n))**((S(1)/2)/2)),f(n)).subs(n,log(n,2)).simplify()</code>.  Trying different values of <em>&alpha;</em> suggested the following formula for Hölder continuous functions with <em>&alpha;</em> of 1/<em>j</em> or greater: (<em>M</em>* &sum;<sub><em>i</em> = 0,...,(<em>j</em>*2)&minus;1</sub> 2<sup><em>i</em>/(2*<em>j</em>)</sup>)/<em>n</em><sup>1/(2*<em>j</em>)</sup> = <em>M</em> / ((2<sup>1/(2*<em>j</em>)</sup>&minus;1)*<em>n</em><sup>1/(2*<em>j</em>)</sup>); and generalizing the latter expression led to the term in the theorem.</p>
</blockquote>

<p><strong>Theorem 2.</strong> <em>Let f(&lambda;) and M be as described in part 2 of Lemma 2, except f maps [0, 1] to the interval [&epsilon;, 1&minus;&epsilon;] for &epsilon; in (0, 1/2).  Then the following approximation scheme determined by <strong>fabove</strong> and <strong>fbelow</strong> meets conditions (i), (iii), and (iv) of Proposition 3 of Nacu and Peres (2005)<sup><a href="#Note1"><strong>(1)</strong></a></sup>, for all n&ge;1 that are integer powers of 2:</em></p>

<ul>
<li><em><strong>fbelow</strong>(n, k) = min(<strong>fbelow</strong>(4,0), <strong>fbelow</strong>(4,1), ..., <strong>fbelow</strong>(4,4)) if n &lt; 4; otherwise, f(k/n) &minus; &eta;(n).</em></li>
<li><em><strong>fabove</strong>(n, k) = max(<strong>fabove</strong>(4,0), <strong>fabove</strong>(4,1), ..., <strong>fabove</strong>(4,4)) if n &lt; 4; otherwise, f(k/n) + &eta;(n).</em></li>
</ul>

<p><em>Where &eta;(n) = M*(2/7)<sup>&alpha;/2</sup>/((2<sup>&alpha;/2</sup>&minus;1)*n<sup>&alpha;/2</sup>).</em></p>

<p><em>Proof.</em>  Follows from part 2 of Lemma 2 above as well as Remark B and the proof of Proposition 10 of Nacu and Peres, including the observation in Remark B of the paper that we can start the algorithm from <em>n</em> = 4; in that case, the upper and lower polynomials of degree 1 through 3 above would be constant functions, so that as polynomials in Bernstein form, the coefficients of each one would be equal.  The term <em>&eta;</em>(<em>n</em>) is found as a solution to the functional equation <em>&eta;</em>(<em>n</em>) = <em>&eta;</em>(2*<em>n</em>) + <em>M</em>*(1/(7*<em>n</em>))<sup><em>&alpha;</em>/2</sup>, and functional equations of this kind were suggested in the proof of Proposition 10, to find the offset by which to shift the approximating polynomials.  &#x25a1;</p>

<blockquote>
<p><strong>Note:</strong> The term <em>&eta;</em>(<em>n</em>) was found in a similar way as the term <em>&delta;</em>(<em>n</em>) in Theorem 1.</p>
</blockquote>

<p><strong>Theorem 3.</strong> <em>Let f(&lambda;) and M be as described in part 3 of Lemma 2, except f maps [0, 1] to the interval [&epsilon;, 1&minus;&epsilon;] for &epsilon; in (0, 1/2).  Then the following approximation scheme determined by <strong>fabove</strong> and <strong>fbelow</strong> meets conditions (i), (iii), and (iv) of Proposition 3 of Nacu and Peres (2005)<sup><a href="#Note1"><strong>(1)</strong></a></sup>, for all n&ge;1 that are integer powers of 2:</em></p>

<ul>
<li><em><strong>fbelow</strong>(n, k) = min(<strong>fbelow</strong>(4,0), <strong>fbelow</strong>(4,1), ..., <strong>fbelow</strong>(4,4)) if n &lt; 4; otherwise, f(k/n) &minus; M/(7*n).</em></li>
<li><em><strong>fabove</strong>(n, k) = max(<strong>fabove</strong>(4,0), <strong>fabove</strong>(4,1), ..., <strong>fabove</strong>(4,4)) if n &lt; 4; otherwise, f(k/n) + M/(7*n).</em></li>
</ul>

<p><em>Proof.</em>  Follows from part 3 of Lemma 2 above as well as Remark B and the proof of Proposition 10 of Nacu and Peres, noting that the solution to the functional equation <em>&kappa;</em>(n) = <em>&kappa;</em>(2*<em>n</em>) + (<em>M</em>/2)*(1/(7*<em>n</em>)) is <em>M</em>/(7*<em>n</em>).  Notably, this exploits the observation in Remark B of the paper that we can start the algorithm from <em>n</em> = 4; in that case, the upper and lower polynomials of degree 1 through 3 above would be constant functions, so that as polynomials in Bernstein form, the coefficients of each one would be equal.  &#x25a1;</p>

<p><strong>Proposition 1.</strong></p>

<ol>
<li><em>Let f be as given in Theorem 1, 2, or 3, except f is concave and may have a minimum of 0.  The approximation scheme of that theorem remains valid if <strong>fbelow</strong>(n, k) = f(k/n), rather than as given in that theorem.</em></li>
<li><em>Let f be as given in Theorem 1, 2, or 3, except f is convex and may have a maximum of 1.  The approximation scheme of that theorem remains valid if <strong>fabove</strong>(n, k) = f(k/n), rather than as given in that theorem.</em></li>
<li><p><em>Theorems 1, 2, and 3 can be extended to all integers n&ge;1, not just those that are powers of 2, by defining&mdash;</em></p>

<ul>
<li><em><strong>fbelow</strong>(n, k) = (k/n)*<strong>fbelow</strong>(n&minus;1, max(0, k&minus;1)) + ((n&minus;k)/n)*<strong>fbelow</strong>(n&minus;1, min(n&minus;1, k)), and</em></li>
<li><em><strong>fabove</strong>(n, k) = (k/n)*<strong>fabove</strong>(n&minus;1, max(0, k&minus;1)) + ((n&minus;k)/n)*<strong>fabove</strong>(n&minus;1, min(n&minus;1, k)),</em></li>
</ul>

<p><em>for all n&ge;1 other than powers of 2. Parts 1 and 2 of this proposition still apply to the modified scheme.</em></p></li>
</ol>

<p><em>Proof.</em> Parts 1 and 2 follow from Theorem 1, 2, or 3, as the case may be, and Jensen&#39;s inequality.  Part 3 also follows from Remark B of Nacu and Peres (2005)<sup><a href="#Note1"><strong>(1)</strong></a></sup>. &#x25a1;</p>

<p><a id=License></a></p>

<h2>License</h2>

<p>Any copyright to this page is released to the Public Domain.  In case this is not possible, this page is also licensed under <a href="https://creativecommons.org/publicdomain/zero/1.0/"><strong>Creative Commons Zero</strong></a>.</p>
</div><nav id="navigation"><ul>
<li><a href="/">Back to start site.</a>
<li><a href="https://github.com/peteroupc/peteroupc.github.io">This site's repository (source code)</a>
<li><a href="https://github.com/peteroupc/peteroupc.github.io/issues">Post an issue or comment</a></ul>
<p>
If you like this software, you should consider donating to me, Peter O., at the link below:</p>
<p class="printonly"><b>peteroupc.github.io</b></p>
<div class="noprint">
<a href="https://www.paypal.com/cgi-bin/webscr?cmd=_s-xclick&hosted_button_id=56E5T4FH7KD2S">
<img src="https://www.paypalobjects.com/en_US/i/btn/btn_donateCC_LG.gif"
name="submit" border="2" alt="PayPal - The safer, easier way to pay online!"></a>
<p>
<a href="//twitter.com/share">Share via Twitter</a>, <a href="//www.facebook.com/sharer/sharer.php" id="sharer">Share via Facebook</a>
</p>
</div>
</nav><script>
if("share" in navigator){
 document.getElementById("sharer").href="javascript:void(null)";
 document.getElementById("sharer").innerHTML="Share This Page";
 navigator.share({title:document.title,url:document.location.href}).then(
   function(){});
} else {
 document.getElementById("sharer").href="//www.facebook.com/sharer/sharer.php?u="+
    encodeURIComponent(document.location.href)
}
</script>
</body></html>
